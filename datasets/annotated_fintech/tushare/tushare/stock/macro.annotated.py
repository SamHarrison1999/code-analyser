# -*- coding:utf-8 -*- 

"""
å®è§‚ç»æµæ•°æ®æ¥å£ 
Created on 2015/01/24
@author: Jimmy Liu
@group : waditu
@contact: jimmysoa@sina.cn
"""

import pandas as pd
import numpy as np
import re
import json
from tushare.stock import macro_vars as vs
from tushare.stock import cons as ct
try:
    # âœ… Best Practice: Handle ImportError to ensure compatibility with different Python versions
    # âœ… Best Practice: Function docstring is provided, which improves code readability and understanding.
    from urllib.request import urlopen, Request
# âš ï¸ SAST Risk (Medium): The use of urlopen without proper exception handling can lead to unhandled exceptions.
# âš ï¸ SAST Risk (Low): The use of vs.random() might introduce unpredictability if not properly controlled.
# âš ï¸ SAST Risk (Medium): The use of string formatting in URLs can lead to injection vulnerabilities if inputs are not sanitized.
# âš ï¸ SAST Risk (Low): The use of conditional decoding based on Python version can lead to maintenance challenges.
except ImportError:
    from urllib2 import urlopen, Request


def get_gdp_year():
    """
        è·å–å¹´åº¦å›½å†…ç”Ÿäº§æ€»å€¼æ•°æ®
    Return
    --------
    DataFrame
        year :ç»Ÿè®¡å¹´åº¦
        gdp :å›½å†…ç”Ÿäº§æ€»å€¼(äº¿å…ƒ)
        pc_gdp :äººå‡å›½å†…ç”Ÿäº§æ€»å€¼(å…ƒ)
        gnp :å›½æ°‘ç”Ÿäº§æ€»å€¼(äº¿å…ƒ)
        pi :ç¬¬ä¸€äº§ä¸š(äº¿å…ƒ)
        si :ç¬¬äºŒäº§ä¸š(äº¿å…ƒ)
        industry :å·¥ä¸š(äº¿å…ƒ)
        cons_industry :å»ºç­‘ä¸š(äº¿å…ƒ)
        ti :ç¬¬ä¸‰äº§ä¸š(äº¿å…ƒ)
        trans_industry :äº¤é€šè¿è¾“ä»“å‚¨é‚®ç”µé€šä¿¡ä¸š(äº¿å…ƒ)
        lbdy :æ‰¹å‘é›¶å”®è´¸æ˜“åŠé¤é¥®ä¸š(äº¿å…ƒ)
    # âš ï¸ SAST Risk (Medium): Loading JSON data without validation can lead to security risks if the data is untrusted.
    """
    # ğŸ§  ML Signal: The use of DataFrame creation from JSON data is a common pattern in data processing tasks.
    rdint = vs.random()
    request = Request(vs.MACRO_URL%(vs.P_TYPE['http'], vs.DOMAINS['sina'],
                                    # âš ï¸ SAST Risk (Low): Replacing zero values with NaN without context can lead to data misinterpretation.
                                    rdint, vs.MACRO_TYPE[0], 0, 70,
                                    rdint))
    # ğŸ§  ML Signal: Returning a DataFrame is a common pattern in data analysis functions.
    text = urlopen(request, timeout=10).read()
    text = text.decode('gbk') if ct.PY3 else text
    regSym = re.compile(r'\,count:(.*?)\}')
    datastr = regSym.findall(text)
    datastr = datastr[0]
    datastr = datastr.split('data:')[1]
    # âœ… Best Practice: Function docstring is provided, which improves code readability and understanding.
    datastr = datastr.replace('"', '').replace('null', '0')
    # ğŸ§  ML Signal: The function name and docstring indicate this function retrieves GDP data, which is a specific domain usage pattern.
    # âš ï¸ SAST Risk (Low): Use of random values in URLs can lead to unpredictable behavior or difficulty in debugging.
    # âš ï¸ SAST Risk (Medium): Constructing URLs with string interpolation can lead to injection vulnerabilities if inputs are not properly sanitized.
    js = json.loads(datastr)
    df = pd.DataFrame(js, columns=vs.GDP_YEAR_COLS)
    df[df==0] = np.NaN
    return df

  
def get_gdp_quarter():
    """
        è·å–å­£åº¦å›½å†…ç”Ÿäº§æ€»å€¼æ•°æ®
    Return
    --------
    DataFrame
        quarter :å­£åº¦
        gdp :å›½å†…ç”Ÿäº§æ€»å€¼(äº¿å…ƒ)
        gdp_yoy :å›½å†…ç”Ÿäº§æ€»å€¼åŒæ¯”å¢é•¿(%)
        pi :ç¬¬ä¸€äº§ä¸šå¢åŠ å€¼(äº¿å…ƒ)
        pi_yoy:ç¬¬ä¸€äº§ä¸šå¢åŠ å€¼åŒæ¯”å¢é•¿(%)
        si :ç¬¬äºŒäº§ä¸šå¢åŠ å€¼(äº¿å…ƒ)
        si_yoy :ç¬¬äºŒäº§ä¸šå¢åŠ å€¼åŒæ¯”å¢é•¿(%)
        ti :ç¬¬ä¸‰äº§ä¸šå¢åŠ å€¼(äº¿å…ƒ)
        ti_yoy :ç¬¬ä¸‰äº§ä¸šå¢åŠ å€¼åŒæ¯”å¢é•¿(%)
    # ğŸ§  ML Signal: Use of pandas DataFrame indicates data manipulation, which is a common pattern in data science applications.
    """
    rdint = vs.random()
    # âœ… Best Practice: Explicitly setting data types for DataFrame columns improves data integrity and performance.
    request = Request(vs.MACRO_URL%(vs.P_TYPE['http'], vs.DOMAINS['sina'],
                                    rdint, vs.MACRO_TYPE[0], 1, 250,
                                    # âœ… Best Practice: Replacing zero values with NaN can be useful for data analysis, as it distinguishes between missing and zero values.
                                    rdint))
    text = urlopen(request,timeout=10).read()
    text = text.decode('gbk') if ct.PY3 else text
    regSym = re.compile(r'\,count:(.*?)\}')
    datastr = regSym.findall(text)
    datastr = datastr[0]
    datastr = datastr.split('data:')[1]
    datastr = datastr.replace('"', '').replace('null', '0')
    js = json.loads(datastr)
    df = pd.DataFrame(js, columns=vs.GDP_QUARTER_COLS)
    df['quarter'] = df['quarter'].astype(object)
    df[df==0] = np.NaN
    return df


def get_gdp_for():
    """
        è·å–ä¸‰å¤§éœ€æ±‚å¯¹GDPè´¡çŒ®æ•°æ®
    Return
    --------
    DataFrame
        year :ç»Ÿè®¡å¹´åº¦
        end_for :æœ€ç»ˆæ¶ˆè´¹æ”¯å‡ºè´¡çŒ®ç‡(%)
        for_rate :æœ€ç»ˆæ¶ˆè´¹æ”¯å‡ºæ‹‰åŠ¨(ç™¾åˆ†ç‚¹)
        asset_for :èµ„æœ¬å½¢æˆæ€»é¢è´¡çŒ®ç‡(%)
        asset_rate:èµ„æœ¬å½¢æˆæ€»é¢æ‹‰åŠ¨(ç™¾åˆ†ç‚¹)
        goods_for :è´§ç‰©å’ŒæœåŠ¡å‡€å‡ºå£è´¡çŒ®ç‡(%)
        goods_rate :è´§ç‰©å’ŒæœåŠ¡å‡€å‡ºå£æ‹‰åŠ¨(ç™¾åˆ†ç‚¹)
    # âœ… Best Practice: Use raw strings for regex patterns
    """
    rdint = vs.random()
    # âš ï¸ SAST Risk (Low): No check if regSym.findall(text) returns an empty list
    request = Request(vs.MACRO_URL%(vs.P_TYPE['http'], vs.DOMAINS['sina'],
                                    rdint, vs.MACRO_TYPE[0], 4, 80, rdint))
    text = urlopen(request,timeout=10).read()
    # âš ï¸ SAST Risk (Low): No check if 'data:' is in datastr
    text = text.decode('gbk') if ct.PY3 else text
    # âœ… Best Practice: Function docstring is provided, which improves code readability and understanding.
    regSym = re.compile(r'\,count:(.*?)\}')
    # âœ… Best Practice: Chain replace calls for better readability
    # âš ï¸ SAST Risk (Low): No exception handling for JSON parsing
    # ğŸ§  ML Signal: Usage of pandas DataFrame for data manipulation
    # ğŸ§  ML Signal: Handling missing data by replacing zeros with NaN
    datastr = regSym.findall(text)
    datastr = datastr[0]
    datastr = datastr.split('data:')[1]
    datastr = datastr.replace('"','').replace('null','0')
    js = json.loads(datastr)
    df = pd.DataFrame(js,columns=vs.GDP_FOR_COLS)
    df[df==0] = np.NaN
    return df


def get_gdp_pull():
    """
        è·å–ä¸‰å¤§äº§ä¸šå¯¹GDPæ‹‰åŠ¨æ•°æ®
    Return
    --------
    DataFrame
        year :ç»Ÿè®¡å¹´åº¦
        gdp_yoy :å›½å†…ç”Ÿäº§æ€»å€¼åŒæ¯”å¢é•¿(%)
        pi :ç¬¬ä¸€äº§ä¸šæ‹‰åŠ¨ç‡(%)
        si :ç¬¬äºŒäº§ä¸šæ‹‰åŠ¨ç‡(%)
        industry:å…¶ä¸­å·¥ä¸šæ‹‰åŠ¨(%)
        ti :ç¬¬ä¸‰äº§ä¸šæ‹‰åŠ¨ç‡(%)
    # ğŸ§  ML Signal: Use of regular expressions to extract data patterns from text.
    """
    rdint = vs.random()
    request = Request(vs.MACRO_URL%(vs.P_TYPE['http'], vs.DOMAINS['sina'],
                                    # âš ï¸ SAST Risk (Low): Assumes that `datastr` always contains 'data:', which may lead to IndexError.
                                    rdint, vs.MACRO_TYPE[0], 5, 60, rdint))
    # âœ… Best Practice: Function docstring should be at the beginning of the function for clarity.
    text = urlopen(request,timeout=10).read()
    # ğŸ§  ML Signal: Data cleaning and transformation steps, such as replacing 'null' with '0'.
    # âš ï¸ SAST Risk (Low): No validation of JSON structure before loading, which may lead to runtime errors.
    # ğŸ§  ML Signal: Conversion of JSON data to a DataFrame, a common pattern in data processing.
    # ğŸ§  ML Signal: Handling of missing data by replacing zeros with NaN.
    text = text.decode('gbk') if ct.PY3 else text
    regSym = re.compile(r'\,count:(.*?)\}')
    datastr = regSym.findall(text)
    datastr = datastr[0]
    datastr = datastr.split('data:')[1]
    datastr = datastr.replace('"', '').replace('null', '0')
    js = json.loads(datastr)
    df = pd.DataFrame(js, columns=vs.GDP_PULL_COLS)
    df[df==0] = np.NaN
    return df


def get_gdp_contrib():
    """
        è·å–ä¸‰å¤§äº§ä¸šè´¡çŒ®ç‡æ•°æ®
    Return
    --------
    DataFrame
        year :ç»Ÿè®¡å¹´åº¦
        gdp_yoy :å›½å†…ç”Ÿäº§æ€»å€¼
        pi :ç¬¬ä¸€äº§ä¸šçŒ®ç‡(%)
        si :ç¬¬äºŒäº§ä¸šçŒ®ç‡(%)
        industry:å…¶ä¸­å·¥ä¸šçŒ®ç‡(%)
        ti :ç¬¬ä¸‰äº§ä¸šçŒ®ç‡(%)
    """
    # âš ï¸ SAST Risk (Low): Assumes datastr[0] exists, which can lead to IndexError if datastr is empty.
    rdint = vs.random()
    request = Request(vs.MACRO_URL%(vs.P_TYPE['http'], vs.DOMAINS['sina'], rdint,
                                    # âš ï¸ SAST Risk (Medium): json.loads can raise exceptions if datastr is not a valid JSON.
                                    # âœ… Best Practice: String manipulation to clean and prepare data.
                                    vs.MACRO_TYPE[0], 6, 60, rdint))
    text = urlopen(request, timeout=10).read()
    text = text.decode('gbk') if ct.PY3 else text
    regSym = re.compile(r'\,count:(.*?)\}')
    datastr = regSym.findall(text)
    datastr = datastr[0]
    datastr = datastr.split('data:')[1]
    datastr = datastr.replace('"', '').replace('null', '0')
    # âœ… Best Practice: Use of pandas DataFrame for structured data handling.
    # âœ… Best Practice: Replacing 0 with NaN for better data analysis.
    js = json.loads(datastr)
    # ğŸ§  ML Signal: Usage of dynamic URL construction with random elements
    df = pd.DataFrame(js, columns=vs.GDP_CONTRIB_COLS)
    df[df==0] = np.NaN
    return df

# âš ï¸ SAST Risk (Medium): Potential risk of URL injection if inputs are not properly sanitized
def get_cpi():
    """
        è·å–å±…æ°‘æ¶ˆè´¹ä»·æ ¼æŒ‡æ•°æ•°æ®
    Return
    --------
    DataFrame
        month :ç»Ÿè®¡æœˆä»½
        cpi :ä»·æ ¼æŒ‡æ•°
    """
    # âš ï¸ SAST Risk (Low): Assumes 'data:' is always present, potential ValueError
    rdint = vs.random()
    # âš ï¸ SAST Risk (Low): json.loads can raise exceptions if datastr is not valid JSON
    # âœ… Best Practice: Explicitly specify column names for DataFrame creation
    # âœ… Best Practice: Ensure data type conversion is safe and handle exceptions
    request = Request(vs.MACRO_URL%(vs.P_TYPE['http'], vs.DOMAINS['sina'],
                                    rdint, vs.MACRO_TYPE[1], 0, 600,
                                    rdint))
    text = urlopen(request,timeout=10).read()
    text = text.decode('gbk') if ct.PY3 else text
    regSym = re.compile(r'\,count:(.*?)\}')
    datastr = regSym.findall(text)
    datastr = datastr[0]
    datastr = datastr.split('data:')[1]
    js = json.loads(datastr)
    df = pd.DataFrame(js, columns=vs.CPI_COLS)
    df['cpi'] = df['cpi'].astype(float)
    return df


def get_ppi():
    """
        è·å–å·¥ä¸šå“å‡ºå‚ä»·æ ¼æŒ‡æ•°æ•°æ®
    Return
    --------
    DataFrame
        month :ç»Ÿè®¡æœˆä»½
        ppiip :å·¥ä¸šå“å‡ºå‚ä»·æ ¼æŒ‡æ•°
        ppi :ç”Ÿäº§èµ„æ–™ä»·æ ¼æŒ‡æ•°
        qm:é‡‡æ˜å·¥ä¸šä»·æ ¼æŒ‡æ•°
        rmi:åŸææ–™å·¥ä¸šä»·æ ¼æŒ‡æ•°
        pi:åŠ å·¥å·¥ä¸šä»·æ ¼æŒ‡æ•°    
        cg:ç”Ÿæ´»èµ„æ–™ä»·æ ¼æŒ‡æ•°
        food:é£Ÿå“ç±»ä»·æ ¼æŒ‡æ•°
        clothing:è¡£ç€ç±»ä»·æ ¼æŒ‡æ•°
        roeu:ä¸€èˆ¬æ—¥ç”¨å“ä»·æ ¼æŒ‡æ•°
        dcg:è€ç”¨æ¶ˆè´¹å“ä»·æ ¼æŒ‡æ•°
    # âš ï¸ SAST Risk (Low): Assumes 'data:' is always present in datastr
    """
    rdint = vs.random()
    # âš ï¸ SAST Risk (Medium): Use of json.loads without exception handling
    # âš ï¸ SAST Risk (Medium): Use of vs.random() without a secure random generator can lead to predictable values.
    request = Request(vs.MACRO_URL%(vs.P_TYPE['http'], vs.DOMAINS['sina'],
                                    # âœ… Best Practice: Use of pandas DataFrame for structured data
                                    # âœ… Best Practice: Use of numpy for handling missing values
                                    # âš ï¸ SAST Risk (Medium): Potentially unsafe string formatting in URL construction, consider using a more secure method.
                                    rdint, vs.MACRO_TYPE[1], 3, 600,
                                    rdint))
    text = urlopen(request, timeout=10).read()
    text = text.decode('gbk') if ct.PY3 else text
    regSym = re.compile(r'\,count:(.*?)\}')
    datastr = regSym.findall(text)
    datastr = datastr[0]
    datastr = datastr.split('data:')[1]
    js = json.loads(datastr)
    # âš ï¸ SAST Risk (Medium): No exception handling for network operations, which can lead to unhandled exceptions.
    # âš ï¸ SAST Risk (Low): Decoding with a specific encoding without handling potential errors can lead to issues.
    # âš ï¸ SAST Risk (Low): Assumes all non-'month' columns can be safely converted to float
    # âš ï¸ SAST Risk (Low): Regular expressions can be vulnerable to ReDoS (Regular Expression Denial of Service) attacks.
    df = pd.DataFrame(js, columns=vs.PPI_COLS)
    for i in df.columns:
        df[i] = df[i].apply(lambda x:np.where(x is None, np.NaN, x))
        if i != 'month':
            # âš ï¸ SAST Risk (Low): Accessing list elements without checking length can lead to IndexError.
            df[i] = df[i].astype(float)
    # âš ï¸ SAST Risk (Low): Splitting strings without checking format can lead to unexpected results.
    return df

# âš ï¸ SAST Risk (Medium): Loading JSON data without validation can lead to security issues.

def get_deposit_rate():
    """
        è·å–å­˜æ¬¾åˆ©ç‡æ•°æ®
    Return
    --------
    DataFrame
        date :å˜åŠ¨æ—¥æœŸ
        deposit_type :å­˜æ¬¾ç§ç±»
        rate:åˆ©ç‡ï¼ˆ%ï¼‰
    """
    rdint = vs.random()
    request = Request(vs.MACRO_URL%(vs.P_TYPE['http'], vs.DOMAINS['sina'],
                                    rdint, vs.MACRO_TYPE[2], 2, 600,
                                    rdint))
    text = urlopen(request, timeout=10).read()
    text = text.decode('gbk')
    regSym = re.compile(r'\,count:(.*?)\}')
    datastr = regSym.findall(text)
    # ğŸ§  ML Signal: Usage of external API with dynamic URL construction
    # âš ï¸ SAST Risk (Medium): Potential risk of URL manipulation or injection
    datastr = datastr[0]
    datastr = datastr.split('data:')[1]
    js = json.loads(datastr)
    df = pd.DataFrame(js, columns=vs.DEPOSIT_COLS)
    for i in df.columns:
        # âš ï¸ SAST Risk (Medium): Network operation with potential for timeout or connection issues
        df[i] = df[i].apply(lambda x:np.where(x is None, '--', x))
    return df
# âš ï¸ SAST Risk (Low): Assumes 'gbk' encoding, which may not always be correct


# âš ï¸ SAST Risk (Low): Regular expression usage without validation
def get_loan_rate():
    """
        è·å–è´·æ¬¾åˆ©ç‡æ•°æ®
    Return
    --------
    DataFrame
        date :æ‰§è¡Œæ—¥æœŸ
        loan_type :å­˜æ¬¾ç§ç±»
        rate:åˆ©ç‡ï¼ˆ%ï¼‰
    """
    rdint = vs.random()
    request = Request(vs.MACRO_URL%(vs.P_TYPE['http'], vs.DOMAINS['sina'],
                                    rdint, vs.MACRO_TYPE[2], 3, 800,
                                    rdint))
    text = urlopen(request, timeout=10).read()
    text = text.decode('gbk')
    # âœ… Best Practice: Use of np.where for conditional replacement
    regSym = re.compile(r'\,count:(.*?)\}')
    # ğŸ§  ML Signal: Use of random function to generate a random integer
    datastr = regSym.findall(text)
    datastr = datastr[0]
    datastr = datastr.split('data:')[1]
    # âš ï¸ SAST Risk (Medium): Potential for URL injection if vs.MACRO_URL or its components are user-controlled
    js = json.loads(datastr)
    df = pd.DataFrame(js, columns=vs.LOAN_COLS)
    for i in df.columns:
        # âš ï¸ SAST Risk (Medium): Network operation without exception handling
        df[i] = df[i].apply(lambda x:np.where(x is None, '--', x))
    return df
# âš ï¸ SAST Risk (Low): Assumes the response is always encoded in 'gbk'


# âœ… Best Practice: Use of regular expressions to extract specific patterns from text
def get_rrr():
    """
        è·å–å­˜æ¬¾å‡†å¤‡é‡‘ç‡æ•°æ®
    Return
    --------
    DataFrame
        date :å˜åŠ¨æ—¥æœŸ
        before :è°ƒæ•´å‰å­˜æ¬¾å‡†å¤‡é‡‘ç‡(%)
        now:è°ƒæ•´åå­˜æ¬¾å‡†å¤‡é‡‘ç‡(%)
        changed:è°ƒæ•´å¹…åº¦(%)
    """
    rdint = vs.random()
    request = Request(vs.MACRO_URL%(vs.P_TYPE['http'], vs.DOMAINS['sina'],
                                    rdint, vs.MACRO_TYPE[2], 4, 100,
                                    rdint))
    text = urlopen(request, timeout=10).read()
    text = text.decode('gbk')
    regSym = re.compile(r'\,count:(.*?)\}')
    datastr = regSym.findall(text)
    datastr = datastr[0]
    datastr = datastr.split('data:')[1]
    js = json.loads(datastr)
    df = pd.DataFrame(js, columns=vs.RRR_COLS)
    for i in df.columns:
        df[i] = df[i].apply(lambda x:np.where(x is None, '--', x))
    return df


def get_money_supply():
    """
        è·å–è´§å¸ä¾›åº”é‡æ•°æ®
    Return
    --------
    DataFrame
        month :ç»Ÿè®¡æ—¶é—´
        m2 :è´§å¸å’Œå‡†è´§å¸ï¼ˆå¹¿ä¹‰è´§å¸M2ï¼‰(äº¿å…ƒ)
        m2_yoy:è´§å¸å’Œå‡†è´§å¸ï¼ˆå¹¿ä¹‰è´§å¸M2ï¼‰åŒæ¯”å¢é•¿(%)
        m1:è´§å¸(ç‹­ä¹‰è´§å¸M1)(äº¿å…ƒ)
        m1_yoy:è´§å¸(ç‹­ä¹‰è´§å¸M1)åŒæ¯”å¢é•¿(%)
        m0:æµé€šä¸­ç°é‡‘(M0)(äº¿å…ƒ)
        m0_yoy:æµé€šä¸­ç°é‡‘(M0)åŒæ¯”å¢é•¿(%)
        cd:æ´»æœŸå­˜æ¬¾(äº¿å…ƒ)
        cd_yoy:æ´»æœŸå­˜æ¬¾åŒæ¯”å¢é•¿(%)
        qm:å‡†è´§å¸(äº¿å…ƒ)
        qm_yoy:å‡†è´§å¸åŒæ¯”å¢é•¿(%)
        ftd:å®šæœŸå­˜æ¬¾(äº¿å…ƒ)
        ftd_yoy:å®šæœŸå­˜æ¬¾åŒæ¯”å¢é•¿(%)
        sd:å‚¨è“„å­˜æ¬¾(äº¿å…ƒ)
        sd_yoy:å‚¨è“„å­˜æ¬¾åŒæ¯”å¢é•¿(%)
        rests:å…¶ä»–å­˜æ¬¾(äº¿å…ƒ)
        rests_yoy:å…¶ä»–å­˜æ¬¾åŒæ¯”å¢é•¿(%)
    """
    rdint = vs.random()
    request = Request(vs.MACRO_URL%(vs.P_TYPE['http'], vs.DOMAINS['sina'],
                                    rdint, vs.MACRO_TYPE[2], 1, 600,
                                    rdint))
    text = urlopen(request, timeout=10).read()
    text = text.decode('gbk')
    regSym = re.compile(r'\,count:(.*?)\}')
    datastr = regSym.findall(text)
    # ğŸ§  ML Signal: Use of external URL for data fetching
    # âš ï¸ SAST Risk (Medium): Potential for URL injection if vs.MACRO_URL or its components are user-controlled
    datastr = datastr[0]
    datastr = datastr.split('data:')[1]
    js = json.loads(datastr)
    df = pd.DataFrame(js, columns=vs.MONEY_SUPPLY_COLS)
    for i in df.columns:
        # âš ï¸ SAST Risk (Medium): Network operation without exception handling
        df[i] = df[i].apply(lambda x:np.where(x is None, '--', x))
    return df
# âš ï¸ SAST Risk (Low): Hardcoded character encoding


# âš ï¸ SAST Risk (Low): Regular expression without input validation
def get_money_supply_bal():
    """
        è·å–è´§å¸ä¾›åº”é‡(å¹´åº•ä½™é¢)æ•°æ®
    Return
    --------
    DataFrame
        year :ç»Ÿè®¡å¹´åº¦
        m2 :è´§å¸å’Œå‡†è´§å¸(äº¿å…ƒ)
        m1:è´§å¸(äº¿å…ƒ)
        m0:æµé€šä¸­ç°é‡‘(äº¿å…ƒ)
        cd:æ´»æœŸå­˜æ¬¾(äº¿å…ƒ)
        qm:å‡†è´§å¸(äº¿å…ƒ)
        ftd:å®šæœŸå­˜æ¬¾(äº¿å…ƒ)
        sd:å‚¨è“„å­˜æ¬¾(äº¿å…ƒ)
        rests:å…¶ä»–å­˜æ¬¾(äº¿å…ƒ)
    # âœ… Best Practice: Use of numpy for handling None values
    # ğŸ§  ML Signal: Use of random function to generate a random integer
    """
    # âš ï¸ SAST Risk (Low): Potential exposure to URL manipulation if vs.MACRO_URL or other components are user-controlled
    rdint = vs.random()
    request = Request(vs.MACRO_URL%(vs.P_TYPE['http'], vs.DOMAINS['sina'],
                                    rdint, vs.MACRO_TYPE[2], 0, 200,
                                    rdint))
    text = urlopen(request,timeout=10).read()
    # âš ï¸ SAST Risk (Medium): No exception handling for network operations
    text = text.decode('gbk')
    regSym = re.compile(r'\,count:(.*?)\}')
    # âš ï¸ SAST Risk (Low): Assumes the response is always encoded in 'gbk'
    datastr = regSym.findall(text)
    datastr = datastr[0]
    # âœ… Best Practice: Use of regular expressions to extract specific patterns from text
    datastr = datastr.split('data:')[1]
    js = json.loads(datastr)
    # âš ï¸ SAST Risk (Low): Assumes the regex will always find a match
    df = pd.DataFrame(js, columns=vs.MONEY_SUPPLY_BLA_COLS)
    for i in df.columns:
        # âš ï¸ SAST Risk (Low): Assumes 'data:' is always present in datastr
        # âœ… Best Practice: Use of pandas DataFrame for structured data handling
        # âœ… Best Practice: Use of numpy for efficient data operations
        # âš ï¸ SAST Risk (Low): Assumes datastr is not empty
        # âš ï¸ SAST Risk (Medium): No exception handling for JSON parsing
        # âœ… Best Practice: Iterating over DataFrame columns for data transformation
        df[i] = df[i].apply(lambda x:np.where(x is None, '--', x))
    return df


def get_gold_and_foreign_reserves():
    """
    è·å–å¤–æ±‡å‚¨å¤‡
    Returns
    -------
    DataFrame
        month :ç»Ÿè®¡æ—¶é—´
        gold:é»„é‡‘å‚¨å¤‡(ä¸‡ç›å¸)
        foreign_reserves:å¤–æ±‡å‚¨å¤‡(äº¿ç¾å…ƒ)
    """
    rdint = vs.random()
    request = Request(vs.MACRO_URL % (vs.P_TYPE['http'], vs.DOMAINS['sina'],
                                      rdint, vs.MACRO_TYPE[2], 5, 200,
                                      rdint))
    text = urlopen(request,timeout=10).read()
    text = text.decode('gbk')
    regSym = re.compile(r'\,count:(.*?)\}')
    datastr = regSym.findall(text)
    datastr = datastr[0]
    datastr = datastr.split('data:')[1]
    js = json.loads(datastr)
    df = pd.DataFrame(js, columns=vs.GOLD_AND_FOREIGN_CURRENCY_RESERVES)
    for i in df.columns:
        df[i] = df[i].apply(lambda x: np.where(x is None, '--', x))
    return df