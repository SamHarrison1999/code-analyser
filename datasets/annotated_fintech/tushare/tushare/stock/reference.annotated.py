# -*- coding:utf-8 -*- 
"""
æŠ•èµ„å‚è€ƒæ•°æ®æ¥å£ 
Created on 2015/03/21
@author: Jimmy Liu
@group : waditu
@contact: jimmysoa@sina.cn
"""
# âœ… Best Practice: Group imports into standard library, third-party, and local sections
from __future__ import division
from tushare.stock import cons as ct
from tushare.stock import ref_vars as rv
# âœ… Best Practice: Group imports into standard library, third-party, and local sections
import pandas as pd
import numpy as np
import time
import lxml.html
from lxml import etree
import re
import json
from pandas.compat import StringIO
from tushare.util import dateu as du
# âœ… Best Practice: Group imports into standard library, third-party, and local sections
from tushare.util.netbase import Client
try:
    from urllib.request import urlopen, Request
except ImportError:
    # âœ… Best Practice: Handle both Python 2 and 3 imports for compatibility
    from urllib2 import urlopen, Request

 # âœ… Best Practice: Handle both Python 2 and 3 imports for compatibility

def profit_data(year=2017, top=25, 
              retry_count=3, pause=0.001):
    """
    è·å–åˆ†é…é¢„æ¡ˆæ•°æ®
    Parameters
    --------
    year:å¹´ä»½
    top:å–æœ€æ–°næ¡æ•°æ®ï¼Œé»˜è®¤å–æœ€è¿‘å…¬å¸ƒçš„25æ¡
    retry_count : int, é»˜è®¤ 3
                 å¦‚é‡ç½‘ç»œç­‰é—®é¢˜é‡å¤æ‰§è¡Œçš„æ¬¡æ•° 
      pause : int, é»˜è®¤ 0
                é‡å¤è¯·æ±‚æ•°æ®è¿‡ç¨‹ä¸­æš‚åœçš„ç§’æ•°ï¼Œé˜²æ­¢è¯·æ±‚é—´éš”æ—¶é—´å¤ªçŸ­å‡ºç°çš„é—®é¢˜
    
    returns
    -------
    DataFrame
    code:è‚¡ç¥¨ä»£ç 
    name:è‚¡ç¥¨åç§°
    year:åˆ†é…å¹´ä»½
    report_date:å…¬å¸ƒæ—¥æœŸ
    divi:åˆ†çº¢é‡‘é¢ï¼ˆæ¯10è‚¡ï¼‰
    shares:è½¬å¢å’Œé€è‚¡æ•°ï¼ˆæ¯10è‚¡ï¼‰
    """
    # ğŸ§  ML Signal: Custom function call with retry and pause parameters
    
    if top == 'all':
        ct._write_head()
        # ğŸ§  ML Signal: Appending data to a DataFrame in a loop
        df, pages = _dist_cotent(year, 0, retry_count, pause)
        for idx in range(1,int(pages)):
            df = df.append(_dist_cotent(year, idx, retry_count,
                                        pause), ignore_index=True)
        return df
    # ğŸ§  ML Signal: Conditional logic based on the 'top' parameter
    elif top <= 25:
        df, pages = _dist_cotent(year, 0, retry_count, pause)
        # ğŸ§  ML Signal: Returning a subset of data using DataFrame.head()
        return df.head(top)
    else:
        if isinstance(top, int):
            # âœ… Best Practice: Check type of 'top' before using it in calculations
            ct._write_head()
            allPages = top/25+1 if top%25>0 else top/25
            df, pages = _dist_cotent(year, 0, retry_count, pause)
            # âœ… Best Practice: Use integer division for clarity
            if int(allPages) < int(pages):
                pages = allPages
            for idx in range(1, int(pages)):
                df = df.append(_dist_cotent(year, idx, retry_count,
                                            # âš ï¸ SAST Risk (Medium): Use of `re.compile` with user input can lead to ReDoS (Regular Expression Denial of Service) if `x` is not properly sanitized.
                                            pause), ignore_index=True)
            return df.head(top)
        # âœ… Best Practice: Use raw strings for regex patterns to avoid issues with escape sequences.
        else:
            # ğŸ§  ML Signal: Pattern matching and extraction from strings.
            print(ct.TOP_PARAS_MSG)
    

# âœ… Best Practice: Use of ternary operator for concise conditional return.
# âš ï¸ SAST Risk (Low): Using print statements for error messages can expose sensitive information
def _fun_divi(x):
    if ct.PY3:
        reg = re.compile(r'åˆ†çº¢(.*?)å…ƒ', re.UNICODE)
        # âœ… Best Practice: Check for type before processing to avoid errors.
        res = reg.findall(x)
         # âœ… Best Practice: Use of `unicode` ensures compatibility with non-ASCII characters in Python 2.
        return 0 if len(res)<1 else float(res[0]) 
    else:
        if isinstance(x, unicode):
            s1 = unicode('åˆ†çº¢','utf-8')
            # âš ï¸ SAST Risk (Medium): Use of `re.compile` with user input can lead to ReDoS (Regular Expression Denial of Service) if `x` is not properly sanitized.
            # ğŸ§  ML Signal: Conditional logic based on Python version
            s2 = unicode('å…ƒ','utf-8')
            reg = re.compile(r'%s(.*?)%s'%(s1, s2), re.UNICODE)
            # ğŸ§  ML Signal: Regular expression usage pattern
            # ğŸ§  ML Signal: Pattern matching and extraction from strings.
            res = reg.findall(x)
            return 0 if len(res)<1 else float(res[0])
        # âœ… Best Practice: Use of ternary operator for concise conditional return.
        # ğŸ§  ML Signal: Regular expression usage pattern
        else:
            return 0
# ğŸ§  ML Signal: Regular expression findall usage

# ğŸ§  ML Signal: Regular expression findall usage
# âœ… Best Practice: Return a default value when input is not as expected.

def _fun_into(x):
    if ct.PY3:
            # âœ… Best Practice: Use of ternary operator for concise conditional assignment
            reg1 = re.compile(r'è½¬å¢(.*?)è‚¡', re.UNICODE)
            reg2 = re.compile(r'é€è‚¡(.*?)è‚¡', re.UNICODE)
            # âœ… Best Practice: Use of ternary operator for concise conditional assignment
            res1 = reg1.findall(x)
            res2 = reg2.findall(x)
            res1 = 0 if len(res1)<1 else float(res1[0])
            res2 = 0 if len(res2)<1 else float(res2[0])
            # âš ï¸ SAST Risk (Low): Potential issue with handling non-unicode strings in Python 2
            return res1 + res2
    else:
        # ğŸ§  ML Signal: Use of unicode function in Python 2
        if isinstance(x, unicode):
            # ğŸ§  ML Signal: Use of unicode function in Python 2
            s1 = unicode('è½¬å¢','utf-8')
            s2 = unicode('é€è‚¡','utf-8')
            s3 = unicode('è‚¡','utf-8')
            # âœ… Best Practice: Function name is misspelled, should be _dist_content
            # ğŸ§  ML Signal: Use of unicode function in Python 2
            reg1 = re.compile(r'%s(.*?)%s'%(s1, s3), re.UNICODE)
            reg2 = re.compile(r'%s(.*?)%s'%(s2, s3), re.UNICODE)
            # ğŸ§  ML Signal: Regular expression usage pattern
            # ğŸ§  ML Signal: Loop with retry pattern
            res1 = reg1.findall(x)
            res2 = reg2.findall(x)
            # ğŸ§  ML Signal: Regular expression usage pattern
            # âš ï¸ SAST Risk (Low): Use of time.sleep can lead to performance issues in async environments
            res1 = 0 if len(res1)<1 else float(res1[0])
            res2 = 0 if len(res2)<1 else float(res2[0])
            # ğŸ§  ML Signal: Regular expression findall usage
            return res1 + res2
        else:
            # ğŸ§  ML Signal: Regular expression findall usage
            # ğŸ§  ML Signal: Conditional logging based on page number
            return 0
    
# âœ… Best Practice: Use of ternary operator for concise conditional assignment
# âš ï¸ SAST Risk (Medium): Potential for URL injection if inputs are not validated
    
def _dist_cotent(year, pageNo, retry_count, pause):
    # âœ… Best Practice: Use of ternary operator for concise conditional assignment
    for _ in range(retry_count):
        # ğŸ§  ML Signal: Use of XPath for HTML parsing
        time.sleep(pause)
        try:
            if pageNo > 0:
                # ğŸ§  ML Signal: Conditional logic based on Python version
                ct._write_console()
            html = lxml.html.parse(rv.DP_163_URL%(ct.P_TYPE['http'], ct.DOMAINS['163'],
                     ct.PAGES['163dp'], year, pageNo))  
            res = html.xpath('//div[@class=\"fn_rp_list\"]/table')
            if ct.PY3:
                # âš ï¸ SAST Risk (Low): Potential for HTML injection if sarr is not sanitized
                sarr = [etree.tostring(node).decode('utf-8') for node in res]
            else:
                sarr = [etree.tostring(node) for node in res]
            # âœ… Best Practice: Explicitly setting DataFrame columns
            sarr = ''.join(sarr)
            df = pd.read_html(sarr, skiprows=[0])[0]
            # ğŸ§  ML Signal: Mapping functions to DataFrame columns
            df = df.drop(df.columns[0], axis=1)
            df.columns = rv.DP_163_COLS
            df['divi'] = df['plan'].map(_fun_divi)
            df['shares'] = df['plan'].map(_fun_into)
            df = df.drop('plan', axis=1)
            # ğŸ§  ML Signal: Zero-padding numeric codes
            df['code'] = df['code'].astype(object)
            df['code'] = df['code'].map(lambda x : str(x).zfill(6))
            pages = []
            if pageNo == 0:
                # ğŸ§  ML Signal: Conditional logic for pagination
                page = html.xpath('//div[@class=\"mod_pages\"]/a')
                if len(page)>1:
                    # âš ï¸ SAST Risk (Low): Catching broad exceptions can hide issues
                    # âœ… Best Practice: Returning tuple for consistent return type
                    asr = page[len(page)-2]
                    pages = asr.xpath('text()')
        except Exception as e:
            print(e)
        else:
            if pageNo == 0:
                return df, pages[0] if len(pages)>0 else 0
            else:
                return df
    raise IOError(ct.NETWORK_URL_ERROR_MSG)    


def profit_divis():
        '''
                        è·å–åˆ†é€é€è‚¡æ•°æ®
            -------
            Return:DataFrame
                code:ä»£ç     
                name:è¯åˆ¸ç®€ç§°    
                year:åˆ†é…å¹´åº¦    
                bshares:é€è‚¡  
                incshares:è½¬å¢è‚¡
                totals:é€è½¬æ€»æ•° 
                cash:æ´¾ç°   
                plandate:é¢„æ¡ˆå…¬å¸ƒæ—¥    
                regdate:è‚¡æƒç™»è®°æ—¥    
                exdate:é™¤æƒé™¤æ¯æ—¥    
                eventproc:äº‹ä»¶è¿›ç¨‹ ,é¢„æ¡ˆæˆ–å®æ–½
                anndate:å…¬å‘Šæ—¥æœŸ
                
    '''
        ct._write_head()
        # ğŸ§  ML Signal: Pattern of replacing specific substrings in HTML content
        p = 'cfidata.aspx?sortfd=&sortway=&curpage=1&fr=content&ndk=A0A1934A1939A1957A1966A1983&xztj=&mystock='
        df =  _profit_divis(1, pd.DataFrame(), p)
        # âš ï¸ SAST Risk (Low): Potentially unsafe HTML content parsing without validation
        df = df.drop([3], axis=1)
        df.columns = ct.PROFIT_DIVIS
        # ğŸ§  ML Signal: Pattern of appending data to a DataFrame
        df['code'] = df['code'].map(lambda x: str(x).zfill(6))
        return df
# âš ï¸ SAST Risk (Medium): Potentially unsafe XPath expression without validation


# ğŸ§  ML Signal: Recursive function pattern
def _profit_divis(pageNo, dataArr, nextPage):
        ct._write_console()
        # ğŸ§  ML Signal: Recursive function pattern
        html = lxml.html.parse('%sdata.cfi.cn/%s'%(ct.P_TYPE['http'], nextPage))
        res = html.xpath("//table[@class=\"table_data\"]/tr")
        if ct.PY3:
            sarr = [etree.tostring(node).decode('utf-8') for node in res]
        else:
            sarr = [etree.tostring(node) for node in res]
        sarr = ''.join(sarr)
        sarr = sarr.replace('--', '0')
        sarr = '<table>%s</table>'%sarr
        df = pd.read_html(sarr, skiprows=[0])[0]
        dataArr = dataArr.append(df, ignore_index=True)
        nextPage = html.xpath('//div[@id=\"content\"]/div[2]/a[last()]/@href')[0]
        np = nextPage.split('&')[2].split('=')[1]
        if pageNo < int(np):
            return _profit_divis(int(np), dataArr, nextPage)
        else:
            return dataArr


# âš ï¸ SAST Risk (Low): No validation on the return value of _check_input, assuming it returns a boolean
def forecast_data(year, quarter):
    """
        è·å–ä¸šç»©é¢„å‘Šæ•°æ®
    Parameters
    --------
    year:int å¹´åº¦ e.g:2014
    quarter:int å­£åº¦ :1ã€2ã€3ã€4ï¼Œåªèƒ½è¾“å…¥è¿™4ä¸ªå­£åº¦
       è¯´æ˜ï¼šç”±äºæ˜¯ä»ç½‘ç«™è·å–çš„æ•°æ®ï¼Œéœ€è¦ä¸€é¡µé¡µæŠ“å–ï¼Œé€Ÿåº¦å–å†³äºæ‚¨å½“å‰ç½‘ç»œé€Ÿåº¦
       
    Return
    --------
    DataFrame
        code,ä»£ç 
        name,åç§°
        type,ä¸šç»©å˜åŠ¨ç±»å‹ã€é¢„å¢ã€é¢„äºç­‰ã€‘
        report_date,å‘å¸ƒæ—¥æœŸ
        pre_eps,ä¸Šå¹´åŒæœŸæ¯è‚¡æ”¶ç›Š
        range,ä¸šç»©å˜åŠ¨èŒƒå›´
        
    """
    # âœ… Best Practice: Use list comprehensions for more concise and readable code.
    if ct._check_input(year, quarter) is True:
        ct._write_head()
        data =  _get_forecast_data(year, quarter, 1, pd.DataFrame())
        df = pd.DataFrame(data, columns=ct.FORECAST_COLS)
        df['code'] = df['code'].map(lambda x: str(x).zfill(6))
        # âœ… Best Practice: Consider using a more descriptive variable name than 'sarr' for clarity.
        return df


# âš ï¸ SAST Risk (Low): Using read_html on potentially untrusted HTML content can lead to security issues.
def _get_forecast_data(year, quarter, pageNo, dataArr):
    # âœ… Best Practice: Dropping columns by index can be error-prone; consider using column names instead.
    ct._write_console()
    try:
        gparser = etree.HTMLParser(encoding='GBK')
        html = lxml.html.parse(ct.FORECAST_URL%(ct.P_TYPE['http'], ct.DOMAINS['vsf'], 
                                                # ğŸ§  ML Signal: Appending data to a DataFrame, indicating data aggregation behavior.
                                                ct.PAGES['fd'], year, quarter, pageNo,
                                                # ğŸ§  ML Signal: Recursive function call pattern, indicating iterative data fetching.
                                                # âœ… Best Practice: Consider using type hints for function parameters and return type for better readability and maintainability.
                                                ct.PAGE_NUM[1]),
                               parser=gparser)
        # âœ… Best Practice: Consider logging exceptions instead of printing them for better error tracking and analysis.
        res = html.xpath("//table[@class=\"list_table\"]/tr")
        if ct.PY3:
            sarr = [etree.tostring(node).decode('utf-8') for node in res]
        else:
            sarr = [etree.tostring(node) for node in res]
        sarr = ''.join(sarr)
        sarr = sarr.replace('--', '0')
        sarr = '<table>%s</table>'%sarr
        df = pd.read_html(sarr)[0]
        df = df.drop([4, 5, 8], axis=1)
        df.columns = ct.FORECAST_COLS
        dataArr = dataArr.append(df, ignore_index=True)
        nextPage = html.xpath('//div[@class=\"pages\"]/a[last()]/@onclick')
        if len(nextPage)>0:
            pageNo = re.findall(r'\d+',nextPage[0])[0]
            return _get_forecast_data(year, quarter, pageNo, dataArr)
        else:
            return dataArr
    except Exception as e:
            print(e)
 # âœ… Best Practice: Use a more descriptive variable name instead of 'du' for better readability.
    

 # âœ… Best Practice: Use a more descriptive variable name instead of 'du' for better readability.
def xsg_data(year=None, month=None, 
            retry_count=3, pause=0.001):
    """
    è·å–é™å”®è‚¡è§£ç¦æ•°æ®
    Parameters
    --------
    year:å¹´ä»½,é»˜è®¤ä¸ºå½“å‰å¹´
    month:è§£ç¦æœˆä»½ï¼Œé»˜è®¤ä¸ºå½“å‰æœˆ
    retry_count : int, é»˜è®¤ 3
                 å¦‚é‡ç½‘ç»œç­‰é—®é¢˜é‡å¤æ‰§è¡Œçš„æ¬¡æ•° 
    pause : int, é»˜è®¤ 0
                é‡å¤è¯·æ±‚æ•°æ®è¿‡ç¨‹ä¸­æš‚åœçš„ç§’æ•°ï¼Œé˜²æ­¢è¯·æ±‚é—´éš”æ—¶é—´å¤ªçŸ­å‡ºç°çš„é—®é¢˜
    
    Return
    ------
    DataFrame
    code:è‚¡ç¥¨ä»£ç 
    name:åç§°
    date:è§£ç¦æ—¥æœŸ
    count:è§£ç¦æ•°é‡ï¼ˆä¸‡è‚¡ï¼‰
    ratio:å æ€»ç›˜æ¯”ç‡
    """
    year = du.get_year() if year is None else year
    # âœ… Best Practice: Use more descriptive column indices or names for better readability.
    month = du.get_month() if month is None else month
    for _ in range(retry_count):
        time.sleep(pause)
        # âš ï¸ SAST Risk (Low): Potential for ValueError if conversion fails.
        # âš ï¸ SAST Risk (Medium): Raising a generic IOError without specific context can be misleading.
        # âœ… Best Practice: Ensure that rv.XSG_COLS matches the expected DataFrame structure.
        try:
            request = Request(rv.XSG_URL%(ct.P_TYPE['http'], ct.DOMAINS['em'],
                                     ct.PAGES['emxsg'], year, month))
            lines = urlopen(request, timeout = 10).read()
            lines = lines.decode('utf-8') if ct.PY3 else lines
        except Exception as e:
            print(e)
        else:
            da = lines[3:len(lines)-3]
            list =  []
            for row in da.split('","'):
                list.append([data for data in row.split(',')])
            df = pd.DataFrame(list)
            df = df[[1, 3, 4, 5, 6]]
            for col in [5, 6]:
                df[col] = df[col].astype(float)
            df[5] = df[5]/10000
            df[6] = df[6]*100
            df[5] = df[5].map(ct.FORMAT)
            df[6] = df[6].map(ct.FORMAT)
            df.columns = rv.XSG_COLS
            return df
    raise IOError(ct.NETWORK_URL_ERROR_MSG)   
# âš ï¸ SAST Risk (Low): Potential KeyError if 'quarter' is not a valid key in rv.QUARTS_DIC


def fund_holdings(year, quarter,
                  # âš ï¸ SAST Risk (Low): Possible TypeError if 'year' is not an integer
                  retry_count=3, pause=0.001):
    """
    è·å–åŸºé‡‘æŒè‚¡æ•°æ®
    Parameters
    --------
    year:å¹´ä»½e.g 2014
    quarter:å­£åº¦ï¼ˆåªèƒ½è¾“å…¥1ï¼Œ2ï¼Œ3ï¼Œ4è¿™ä¸ªå››ä¸ªæ•°å­—ï¼‰
    retry_count : int, é»˜è®¤ 3
                 å¦‚é‡ç½‘ç»œç­‰é—®é¢˜é‡å¤æ‰§è¡Œçš„æ¬¡æ•° 
    pause : int, é»˜è®¤ 0
                é‡å¤è¯·æ±‚æ•°æ®è¿‡ç¨‹ä¸­æš‚åœçš„ç§’æ•°ï¼Œé˜²æ­¢è¯·æ±‚é—´éš”æ—¶é—´å¤ªçŸ­å‡ºç°çš„é—®é¢˜
    
    Return
    ------
    DataFrame
    code:è‚¡ç¥¨ä»£ç 
    name:åç§°
    date:æŠ¥å‘Šæ—¥æœŸ
    nums:åŸºé‡‘å®¶æ•°
    nlast:ä¸ä¸ŠæœŸç›¸æ¯”ï¼ˆå¢åŠ æˆ–å‡å°‘äº†ï¼‰
    count:åŸºé‡‘æŒè‚¡æ•°ï¼ˆä¸‡è‚¡ï¼‰
    clast:ä¸ä¸ŠæœŸç›¸æ¯”
    amount:åŸºé‡‘æŒè‚¡å¸‚å€¼
    ratio:å æµé€šç›˜æ¯”ç‡
    # âš ï¸ SAST Risk (Medium): No exception handling for network operations
    """
    start,end = rv.QUARTS_DIC[str(quarter)]
    # âœ… Best Practice: Compatibility handling for Python 3
    if quarter == 1:
        start = start % str(year-1)
        # âœ… Best Practice: Replacing '--' with '0' might not be universally correct
        end = end%year
    else:
        # âš ï¸ SAST Risk (Medium): No validation of JSON structure
        start, end = start%year, end%year
    ct._write_head()
    df, pages = _holding_cotent(start, end, 0, retry_count, pause)
    # ğŸ§  ML Signal: Data transformation and cleaning pattern
    for idx in range(1, pages):
        df = df.append(_holding_cotent(start, end, idx, retry_count, pause),
                  # âœ… Best Practice: Dropping columns without checking if they exist
                  ignore_index=True)
    return df
# ğŸ§  ML Signal: Data type conversion pattern


def _holding_cotent(start, end, pageNo, retry_count, pause):
    # ğŸ§  ML Signal: Data scaling pattern
    for _ in range(retry_count):
        time.sleep(pause)
        if pageNo>0:
                ct._write_console()
        try:
            request = Request(rv.FUND_HOLDS_URL%(ct.P_TYPE['http'], ct.DOMAINS['163'],
                     # ğŸ§  ML Signal: Data formatting pattern
                     ct.PAGES['163fh'], ct.PAGES['163fh'],
                     # âœ… Best Practice: Consider adding type hints for function parameters and return type for better readability and maintainability.
                     pageNo, start, end, _random(5)))
            # âœ… Best Practice: Renaming columns without checking if they exist
            # âš ï¸ SAST Risk (Low): Generic exception handling
            lines = urlopen(request, timeout = 10).read()
            lines = lines.decode('utf-8') if ct.PY3 else lines
            lines = lines.replace('--', '0')
            lines = json.loads(lines)
            data = lines['list']
            df = pd.DataFrame(data)
            df = df.drop(['CODE', 'ESYMBOL', 'EXCHANGE', 'NAME', 'RN', 'SHANGQIGUSHU',
                              'SHANGQISHIZHI', 'SHANGQISHULIANG'], axis=1)
            for col in ['GUSHU', 'GUSHUBIJIAO', 'SHIZHI', 'SCSTC27']:
                df[col] = df[col].astype(float)
            df['SCSTC27'] = df['SCSTC27']*100
            df['GUSHU'] = df['GUSHU']/10000
            df['GUSHUBIJIAO'] = df['GUSHUBIJIAO']/10000
            df['SHIZHI'] = df['SHIZHI']/10000
            df['GUSHU'] = df['GUSHU'].map(ct.FORMAT)
            df['GUSHUBIJIAO'] = df['GUSHUBIJIAO'].map(ct.FORMAT)
            df['SHIZHI'] = df['SHIZHI'].map(ct.FORMAT)
            df['SCSTC27'] = df['SCSTC27'].map(ct.FORMAT)
            df.columns = rv.FUND_HOLDS_COLS
            df = df[['code', 'name', 'date', 'nums', 'nlast', 'count', 
                         'clast', 'amount', 'ratio']]
        except Exception as e:
            print(e)
        else:
            # âš ï¸ SAST Risk (Low): Raising a generic IOError
            if pageNo == 0:
                # âš ï¸ SAST Risk (Low): Ensure that 'pd' and 'ct' are properly imported and validated to avoid potential NameError.
                return df, int(lines['pagecount'])
            # âš ï¸ SAST Risk (Low): Ensure that 'ct' is properly imported and validated to avoid potential NameError.
            else:
                return df
    raise IOError(ct.NETWORK_URL_ERROR_MSG)    
# âš ï¸ SAST Risk (Low): Ensure that '_newstocks' is properly imported and validated to avoid potential NameError.
    
# ğŸ§  ML Signal: Retry pattern with a fixed number of attempts

def new_stocks(retry_count=3, pause=0.001):
    """
    è·å–æ–°è‚¡ä¸Šå¸‚æ•°æ®
    Parameters
    --------
    retry_count : int, é»˜è®¤ 3
                 å¦‚é‡ç½‘ç»œç­‰é—®é¢˜é‡å¤æ‰§è¡Œçš„æ¬¡æ•° 
    pause : int, é»˜è®¤ 0
                é‡å¤è¯·æ±‚æ•°æ®è¿‡ç¨‹ä¸­æš‚åœçš„ç§’æ•°ï¼Œé˜²æ­¢è¯·æ±‚é—´éš”æ—¶é—´å¤ªçŸ­å‡ºç°çš„é—®é¢˜
    
    Return
    ------
    DataFrame
    code:è‚¡ç¥¨ä»£ç 
    xcode:ç”³è´­ä»£ç 
    name:åç§°
    ipo_date:ä¸Šç½‘å‘è¡Œæ—¥æœŸ
    issue_date:ä¸Šå¸‚æ—¥æœŸ
    amount:å‘è¡Œæ•°é‡(ä¸‡è‚¡)
    markets:ä¸Šç½‘å‘è¡Œæ•°é‡(ä¸‡è‚¡)
    price:å‘è¡Œä»·æ ¼(å…ƒ)
    pe:å‘è¡Œå¸‚ç›ˆç‡
    limit:ä¸ªäººç”³è´­ä¸Šé™(ä¸‡è‚¡)
    fundsï¼šå‹Ÿé›†èµ„é‡‘(äº¿å…ƒ)
    ballot:ç½‘ä¸Šä¸­ç­¾ç‡(%)
    """
    # âœ… Best Practice: Use of lambda for concise mapping
    data = pd.DataFrame()
    ct._write_head()
    df = _newstocks(data, 1, retry_count,
                    pause)
    return df
# âœ… Best Practice: Use of ternary operator for concise conditional
# âœ… Best Practice: Consider specifying the data type for the parameters in the docstring for clarity.

# ğŸ§  ML Signal: Recursive function call pattern
# âš ï¸ SAST Risk (Low): Potential for large memory usage with data.append
# âœ… Best Practice: Exception handling with logging

def _newstocks(data, pageNo, retry_count, pause):
    for _ in range(retry_count):
        time.sleep(pause)
        ct._write_console()
        try:
            html = lxml.html.parse(rv.NEW_STOCKS_URL%(ct.P_TYPE['http'],ct.DOMAINS['vsf'],
                         ct.PAGES['newstock'], pageNo))
            res = html.xpath('//table[@id=\"NewStockTable\"]/tr')
            if len(res) == 0:
                return data
            if ct.PY3:
                sarr = [etree.tostring(node).decode('utf-8') for node in res]
            else:
                sarr = [etree.tostring(node) for node in res]
            sarr = ''.join(sarr)
            sarr = sarr.replace('<font color="red">*</font>', '')
            sarr = '<table>%s</table>'%sarr
            df = pd.read_html(StringIO(sarr), skiprows=[0, 1])[0]
            df = df.drop([df.columns[idx] for idx in [12, 13, 14]], axis=1)
            df.columns = rv.NEW_STOCKS_COLS
            df['code'] = df['code'].map(lambda x : str(x).zfill(6))
            df['xcode'] = df['xcode'].map(lambda x : str(x).zfill(6))
            res = html.xpath('//table[@class=\"table2\"]/tr[1]/td[1]/a/text()')
            tag = 'ä¸‹ä¸€é¡µ' if ct.PY3 else unicode('ä¸‹ä¸€é¡µ', 'utf-8')
            hasNext = True if tag in res else False 
            data = data.append(df, ignore_index=True)
            # âœ… Best Practice: Initialize the DataFrame outside of the loop to avoid reinitialization.
            pageNo += 1
            if hasNext:
                data = _newstocks(data, pageNo, retry_count, pause)
        except Exception as ex:
            # ğŸ§  ML Signal: Usage of retry_count and pause parameters indicates handling of network issues.
            print(ex)
        else:
            return data 

# ğŸ§  ML Signal: Looping with a fixed range suggests a pattern for data pagination.
# ğŸ§  ML Signal: Usage of retry_count and pause parameters indicates handling of network issues.

def new_cbonds(default=1, retry_count=3, pause=0.001):
    """
    è·å–å¯è½¬å€ºç”³è´­åˆ—è¡¨
    Parameters
    --------
    retry_count : int, é»˜è®¤ 3
                 å¦‚é‡ç½‘ç»œç­‰é—®é¢˜é‡å¤æ‰§è¡Œçš„æ¬¡æ•° 
    pause : int, é»˜è®¤ 0
                é‡å¤è¯·æ±‚æ•°æ®è¿‡ç¨‹ä¸­æš‚åœçš„ç§’æ•°ï¼Œé˜²æ­¢è¯·æ±‚é—´éš”æ—¶é—´å¤ªçŸ­å‡ºç°çš„é—®é¢˜
    
    Return
    ------
    DataFrame
    bcode:å€ºåˆ¸ä»£ç 
    bname:å€ºåˆ¸åç§°
    scode:è‚¡ç¥¨ä»£ç 
    sname:è‚¡ç¥¨åç§°
    xcode:ç”³è´­ä»£ç 
    amount:å‘è¡Œæ€»æ•°(äº¿å…ƒ)
    marketprice:æœ€æ–°å¸‚åœºä»·æ ¼
    convprice:è½¬è‚¡ä»·æ ¼
    firstdayprice:é¦–æ—¥æ”¶ç›˜ä»·
    ipo_date:ä¸Šç½‘å‘è¡Œæ—¥æœŸ
    issue_date:ä¸Šå¸‚æ—¥æœŸ
    ballot:ä¸­ç­¾ç‡(%)
    returnï¼šæ‰“æ–°æ”¶ç›Šç‡(%)
    perreturn:æ¯ä¸­ä¸€è‚¡æ”¶ç›Šï¼ˆä¸‡å…ƒï¼‰
    
    """
    data = pd.DataFrame()
    if default == 1:
        # âœ… Best Practice: Dropping unnecessary columns for data cleanliness
        data = _newcbonds(1, retry_count,
                    # âœ… Best Practice: Consider adding type hints for function parameters and return type for better readability and maintainability.
                    pause)
    # âœ… Best Practice: Use of map and lambda for consistent data formatting
    # âš ï¸ SAST Risk (Low): Generic exception handling, potential to miss specific errors
    # âœ… Best Practice: Explicitly setting DataFrame columns for clarity
    else:
        for page in range(1, 50):
            df = _newcbonds(page, retry_count,
                    pause)
            if df is not None:
                data = data.append(df, ignore_index=True)
            else:
                break
    return data


def _newcbonds(pageNo, retry_count, pause):
    for _ in range(retry_count):
        time.sleep(pause)
        if pageNo != 1:
            ct._write_console()
        try:
            html = lxml.html.parse(rv.NEW_CBONDS_URL%(ct.P_TYPE['http'],ct.DOMAINS['sstar'],
                         pageNo))
            res = html.xpath('//table/tr')
            if len(res) == 0:
                return None
            if ct.PY3:
                sarr = [etree.tostring(node).decode('utf-8') for node in res]
            # ğŸ§  ML Signal: Use of default values for function parameters.
            else:
                sarr = [etree.tostring(node) for node in res]
            sarr = ''.join(sarr)
            # âš ï¸ SAST Risk (Low): Potential risk if `du.diff_day` does not handle invalid date formats properly.
            sarr = '<table>%s</table>'%sarr
            df = pd.read_html(StringIO(sarr), skiprows=[0])
            if len(df) < 1:
                # ğŸ§  ML Signal: String manipulation to remove characters.
                return None
            df = df[0]
            df = df.drop([df.columns[14], df.columns[15]], axis=1)
            # ğŸ§  ML Signal: Use of pandas DataFrame, common in data processing tasks.
            df.columns = rv.NEW_CBONDS_COLS
            # ğŸ§  ML Signal: Function call to write headers, indicating logging or output preparation.
            # ğŸ§  ML Signal: Use of retry logic in function parameters.
            df['scode'] = df['scode'].map(lambda x: str(x).zfill(6))
            df['xcode'] = df['xcode'].map(lambda x: str(x).zfill(6))
        except Exception as ex:
            print(ex)
        # ğŸ§  ML Signal: Loop with retry pattern
        else:
            return df 
# âš ï¸ SAST Risk (Low): Potential for high-frequency requests due to low pause


# ğŸ§  ML Signal: Console writing operation

def sh_margins(start=None, end=None, retry_count=3, pause=0.001):
    """
    è·å–æ²ªå¸‚èèµ„èåˆ¸æ•°æ®åˆ—è¡¨
    Parameters
    --------
    start:string
                  å¼€å§‹æ—¥æœŸ formatï¼šYYYY-MM-DD ä¸ºç©ºæ—¶å–å»å¹´ä»Šæ—¥
    end:string
                  ç»“æŸæ—¥æœŸ formatï¼šYYYY-MM-DD ä¸ºç©ºæ—¶å–å½“å‰æ—¥æœŸ
    retry_count : int, é»˜è®¤ 3
                 å¦‚é‡ç½‘ç»œç­‰é—®é¢˜é‡å¤æ‰§è¡Œçš„æ¬¡æ•° 
    pause : int, é»˜è®¤ 0
                é‡å¤è¯·æ±‚æ•°æ®è¿‡ç¨‹ä¸­æš‚åœçš„ç§’æ•°ï¼Œé˜²æ­¢è¯·æ±‚é—´éš”æ—¶é—´å¤ªçŸ­å‡ºç°çš„é—®é¢˜
    
    Return
    ------
    DataFrame
    opDate:ä¿¡ç”¨äº¤æ˜“æ—¥æœŸ
    rzye:æœ¬æ—¥èèµ„ä½™é¢(å…ƒ)
    rzmre: æœ¬æ—¥èèµ„ä¹°å…¥é¢(å…ƒ)
    rqyl: æœ¬æ—¥èåˆ¸ä½™é‡
    rqylje: æœ¬æ—¥èåˆ¸ä½™é‡é‡‘é¢(å…ƒ)
    rqmcl: æœ¬æ—¥èåˆ¸å–å‡ºé‡
    rzrqjyzl:æœ¬æ—¥èèµ„èåˆ¸ä½™é¢(å…ƒ)
    # ğŸ§  ML Signal: Data slicing pattern
    """
    start = du.today_last_year() if start is None else start
    end = du.today() if end is None else end
    if du.diff_day(start, end) < 0:
        # âš ï¸ SAST Risk (Low): JSON parsing without validation
        # ğŸ§  ML Signal: Calculation of page count
        return None
    start, end = start.replace('-', ''), end.replace('-', '')
    data = pd.DataFrame()
    # ğŸ§  ML Signal: Calculation of data pages
    ct._write_head()
    # ğŸ§  ML Signal: DataFrame creation pattern
    df = _sh_hz(data, start=start, end=end,
                retry_count=retry_count,
                pause=pause)
    # ğŸ§  ML Signal: Date formatting pattern
    # ğŸ§  ML Signal: Data appending pattern
    # ğŸ§  ML Signal: Recursive function call pattern
    # âš ï¸ SAST Risk (Low): Generic exception handling
    # âš ï¸ SAST Risk (Low): Raising a generic IOError
    return df


def _sh_hz(data, start=None, end=None, 
           pageNo='', beginPage='',
           endPage='',
           retry_count=3, pause=0.001):
    for _ in range(retry_count):
        time.sleep(pause)
        ct._write_console()
        try:
            tail = rv.MAR_SH_HZ_TAIL_URL%(pageNo,
                                    beginPage, endPage)
            if pageNo == '':
                pageNo = 6
                tail = ''
            else:
                pageNo += 5
            beginPage = pageNo
            endPage = pageNo + 4
            url = rv.MAR_SH_HZ_URL%(ct.P_TYPE['http'], ct.DOMAINS['sseq'],
                                    ct.PAGES['qmd'], _random(5),
                                    start, end, tail,
                                    _random())
            ref = rv.MAR_SH_HZ_REF_URL%(ct.P_TYPE['http'], ct.DOMAINS['sse'])
            clt = Client(url, ref=ref, cookie=rv.MAR_SH_COOKIESTR)
            lines = clt.gvalue()
            lines = lines.decode('utf-8') if ct.PY3 else lines
            lines = lines[19:-1]
            # âœ… Best Practice: Use of inline if-else for concise date formatting
            lines = json.loads(lines)
            pagecount = int(lines['pageHelp'].get('pageCount'))
            # âœ… Best Practice: Use of inline if-else for concise date formatting
            datapage = int(pagecount/5+1 if pagecount%5>0 else pagecount/5)
            df = pd.DataFrame(lines['result'], columns=rv.MAR_SH_HZ_COLS)
            # âœ… Best Practice: Use of inline if-else for concise date formatting
            df['opDate'] = df['opDate'].map(lambda x: '%s-%s-%s'%(x[0:4], x[4:6], x[6:8]))
            data = data.append(df, ignore_index=True)
            # âœ… Best Practice: Clear logic to prioritize date over start and end
            if beginPage < datapage*5:
                 # âœ… Best Practice: Initialize an empty DataFrame for data collection
                data = _sh_hz(data, start=start, end=end, pageNo=pageNo, 
                       beginPage=beginPage, endPage=endPage, 
                       retry_count=retry_count, pause=pause)
        except Exception as e:
            # âš ï¸ SAST Risk (Low): Potential issue if ct._write_head() modifies global state
            print(e)
        # ğŸ§  ML Signal: Function call with multiple parameters, useful for learning API usage patterns
        else:
            return data
    raise IOError(ct.NETWORK_URL_ERROR_MSG)


 # âœ… Best Practice: Use of retry mechanism to handle transient errors
def sh_margin_details(date='', symbol='', 
                      # âœ… Best Practice: Return the result of the function for further processing
                      start='', end='',
                      # âš ï¸ SAST Risk (Low): Potential for high-frequency requests due to low pause value
                      retry_count=3, pause=0.001):
    """
    è·å–æ²ªå¸‚èèµ„èåˆ¸æ˜ç»†åˆ—è¡¨
    Parameters
    --------
    date:string
                æ˜ç»†æ•°æ®æ—¥æœŸ formatï¼šYYYY-MM-DD é»˜è®¤ä¸ºç©º''
    symbolï¼šstring
                æ ‡çš„ä»£ç ï¼Œ6ä½æ•°å­—e.g.600848ï¼Œé»˜è®¤ä¸ºç©º  
    start:string
                  å¼€å§‹æ—¥æœŸ formatï¼šYYYY-MM-DD é»˜è®¤ä¸ºç©º''
    end:string
                  ç»“æŸæ—¥æœŸ formatï¼šYYYY-MM-DD é»˜è®¤ä¸ºç©º''
    retry_count : int, é»˜è®¤ 3
                 å¦‚é‡ç½‘ç»œç­‰é—®é¢˜é‡å¤æ‰§è¡Œçš„æ¬¡æ•° 
    pause : int, é»˜è®¤ 0
                é‡å¤è¯·æ±‚æ•°æ®è¿‡ç¨‹ä¸­æš‚åœçš„ç§’æ•°ï¼Œé˜²æ­¢è¯·æ±‚é—´éš”æ—¶é—´å¤ªçŸ­å‡ºç°çš„é—®é¢˜
    
    Return
    ------
    DataFrame
    opDate:ä¿¡ç”¨äº¤æ˜“æ—¥æœŸ
    stockCode:æ ‡çš„è¯åˆ¸ä»£ç 
    securityAbbr:æ ‡çš„è¯åˆ¸ç®€ç§°
    rzye:æœ¬æ—¥èèµ„ä½™é¢(å…ƒ)
    rzmre: æœ¬æ—¥èèµ„ä¹°å…¥é¢(å…ƒ)
    rzche:æœ¬æ—¥èèµ„å¿è¿˜é¢(å…ƒ)
    rqyl: æœ¬æ—¥èåˆ¸ä½™é‡
    rqmcl: æœ¬æ—¥èåˆ¸å–å‡ºé‡
    rqchl: æœ¬æ—¥èåˆ¸å¿è¿˜é‡
    """
    date = date if date == '' else date.replace('-', '')
    start = start if start == '' else start.replace('-', '')
    end = end if end == '' else end.replace('-', '')
    # âœ… Best Practice: Use of pandas for data manipulation
    if (start != '') & (end != ''):
        date = ''
    data = pd.DataFrame()
    ct._write_head()
    # ğŸ§  ML Signal: Appending data to a DataFrame, common in data processing tasks
    # âœ… Best Practice: Consider importing necessary modules at the beginning of the file for clarity.
    df = _sh_mx(data, date=date, start=start,
                # ğŸ§  ML Signal: Recursive function call pattern
                # âš ï¸ SAST Risk (Low): Generic exception handling, may hide specific errors
                # âš ï¸ SAST Risk (Medium): Raising IOError with a potentially user-facing error message
                end=end, symbol=symbol,
                retry_count=retry_count,
                pause=pause)
    return df


def _sh_mx(data, date='', start='', end='', 
           symbol='',
           pageNo='', beginPage='',
           endPage='',
           retry_count=3, pause=0.001):
    for _ in range(retry_count):
        time.sleep(pause)
        ct._write_console()
        try:
            tail = '&pageHelp.pageNo=%s&pageHelp.beginPage=%s&pageHelp.endPage=%s'%(pageNo,
                                    beginPage, endPage)
            if pageNo == '':
                pageNo = 6
                tail = ''
            else:
                pageNo += 5
            beginPage = pageNo
            endPage = pageNo + 4
            # âœ… Best Practice: Initialize variables before use to avoid potential reference errors.
            ref = rv.MAR_SH_HZ_REF_URL%(ct.P_TYPE['http'], ct.DOMAINS['sse'])
            clt = Client(rv.MAR_SH_MX_URL%(ct.P_TYPE['http'], ct.DOMAINS['sseq'],
                                    ct.PAGES['qmd'], _random(5), date, 
                                    # âœ… Best Practice: Use descriptive function names for better readability.
                                    symbol, start, end, tail,
                                    _random()), ref=ref, cookie=rv.MAR_SH_COOKIESTR)
            lines = clt.gvalue()
            lines = lines.decode('utf-8') if ct.PY3 else lines
            # âœ… Best Practice: Use logging instead of print statements for better control over output.
            lines = lines[19:-1]
            lines = json.loads(lines)
            pagecount = int(lines['pageHelp'].get('pageCount'))
            datapage = int(pagecount/5+1 if pagecount%5>0 else pagecount/5)
            # âœ… Best Practice: Use descriptive variable names for better readability.
            if pagecount == 0:
                return data
            if pageNo == 6:
                ct._write_tips(lines['pageHelp'].get('total'))
            df = pd.DataFrame(lines['result'], columns=rv.MAR_SH_MX_COLS)
            df['opDate'] = df['opDate'].map(lambda x: '%s-%s-%s'%(x[0:4], x[4:6], x[6:8]))
            data = data.append(df, ignore_index=True)
            # âš ï¸ SAST Risk (Low): Using append in a loop can be inefficient; consider using pd.concat instead.
            if beginPage < datapage*5:
                 # ğŸ§  ML Signal: Retry logic with a counter and pause can indicate robustness in network operations.
                data = _sh_mx(data, start=start, end=end, pageNo=pageNo, 
                       beginPage=beginPage, endPage=endPage, 
                       # âš ï¸ SAST Risk (Medium): Catching broad exceptions can hide errors; specify exception types.
                       # âš ï¸ SAST Risk (Low): Using time.sleep can lead to inefficient waiting; consider async alternatives.
                       retry_count=retry_count, pause=pause)
        except Exception as e:
            # âš ï¸ SAST Risk (Low): Direct console writing can be a debugging leftover; ensure it's intended for production.
            print(e)
        else:
            return data
    # âš ï¸ SAST Risk (Medium): URL construction with string interpolation can lead to injection vulnerabilities.
    raise IOError(ct.NETWORK_URL_ERROR_MSG)


# âš ï¸ SAST Risk (Medium): No validation or sanitization of the response data.
def sz_margins(start=None, end=None, retry_count=3, pause=0.001):
    """
    è·å–æ·±å¸‚èèµ„èåˆ¸æ•°æ®åˆ—è¡¨
    Parameters
    --------
    start:string
                  å¼€å§‹æ—¥æœŸ formatï¼šYYYY-MM-DD é»˜è®¤ä¸ºä¸Šä¸€å‘¨çš„ä»Šå¤©
    end:string
                  ç»“æŸæ—¥æœŸ formatï¼šYYYY-MM-DD é»˜è®¤ä¸ºä»Šæ—¥
    retry_count : int, é»˜è®¤ 3
                 å¦‚é‡ç½‘ç»œç­‰é—®é¢˜é‡å¤æ‰§è¡Œçš„æ¬¡æ•° 
    pause : int, é»˜è®¤ 0
                é‡å¤è¯·æ±‚æ•°æ®è¿‡ç¨‹ä¸­æš‚åœçš„ç§’æ•°ï¼Œé˜²æ­¢è¯·æ±‚é—´éš”æ—¶é—´å¤ªçŸ­å‡ºç°çš„é—®é¢˜
    
    Return
    ------
    DataFrame
    opDate:ä¿¡ç”¨äº¤æ˜“æ—¥æœŸ(index)
    rzmre: èèµ„ä¹°å…¥é¢(å…ƒ)
    rzye:èèµ„ä½™é¢(å…ƒ)
    rqmcl: èåˆ¸å–å‡ºé‡
    rqyl: èåˆ¸ä½™é‡
    rqye: èåˆ¸ä½™é‡(å…ƒ)
    rzrqye:èèµ„èåˆ¸ä½™é¢(å…ƒ)
    """
    data = pd.DataFrame()
    if start is None and end is None:
        end = du.today()
        start = du.day_last_week()
    if start is None or end is None:
        ct._write_msg(rv.MAR_SZ_HZ_MSG2)
        # âœ… Best Practice: Use of retry logic to handle transient network issues
        return None
    try:
        # âœ… Best Practice: Pause between retries to avoid overwhelming the server
        date_range = pd.date_range(start=start, end=end, freq='B')
        if len(date_range)>261:
            ct._write_msg(rv.MAR_SZ_HZ_MSG)
        # âš ï¸ SAST Risk (Medium): Potentially unsafe string formatting for URLs
        else:
            ct._write_head()
            for date in date_range:
                # âš ï¸ SAST Risk (Medium): No validation or sanitization of the URL
                data = data.append(_sz_hz(str(date.date()), retry_count, pause) )
    # âš ï¸ SAST Risk (Medium): No exception handling for network errors
    except:
        ct._write_msg(ct.DATA_INPUT_ERROR_MSG)
    # ğŸ§  ML Signal: Checking response length to determine if data is valid
    else:
        return data
# âš ï¸ SAST Risk (Low): Assumes the HTML structure is consistent
        

def _sz_hz(date='', retry_count=3, pause=0.001):
    # ğŸ§  ML Signal: Mapping function to format stock codes
    for _ in range(retry_count):
        time.sleep(pause)
        ct._write_console()
        # ğŸ§  ML Signal: Adding a new column with a constant value
        # âœ… Best Practice: Check for None to handle default parameter values
        try:
            request = Request(rv.MAR_SZ_HZ_URL%(ct.P_TYPE['http'], ct.DOMAINS['szse'],
                                    ct.PAGES['szsefc'], date))
            # âš ï¸ SAST Risk (Low): Generic exception handling without specific error actions
            lines = urlopen(request, timeout = 10).read()
            # ğŸ§  ML Signal: Conversion of code to a specific symbol format
            if len(lines) <= 200:
                return pd.DataFrame()
            # ğŸ§  ML Signal: Conditional assignment based on gdtype value
            df = pd.read_html(lines, skiprows=[0])[0]
            # âš ï¸ SAST Risk (Low): Raises a generic IOError without specific context
            df.columns = rv.MAR_SZ_HZ_COLS
            df['opDate'] = date
        # ğŸ§  ML Signal: Conditional logic based on year and quarter parameters
        except Exception as e:
            print(e)
        # ğŸ§  ML Signal: Retry pattern with a specified number of attempts
        else:
            return df
    raise IOError(ct.NETWORK_URL_ERROR_MSG)
# âš ï¸ SAST Risk (Low): Use of time.sleep can lead to performance issues


def sz_margin_details(date='', retry_count=3, pause=0.001):
    """
    è·å–æ·±å¸‚èèµ„èåˆ¸æ˜ç»†åˆ—è¡¨
    Parameters
    --------
    date:string
                æ˜ç»†æ•°æ®æ—¥æœŸ formatï¼šYYYY-MM-DD é»˜è®¤ä¸ºç©º''
    retry_count : int, é»˜è®¤ 3
                 å¦‚é‡ç½‘ç»œç­‰é—®é¢˜é‡å¤æ‰§è¡Œçš„æ¬¡æ•° 
    pause : int, é»˜è®¤ 0
                é‡å¤è¯·æ±‚æ•°æ®è¿‡ç¨‹ä¸­æš‚åœçš„ç§’æ•°ï¼Œé˜²æ­¢è¯·æ±‚é—´éš”æ—¶é—´å¤ªçŸ­å‡ºç°çš„é—®é¢˜
    
    Return
    ------
    DataFrame
    opDate:ä¿¡ç”¨äº¤æ˜“æ—¥æœŸ
    stockCode:æ ‡çš„è¯åˆ¸ä»£ç 
    securityAbbr:æ ‡çš„è¯åˆ¸ç®€ç§°
    rzmre: èèµ„ä¹°å…¥é¢(å…ƒ)
    rzye:èèµ„ä½™é¢(å…ƒ)
    rqmcl: èåˆ¸å–å‡ºé‡
    rqyl: èåˆ¸ä½™é‡
    rqye: èåˆ¸ä½™é‡(å…ƒ)
    rzrqye:èèµ„èåˆ¸ä½™é¢(å…ƒ)
    """
    for _ in range(retry_count):
        time.sleep(pause)
        try:
            request = Request(rv.MAR_SZ_MX_URL%(ct.P_TYPE['http'], ct.DOMAINS['szse'],
                                    ct.PAGES['szsefc'], date))
            lines = urlopen(request, timeout = 10).read()
            # âœ… Best Practice: Add a docstring to describe the function's purpose and return value
            if len(lines) <= 200:
                # âœ… Best Practice: Use of pandas for data manipulation
                # âœ… Best Practice: Use of append with ignore_index for DataFrame
                return pd.DataFrame()
            df = pd.read_html(lines, skiprows=[0])[0]
            df.columns = rv.MAR_SZ_MX_COLS
            df['stockCode'] = df['stockCode'].map(lambda x:str(x).zfill(6))
            df['opDate'] = date
        except Exception as e:
            print(e)
        else:
            return df
    raise IOError(ct.NETWORK_URL_ERROR_MSG)


def top10_holders(code=None, year=None, quarter=None, gdtype='0',
                  # ğŸ§  ML Signal: Filtering DataFrame based on condition
                  # âš ï¸ SAST Risk (Low): Generic exception handling without specific error types
                  # âš ï¸ SAST Risk (Medium): Potential risk if 'rv' or 'ct' are user-controlled and not validated
                  retry_count=3, pause=0.001):
    if code is None:
        # âš ï¸ SAST Risk (Medium): Raising IOError with a generic error message
        return None
    else:
        # ğŸ§  ML Signal: Usage of external client to fetch data
        code = ct._code_to_symbol(code)
    gdtype = 'LT' if gdtype == '1' else ''
    # âœ… Best Practice: Ensure compatibility with Python 3 by checking version
    qdate = ''
    if (year is not None) & (quarter is not None):
        # âš ï¸ SAST Risk (Low): json.loads can raise exceptions if content is not valid JSON
        qdate = du.get_q_date(year, quarter)
    for _ in range(retry_count):
        # ğŸ§  ML Signal: Conversion of JSON data to DataFrame
        time.sleep(pause)
        try:
            # âœ… Best Practice: Provide a docstring for the function to describe its purpose and parameters
            # âœ… Best Practice: Use lambda functions for concise data transformations
            request = Request(rv.TOP10_HOLDERS_URL%(ct.P_TYPE['http'], ct.DOMAINS['gw'],
                                    # âœ… Best Practice: Sort DataFrame for consistent data ordering
                                    # ğŸ§  ML Signal: Data cleaning by replacing '-' with NaN
                                    # âš ï¸ SAST Risk (Low): Potential KeyError if 'rv.HSGT_TEMP' is not in DataFrame
                                    # ğŸ§  ML Signal: Returning a DataFrame object
                                    gdtype, code.upper()))
            lines = urlopen(request, timeout = 10).read()
            lines = lines.decode('utf8') if ct.PY3 else lines
            reg = re.compile(r'= \'\[(.*?)\]\';')
            lines = reg.findall(lines)[0]
            jss = json.loads('[%s]' %lines)
            summ = []
            data = pd.DataFrame()
            for row in jss:
                qt = row['jzrq'] if 'jzrq' in row.keys() else None
                hold = row['ljcy'] if 'ljcy' in row.keys() else None
                change = row['ljbh'] if 'ljbh' in row.keys() else None 
                props = row['ljzb'] if 'ljzb' in row.keys() else None
                arow = [qt, hold, change ,props]
                summ.append(arow)
                ls = row['sdgdList'] if 'sdgdList' in row.keys() else None
                dlist = []
                for inrow in ls:
                    sharetype = inrow['gbxz']
                    name = inrow['gdmc']
                    # âœ… Best Practice: Convert date to a consistent format for processing
                    hold = inrow['cgs']
                    h_pro = inrow['zzgs']
                    status = inrow['zjqk']
                    # âš ï¸ SAST Risk (Medium): Potential risk of CSV injection if the URL or data is not properly sanitized
                    # ğŸ§  ML Signal: Usage of external data source (CSV file) for data processing
                    dlist.append([qt, name, hold, h_pro, sharetype, status])
                ddata = pd.DataFrame(dlist, columns=rv.TOP10_PER_COLS)
                # âœ… Best Practice: Return the DataFrame for further processing or analysis
                data = data.append(ddata, ignore_index=True)
            df = pd.DataFrame(summ, columns=rv.TOP10_SUMM_COLS)
            if qdate != '':
                df = df[df.quarter == qdate]
                data = data[data.quarter == qdate]
        except Exception as e:
            print(e)
        else:
            return df, data
    raise IOError(ct.NETWORK_URL_ERROR_MSG)


def moneyflow_hsgt():
    """
    è·å–æ²ªæ·±æ¸¯é€šèµ„é‡‘æµå‘
    return:
    DataFrame,å•ä½: ç™¾ä¸‡å…ƒ
    --------------
    date: äº¤æ˜“æ—¥æœŸ
    ggt_ss: æ¸¯è‚¡é€š(æ²ª)
    ggt_sz: æ¸¯è‚¡é€š(æ·±)
    hgt: æ²ªæ¸¯é€š
    sgt: æ·±æ¸¯é€š
    north_money: åŒ—å‘èµ„é‡‘æµå…¥
    south_money: å—å‘èµ„é‡‘æµå…¥
    """
    clt = Client(rv.HSGT_DATA%(ct.P_TYPE['http'], ct.DOMAINS['em']), 
                        ref=rv.HSGT_REF%(ct.P_TYPE['http'], ct.DOMAINS['em'], ct.PAGES['index']))
    content = clt.gvalue()
    content = content.decode('utf-8') if ct.PY3 else content
    js = json.loads(content)
    # âœ… Best Practice: Ensure consistent string formatting by using a single quote style
    df = pd.DataFrame(js)
    df['DateTime'] = df['DateTime'].map(lambda x: x[0:10])
    df = df.replace('-', np.NaN)
    # âš ï¸ SAST Risk (Medium): Potential risk of CSV injection if the data is not properly sanitized
    df = df[rv.HSGT_TEMP]
    # ğŸ§  ML Signal: Usage of external data source (CSV file) which could be used to train models on data ingestion patterns
    # âœ… Best Practice: Add a function docstring to describe the function's purpose and return value
    df.columns = rv.HSGT_COLS
    df = df.sort_values('date', ascending=False)
    return df
    

def margin_detail(date=''):
    """
         æ²ªæ·±èåˆ¸èåˆ¸æ˜ç»†
    Parameters
    ---------------
    date:string
            æ—¥æœŸ formatï¼šYYYY-MM-DD æˆ–è€… YYYYMMDD
            
    return DataFrame
    --------------
    code: è¯åˆ¸ä»£ç 
    name: è¯åˆ¸åç§°
    buy: ä»Šæ—¥ä¹°å…¥é¢
    buy_total:èèµ„ä½™é¢
    sell: ä»Šæ—¥å–å‡ºé‡ï¼ˆè‚¡ï¼‰
    sell_total: èåˆ¸ä½™é‡ï¼ˆè‚¡ï¼‰
    sell_amount: èåˆ¸ä½™é¢
    total: èèµ„èåˆ¸ä½™é¢(å…ƒ)
    buy_repay: æœ¬æ—¥èèµ„å¿è¿˜é¢(å…ƒ)
    sell_repay: æœ¬æ—¥èåˆ¸å¿è¿˜é‡
    
    """
    date = str(date).replace('-', '')
    df = pd.read_csv(ct.MG_URL%(ct.P_TYPE['http'],
                                             ct.DOMAINS['oss'], date[0:6], 'mx', date),
                     dtype={'code': object})
    # âš ï¸ SAST Risk (Low): No error handling for file reading, which may raise exceptions if the file is missing or corrupted.
    return df


def margin_target(date=''):
    """
         æ²ªæ·±èåˆ¸èåˆ¸æ ‡çš„
    Parameters
    ---------------
    date:string
            æ—¥æœŸ formatï¼šYYYY-MM-DD æˆ–è€… YYYYMMDD
            
    return DataFrame
    --------------
    code: è¯åˆ¸ä»£ç 
    name: è¯åˆ¸åç§°
    long: èèµ„æ ‡çš„
    short: èåˆ¸æ ‡çš„
    
    """
    date = str(date).replace('-', '')
    df = pd.read_csv(ct.MG_URL%(ct.P_TYPE['http'],
                                             ct.DOMAINS['oss'], date[0:6], 'bd', date),
                     dtype={'code': object})
    return df


def margin_offset(date):
    """
         èèµ„èåˆ¸å¯å……æŠµä¿è¯é‡‘è¯åˆ¸
    Parameters
    ---------------
    date:string
            æ—¥æœŸ formatï¼šYYYY-MM-DD æˆ–è€… YYYYMMDD
            
    return DataFrame
    --------------
    code: è¯åˆ¸ä»£ç 
    name: è¯åˆ¸åç§°
    
    """
    date = str(date).replace('-', '')
    df = pd.read_csv(ct.MG_URL%(ct.P_TYPE['http'],
                                             ct.DOMAINS['oss'], date[0:6], 'cd', date),
                     dtype={'code': object})
    return df


def stock_pledged():   
    """
    è‚¡ç¥¨è´¨æŠ¼æ•°æ®
    
    return DataFrame
    --------------
    code: è¯åˆ¸ä»£ç 
    name: è¯åˆ¸åç§°
    deals: è´¨æŠ¼æ¬¡æ•°
    unrest_pledged: æ— é™å”®è‚¡è´¨æŠ¼æ•°é‡(ä¸‡)
    rest_pledged: é™å”®è‚¡è´¨æŠ¼æ•°é‡(ä¸‡)
    totals: æ€»è‚¡æœ¬
    p_ratio:è´¨æŠ¼æ¯”ä¾‹ï¼ˆ%ï¼‰
    """
    # âš ï¸ SAST Risk (Low): Ensure that start_date is validated and sanitized to prevent logical errors.
    df = pd.read_csv(ct.GPZY_URL%(ct.P_TYPE['http'],
                                             ct.DOMAINS['oss'], 'gpzy'),
                     dtype={'code': object})
    # âš ï¸ SAST Risk (Low): Ensure that end_date is validated and sanitized to prevent logical errors.
    return df

   # âœ… Best Practice: Consider using vectorized operations for better performance.
   # âœ… Best Practice: Use of a leading underscore in the function name suggests it's intended for internal use.

def pledged_detail():   
    """
    è‚¡ç¥¨è´¨æŠ¼æ•°æ®
    
    return DataFrame
    --------------
    code: è¯åˆ¸ä»£ç 
    name: è¯åˆ¸åç§°
    ann_date: å…¬å‘Šæ—¥æœŸ
    pledgor:å‡ºè´¨äºº
    pledgee:è´¨æƒäºº
    volume:è´¨æŠ¼æ•°é‡
    from_date:è´¨æŠ¼æ—¥æœŸ
    end_date: è§£é™¤æ—¥æœŸ
    """
    df = pd.read_csv(ct.GPZY_D_URL%(ct.P_TYPE['http'],
                                             ct.DOMAINS['oss'], 'gpzy_detail'),
                     dtype={'code': object, 'ann_date': object, 'end_date': object})
    df['code'] = df['code'].map(lambda x : str(x).zfill(6))
    df['end_date'] = np.where(df['end_date'] == '--', np.NaN, df['end_date'])
    return df



def margin_zsl(date='', broker=''):   
    """
         èèµ„èåˆ¸å……æŠµä¿è¯é‡‘æŠ˜ç®—ç‡
    Parameters
    ---------------
    date:string
            æ—¥æœŸ formatï¼šYYYY-MM-DD æˆ–è€… YYYYMMDD
    broker:
    gtja:å›½æ³°å›å®‰
    yhzq:é“¶æ²³è¯åˆ¸
    gfzqï¼šå¹¿å‘è¯åˆ¸
    zszqï¼šæ‹›å•†è¯åˆ¸
    gxzqï¼šå›½ä¿¡è¯åˆ¸
    swhyï¼šç”³ä¸‡å®æº
    zxjtï¼šä¸­ä¿¡å»ºæŠ•
    zxzqï¼šä¸­ä¿¡è¯åˆ¸
    
    return DataFrame
    --------------
    code: è¯åˆ¸ä»£ç 
    name: è¯åˆ¸åç§°
    ratio:æ¯”ç‡
    broker:åˆ¸å•†ä»£ç 
    """
    date = str(date).replace('-', '')
    df = pd.read_csv(ct.MG_ZSL_URL%(ct.P_TYPE['http'],
                                             ct.DOMAINS['oss'], date[0:6], broker, date),
                     dtype={'code': object})
    return df


def stock_issuance(start_date='', end_date=''):
    """
         è‚¡ç¥¨å¢å‘
    Parameters
    ---------------
    start_date:string
    end_date:string
            æ—¥æœŸ formatï¼šYYYY-MM-DD
            
    return DataFrame
    --------------
    code: è¯åˆ¸ä»£ç 
    name: è¯åˆ¸åç§°
    type:ç±»å‹ï¼Œå®šå‘å¢å‘/å…¬å¼€å¢å‘
    count:æ•°é‡
    price:å¢å‘ä»·æ ¼
    close:æœ€è¿‘æ”¶ç›˜ä»·
    issue_date:å¢å‘æ—¥æœŸ
    list_date:ä¸Šå¸‚æ—¥æœŸ
    locked_year:é”å®šå¹´æ•°
    prem:æˆªæ­¢å½“å‰æº¢ä»·(%)
    """
    df = pd.read_csv(ct.ZF%(ct.P_TYPE['http'],
                                             ct.DOMAINS['oss'], 'zf'),
                     dtype={'code': object})
    if start_date != '' and start_date is not None:
        df = df[df.issue_date >= start_date]
    if end_date != '' and end_date is not None:
        df = df[df.issue_date <= start_date]
    df['prem'] = (df['close'] - df['price']) / df['price'] * 100
    df['prem'] = df['prem'].map(ct.FORMAT)
    df['prem'] = df['prem'].astype(float)
    return df
 
    
def _random(n=13):
    from random import randint
    start = 10**(n-1)
    end = (10**n)-1
    return str(randint(start, end))