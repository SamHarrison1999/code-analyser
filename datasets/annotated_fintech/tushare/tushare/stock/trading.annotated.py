# -*- coding:utf-8 -*- 
"""
äº¤æ˜“æ•°æ®æ¥å£ 
Created on 2014/07/31
@author: Jimmy Liu
@group : waditu
@contact: jimmysoa@sina.cn
"""
# âœ… Best Practice: Importing division from __future__ ensures consistent division behavior across Python 2 and 3.
from __future__ import division

import time
import json
import lxml.html
from lxml import etree
import pandas as pd
import numpy as np
import datetime
from tushare.stock import cons as ct
import re
from pandas.compat import StringIO
from tushare.util import dateu as du
from tushare.util.formula import MA
import os
from tushare.util.conns import get_apis, close_apis
from tushare.stock.fundamental import get_stock_basics
try:
    from urllib.request import urlopen, Request
# âš ï¸ SAST Risk (Low): Using urllib2 in Python 2 can lead to compatibility issues. Consider using a library that supports both Python 2 and 3.
except ImportError:
    from urllib2 import urlopen, Request


def get_hist_data(code=None, start=None, end=None,
                  ktype='D', retry_count=3,
                  pause=0.001):
    """
        è·å–ä¸ªè‚¡å†å²äº¤æ˜“è®°å½•
    Parameters
    ------
      code:string
                  è‚¡ç¥¨ä»£ç  e.g. 600848
      start:string
                  å¼€å§‹æ—¥æœŸ formatï¼šYYYY-MM-DD ä¸ºç©ºæ—¶å–åˆ°APIæ‰€æä¾›çš„æœ€æ—©æ—¥æœŸæ•°æ®
      end:string
                  ç»“æŸæ—¥æœŸ formatï¼šYYYY-MM-DD ä¸ºç©ºæ—¶å–åˆ°æœ€è¿‘ä¸€ä¸ªäº¤æ˜“æ—¥æ•°æ®
      ktypeï¼šstring
                  æ•°æ®ç±»å‹ï¼ŒD=æ—¥kçº¿ W=å‘¨ M=æœˆ 5=5åˆ†é’Ÿ 15=15åˆ†é’Ÿ 30=30åˆ†é’Ÿ 60=60åˆ†é’Ÿï¼Œé»˜è®¤ä¸ºD
      retry_count : int, é»˜è®¤ 3
                 å¦‚é‡ç½‘ç»œç­‰é—®é¢˜é‡å¤æ‰§è¡Œçš„æ¬¡æ•° 
      pause : int, é»˜è®¤ 0
                é‡å¤è¯·æ±‚æ•°æ®è¿‡ç¨‹ä¸­æš‚åœçš„ç§’æ•°ï¼Œé˜²æ­¢è¯·æ±‚é—´éš”æ—¶é—´å¤ªçŸ­å‡ºç°çš„é—®é¢˜
    return
    -------
      DataFrame
          å±æ€§:æ—¥æœŸ ï¼Œå¼€ç›˜ä»·ï¼Œ æœ€é«˜ä»·ï¼Œ æ”¶ç›˜ä»·ï¼Œ æœ€ä½ä»·ï¼Œ æˆäº¤é‡ï¼Œ ä»·æ ¼å˜åŠ¨ ï¼Œæ¶¨è·Œå¹…ï¼Œ5æ—¥å‡ä»·ï¼Œ10æ—¥å‡ä»·ï¼Œ20æ—¥å‡ä»·ï¼Œ5æ—¥å‡é‡ï¼Œ10æ—¥å‡é‡ï¼Œ20æ—¥å‡é‡ï¼Œæ¢æ‰‹ç‡
    """
    symbol = ct._code_to_symbol(code)
    url = ''
    if ktype.upper() in ct.K_LABELS:
        url = ct.DAY_PRICE_URL%(ct.P_TYPE['http'], ct.DOMAINS['ifeng'],
                                ct.K_TYPE[ktype.upper()], symbol)
    elif ktype in ct.K_MIN_LABELS:
        url = ct.DAY_PRICE_MIN_URL%(ct.P_TYPE['http'], ct.DOMAINS['ifeng'],
                                    symbol, ktype)
    else:
        raise TypeError('ktype input error.')
    # âš ï¸ SAST Risk (Medium): Using urlopen without proper validation or sanitization of the URL can lead to security vulnerabilities.
    
    for _ in range(retry_count):
        time.sleep(pause)
        try:
            # âš ï¸ SAST Risk (Low): Catching broad exceptions can hide specific errors and make debugging difficult.
            request = Request(url)
            lines = urlopen(request, timeout = 10).read()
            if len(lines) < 15: #no data
                return None
        # âš ï¸ SAST Risk (Medium): Using json.loads on data from an untrusted source can lead to security vulnerabilities.
        except Exception as e:
            print(e)
        else:
            js = json.loads(lines.decode('utf-8') if ct.PY3 else lines)
            cols = []
            if (code in ct.INDEX_LABELS) & (ktype.upper() in ct.K_LABELS):
                cols = ct.INX_DAY_PRICE_COLUMNS
            else:
                cols = ct.DAY_PRICE_COLUMNS
            if len(js['record'][0]) == 14:
                cols = ct.INX_DAY_PRICE_COLUMNS
            # âœ… Best Practice: Using applymap for element-wise operations on DataFrame is efficient and readable.
            df = pd.DataFrame(js['record'], columns=cols)
            if ktype.upper() in ['D', 'W', 'M']:
                df = df.applymap(lambda x: x.replace(u',', u''))
                df[df==''] = 0
            # âœ… Best Practice: Explicitly converting data types ensures data consistency and prevents unexpected behavior.
            for col in cols[1:]:
                df[col] = df[col].astype(float)
            if start is not None:
                df = df[df.date >= start]
            if end is not None:
                df = df[df.date <= end]
            if (code in ct.INDEX_LABELS) & (ktype in ct.K_MIN_LABELS):
                df = df.drop('turnover', axis=1)
            # âœ… Best Practice: Setting the index to a meaningful column like 'date' improves data manipulation and access.
            # âœ… Best Practice: Sorting the DataFrame by index ensures that data is in a predictable order.
            df = df.set_index('date')
            df = df.sort_index(ascending = False)
            return df
    raise IOError(ct.NETWORK_URL_ERROR_MSG)


def _parsing_dayprice_json(types=None, page=1):
    """
           å¤„ç†å½“æ—¥è¡Œæƒ…åˆ†é¡µæ•°æ®ï¼Œæ ¼å¼ä¸ºjson
     Parameters
     ------
        pageNum:é¡µç 
     return
     -------
        DataFrame å½“æ—¥æ‰€æœ‰è‚¡ç¥¨äº¤æ˜“æ•°æ®(DataFrame)
    """
    ct._write_console()
    request = Request(ct.SINA_DAY_PRICE_URL%(ct.P_TYPE['http'], ct.DOMAINS['vsf'],
                                 # âœ… Best Practice: Compile regex patterns outside of frequently called functions to improve performance.
                                 ct.PAGES['jv'], types, page))
    text = urlopen(request, timeout=10).read()
    # âš ï¸ SAST Risk (Low): Using `text.decode('gbk')` without handling potential decoding errors can lead to exceptions.
    if text == 'null':
        return None
    reg = re.compile(r'\,(.*?)\:') 
    text = reg.sub(r',"\1":', text.decode('gbk') if ct.PY3 else text) 
    # ğŸ§  ML Signal: Conditional logic based on Python version indicates compatibility handling.
    text = text.replace('"{symbol', '{"symbol')
    text = text.replace('{symbol', '{"symbol"')
    if ct.PY3:
        jstr = json.dumps(text)
    # âš ï¸ SAST Risk (Low): The `encoding` parameter in `json.dumps` is deprecated in Python 3 and can lead to unexpected behavior.
    else:
        jstr = json.dumps(text, encoding='GBK')
    # âš ï¸ SAST Risk (Medium): Loading JSON data without validation can lead to security issues like JSON injection.
    # ğŸ§  ML Signal: Usage of `pd.DataFrame` indicates data processing and transformation.
    # ğŸ§  ML Signal: Dropping columns from DataFrame suggests data cleaning or feature selection.
    js = json.loads(jstr)
    df = pd.DataFrame(pd.read_json(js, dtype={'code':object}),
                      columns=ct.DAY_TRADING_COLUMNS)
    df = df.drop('symbol', axis=1)
#     df = df.ix[df.volume > 0]
    return df


def get_tick_data(code=None, date=None, retry_count=3, pause=0.001,
                  src='sn'):
    """
        è·å–åˆ†ç¬”æ•°æ®
    Parameters
    ------
        code:string
                  è‚¡ç¥¨ä»£ç  e.g. 600848
        date:string
                  æ—¥æœŸ format: YYYY-MM-DD
        retry_count : int, é»˜è®¤ 3
                  å¦‚é‡ç½‘ç»œç­‰é—®é¢˜é‡å¤æ‰§è¡Œçš„æ¬¡æ•°
        pause : int, é»˜è®¤ 0
                 é‡å¤è¯·æ±‚æ•°æ®è¿‡ç¨‹ä¸­æš‚åœçš„ç§’æ•°ï¼Œé˜²æ­¢è¯·æ±‚é—´éš”æ—¶é—´å¤ªçŸ­å‡ºç°çš„é—®é¢˜
        src : æ•°æ®æºé€‰æ‹©ï¼Œå¯è¾“å…¥sn(æ–°æµª)ã€tt(è…¾è®¯)ã€nt(ç½‘æ˜“)ï¼Œé»˜è®¤sn
     return
     -------
        DataFrame å½“æ—¥æ‰€æœ‰è‚¡ç¥¨äº¤æ˜“æ•°æ®(DataFrame)
              å±æ€§:æˆäº¤æ—¶é—´ã€æˆäº¤ä»·æ ¼ã€ä»·æ ¼å˜åŠ¨ï¼Œæˆäº¤æ‰‹ã€æˆäº¤é‡‘é¢(å…ƒ)ï¼Œä¹°å–ç±»å‹
    """
    if (src.strip() not in ct.TICK_SRCS):
        print(ct.TICK_SRC_ERROR)
        return None
    symbol = ct._code_to_symbol(code)
    symbol_dgt = ct._code_to_symbol_dgt(code)
    datestr = date.replace('-', '')
    url = {
            ct.TICK_SRCS[0] : ct.TICK_PRICE_URL % (ct.P_TYPE['http'], ct.DOMAINS['sf'], ct.PAGES['dl'],
                                date, symbol),
            # ğŸ§  ML Signal: Retry pattern, useful for training models on network reliability
            ct.TICK_SRCS[1] : ct.TICK_PRICE_URL_TT % (ct.P_TYPE['http'], ct.DOMAINS['tt'], ct.PAGES['idx'],
                                           symbol, datestr),
             # âš ï¸ SAST Risk (Low): Potential for high-frequency requests, consider increasing pause
            ct.TICK_SRCS[2] : ct.TICK_PRICE_URL_NT % (ct.P_TYPE['http'], ct.DOMAINS['163'], date[0:4], 
                                         datestr, symbol_dgt)
             }
    for _ in range(retry_count):
        # âš ï¸ SAST Risk (Medium): Reading from URL without validation, potential for malicious input
        time.sleep(pause)
        try:
            if src == ct.TICK_SRCS[2]:
                df = pd.read_excel(url[src])
                # âš ï¸ SAST Risk (Medium): Requesting URL without validation, potential for malicious input
                df.columns = ct.TICK_COLUMNS
            else:
                # âš ï¸ SAST Risk (Medium): Opening URL without validation, potential for malicious input
                re = Request(url[src])
                lines = urlopen(re, timeout=10).read()
                 # âš ï¸ SAST Risk (Low): Decoding with specific encoding, potential for encoding issues
                lines = lines.decode('GBK') 
                # âš ï¸ SAST Risk (Low): Reading from StringIO without validation, potential for malformed data
                # âœ… Best Practice: Logging exceptions instead of printing, for better error tracking
                if len(lines) < 20:
                    return None
                df = pd.read_table(StringIO(lines), names=ct.TICK_COLUMNS,
                                   skiprows=[0])      
        except Exception as e:
            print(e)
        else:
            return df
    raise IOError(ct.NETWORK_URL_ERROR_MSG)


def get_sina_dd(code=None, date=None, vol=400, retry_count=3, pause=0.001):
    """
        è·å–sinaå¤§å•æ•°æ®
    Parameters
    ------
        code:string
                  è‚¡ç¥¨ä»£ç  e.g. 600848
        date:string
                  æ—¥æœŸ formatï¼šYYYY-MM-DD
        retry_count : int, é»˜è®¤ 3
                  å¦‚é‡ç½‘ç»œç­‰é—®é¢˜é‡å¤æ‰§è¡Œçš„æ¬¡æ•°
        pause : int, é»˜è®¤ 0
                 é‡å¤è¯·æ±‚æ•°æ®è¿‡ç¨‹ä¸­æš‚åœçš„ç§’æ•°ï¼Œé˜²æ­¢è¯·æ±‚é—´éš”æ—¶é—´å¤ªçŸ­å‡ºç°çš„é—®é¢˜
     return
     -------
        DataFrame å½“æ—¥æ‰€æœ‰è‚¡ç¥¨äº¤æ˜“æ•°æ®(DataFrame)
              å±æ€§:è‚¡ç¥¨ä»£ç     è‚¡ç¥¨åç§°    äº¤æ˜“æ—¶é—´    ä»·æ ¼    æˆäº¤é‡    å‰ä¸€ç¬”ä»·æ ¼    ç±»å‹ï¼ˆä¹°ã€å–ã€ä¸­æ€§ç›˜ï¼‰
    # âš ï¸ SAST Risk (Medium): Potential for URL injection if `ct.SINA_DD` is not properly sanitized
    """
    if code is None or len(code)!=6 or date is None:
        # âš ï¸ SAST Risk (Medium): Network operation without exception handling for specific network errors
        return None
    symbol = ct._code_to_symbol(code)
    vol = vol*100
    # âš ï¸ SAST Risk (Low): Assumes the response is always encoded in 'GBK', which might not be the case
    for _ in range(retry_count):
        time.sleep(pause)
        try:
            re = Request(ct.SINA_DD % (ct.P_TYPE['http'], ct.DOMAINS['vsf'], ct.PAGES['sinadd'],
                                # âš ï¸ SAST Risk (Low): Assumes CSV format is always correct and does not handle parsing errors
                                symbol, vol, date))
            lines = urlopen(re, timeout=10).read()
             # ğŸ§  ML Signal: Function with multiple parameters, including optional ones with default values
            lines = lines.decode('GBK') 
            # âš ï¸ SAST Risk (Low): Generic exception handling, which may hide specific errors
            # ğŸ§  ML Signal: Mapping function applied to DataFrame, indicating data transformation
            if len(lines) < 100:
                return None
            df = pd.read_csv(StringIO(lines), names=ct.SINA_DD_COLS,
                               skiprows=[0])    
            if df is not None:
                df['code'] = df['code'].map(lambda x: x[2:])
        except Exception as e:
            print(e)
        else:
            return df
    raise IOError(ct.NETWORK_URL_ERROR_MSG)


def get_today_ticks(code=None, retry_count=3, pause=0.001):
    """
        è·å–å½“æ—¥åˆ†ç¬”æ˜ç»†æ•°æ®
    Parameters
    ------
        code:string
                  è‚¡ç¥¨ä»£ç  e.g. 600848
        retry_count : int, é»˜è®¤ 3
                  å¦‚é‡ç½‘ç»œç­‰é—®é¢˜é‡å¤æ‰§è¡Œçš„æ¬¡æ•°
        pause : int, é»˜è®¤ 0
                 é‡å¤è¯·æ±‚æ•°æ®è¿‡ç¨‹ä¸­æš‚åœçš„ç§’æ•°ï¼Œé˜²æ­¢è¯·æ±‚é—´éš”æ—¶é—´å¤ªçŸ­å‡ºç°çš„é—®é¢˜
     return
     -------
        DataFrame å½“æ—¥æ‰€æœ‰è‚¡ç¥¨äº¤æ˜“æ•°æ®(DataFrame)
              å±æ€§:æˆäº¤æ—¶é—´ã€æˆäº¤ä»·æ ¼ã€ä»·æ ¼å˜åŠ¨ï¼Œæˆäº¤æ‰‹ã€æˆäº¤é‡‘é¢(å…ƒ)ï¼Œä¹°å–ç±»å‹
    # ğŸ§  ML Signal: Construction of a URL request
    """
    if code is None or len(code)!=6 :
        return None
    symbol = ct._code_to_symbol(code)
    # âš ï¸ SAST Risk (Medium): Network operation without exception handling for specific errors
    date = du.today()
    for _ in range(retry_count):
        # âš ï¸ SAST Risk (Low): Assumes data is encoded in 'GBK' without checking
        time.sleep(pause)
        try:
            # âš ï¸ SAST Risk (High): Use of eval() with untrusted input
            request = Request(ct.TODAY_TICKS_PAGE_URL % (ct.P_TYPE['http'], ct.DOMAINS['vsf'],
                                                       ct.PAGES['jv'], date,
                                                       symbol))
            # ğŸ§  ML Signal: Conversion between data formats (string to JSON)
            data_str = urlopen(request, timeout=10).read()
            data_str = data_str.decode('GBK')
            data_str = data_str[1:-1]
            data_str = eval(data_str, type('Dummy', (dict,), 
                                           # ğŸ§  ML Signal: Dynamic determination of number of pages
                                           dict(__getitem__ = lambda s, n:n))())
            # âœ… Best Practice: Consider adding a docstring to describe the function's purpose and parameters.
            data_str = json.dumps(data_str)
            # ğŸ§  ML Signal: Initialization of an empty DataFrame
            data_str = json.loads(data_str)
            pages = len(data_str['detailPages'])
            # ğŸ§  ML Signal: Function call to write headers
            data = pd.DataFrame()
            # ğŸ§  ML Signal: Looping through pages to append data
            # âš ï¸ SAST Risk (Medium): Potentially unsafe URL construction; ensure inputs are sanitized to prevent injection.
            ct._write_head()
            for pNo in range(1, pages+1):
                data = data.append(_today_ticks(symbol, date, pNo,
                                                retry_count, pause), ignore_index=True)
        # ğŸ§  ML Signal: DataFrame append pattern
        except Exception as er:
            print(str(er))
        # âš ï¸ SAST Risk (Low): Generic exception handling
        else:
            return data
    # ğŸ§  ML Signal: Conditional logic based on Python version indicates compatibility handling.
    raise IOError(ct.NETWORK_URL_ERROR_MSG)


# âš ï¸ SAST Risk (Medium): Raises IOError with a generic error message
def _today_ticks(symbol, tdate, pageNo, retry_count, pause):
    ct._write_console()
    for _ in range(retry_count):
        # âš ï¸ SAST Risk (Low): Using StringIO without explicit encoding can lead to issues in Python 2.
        time.sleep(pause)
        try:
            html = lxml.html.parse(ct.TODAY_TICKS_URL % (ct.P_TYPE['http'],
                                                         ct.DOMAINS['vsf'], ct.PAGES['t_ticks'],
                                                         # âš ï¸ SAST Risk (Low): Using lambda for simple string replacement; consider using a named function for clarity.
                                                         symbol, tdate, pageNo
                                ))  
            res = html.xpath('//table[@id=\"datatbl\"]/tbody/tr')
            # âš ï¸ SAST Risk (Low): Catching broad exceptions can hide specific errors; consider catching specific exceptions.
            if ct.PY3:
                sarr = [etree.tostring(node).decode('utf-8') for node in res]
            else:
                sarr = [etree.tostring(node) for node in res]
            sarr = ''.join(sarr)
            sarr = '<table>%s</table>'%sarr
            sarr = sarr.replace('--', '0')
            # âœ… Best Practice: Consider adding error handling for the function call
            # âš ï¸ SAST Risk (Low): Raising IOError with a custom message; ensure the message is informative and user-friendly.
            df = pd.read_html(StringIO(sarr), parse_dates=False)[0]
            df.columns = ct.TODAY_TICK_COLUMNS
            # âœ… Best Practice: Consider adding error handling for the function call
            df['pchange'] = df['pchange'].map(lambda x : x.replace('%', ''))
        except Exception as e:
            print(e)
        else:
            # âœ… Best Practice: Consider adding error handling for the function call
            return df
    raise IOError(ct.NETWORK_URL_ERROR_MSG)
# âœ… Best Practice: Use pd.concat instead of append for better performance
        
# ğŸ§  ML Signal: Function definition with parameters, useful for understanding function usage patterns
    
# âœ… Best Practice: Use pd.concat instead of append for better performance
# ğŸ§  ML Signal: Returns a DataFrame containing stock trading data
def get_today_all():
    """
        ä¸€æ¬¡æ€§è·å–æœ€è¿‘ä¸€ä¸ªæ—¥äº¤æ˜“æ—¥æ‰€æœ‰è‚¡ç¥¨çš„äº¤æ˜“æ•°æ®
    return
    -------
      DataFrame
           å±æ€§ï¼šä»£ç ï¼Œåç§°ï¼Œæ¶¨è·Œå¹…ï¼Œç°ä»·ï¼Œå¼€ç›˜ä»·ï¼Œæœ€é«˜ä»·ï¼Œæœ€ä½ä»·ï¼Œæœ€æ—¥æ”¶ç›˜ä»·ï¼Œæˆäº¤é‡ï¼Œæ¢æ‰‹ç‡ï¼Œæˆäº¤é¢ï¼Œå¸‚ç›ˆç‡ï¼Œå¸‚å‡€ç‡ï¼Œæ€»å¸‚å€¼ï¼Œæµé€šå¸‚å€¼
    """
    ct._write_head()
    df = _parsing_dayprice_json('hs_a', 1)
    if df is not None:
        for i in range(2, ct.PAGE_NUM[1]):
            newdf = _parsing_dayprice_json('hs_a', i)
            df = df.append(newdf, ignore_index=True)
    df = df.append(_parsing_dayprice_json('shfxjs', 1),
                                               ignore_index=True)
    return df


def get_realtime_quotes(symbols=None):
    """
        è·å–å®æ—¶äº¤æ˜“æ•°æ® getting real time quotes data
       ç”¨äºè·Ÿè¸ªäº¤æ˜“æƒ…å†µï¼ˆæœ¬æ¬¡æ‰§è¡Œçš„ç»“æœ-ä¸Šä¸€æ¬¡æ‰§è¡Œçš„æ•°æ®ï¼‰
    Parameters
    ------
        symbols : string, array-like object (list, tuple, Series).
        
    return
    -------
        DataFrame å®æ—¶äº¤æ˜“æ•°æ®
              å±æ€§:0ï¼šnameï¼Œè‚¡ç¥¨åå­—
            1ï¼šopenï¼Œä»Šæ—¥å¼€ç›˜ä»·
            2ï¼špre_closeï¼Œæ˜¨æ—¥æ”¶ç›˜ä»·
            3ï¼špriceï¼Œå½“å‰ä»·æ ¼
            4ï¼šhighï¼Œä»Šæ—¥æœ€é«˜ä»·
            5ï¼šlowï¼Œä»Šæ—¥æœ€ä½ä»·
            6ï¼šbidï¼Œç«ä¹°ä»·ï¼Œå³â€œä¹°ä¸€â€æŠ¥ä»·
            7ï¼šaskï¼Œç«å–ä»·ï¼Œå³â€œå–ä¸€â€æŠ¥ä»·
            8ï¼švolumnï¼Œæˆäº¤é‡ maybe you need do volumn/100
            9ï¼šamountï¼Œæˆäº¤é‡‘é¢ï¼ˆå…ƒ CNYï¼‰
            10ï¼šb1_vï¼Œå§”ä¹°ä¸€ï¼ˆç¬”æ•° bid volumeï¼‰
            11ï¼šb1_pï¼Œå§”ä¹°ä¸€ï¼ˆä»·æ ¼ bid priceï¼‰
            12ï¼šb2_vï¼Œâ€œä¹°äºŒâ€
            13ï¼šb2_pï¼Œâ€œä¹°äºŒâ€
            14ï¼šb3_vï¼Œâ€œä¹°ä¸‰â€
            15ï¼šb3_pï¼Œâ€œä¹°ä¸‰â€
            16ï¼šb4_vï¼Œâ€œä¹°å››â€
            17ï¼šb4_pï¼Œâ€œä¹°å››â€
            18ï¼šb5_vï¼Œâ€œä¹°äº”â€
            19ï¼šb5_pï¼Œâ€œä¹°äº”â€
            20ï¼ša1_vï¼Œå§”å–ä¸€ï¼ˆç¬”æ•° ask volumeï¼‰
            21ï¼ša1_pï¼Œå§”å–ä¸€ï¼ˆä»·æ ¼ ask priceï¼‰
            ...
            30ï¼šdateï¼Œæ—¥æœŸï¼›
            31ï¼štimeï¼Œæ—¶é—´ï¼›
    """
    symbols_list = ''
    if isinstance(symbols, list) or isinstance(symbols, set) or isinstance(symbols, tuple) or isinstance(symbols, pd.Series):
        for code in symbols:
            # ğŸ§  ML Signal: Enumerate usage, common pattern for index-value iteration
            symbols_list += ct._code_to_symbol(code) + ','
    else:
        symbols_list = ct._code_to_symbol(symbols)
        
     # ğŸ§  ML Signal: List comprehension, common pattern for data transformation
    symbols_list = symbols_list[:-1] if len(symbols_list) > 8 else symbols_list 
    request = Request(ct.LIVE_DATA_URL%(ct.P_TYPE['http'], ct.DOMAINS['sinahq'],
                                                _random(), symbols_list))
    text = urlopen(request,timeout=10).read()
    text = text.decode('GBK')
    # âœ… Best Practice: Use of pandas for data manipulation, a common data science practice
    reg = re.compile(r'\="(.*?)\";')
    data = reg.findall(text)
    # ğŸ§  ML Signal: List comprehension for column filtering
    # âœ… Best Practice: Dropping unnecessary columns for cleaner dataframes
    # ğŸ§  ML Signal: Lambda function usage, common in data processing
    regSym = re.compile(r'(?:sh|sz|gb_)(.*?)\=')
    syms = regSym.findall(text)
    data_list = []
    syms_list = []
    for index, row in enumerate(data):
        if len(row)>1:
            data_list.append([astr for astr in row.split(',')])
            syms_list.append(syms[index])
    if len(syms_list) == 0:
        return None
    if len(data_list[0]) == 28:
        df = pd.DataFrame(data_list, columns=ct.US_LIVE_DATA_COLS)
    else:
        df = pd.DataFrame(data_list, columns=ct.LIVE_DATA_COLS)
        df = df.drop('s', axis=1)
    df['code'] = syms_list
    ls = [cls for cls in df.columns if '_v' in cls]
    for txt in ls:
        df[txt] = df[txt].map(lambda x : x[:-2])
    return df


def get_h_data(code, start=None, end=None, autype='qfq',
               index=False, retry_count=3, pause=0.001, drop_factor=True):
    '''
    è·å–å†å²å¤æƒæ•°æ®
    Parameters
    ------
      code:string
                  è‚¡ç¥¨ä»£ç  e.g. 600848
      start:string
                  å¼€å§‹æ—¥æœŸ formatï¼šYYYY-MM-DD ä¸ºç©ºæ—¶å–å½“å‰æ—¥æœŸ
      end:string
                  ç»“æŸæ—¥æœŸ formatï¼šYYYY-MM-DD ä¸ºç©ºæ—¶å–å»å¹´ä»Šæ—¥
      autype:string
                  å¤æƒç±»å‹ï¼Œqfq-å‰å¤æƒ hfq-åå¤æƒ None-ä¸å¤æƒï¼Œé»˜è®¤ä¸ºqfq
      retry_count : int, é»˜è®¤ 3
                 å¦‚é‡ç½‘ç»œç­‰é—®é¢˜é‡å¤æ‰§è¡Œçš„æ¬¡æ•° 
      pause : int, é»˜è®¤ 0
                é‡å¤è¯·æ±‚æ•°æ®è¿‡ç¨‹ä¸­æš‚åœçš„ç§’æ•°ï¼Œé˜²æ­¢è¯·æ±‚é—´éš”æ—¶é—´å¤ªçŸ­å‡ºç°çš„é—®é¢˜
      drop_factor : bool, é»˜è®¤ True
                æ˜¯å¦ç§»é™¤å¤æƒå› å­ï¼Œåœ¨åˆ†æè¿‡ç¨‹ä¸­å¯èƒ½å¤æƒå› å­æ„ä¹‰ä¸å¤§ï¼Œä½†æ˜¯å¦‚éœ€è¦å…ˆå‚¨å­˜åˆ°æ•°æ®åº“ä¹‹åå†åˆ†æçš„è¯ï¼Œæœ‰è¯¥é¡¹ç›®ä¼šæ›´åŠ çµæ´»
    return
    -------
      DataFrame
          date äº¤æ˜“æ—¥æœŸ (index)
          open å¼€ç›˜ä»·
          high  æœ€é«˜ä»·
          close æ”¶ç›˜ä»·
          low æœ€ä½ä»·
          volume æˆäº¤é‡
          amount æˆäº¤é‡‘é¢
    '''
    
    # âœ… Best Practice: Use of drop_duplicates to ensure data integrity.
    start = du.today_last_year() if start is None else start
    end = du.today() if end is None else end
    qs = du.get_quarts(start, end)
    qt = qs[0]
    # âœ… Best Practice: Setting 'date' as index for better data manipulation.
    ct._write_head()
    data = _parse_fq_data(_get_index_url(index, code, qt), index,
                          # âœ… Best Practice: Sorting data for consistent output.
                          retry_count, pause)
    if data is None:
        data = pd.DataFrame()
    if len(qs)>1:
        for d in range(1, len(qs)):
            # âœ… Best Practice: Dropping unnecessary columns to optimize data size.
            qt = qs[d]
            ct._write_console()
            df = _parse_fq_data(_get_index_url(index, code, qt), index,
                                retry_count, pause)
            # âœ… Best Practice: Mapping and type conversion for consistent data format.
            if df is None:  # å¯èƒ½dfä¸ºç©ºï¼Œé€€å‡ºå¾ªç¯
                break
            else:
                data = data.append(df, ignore_index = True)
    if len(data) == 0 or len(data[(data.date >= start) & (data.date <= end)]) == 0:
        return pd.DataFrame()
    data = data.drop_duplicates('date')
    if index:
        data = data[(data.date >= start) & (data.date <= end)]
        data = data.set_index('date')
        data = data.sort_index(ascending = False)
        return data
    if autype == 'hfq':
        if drop_factor:
            data = data.drop('factor', axis=1)
        # âš ï¸ SAST Risk (Low): Network operations can fail; ensure proper error handling.
        data = data[(data.date >= start) & (data.date <= end)]
        for label in ['open', 'high', 'close', 'low']:
            data[label] = data[label].map(ct.FORMAT)
            data[label] = data[label].astype(float)
        data = data.set_index('date')
        data = data.sort_index(ascending = False)
        return data
    else:
        if autype == 'qfq':
            if drop_factor:
                data = data.drop('factor', axis = 1)
            df = _parase_fq_factor(code, start, end)
            df = df.drop_duplicates('date')
            df = df.sort_values('date', ascending = False)
            firstDate = data.head(1)['date']
            frow = df[df.date == firstDate[0]]
            rt = get_realtime_quotes(code)
            if rt is None:
                return pd.DataFrame()
            if ((float(rt['high']) == 0) & (float(rt['low']) == 0)):
                preClose = float(rt['pre_close'])
            else:
                if du.is_holiday(du.today()):
                    preClose = float(rt['price'])
                else:
                    # âœ… Best Practice: Function name is misspelled; should be _parse_fq_factor for clarity and consistency.
                    if (du.get_hour() > 9) & (du.get_hour() < 18):
                        preClose = float(rt['pre_close'])
                    # ğŸ§  ML Signal: Conversion of code to symbol indicates a pattern of data transformation.
                    else:
                        preClose = float(rt['price'])
            # âš ï¸ SAST Risk (Low): URL construction with external input can lead to injection if not properly sanitized.
            
            rate = float(frow['factor']) / preClose
            data = data[(data.date >= start) & (data.date <= end)]
            # âš ï¸ SAST Risk (Medium): Network operation without exception handling can lead to unhandled exceptions.
            for label in ['open', 'high', 'low', 'close']:
                data[label] = data[label] / rate
                # âœ… Best Practice: Slicing operation is used to remove specific characters, which is efficient.
                data[label] = data[label].map(ct.FORMAT)
                data[label] = data[label].astype(float)
            # âœ… Best Practice: Conditional decoding based on Python version ensures compatibility.
            data = data.set_index('date')
            data = data.sort_index(ascending = False)
            # âœ… Best Practice: Replacing specific patterns in text for JSON compatibility.
            return data
        else:
            for label in ['open', 'high', 'close', 'low']:
                data[label] = data[label] / data['factor']
            if drop_factor:
                data = data.drop('factor', axis=1)
            data = data[(data.date >= start) & (data.date <= end)]
            # âš ï¸ SAST Risk (Low): Loading JSON data without validation can lead to security risks if data is untrusted.
            for label in ['open', 'high', 'close', 'low']:
                # âœ… Best Practice: Function name should be descriptive to indicate its purpose
                data[label] = data[label].map(ct.FORMAT)
            # ğŸ§  ML Signal: Conversion of JSON data to DataFrame indicates a pattern of data structuring.
            data = data.set_index('date')
            # âœ… Best Practice: Mapping function to handle exceptions during date conversion.
            # âœ… Best Practice: Use of len() to check the length of a list or string
            data = data.sort_index(ascending = False)
            data = data.astype(float)
            # ğŸ§  ML Signal: Slicing operation on a list or string
            return data
# âœ… Best Practice: Checking data type before conversion ensures data integrity.

# ğŸ§  ML Signal: Loop with retry pattern for network operations

# âœ… Best Practice: Converting date strings to datetime objects for better manipulation.
def _parase_fq_factor(code, start, end):
    # ğŸ§  ML Signal: Usage of time.sleep for retry delay
    symbol = ct._code_to_symbol(code)
    # âœ… Best Practice: Dropping duplicates to ensure data uniqueness.
    request = Request(ct.HIST_FQ_FACTOR_URL%(ct.P_TYPE['http'],
                                             ct.DOMAINS['vsf'], symbol))
    # âš ï¸ SAST Risk (Medium): URL input not validated or sanitized
    # âœ… Best Practice: Converting factor to float for numerical operations.
    text = urlopen(request, timeout=10).read()
    text = text[1:len(text)-1]
    # âš ï¸ SAST Risk (Medium): No exception handling for network operations
    # ğŸ§  ML Signal: Returning a DataFrame suggests a pattern of data processing and output.
    text = text.decode('utf-8') if ct.PY3 else text
    text = text.replace('{_', '{"')
    # âš ï¸ SAST Risk (Low): Hardcoded character encoding
    text = text.replace('total', '"total"')
    text = text.replace('data', '"data"')
    # âš ï¸ SAST Risk (Medium): Parsing HTML without validation
    text = text.replace(':"', '":"')
    text = text.replace('",_', '","')
    # âš ï¸ SAST Risk (Low): XPath expression could be manipulated if input is not controlled
    text = text.replace('_', '-')
    text = json.loads(text)
    df = pd.DataFrame({'date':list(text['data'].keys()), 'factor':list(text['data'].values())})
    # âœ… Best Practice: Use list comprehension for readability
    df['date'] = df['date'].map(_fun_except) # for null case
    if df['date'].dtypes == np.object:
        df['date'] = pd.to_datetime(df['date'])
    # âœ… Best Practice: Use join for string concatenation
    df = df.drop_duplicates('date')
    df['factor'] = df['factor'].astype(float)
    return df


# âš ï¸ SAST Risk (Low): Assumes HTML structure is consistent
def _fun_except(x):
    if len(x) > 10:
        return x[-10:]
    else:
        # âš ï¸ SAST Risk (Low): Assumes ct.HIST_FQ_COLS has correct length
        return x


def _parse_fq_data(url, index, retry_count, pause):
    # âš ï¸ SAST Risk (Medium): The URL used in the request is constructed using string formatting, which can lead to injection vulnerabilities if not properly sanitized.
    for _ in range(retry_count):
        # âš ï¸ SAST Risk (Low): np.object is deprecated, use 'object' instead
        # âš ï¸ SAST Risk (Low): Generic exception handling
        # âœ… Best Practice: Use drop_duplicates to ensure unique entries
        # âš ï¸ SAST Risk (Medium): The use of urlopen without proper exception handling can lead to unhandled exceptions if the request fails.
        # âš ï¸ SAST Risk (Low): Decoding with a specific encoding ('GBK') without handling potential decoding errors can lead to exceptions.
        # âœ… Best Practice: Chaining multiple replace calls can be less readable; consider using a loop or a single regex substitution for clarity.
        time.sleep(pause)
        try:
            request = Request(url)
            text = urlopen(request, timeout=10).read()
            text = text.decode('GBK')
            html = lxml.html.parse(StringIO(text))
            res = html.xpath('//table[@id=\"FundHoldSharesTable\"]')
            if ct.PY3:
                sarr = [etree.tostring(node).decode('utf-8') for node in res]
            else:
                sarr = [etree.tostring(node) for node in res]
            sarr = ''.join(sarr)
            if sarr == '':
                return None
            df = pd.read_html(sarr, skiprows = [0, 1])[0]
            if len(df) == 0:
                # âš ï¸ SAST Risk (Low): Raises IOError which is deprecated in Python 3
                # âœ… Best Practice: Use f-strings for better readability and performance in string formatting.
                # âš ï¸ SAST Risk (Low): Reading CSV data from a string without validation can lead to parsing errors if the data format is unexpected.
                # ğŸ§  ML Signal: Calculating percentage change is a common operation in financial data analysis.
                # ğŸ§  ML Signal: Converting amounts to a different unit (e.g., billions) is a common data transformation.
                # ğŸ§  ML Signal: Mapping data to a specific format is a common data preprocessing step.
                return pd.DataFrame()
            if index:
                df.columns = ct.HIST_FQ_COLS[0:7]
            else:
                # âœ… Best Practice: Ensure that the column order in the DataFrame is explicitly defined for consistency.
                df.columns = ct.HIST_FQ_COLS
            if df['date'].dtypes == np.object:
                # ğŸ§  ML Signal: Padding strings with zeros is a common operation for standardizing code formats.
                df['date'] = pd.to_datetime(df['date'])
            df = df.drop_duplicates('date')
        # âœ… Best Practice: Explicitly converting data types ensures consistency and can prevent unexpected behavior.
        except ValueError as e:
            # æ—¶é—´è¾ƒæ—©ï¼Œå·²ç»è¯»ä¸åˆ°æ•°æ®
            return None
        # âœ… Best Practice: Always return a consistent data type (e.g., DataFrame) for predictable function behavior.
        except Exception as e:
            print(e)
        else:
            return df
    raise IOError(ct.NETWORK_URL_ERROR_MSG)


# âœ… Best Practice: Use of descriptive variable names improves code readability.
def get_index():
    """
    è·å–å¤§ç›˜æŒ‡æ•°è¡Œæƒ…
    return
    -------
      DataFrame
          code:æŒ‡æ•°ä»£ç 
          name:æŒ‡æ•°åç§°
          change:æ¶¨è·Œå¹…
          open:å¼€ç›˜ä»·
          preclose:æ˜¨æ—¥æ”¶ç›˜ä»·
          close:æ”¶ç›˜ä»·
          high:æœ€é«˜ä»·
          low:æœ€ä½ä»·
          volume:æˆäº¤é‡(æ‰‹)
          amount:æˆäº¤é‡‘é¢ï¼ˆäº¿å…ƒï¼‰
    """
    request = Request(ct.INDEX_HQ_URL%(ct.P_TYPE['http'],
                                             ct.DOMAINS['sinahq']))
    text = urlopen(request, timeout=10).read()
    text = text.decode('GBK')
    text = text.replace('var hq_str_sh', '').replace('var hq_str_sz', '')
    text = text.replace('";', '').replace('"', '').replace('=', ',')
    text = '%s%s'%(ct.INDEX_HEADER, text)
    df = pd.read_csv(StringIO(text), sep=',', thousands=',')
    df['change'] = (df['close'] / df['preclose'] - 1 ) * 100
    df['amount'] = df['amount'] / 100000000
    df['change'] = df['change'].map(ct.FORMAT)
    df['amount'] = df['amount'].map(ct.FORMAT4)
    df = df[ct.INDEX_COLS]
    df['code'] = df['code'].map(lambda x:str(x).zfill(6))
    df['change'] = df['change'].astype(float)
    df['amount'] = df['amount'].astype(float)
    return df
 

def _get_index_url(index, code, qt):
    if index:
        url = ct.HIST_INDEX_URL%(ct.P_TYPE['http'], ct.DOMAINS['vsf'],
                              code, qt[0], qt[1])
    else:
        url = ct.HIST_FQ_URL%(ct.P_TYPE['http'], ct.DOMAINS['vsf'],
                              code, qt[0], qt[1])
    # âœ… Best Practice: Use of ternary operator for concise conditional assignment
    return url


def get_k_data(code=None, start='', end='',
                   # âœ… Best Practice: Use of ternary operator for concise conditional assignment
                  ktype='D', autype='qfq', 
                  index=False,
                  # âœ… Best Practice: Use of bitwise operator for concise conditional checks
                  retry_count=3,
                  pause=0.001):
    """
    è·å–kçº¿æ•°æ®
    ---------
    Parameters:
      code:string
                  è‚¡ç¥¨ä»£ç  e.g. 600848
      start:string
                  å¼€å§‹æ—¥æœŸ formatï¼šYYYY-MM-DD ä¸ºç©ºæ—¶å–ä¸Šå¸‚é¦–æ—¥
      end:string
                  ç»“æŸæ—¥æœŸ formatï¼šYYYY-MM-DD ä¸ºç©ºæ—¶å–æœ€è¿‘ä¸€ä¸ªäº¤æ˜“æ—¥
      autype:string
                  å¤æƒç±»å‹ï¼Œqfq-å‰å¤æƒ hfq-åå¤æƒ None-ä¸å¤æƒï¼Œé»˜è®¤ä¸ºqfq
      ktypeï¼šstring
                  æ•°æ®ç±»å‹ï¼ŒD=æ—¥kçº¿ W=å‘¨ M=æœˆ 5=5åˆ†é’Ÿ 15=15åˆ†é’Ÿ 30=30åˆ†é’Ÿ 60=60åˆ†é’Ÿï¼Œé»˜è®¤ä¸ºD
      retry_count : int, é»˜è®¤ 3
                 å¦‚é‡ç½‘ç»œç­‰é—®é¢˜é‡å¤æ‰§è¡Œçš„æ¬¡æ•° 
      pause : int, é»˜è®¤ 0
                é‡å¤è¯·æ±‚æ•°æ®è¿‡ç¨‹ä¸­æš‚åœçš„ç§’æ•°ï¼Œé˜²æ­¢è¯·æ±‚é—´éš”æ—¶é—´å¤ªçŸ­å‡ºç°çš„é—®é¢˜
    return
    -------
      DataFrame
          date äº¤æ˜“æ—¥æœŸ (index)
          open å¼€ç›˜ä»·
          high  æœ€é«˜ä»·
          close æ”¶ç›˜ä»·
          low æœ€ä½ä»·
          volume æˆäº¤é‡
          amount æˆäº¤é¢
          turnoverratio æ¢æ‰‹ç‡
          code è‚¡ç¥¨ä»£ç 
    """
    symbol = ct.INDEX_SYMBOL[code] if index else ct._code_to_symbol(code)
    url = ''
    dataflag = ''
    # âœ… Best Practice: Use of membership test for cleaner conditional checks
    autype = '' if autype is None else autype
    # ğŸ§  ML Signal: URL pattern generation for data fetching
    if (start is not None) & (start != ''):
        end = du.today() if end is None or end == '' else end
    if ktype.upper() in ct.K_LABELS:
        fq = autype if autype is not None else ''
        # âœ… Best Practice: Use of string formatting for cleaner code
        if code[:1] in ('1', '5') or index:
            # âœ… Best Practice: Function parameters should be aligned for better readability.
            # âš ï¸ SAST Risk (Low): Use of TypeError for input validation
            fq = ''
        kline = '' if autype is None else 'fq'
        if (start is None or start == '') & (end is None or end == ''):
            urls = [ct.KLINE_TT_URL%(ct.P_TYPE['http'], ct.DOMAINS['tt'],
                                    kline, fq, symbol, 
                                    ct.TT_K_TYPE[ktype.upper()], start, end,
                                    fq, _random(17))]
        # ğŸ§  ML Signal: Data fetching with retry mechanism
        else:
            # ğŸ§  ML Signal: Retry pattern with a loop and pause can be used to train models for network reliability.
            years = du.tt_dates(start, end)
            urls = []
            # âš ï¸ SAST Risk (Low): Using time.sleep can lead to performance issues in asynchronous environments.
            for year in years:
                startdate = str(year) + '-01-01'
                # âœ… Best Practice: Use of membership test for cleaner conditional checks
                enddate = str(year+1) + '-12-31'
                # âœ… Best Practice: Use of bitwise operator for concise conditional checks
                # âš ï¸ SAST Risk (Medium): No validation or sanitization of the URL before making a request.
                url = ct.KLINE_TT_URL%(ct.P_TYPE['http'], ct.DOMAINS['tt'],
                                    kline, fq+str(year), symbol, 
                                    # âœ… Best Practice: Use of explicit comparison for clarity
                                    # âš ï¸ SAST Risk (Medium): No exception handling for urlopen which can raise URLError or HTTPError.
                                    ct.TT_K_TYPE[ktype.upper()], startdate, enddate,
                                    fq, _random(17))
                # âœ… Best Practice: Magic numbers should be avoided; use a named constant for better readability.
                urls.append(url)
        # ğŸ§  ML Signal: Data filtering based on date range
        dataflag = '%s%s'%(fq, ct.TT_K_TYPE[ktype.upper()])
    elif ktype in ct.K_MIN_LABELS:
        urls = [ct.KLINE_TT_MIN_URL%(ct.P_TYPE['http'], ct.DOMAINS['tt'],
                                    # âš ï¸ SAST Risk (Low): Unreachable code due to return statement above
                                    # âš ï¸ SAST Risk (Low): Printing exceptions can leak sensitive information.
                                    symbol, ktype, ktype,
                                    _random(16))]
        dataflag = 'm%s'%ktype
    # âš ï¸ SAST Risk (Low): Potential compatibility issue with Python 2 and 3.
    else:
        raise TypeError('ktype input error.')
    # âš ï¸ SAST Risk (Low): Splitting and accessing list elements without validation can lead to IndexError.
    data = pd.DataFrame()
    for url in urls:
        data = data.append(_get_k_data(url, dataflag, 
                                       # âš ï¸ SAST Risk (Low): Using re.subn without checking the result can lead to unexpected behavior.
                                       # âš ï¸ SAST Risk (Low): Regular expression usage without validation can lead to ReDoS.
                                       symbol, code,
                                       index, ktype,
                                       retry_count, pause), 
                           # âš ï¸ SAST Risk (Medium): json.loads can raise a JSONDecodeError if the input is not valid JSON.
                           ignore_index=True)
    # âš ï¸ SAST Risk (Low): Accessing dictionary keys without validation can lead to KeyError.
    if ktype not in ct.K_MIN_LABELS:
        if ((start is not None) & (start != '')) & ((end is not None) & (end != '')):
            if data.empty==False:       
                # âš ï¸ SAST Risk (Low): Accessing nested dictionary keys without validation can lead to KeyError.
                data = data[(data.date >= start) & (data.date <= end)]
    return data
    raise IOError(ct.NETWORK_URL_ERROR_MSG)
# âš ï¸ SAST Risk (Low): Accessing list elements without validation can lead to IndexError.
    

def _get_k_data(url, dataflag='',
                # âœ… Best Practice: Use keyword arguments for better readability.
                symbol='',
                code = '',
                index = False,
                ktype = '',
                # âœ… Best Practice: Check if 'symbols' is a list, set, tuple, or pd.Series for flexibility
                retry_count=3,
                # âœ… Best Practice: Use consistent variable naming and spacing.
                pause=0.001):
    # ğŸ§  ML Signal: Iterating over a collection to fetch data for each item
    # ğŸ§  ML Signal: Date formatting pattern can be used to train models for date parsing.
    for _ in range(retry_count):
            time.sleep(pause)
            try:
                request = Request(url)
                lines = urlopen(request, timeout = 10).read()
                # âœ… Best Practice: Consider using a more descriptive variable name than 'col'.
                # ğŸ§  ML Signal: Adding a new column to a DataFrame
                if len(lines) < 100: #no data
                    return None
            # âš ï¸ SAST Risk (Low): DataFrame.append is inefficient for large datasets; consider using pd.concat
            except Exception as e:
                # âœ… Best Practice: Consider adding type hints for the function parameters and return type for better readability and maintainability.
                # âš ï¸ SAST Risk (Low): Converting data types without validation can lead to ValueError.
                print(e)
            # âœ… Best Practice: Return None explicitly if input is not a valid type
            else:
                lines = lines.decode('utf-8') if ct.PY3 else lines
                lines = lines.split('=')[1]
                reg = re.compile(r',{"nd.*?}') 
                lines = re.subn(reg, '', lines) 
                js = json.loads(lines[0])
                dataflag = dataflag if dataflag in list(js['data'][symbol].keys()) else ct.TT_K_TYPE[ktype.upper()]
                if len(js['data'][symbol][dataflag]) == 0:
                    return None
                if len(js['data'][symbol][dataflag][0]) == 6:
                    df = pd.DataFrame(js['data'][symbol][dataflag], 
                                  columns = ct.KLINE_TT_COLS_MINS)
                else:
                    df = pd.DataFrame(js['data'][symbol][dataflag], 
                                  columns = ct.KLINE_TT_COLS)
                df['code'] = symbol if index else code
                if ktype in ct.K_MIN_LABELS:
                    df['date'] = df['date'].map(lambda x: '%s-%s-%s %s:%s'%(x[0:4], x[4:6], 
                                                                            x[6:8], x[8:10], 
                                                                            x[10:12]))
                # ğŸ§  ML Signal: Usage of default parameter values can be a signal for ML models to understand function behavior.
                for col in df.columns[1:6]:
                    df[col] = df[col].astype(float)
                # âœ… Best Practice: Consider validating the date format to ensure it matches the expected 'YYYY-MM-DD' format.
                return df

# âš ï¸ SAST Risk (Low): Hardcoded date strings can lead to maintenance issues and potential logic errors.
def get_hists(symbols, start=None, end=None,
                  ktype='D', retry_count=3,
                  pause=0.001):
    """
    æ‰¹é‡è·å–å†å²è¡Œæƒ…æ•°æ®ï¼Œå…·ä½“å‚æ•°å’Œè¿”å›æ•°æ®ç±»å‹è¯·å‚è€ƒget_hist_dataæ¥å£
    # âš ï¸ SAST Risk (Medium): Using external input (date) to construct file paths can lead to path traversal vulnerabilities.
    """
    # ğŸ§  ML Signal: Conversion of datetime object to string format
    df = pd.DataFrame()
    if isinstance(symbols, list) or isinstance(symbols, set) or isinstance(symbols, tuple) or isinstance(symbols, pd.Series):
        # âœ… Best Practice: Chaining string methods for concise code
        for symbol in symbols:
            # ğŸ§  ML Signal: Function signature with default parameters
            # ğŸ§  ML Signal: Returning data frames is a common pattern in data processing functions.
            data = get_hist_data(symbol, start=start, end=end,
                                 ktype=ktype, retry_count=retry_count,
                                 pause=pause)
            # âš ï¸ SAST Risk (Low): Potential for path traversal if filepath is user-controlled
            data['code'] = symbol
            df = df.append(data, ignore_index=True)
        # âš ï¸ SAST Risk (Low): Opening a file without exception handling
        return df
    else:
        return None
# âš ï¸ SAST Risk (Low): Use of deprecated .ix indexer
  
  
def get_day_all(date=None):
    """
    è·å–æ¯æ—¥æ”¶ç›˜è¡Œæƒ…
    Parameters:
    -------------
    date:äº¤æ˜“æ—¥æœŸï¼Œæ ¼å¼:YYYY-MM-DD
    
    Return:
    -------------
    DataFrame
    code ä»£ç , name åç§°, p_change æ¶¨å¹…%,
    price ç°ä»·, change æ¶¨è·Œ, open ä»Šå¼€, high æœ€é«˜,
    low æœ€ä½, preprice æ˜¨æ”¶, pe å¸‚ç›ˆ(åŠ¨),
    volratio é‡æ¯”, turnover æ¢æ‰‹%, range æŒ¯å¹…%%,
    volume æ€»é‡, selling å†…ç›˜, buying å¤–ç›˜,
    amount æ€»é‡‘é¢, totals æ€»è‚¡æœ¬(ä¸‡), industry ç»†åˆ†è¡Œä¸š,
    area åœ°åŒº, floats æµé€šè‚¡æœ¬(ä¸‡), fvalues æµé€šå¸‚å€¼,
    abvalues ABè‚¡æ€»å¸‚å€¼, avgprice å‡ä»·, strength å¼ºå¼±åº¦%,
    activity æ´»è·ƒåº¦, avgturnover ç¬”æ¢æ‰‹, attack æ”»å‡»æ³¢%,
    interval3 è¿‘3æœˆæ¶¨å¹… ï¼Œinterval è¿‘6æœˆæ¶¨å¹…
    """
    wdate = du.last_tddate() if date is None else date
    wdate = wdate.replace('-', '')
    if wdate < '20170614':
        return None
    # âœ… Best Practice: Use a loop or mapping for type conversion
    datepre = '' if date is None else wdate[0:4] + wdate[4:6] + '/'
    df = pd.read_csv(ct.ALL_DAY_FILE%(datepre, \
                                      'hq' if date is None else wdate), \
                                      dtype={'code':'object'})
    return df


# âœ… Best Practice: Use a loop or mapping for repetitive operations
def get_dt_time(t):
    tstr = str(t)[:-2]
    tstr = tstr.replace('-', '').replace(':', '')
    return tstr

# âœ… Best Practice: Use a loop or mapping for repetitive assignments

def bar2h5(market='', date='', freq='D', asset='E', filepath=''):
    cons = get_apis()
    stks = get_stock_basics()
    fname = "%s%s%sbar%s.h5"%(filepath, market, date, freq)
    store = pd.HDFStore(fname, "a")
    if market in ['SH', 'SZ']:
        if market == 'SH':
            stks = stks.ix[stks.index.str[0]=='6', :]
        elif market == 'SZ':
            stks = stks.ix[stks.index.str[0]!='6', :]
        else:
            stks = ''
        market = 1 if market == 'SH' else 0
        for stk in stks.index:
            symbol = '%s.SH'%stk
            if 'min' in freq:
                df = bar(stk, conn=cons, start_date=date, end_date=date, freq=freq, 
                             market=market, asset=asset)
                df['Time'] = df.index
                df['Time'] = df['Time'].apply(get_dt_time) 
                df.index = df['Time']
                df.drop(['code','Time'], axis = 1, inplace=True)    
                df.rename(columns={'open':'OPEN'}, inplace=True) 
                df.rename(columns={'close':'CLOSE'}, inplace=True)
                df.rename(columns={'low':'LOW'}, inplace=True)
                df.rename(columns={'high':'HIGH'}, inplace=True)
                df.rename(columns={'vol':'VOLUME'}, inplace=True) 
                df.rename(columns={'amount':'TURNOVER'}, inplace=True) 
                df.loc[:,'HIGH'] =  df.loc[:,'HIGH'].astype("int64")
                df.loc[:,'LOW'] =  df.loc[:,'LOW'].astype("int64")
                df.loc[:,'OPEN'] =  df.loc[:,'OPEN'].astype("int64")
                df.loc[:,'CLOSE'] =  df.loc[:,'CLOSE'].astype("int64")
                df.loc[:,'VOLUME'] =  df.loc[:,'VOLUME'].astype("int64")
                df.loc[:,'TURNOVER'] =  df.loc[:,'TURNOVER'].astype("int64")    
                df.loc[:,'OPEN'] *= 10000   
                df.loc[:,'CLOSE'] *= 10000    
                df.loc[:,'HIGH'] *= 10000    
                df.loc[:,'LOW'] *= 10000
                df.loc[:,'ASKPRICE1']  = 0
                df.loc[:,'ASKPRICE2']  = 0
                df.loc[:,'ASKPRICE3']  = 0
                df.loc[:,'ASKPRICE4']  = 0
                df.loc[:,'ASKPRICE5']  = 0
                df.loc[:,'ASKPRICE6']  = 0
                # ğŸ§  ML Signal: Printing dataframes for debugging
                # âš ï¸ SAST Risk (Low): Potential data loss if df is not properly validated
                df.loc[:,'ASKPRICE7']  = 0
                df.loc[:,'ASKPRICE8']  = 0
                df.loc[:,'ASKPRICE9']  = 0
                df.loc[:,'ASKPRICE10'] = 0    
                df.loc[:,'BIDPRICE1']  = 0
                df.loc[:,'BIDPRICE2']  = 0
                df.loc[:,'BIDPRICE3']  = 0
                df.loc[:,'BIDPRICE4']  = 0
                df.loc[:,'BIDPRICE5']  = 0
                df.loc[:,'BIDPRICE6']  = 0
                df.loc[:,'BIDPRICE7']  = 0
                df.loc[:,'BIDPRICE8']  = 0
                df.loc[:,'BIDPRICE9']  = 0
                df.loc[:,'BIDPRICE10'] = 0    
                df.loc[:,'ASKVOL1']  = 0
                df.loc[:,'ASKVOL2']  = 0
                df.loc[:,'ASKVOL3']  = 0
                df.loc[:,'ASKVOL4']  = 0
                df.loc[:,'ASKVOL5']  = 0
                df.loc[:,'ASKVOL6']  = 0
                df.loc[:,'ASKVOL7']  = 0
                df.loc[:,'ASKVOL8']  = 0
                df.loc[:,'ASKVOL9']  = 0
                df.loc[:,'ASKVOL10'] = 0    
                df.loc[:,'BIDVOL1']  = 0
                df.loc[:,'BIDVOL2']  = 0
                # âœ… Best Practice: Strip and normalize the code to uppercase for consistency
                df.loc[:,'BIDVOL3']  = 0
                df.loc[:,'BIDVOL4']  = 0
                # ğŸ§  ML Signal: Retry pattern for network operations
                df.loc[:,'BIDVOL5']  = 0
                df.loc[:,'BIDVOL6']  = 0
                df.loc[:,'BIDVOL7']  = 0
                df.loc[:,'BIDVOL8']  = 0
                # âš ï¸ SAST Risk (Low): Printing error messages can leak information
                df.loc[:,'BIDVOL9']  = 0
                df.loc[:,'BIDVOL10'] = 0    
                df.loc[:,'VWAP'] = 0.0
                # âœ… Best Practice: Unpacking connection tuple for clarity
                df.loc[:,'VOL30']=0.0
                df.loc[:,'TOTAL_VOLUME']=0.0
                # âœ… Best Practice: Strip and normalize the frequency to uppercase for consistency
                df.loc[:,'TOTAL_TURNOVER']=0.0
                df.loc[:,'INTEREST']=0.0
                # âœ… Best Practice: Strip and normalize the asset type to uppercase for consistency
                print(df)
#             if market == 1 and stk[0] == '6':
            # âœ… Best Practice: Use a helper function to determine market code
#                 df = bar(stk, conn=cons, start_date=date, end_date=date, freq=freq, market=market, asset=asset)
                
            store[symbol] = df
    # âœ… Best Practice: Use getattr for dynamic function retrieval
    
    store.close()
    close_apis(cons)
 # âœ… Best Practice: Adjust ktype for non-standard assets
 

def bar(code, conn=None, start_date=None, end_date=None, freq='D', asset='E', 
           market='',
           adj = None,
           ma = [],
           # ğŸ§  ML Signal: Pagination pattern for data retrieval
           factors = [],
           retry_count = 3):
    """
    BARæ•°æ®
    Parameters:
    ------------
    code:è¯åˆ¸ä»£ç ï¼Œæ”¯æŒè‚¡ç¥¨,ETF/LOF,æœŸè´§/æœŸæƒ,æ¸¯è‚¡
    con:æœåŠ¡å™¨è¿æ¥ ï¼Œé€šè¿‡ts.api()æˆ–è€…ts.xpi()è·å¾—
    start_date:å¼€å§‹æ—¥æœŸ  YYYY-MM-DD/YYYYMMDD
    end_date:ç»“æŸæ—¥æœŸ YYYY-MM-DD/YYYYMMDD
    freq:æ”¯æŒ1/5/15/30/60åˆ†é’Ÿ,å‘¨/æœˆ/å­£/å¹´
    asset:è¯åˆ¸ç±»å‹ E:è‚¡ç¥¨å’Œäº¤æ˜“æ‰€åŸºé‡‘ï¼ŒINDEX:æ²ªæ·±æŒ‡æ•°,X:æœŸè´§/æœŸæƒ/æ¸¯è‚¡/ä¸­æ¦‚ç¾å›½/ä¸­è¯æŒ‡æ•°/å›½é™…æŒ‡æ•°
    market:å¸‚åœºä»£ç ï¼Œé€šè¿‡ts.get_markets()è·å–
    adj:å¤æƒç±»å‹,Noneä¸å¤æƒ,qfq:å‰å¤æƒ,hfq:åå¤æƒ
    ma:å‡çº¿,æ”¯æŒè‡ªå®šä¹‰å‡çº¿é¢‘åº¦ï¼Œå¦‚ï¼šma5/ma10/ma20/ma60/maN
    factorså› å­æ•°æ®ï¼Œç›®å‰æ”¯æŒä»¥ä¸‹ä¸¤ç§ï¼š
        vr:é‡æ¯”,é»˜è®¤ä¸è¿”å›ï¼Œè¿”å›éœ€æŒ‡å®šï¼šfactor=['vr']
        tor:æ¢æ‰‹ç‡ï¼Œé»˜è®¤ä¸è¿”å›ï¼Œè¿”å›éœ€æŒ‡å®šï¼šfactor=['tor']
                    ä»¥ä¸Šä¸¤ç§éƒ½éœ€è¦ï¼šfactor=['vr', 'tor']
    retry_count:ç½‘ç»œé‡è¯•æ¬¡æ•°
    
    Return
    ----------
    DataFrame
    code:ä»£ç 
    openï¼šå¼€ç›˜close/high/low/volæˆäº¤é‡/amountæˆäº¤é¢/maNå‡ä»·/vré‡æ¯”/toræ¢æ‰‹ç‡
    
         æœŸè´§(asset='X')
    code/open/close/high/low/avg_priceï¼šå‡ä»·  positionï¼šæŒä»“é‡  volï¼šæˆäº¤æ€»é‡
    """
    code = code.strip().upper()
    # âš ï¸ SAST Risk (Low): Use of deprecated 'ix' indexer, which can lead to unexpected behavior
    for _ in range(retry_count):
        try:
            # ğŸ§  ML Signal: Usage of lambda function for mapping
            if conn is None:
                print(ct.MSG_NOT_CONNECTED)
                # ğŸ§  ML Signal: Conditional logic based on variable 'adj'
                return None
            api, xapi = conn
            # âœ… Best Practice: Drop unnecessary columns for clarity
            ktype = freq.strip().upper()
            asset = asset.strip().upper()
            mkcode = _get_mkcode(code, asset=asset, xapi=xapi) if market == '' else market
            if asset in['E', 'INDEX']:
                # ğŸ§  ML Signal: Mapping function applied to data column
                func = getattr(api, ct.ASSET[asset])
            # âœ… Best Practice: Use a separate function for factor adjustment
            else:
                # âœ… Best Practice: Dropping temporary columns after use to maintain clean data structure
                ktype = 'XD' if ktype == 'D' else ktype
                func = getattr(xapi, ct.ASSET['X'])
            # âœ… Best Practice: Checking for None and length > 0 before processing
            # âœ… Best Practice: Merge DataFrames for additional data
            if ktype in ct.KTYPE_LOW_COLS:
                data = pd.DataFrame()
                 # ğŸ§  ML Signal: Checking for specific value in list
                 # âœ… Best Practice: Fill missing values with backfill method
                for i in range(100): 
                    ds = func(ct.KTYPE[ktype], mkcode, code, i * 800, 800)
                    # âš ï¸ SAST Risk (Medium): Use of deprecated 'ix' indexer, which can lead to unexpected behavior
                    df =  api.to_df(ds)
                    # ğŸ§  ML Signal: Conditional logic based on variable 'ktype'
                    data = data.append(df) if i == 0 else df.append(data,  ignore_index=True)
                    if len(ds) < 800:
                        # âœ… Best Practice: Merging dataframes with index alignment
                        break
                data['datetime'] = data['datetime'].apply(lambda x: str(x[0:10]))
            # âœ… Best Practice: Using fillna with method to handle missing data
            if ktype in ct.KTYPE_ARR:
                data = pd.DataFrame()
                for i in range(100): 
                    ds = func(ct.KTYPE[ktype], mkcode, code, i * 800, 800)
                    df =  api.to_df(ds)
                    data = data.append(df) if i == 0 else df.append(data,  ignore_index=True)
                    if len(ds) < 800:
                        break
            data['datetime'] = pd.to_datetime(data['datetime'])
            data = data.assign(code=str(code)) \
                # âœ… Best Practice: Use string formatting for better readability and maintainability
                .set_index('datetime', drop=True, inplace=False) \
                .drop(ct.T_DROP_COLS, axis=1)[ None if start_date == '' else start_date : 
                                              None if end_date == '' else end_date]
            data = data.sort_index(ascending=False)
            if asset in['E', 'INDEX']:
                data = data[ct.BAR_E_COLS]
                if ktype in ct.KTYPE_ARR:
                    data['vol'] = data['vol'] / 100
            else:
                # âš ï¸ SAST Risk (Low): Catching broad exceptions can hide errors and make debugging difficult
                data = data[ct.BAR_X_COLS]
                if mkcode in [28, 29, 30, 47, 60]:
                    data.columns = ct.BAR_X_FUTURE_COLS
                    # âœ… Best Practice: The 'else' block after 'try' is redundant if 'except' returns
                    data = data[ct.BAR_X_FUTURE_RL_COLS]
                # âœ… Best Practice: Consider providing type hints for function parameters and return type for better readability and maintainability.
                else:
                    data = data.drop(['price', 'position'], axis=1)
                    data.columns = ct.BAR_X_OTHER_COLS
            # âš ï¸ SAST Risk (Low): Raising a generic IOError without context can make error handling difficult
            if asset == 'E':
                # ğŸ§  ML Signal: Conditional logic based on asset type can indicate different processing paths.
                if adj is not None:
                    df = factor_adj(code)
                    if ktype in ct.KTYPE_LOW_COLS: 
                        # ğŸ§  ML Signal: Different asset types trigger different function calls.
                        data = data.merge(df, left_index=True, right_index=True)
                        data['adj_factor'] = data['adj_factor'].fillna(method='bfill')
                    else:
                        # âš ï¸ SAST Risk (Low): Using os.path.exists can be risky if the path is user-controlled, leading to potential path traversal issues.
                        def get_val(day):
                            return df.ix[day]['adj_factor']
                        # ğŸ§  ML Signal: Use of pandas to read data from a pickle file indicates data processing patterns.
                        data['adj_factor'] = data.index.map(lambda x: get_val(str(x)[0:10]))
                    for col in ct.BAR_E_COLS[1:5]:
                        if adj == 'hfq':
                            # âš ï¸ SAST Risk (Medium): Accessing DataFrame values without checking if the code exists can lead to IndexError.
                            # ğŸ§  ML Signal: Function call to get_instrument suggests dynamic data retrieval.
                            # ğŸ§  ML Signal: Use of to_pickle indicates data serialization patterns.
                            data[col] = data[col] * data['adj_factor']
                        else:
                            data[col] = data[col] * data['adj_factor'] / float(df['adj_factor'][0])
                        data[col] = data[col].map(ct.FORMAT)
                    data = data.drop('adj_factor', axis=1)
                if factors is not None and len(factors) >0 :
                    if 'tor' in factors:
                        df = factor_shares(code)
                        if ktype in ct.KTYPE_LOW_COLS: 
                            data = data.merge(df, left_index=True, right_index=True)
                            data['floats'] = data['floats'].fillna(method='bfill')
                        else:
                            def get_val(day):
                                return df.ix[day]['floats']
                            data['floats'] = data.index.map(lambda x: get_val(str(x)[0:10]))
                        data['tor'] = data['vol'] / data['floats'] 
                        data['tor'] = data['tor'].map(ct.FORMAT)
                        data['tor'] = data['tor'].astype(float)
                        data = data.drop('floats', axis=1)
                    if 'vr' in factors:
                        data['vol5'] = MA(data['vol'], 5)
                        data['mean'] = data['vol5'].shift(-5)
                        data['vr'] = (data['vol'] / data['mean']).map(ct.FORMAT)
                        data['vr'] = data['vr'].astype(float)
                        data = data.drop(['vol5', 'mean'], axis=1)
            if ma is not None and len(ma) > 0:
                for a in ma:
                    if isinstance(a, int):
                        data['ma%s'%a] = MA(data['close'], a).map(ct.FORMAT).shift(-(a-1))
                        # âœ… Best Practice: Convert date to integer for consistent format and easier comparison
                        data['ma%s'%a] = data['ma%s'%a].astype(float)
            for col in ['open', 'high', 'low', 'close']:
                # âœ… Best Practice: Convert today's date to integer for consistent format and easier comparison
                data[col] = data[col].astype(float)
            data['p_change'] = data['close'].pct_change(-1) * 100
            data['p_change'] = data['p_change'].map(ct.FORMAT).astype(float)
            return data
        except:
            # âš ï¸ SAST Risk (Low): Printing error messages can expose sensitive information
            return None
        else:
            data['p_change'] = data['close'].pct_change(-1) * 100
            data['p_change'] = data['p_change'].map(ct.FORMAT).astype(float)
            return data
    # âœ… Best Practice: Use a helper function to determine market code for better readability
    raise IOError(ct.NETWORK_URL_ERROR_MSG)
# âœ… Best Practice: Use appropriate API connection based on asset type


def _get_mkcode(code='', asset='E', xapi=None):
    mkcode = ''
    if asset == 'E':
        # ğŸ§  ML Signal: Pattern of fetching transaction data for the current date
        mkcode = ct._market_code(code)
    elif asset == 'INDEX':
        mkcode = ct._idx_market_code(code)
    # ğŸ§  ML Signal: Pattern of fetching historical transaction data
    else:
        if os.path.exists(ct.INST_PLK_F):
            # âœ… Best Practice: Convert data to DataFrame for easier manipulation
            mks = pd.read_pickle(ct.INST_PLK_F)
        else:
            # âœ… Best Practice: Append data to DataFrame in a consistent manner
            mks = get_instrument(xapi)
            mks.to_pickle(ct.INST_PLK_F)
        mkcode = mks[mks.code == code]['market'].values[0]
    return mkcode


def tick(code, conn=None, date='', asset='E', market='', retry_count = 3):
    """
    tickæ•°æ®
    Parameters:
    ------------
    code:è¯åˆ¸ä»£ç ï¼Œæ”¯æŒè‚¡ç¥¨,ETF/LOF,æœŸè´§/æœŸæƒ,æ¸¯è‚¡
    conn:æœåŠ¡å™¨è¿æ¥ ï¼Œé€šè¿‡ts.api()æˆ–è€…ts.xpi()è·å¾—
    date:æ—¥æœŸ
    asset:è¯åˆ¸å“ç§ï¼ŒE:æ²ªæ·±äº¤æ˜“æ‰€è‚¡ç¥¨å’ŒåŸºé‡‘, INDEX:æ²ªæ·±äº¤æ˜“æ‰€æŒ‡æ•°ï¼Œ X:å…¶ä»–è¯åˆ¸å“ç§ï¼Œå¤§è‡´å¦‚ä¸‹ï¼š
                     æ”¯æŒçš„æ‰©å±•è¡Œæƒ…åŒ…æ‹¬(asset='X')ï¼š
                            éƒ‘å·å•†å“æœŸæƒ         OZ å¤§è¿å•†å“æœŸæƒ         OD ä¸Šæµ·å•†å“æœŸæƒ         OS
                            ä¸Šæµ·ä¸ªè‚¡æœŸæƒ         QQ é¦™æ¸¯æŒ‡æ•°         FH éƒ‘å·å•†å“         QZ å¤§è¿å•†å“         QD ä¸Šæµ·æœŸè´§         QS
                            é¦™æ¸¯ä¸»æ¿         KH é¦™æ¸¯æƒè¯         KR å¼€æ”¾å¼åŸºé‡‘         FU è´§å¸å‹åŸºé‡‘         FB
                            æ‹›å•†ç†è´¢äº§å“         LC æ‹›å•†è´§å¸äº§å“         LB å›½é™…æŒ‡æ•°         FW å›½å†…å®è§‚æŒ‡æ ‡         HG ä¸­å›½æ¦‚å¿µè‚¡         CH
                            ç¾è‚¡çŸ¥åå…¬å¸         MG Bè‚¡è½¬Hè‚¡         HB è‚¡ä»½è½¬è®©         SB è‚¡æŒ‡æœŸè´§         CZ é¦™æ¸¯åˆ›ä¸šæ¿         KG é¦™æ¸¯ä¿¡æ‰˜åŸºé‡‘         KT
                             å›½å€ºé¢„å‘è¡Œ         GY ä¸»åŠ›æœŸè´§åˆçº¦         MA
                              ä¸­è¯æŒ‡æ•°         ZZ æ¸¯è‚¡é€š         GH
    market:å¸‚åœºä»£ç ï¼Œé€šè¿‡ts.get_markets()è·å–
                  
    Return
    ----------
    DataFrame
    date:æ—¥æœŸ
    time:æ—¶é—´
    price:æˆäº¤ä»·
    vol:æˆäº¤é‡
    type:ä¹°å–æ–¹å‘ï¼Œ0-ä¹°å…¥ 1-å–å‡º 2-é›†åˆç«ä»·æˆäº¤
            æœŸè´§  0:å¼€ä»“  1:å¤šå¼€   -1:ç©ºå¼€
         æœŸè´§å¤šä¸€åˆ—æ•°æ®oi_change:å¢ä»“æ•°æ®

    """
    # âœ… Best Practice: Rename columns for clarity
    code = code.strip().upper()
    date = int(date.replace('-', ''))
    # âš ï¸ SAST Risk (Low): Printing error messages can expose sensitive information
    today = int(str(du.today()).replace('-', ''))
    # âœ… Best Practice: Drop unnecessary columns for other market codes
    for _ in range(retry_count):
        try:
            if conn is None:
                # âš ï¸ SAST Risk (Low): Printing exception messages can expose sensitive information
                print(ct.MSG_NOT_CONNECTED)
                # âœ… Best Practice: Use isinstance for type checking
                return None
            api, xapi = conn
            data = pd.DataFrame()
            mkcode = _get_mkcode(code, asset=asset, xapi=xapi) if market == '' else market
            con = api if asset in['E', 'INDEX'] else xapi
            for i in range(200):
                if date == today:
                    ds = con.get_transaction_data(market=mkcode, code=code, start=i * 300, count=300)
                else:
                    ds = con.get_history_transaction_data(market=mkcode, code=code, date=date, start=i * 300, count=300)
                # âœ… Best Practice: Use pd.concat instead of DataFrame.append for better performance
                df =  api.to_df(ds)
                data = data.append(df) if i == 0 else df.append(data,  ignore_index=True)
                if len(ds) < 300:
                    break
            if asset in['E', 'INDEX']:
                data['date'] = date
                data['date'] = data['date'].map(lambda x: '%s-%s-%s '%(str(x)[0:4], str(x)[4:6], str(x)[6:8]))
                data['datetime'] = data['date'] + data['time']
                data = data[['datetime', 'price', 'vol', 'buyorsell']]
                data.columns = ['datetime', 'price', 'vol', 'type']
            else:
                if mkcode in [31, 71]:
                    if date == today:
                        data = data.drop(['hour', 'minute', 'nature_name', 'zengcang', 'direction', 
                                        'second', 'nature_mark', 'nature_value'], axis=1)
                    else:
                        data = data.drop(['hour', 'minute', 'nature_name', 'zengcang', 'direction'], axis=1)
                    data.loc[data.nature== 512, 'nature' ] = 2
                    data.loc[data.nature== 256, 'nature' ] = 1
                    data = data.sort_values('date')
                    data.columns = ['date', 'price', 'vol', 'type']
                elif mkcode in [28, 29, 30, 47, 60]:
                    # âš ï¸ SAST Risk (Low): Catching broad exceptions can hide bugs and make debugging difficult
                    if date == today:
                        data = data.drop(['hour', 'minute', 'nature', 'direction', 
                                            'second', 'nature_mark', 'nature_value'], axis=1)
                    else:
                        # âš ï¸ SAST Risk (Low): Raising generic IOError without specific context can be misleading
                        # âœ… Best Practice: Initialize variables before using them in a loop
                        data = data.drop(['hour', 'minute', 'nature', 'direction'], axis=1)
                    data.columns = ['date', 'price', 'vol', 'oi_change', 'type']
                else:
                    # ğŸ§  ML Signal: Iterating over a range with a fixed step size
                    data = data.drop(['hour', 'minute', 'nature_name', 'zengcang', 'direction', 'nature'], axis=1)
            
        # âœ… Best Practice: Use list concatenation for readability
        except Exception as e:
            print(e)
        # âš ï¸ SAST Risk (Low): Assumes that the API returns a list with a predictable length
        else:
            # âœ… Best Practice: Import statements should be at the top of the file for better readability and maintainability.
            return data
# ğŸ§  ML Signal: Converting data to a DataFrame before returning



# âœ… Best Practice: Use of default parameter values to provide flexibility in function usage.
# ğŸ§  ML Signal: Use of default parameter values can indicate optional dependencies or configurations.
def quotes(symbols, conn=None, asset='E', market=[], retry_count = 3):
    """
        è·å–å®æ—¶å¿«ç…§
    Parameters
    ------
        symbols : string, array-like object (list, tuple, Series).
        
    return
    -------
        DataFrame å®æ—¶å¿«ç…§ï¼Œ5æ¡£è¡Œæƒ…
    """
    # âœ… Best Practice: Import statements should be at the top of the file.
    for _ in range(retry_count):
        # ğŸ§  ML Signal: Conversion of data to a DataFrame, indicating data processing or analysis task.
        try:
            if conn is None:
                print(ct.MSG_NOT_CONNECTED)
                # âš ï¸ SAST Risk (Low): Use of pickle for data serialization can lead to security risks if loading untrusted data.
                # ğŸ§  ML Signal: Function with default parameter value indicating optional argument usage.
                # âœ… Best Practice: Use of default parameter value to handle optional argument.
                return None
            api, xapi = conn
            data = pd.DataFrame()
            # ğŸ§  ML Signal: Returning processed data, common in data transformation functions.
            # âš ï¸ SAST Risk (Low): Potential use of an undefined variable 'ct' if not imported.
            if isinstance(symbols, list) or isinstance(symbols, set) or isinstance(symbols, tuple) or isinstance(symbols, pd.Series):
                for code in symbols:
                    mkcode = _get_mkcode(code, asset=asset, xapi=xapi)
                    if asset == 'E':
                        df = api.to_df(api.get_security_quotes([(mkcode, code)]))
                    # ğŸ§  ML Signal: Use of a loop to process data in chunks.
                    elif asset == 'INDEX':
                        df = api.to_df(api.get_security_quotes([(mkcode, code)]))
                    else:
                        df = xapi.to_df(xapi.get_instrument_quote(mkcode, code))
                    data = data.append(df)
            else:
                # ğŸ§  ML Signal: Conversion of data to a DataFrame, indicating data processing pattern.
                mkcode = _get_mkcode(symbols, asset=asset, xapi=xapi)
                if asset == 'E':
                    data = api.to_df(api.get_security_quotes([(mkcode, symbols)]))
                # âœ… Best Practice: Check if xapi is None to avoid calling methods on a NoneType
                elif asset == 'INDEX':
                    data = api.to_df(api.get_security_quotes([(mkcode, symbols)]))
                # âš ï¸ SAST Risk (Low): Printing error messages can expose internal state
                else:
                    data = xapi.to_df(xapi.get_instrument_quote(mkcode, symbols))
            if asset in ['E', 'INDEX']:
                # ğŸ§  ML Signal: Usage of xapi.get_markets() indicates interaction with an API
                data = data.drop(['market', 'active1', 'active2', 'reversed_bytes0', 'reversed_bytes1', 'reversed_bytes2',
                                  # ğŸ§  ML Signal: Function definition with a single parameter, indicating a common pattern for data processing functions
                                  'reversed_bytes3',
                                  # ğŸ§  ML Signal: Conversion to DataFrame suggests data processing or analysis
                                  # âš ï¸ SAST Risk (Low): External URL usage in pd.read_csv can lead to data exposure or injection if not properly validated
                                  'reversed_bytes4',
                                  'reversed_bytes5',
                                  'reversed_bytes6',
                                  'reversed_bytes7',
                                  # ğŸ§  ML Signal: Function definition with a parameter, indicating a reusable component
                                  # ğŸ§  ML Signal: Setting a DataFrame index, a common operation in data manipulation tasks
                                  'reversed_bytes8',
                                  # âš ï¸ SAST Risk (Low): External URL usage can lead to security risks if not validated
                                  # ğŸ§  ML Signal: Returning a DataFrame, indicating the function's purpose is data transformation
                                  'reversed_bytes9'], axis=1)
            else:
                # ğŸ§  ML Signal: Reading data from a CSV file, indicating data processing
                data = data.drop(['market'], axis=1)
        except Exception as e:
            # âœ… Best Practice: Use of a leading underscore in the function name indicates it's intended for internal use.
            print(e)
        # âœ… Best Practice: Setting 'datetime' as index for better time series handling
        else:
            # âœ… Best Practice: Importing only the required function from a module.
            return data
    # ğŸ§  ML Signal: Returning a DataFrame, indicating data transformation
    raise IOError(ct.NETWORK_URL_ERROR_MSG)
# âœ… Best Practice: Use of exponentiation for calculating powers of 10.
# ğŸ§  ML Signal: Use of random number generation.
# âš ï¸ SAST Risk (Low): Predictable random number generation with randint.



def get_security(api):
    """
            è·å–è‚¡ç¥¨åˆ—è¡¨
    """
    data = []
    for p in range(100):
        ds = api.get_security_list(0, p*1000)
        data += ds
        if len(ds) < 1000:
            break
    data = api.to_df(data)
    return data


def reset_instrument(xapi=None):
    """
            é‡æ–°è®¾ç½®æœ¬åœ°è¯åˆ¸åˆ—è¡¨
    """
    import tushare.util.conns as cs 
    xapi = cs.xapi_x() if xapi is None else xapi
    data=[]
    for i in range(200): 
        ds = xapi.get_instrument_info(i * 300, 300)
        data += ds
        if len(ds) < 300:
            break
    data = xapi.to_df(data)
    data.to_pickle(ct.INST_PLK_F)
    return data



def get_instrument(xapi=None):
    """
            è·å–è¯åˆ¸åˆ—è¡¨
    """
    import tushare.util.conns as cs 
    xapi = cs.xapi_x() if xapi is None else xapi
    if xapi is None:
        print(ct.MSG_NOT_CONNECTED)
        return None
    data=[]
    for i in range(200): # range for python2/3
        ds = xapi.get_instrument_info(i * 300, 300)
        data += ds
        if len(ds) < 300:
            break
    data = xapi.to_df(data)
    return data


def get_markets(xapi=None):
    """
            è·å–å¸‚åœºä»£ç 
    """
    if xapi is None:
        print(ct.MSG_NOT_CONNECTED)
        return None
    data = xapi.get_markets()
    data = xapi.to_df(data)
    return data
    
    
def factor_adj(code):
    df = pd.read_csv(ct.ADJ_FAC_URL%(ct.P_TYPE['http'],
                                             ct.DOMAINS['oss'], code))
    df = df.set_index('datetime')
    return df


def factor_shares(code):
    df = pd.read_csv(ct.SHS_FAC_URL%(ct.P_TYPE['http'],
                                             ct.DOMAINS['oss'], code))[['datetime', 'floats']]
    df = df.set_index('datetime')
    return df


def _random(n=13):
    from random import randint
    start = 10**(n-1)
    end = (10**n)-1
    return str(randint(start, end))