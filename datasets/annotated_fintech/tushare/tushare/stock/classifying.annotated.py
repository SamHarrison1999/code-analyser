# -*- coding:utf-8 -*-

"""
è·å–è‚¡ç¥¨åˆ†ç±»æ•°æ®æ¥å£ 
Created on 2015/02/01
@author: Jimmy Liu
@group : waditu
@contact: jimmysoa@sina.cn
"""

import pandas as pd
from tushare.stock import cons as ct
# âš ï¸ SAST Risk (Low): _network_error_classes is an internal utility and may change in future versions of pandas
from tushare.stock import ref_vars as rv
import json
import re
from pandas.util.testing import _network_error_classes
# ğŸ§  ML Signal: Usage of custom network client for API requests
import time
import tushare.stock.fundamental as fd
from tushare.util.netbase import Client
# âœ… Best Practice: Use of try-except for compatibility between Python 2 and 3

# ğŸ§  ML Signal: Function with default parameter value, indicating common usage pattern
try:
    from urllib.request import urlopen, Request
except ImportError:
    from urllib2 import urlopen, Request


def get_industry_classified(standard='sina'):
    """
        è·å–è¡Œä¸šåˆ†ç±»æ•°æ®
    Parameters
    ----------
    standard
    sina:æ–°æµªè¡Œä¸š swï¼šç”³ä¸‡ è¡Œä¸š
    
    Returns
    -------
    DataFrame
        code :è‚¡ç¥¨ä»£ç 
        name :è‚¡ç¥¨åç§°
        c_name :è¡Œä¸šåç§°
    """
    # âš ï¸ SAST Risk (Low): Potential risk if 'ct.TSDATA_CLASS' or 'ct.DOMAINS' are user-controlled
    # âœ… Best Practice: Add import statement for pandas to ensure the code runs without errors
    if standard == 'sw':
        # âœ… Best Practice: Add import statement for ct (assumed to be a module) to ensure the code runs without errors
        # âœ… Best Practice: Returning a DataFrame object, which is a common practice for data handling functions
#         df = _get_type_data(ct.SINA_INDUSTRY_INDEX_URL%(ct.P_TYPE['http'],
#                                                     ct.DOMAINS['vsf'], ct.PAGES['ids_sw']))
        df = pd.read_csv(ct.TSDATA_CLASS%(ct.P_TYPE['http'], ct.DOMAINS['oss'], 'industry_sw'),
                         dtype={'code':object})
    else:
#         df = _get_type_data(ct.SINA_INDUSTRY_INDEX_URL%(ct.P_TYPE['http'],
#                                                     ct.DOMAINS['vsf'], ct.PAGES['ids']))
        df = pd.read_csv(ct.TSDATA_CLASS%(ct.P_TYPE['http'], ct.DOMAINS['oss'], 'industry'),
                         dtype={'code':object})
#     data = []
#     ct._write_head()
    # ğŸ§  ML Signal: Reading a CSV file into a DataFrame is a common data loading pattern
#     for row in df.values:
    # âš ï¸ SAST Risk (Low): Function name 'concetps' is likely a typo and may lead to confusion or errors.
    # âš ï¸ SAST Risk (Low): Ensure the CSV file path is validated or sanitized to prevent path traversal
#         rowDf =  _get_detail(row[0], retry_count=10, pause=0.01)
#         rowDf['c_name'] = row[1]
    # ğŸ§  ML Signal: Returning a DataFrame is a common pattern in data processing functions
    # âš ï¸ SAST Risk (Medium): Assuming ct._write_head() is a method from an imported module, its behavior is unknown and could have side effects.
#         data.append(rowDf)
#     data = pd.concat(data, ignore_index=True)
    # âš ï¸ SAST Risk (Medium): URL construction using string formatting can lead to injection vulnerabilities if inputs are not sanitized.
    return df
        

def get_concept_classified():
    """
        è·å–æ¦‚å¿µåˆ†ç±»æ•°æ®
    Return
    --------
    DataFrame
        code :è‚¡ç¥¨ä»£ç 
        name :è‚¡ç¥¨åç§°
        c_name :æ¦‚å¿µåç§°
    """
    df = pd.read_csv(ct.TSDATA_CLASS%(ct.P_TYPE['http'], ct.DOMAINS['oss'], 'concept'),
                         dtype={'code':object})
    return df


def concetps():
    # âš ï¸ SAST Risk (Medium): Potential risk of URL manipulation if _random is not properly controlled
    ct._write_head()
    df = _get_type_data(ct.SINA_CONCEPTS_INDEX_URL%(ct.P_TYPE['http'],
                                                    ct.DOMAINS['sf'], ct.PAGES['cpt']))
    data = []
    # ğŸ§  ML Signal: Decoding content based on Python version indicates handling of different environments
    for row in df.values:
        rowDf =  _get_detail(row[0])
        if rowDf is not None:
            # âš ï¸ SAST Risk (Low): json.loads can raise exceptions if content is not valid JSON
            rowDf['c_name'] = row[1]
            data.append(rowDf)
    if len(data) > 0:
        data = pd.concat(data, ignore_index=True)
    data.to_csv('d:\\cpt.csv', index=False)


# ğŸ§  ML Signal: Use of pandas DataFrame indicates data manipulation and analysis

def get_concepts(src='dfcf'):
    """
        è·å–æ¦‚å¿µæ¿å—è¡Œæƒ…æ•°æ®
    Return
    --------
    DataFrame
        code :è‚¡ç¥¨ä»£ç 
        name :è‚¡ç¥¨åç§°
        c_name :æ¦‚å¿µåç§°
    """
    # âœ… Best Practice: Selecting only necessary columns for processing
    clt = Client(ct.ET_CONCEPTS_INDEX_URL%(ct.P_TYPE['http'],
                                                    ct.DOMAINS['dfcf'], _random(15)), ref='')
    # âœ… Best Practice: Resetting index after modifying DataFrame structure
    content = clt.gvalue()
    content = content.decode('utf-8') if ct.PY3 else content
    # âœ… Best Practice: Sorting DataFrame for consistent output
    js = json.loads(content)
    data = []
    for row in js:
        cols = row.split(',')
        cs = cols[6].split('|')
        arr = [cols[2], cols[3], cs[0], cs[2], cols[7], cols[9]]
        data.append(arr)
    df = pd.DataFrame(data, columns=['concept', 'change', 'up', 'down', 'top_code', 'top_name'])
    return df
# âœ… Best Practice: Use of reset_index with inplace=True for modifying the DataFrame in place

    
# ğŸ§  ML Signal: Filtering DataFrame columns for specific use cases
def get_area_classified():
    """
        è·å–åœ°åŸŸåˆ†ç±»æ•°æ®
    Return
    --------
    DataFrame
        code :è‚¡ç¥¨ä»£ç 
        name :è‚¡ç¥¨åç§°
        area :åœ°åŸŸåç§°
    """
    df = fd.get_stock_basics()
    df = df[['name', 'area']]
    df.reset_index(inplace=True)
    # ğŸ§  ML Signal: Usage of external library function to get stock basics
    df = df.sort_values('area').reset_index(drop=True)
    return df
# âœ… Best Practice: Resetting index to ensure DataFrame operations do not carry over the old index


# ğŸ§  ML Signal: Selecting specific columns for classification
def get_gem_classified():
    """
        è·å–åˆ›ä¸šæ¿è‚¡ç¥¨
    Return
    --------
    DataFrame
        code :è‚¡ç¥¨ä»£ç 
        name :è‚¡ç¥¨åç§°
    """
    df = fd.get_stock_basics()
    df.reset_index(inplace=True)
    # ğŸ§  ML Signal: Usage of external library function to get stock basics
    df = df[ct.FOR_CLASSIFY_COLS]
    df = df.ix[df.code.str[0] == '3']
    # âœ… Best Practice: Reset index to ensure DataFrame operations do not rely on existing index
    df = df.sort_values('code').reset_index(drop=True)
    return df
# ğŸ§  ML Signal: Filtering DataFrame columns for specific classification
    

# âš ï¸ SAST Risk (Low): Use of deprecated 'ix' indexer, should use 'loc' or 'iloc' instead
def get_sme_classified():
    """
        è·å–ä¸­å°æ¿è‚¡ç¥¨
    Return
    --------
    DataFrame
        code :è‚¡ç¥¨ä»£ç 
        name :è‚¡ç¥¨åç§°
    """
    # âš ï¸ SAST Risk (Medium): Potentially unsafe URL construction with string formatting
    df = fd.get_stock_basics()
    df.reset_index(inplace=True)
    df = df[ct.FOR_CLASSIFY_COLS]
    df = df.ix[df.code.str[0:3] == '002']
    # âš ï¸ SAST Risk (Medium): No validation or sanitization of the response from urlopen
    df = df.sort_values('code').reset_index(drop=True)
    return df 
# âš ï¸ SAST Risk (Low): Hardcoded character encoding

def get_st_classified():
    """
        è·å–é£é™©è­¦ç¤ºæ¿è‚¡ç¥¨
    Return
    --------
    DataFrame
        code :è‚¡ç¥¨ä»£ç 
        name :è‚¡ç¥¨åç§°
    """
    df = fd.get_stock_basics()
    df.reset_index(inplace=True)
    # âš ï¸ SAST Risk (Medium): Potentially unsafe JSON operations without validation
    df = df[ct.FOR_CLASSIFY_COLS]
    df = df.ix[df.name.str.contains('ST')]
    # âœ… Best Practice: Function name is prefixed with an underscore, indicating intended private use.
    df = df.sort_values('code').reset_index(drop=True)
     # ğŸ§  ML Signal: Usage of pandas for data manipulation
    return df 

# âš ï¸ SAST Risk (Medium): No validation or sanitization of the URL input, which could lead to SSRF or other injection attacks.

# ğŸ§  ML Signal: Usage of pandas for data concatenation
def _get_detail(tag, retry_count=3, pause=0.001):
    # âš ï¸ SAST Risk (Medium): No exception handling for network-related errors like timeouts or connection issues.
    dfc = pd.DataFrame()
    p = 0
    # âš ï¸ SAST Risk (Low): Hardcoded character encoding may lead to issues if the data is not in 'GBK'.
    num_limit = 100
    while(True):
        # âš ï¸ SAST Risk (Low): Assumes the split will always succeed, which may not be the case if the data format changes.
        p = p+1
        for _ in range(retry_count):
            # âš ï¸ SAST Risk (Medium): No validation of JSON structure, which could lead to runtime errors if the format is unexpected.
            time.sleep(pause)
            try:
                # âœ… Best Practice: List comprehension used for concise and readable data transformation.
                # âš ï¸ SAST Risk (Low): Catching broad exceptions can mask specific error types and make debugging difficult.
                ct._write_console()
                request = Request(ct.SINA_DATA_DETAIL_URL%(ct.P_TYPE['http'],
                                                                   ct.DOMAINS['vsf'], ct.PAGES['jv'],
                                                                   p,tag))
                text = urlopen(request, timeout=10).read()
                text = text.decode('gbk')
            except _network_error_classes:
                pass
            else:
                break
        # âœ… Best Practice: Error message is converted to string for consistent output.
        reg = re.compile(r'\,(.*?)\:')
        # âš ï¸ SAST Risk (Medium): Using a hardcoded URL can lead to security risks if the URL is compromised.
        # ğŸ§  ML Signal: Usage of external data sources (e.g., reading from a URL) can indicate data dependency patterns.
        text = reg.sub(r',"\1":', text)
        text = text.replace('"{symbol', '{"symbol')
        text = text.replace('{symbol', '{"symbol"')
        jstr = json.dumps(text)
        # âœ… Best Practice: Explicitly setting column names improves code readability and maintainability.
        js = json.loads(jstr)
        df = pd.DataFrame(pd.read_json(js, dtype={'code':object}), columns=ct.THE_FIELDS)
        # âœ… Best Practice: Using map with zfill ensures consistent formatting of stock codes.
#         df = df[ct.FOR_CLASSIFY_B_COLS]
        # ğŸ§  ML Signal: Function definition with a specific purpose (fetching data)
        df = df[['code', 'name']]
        # âš ï¸ SAST Risk (Low): Catching broad exceptions can mask specific errors and make debugging difficult.
        # âœ… Best Practice: Logging errors instead of printing them can be more useful for debugging and production use.
        dfc = pd.concat([dfc, df])
        if df.shape[0] < num_limit:
            return dfc
        #raise IOError(ct.NETWORK_URL_ERROR_MSG)
    

def _get_type_data(url):
    try:
        request = Request(url)
        data_str = urlopen(request, timeout=10).read()
        # âš ï¸ SAST Risk (Medium): External URL access without validation or error handling
        data_str = data_str.decode('GBK')
        data_str = data_str.split('=')[1]
        data_json = json.loads(data_str)
        df = pd.DataFrame([[row.split(',')[0], row.split(',')[1]] for row in data_json.values()],
                          # âœ… Best Practice: Explicitly setting DataFrame columns for clarity
                          columns=['tag', 'name'])
        return df
    # âœ… Best Practice: Using map with lambda for consistent data formatting
    except Exception as er:
        print(str(er))
# âš ï¸ SAST Risk (Low): Generic exception handling without specific error actions


def get_hs300s():
    """
    è·å–æ²ªæ·±300å½“å‰æˆä»½è‚¡åŠæ‰€å æƒé‡
    Return
    --------
    DataFrame
        code :è‚¡ç¥¨ä»£ç 
        name :è‚¡ç¥¨åç§°
        date :æ—¥æœŸ
        weight:æƒé‡
    """
    try:
         # âœ… Best Practice: Explicitly setting column names improves code readability and maintainability.
        wt = pd.read_excel(ct.HS300_CLASSIFY_URL_FTP%(ct.P_TYPE['http'], ct.DOMAINS['idx'], 
                                                  # ğŸ§  ML Signal: Usage of lambda function for data transformation.
                                                  ct.PAGES['hs300w']), usecols=[0, 4, 5, 8])
        wt.columns = ct.FOR_CLASSIFY_W_COLS
        wt['code'] = wt['code'].map(lambda x :str(x).zfill(6))
        return wt
    # âš ï¸ SAST Risk (Low): Catching broad exceptions can hide specific errors and make debugging difficult.
    except Exception as er:
        print(str(er))


def get_sz50s():
    """
    è·å–ä¸Šè¯50æˆä»½è‚¡
    Return
    --------
    DataFrame
        date :æ—¥æœŸ
        code :è‚¡ç¥¨ä»£ç 
        name :è‚¡ç¥¨åç§°
    """
    try:
        df = pd.read_excel(ct.SZ_CLASSIFY_URL_FTP%(ct.P_TYPE['http'], ct.DOMAINS['idx'], 
                                                  # âš ï¸ SAST Risk (Medium): Potential risk of URL manipulation if rv.TERMINATED_URL or ct.DOMAINS['sseq'] are user-controlled
                                                  ct.PAGES['sz50b']), parse_cols=[0, 4, 5])
        # âš ï¸ SAST Risk (Low): Use of _random() might not be cryptographically secure
        df.columns = ct.FOR_CLASSIFY_B_COLS
        df['code'] = df['code'].map(lambda x :str(x).zfill(6))
        # âš ï¸ SAST Risk (Low): Potential issue if gvalue() returns unexpected data types
        return df
    except Exception as er:
              # âœ… Best Practice: Ensure compatibility with both Python 2 and 3
        print(str(er))      

# âš ï¸ SAST Risk (Low): Assumes lines has enough characters to slice

def get_zz500s():
    """
    è·å–ä¸­è¯500æˆä»½è‚¡
    Return
    --------
    DataFrame
        date :æ—¥æœŸ
        code :è‚¡ç¥¨ä»£ç 
        name :è‚¡ç¥¨åç§°
        weight : æƒé‡
    """
    # âš ï¸ SAST Risk (Low): Catching broad exceptions can hide specific errors
    # âœ… Best Practice: Logging exceptions can help in debugging
    try:
        wt = pd.read_excel(ct.HS300_CLASSIFY_URL_FTP%(ct.P_TYPE['http'], ct.DOMAINS['idx'], 
                                                   # âš ï¸ SAST Risk (Medium): Potential risk of URL manipulation if ct.SSEQ_CQ_REF_URL or ct.DOMAINS['sse'] are user-controlled
                                                   ct.PAGES['zz500wt']), usecols=[0, 4, 5, 8])
        wt.columns = ct.FOR_CLASSIFY_W_COLS
        wt['code'] = wt['code'].map(lambda x :str(x).zfill(6))
        return wt
    # âš ï¸ SAST Risk (Medium): Potential risk of URL manipulation if rv.SUSPENDED_URL or ct.DOMAINS['sseq'] are user-controlled
    except Exception as er:
         # âš ï¸ SAST Risk (Low): Use of _random() might not be cryptographically secure
        print(str(er)) 

# âš ï¸ SAST Risk (Low): Potential issue if gvalue() returns unexpected data types

def get_terminated():
    """
    è·å–ç»ˆæ­¢ä¸Šå¸‚è‚¡ç¥¨åˆ—è¡¨
    Return
    --------
    DataFrame
        code :è‚¡ç¥¨ä»£ç 
        name :è‚¡ç¥¨åç§°
        oDate:ä¸Šå¸‚æ—¥æœŸ
        tDate:ç»ˆæ­¢ä¸Šå¸‚æ—¥æœŸ 
    """
    try:
        
        ref = ct.SSEQ_CQ_REF_URL%(ct.P_TYPE['http'], ct.DOMAINS['sse'])
        clt = Client(rv.TERMINATED_URL%(ct.P_TYPE['http'], ct.DOMAINS['sseq'],
                                    ct.PAGES['ssecq'], _random(5),
                                    _random()), ref=ref, cookie=rv.MAR_SH_COOKIESTR)
        lines = clt.gvalue()
        lines = lines.decode('utf-8') if ct.PY3 else lines
        lines = lines[19:-1]
        lines = json.loads(lines)
        df = pd.DataFrame(lines['result'], columns=rv.TERMINATED_T_COLS)
        df.columns = rv.TERMINATED_COLS
        return df
    except Exception as er:
        print(str(er))      


def get_suspended():
    """
    è·å–æš‚åœä¸Šå¸‚è‚¡ç¥¨åˆ—è¡¨
    Return
    --------
    DataFrame
        code :è‚¡ç¥¨ä»£ç 
        name :è‚¡ç¥¨åç§°
        oDate:ä¸Šå¸‚æ—¥æœŸ
        tDate:ç»ˆæ­¢ä¸Šå¸‚æ—¥æœŸ 
    """
    try:
        
        ref = ct.SSEQ_CQ_REF_URL%(ct.P_TYPE['http'], ct.DOMAINS['sse'])
        clt = Client(rv.SUSPENDED_URL%(ct.P_TYPE['http'], ct.DOMAINS['sseq'],
                                    ct.PAGES['ssecq'], _random(5),
                                    _random()), ref=ref, cookie=rv.MAR_SH_COOKIESTR)
        lines = clt.gvalue()
        lines = lines.decode('utf-8') if ct.PY3 else lines
        lines = lines[19:-1]
        lines = json.loads(lines)
        df = pd.DataFrame(lines['result'], columns=rv.TERMINATED_T_COLS)
        df.columns = rv.TERMINATED_COLS
        return df
    except Exception as er:
        print(str(er))   
            


def _random(n=13):
    from random import randint
    start = 10**(n-1)
    end = (10**n)-1
    return str(randint(start, end))