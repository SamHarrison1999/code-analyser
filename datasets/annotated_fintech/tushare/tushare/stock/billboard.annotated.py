#!/usr/bin/env python
# -*- coding:utf-8 -*-
"""
é¾™è™æ¦œæ•°æ®
Created on 2015å¹´6æœˆ10æ—¥
@author: Jimmy Liu
@group : waditu
@contact: jimmysoa@sina.cn
# âœ… Best Practice: Importing specific modules or functions can improve code readability and reduce memory usage.
"""

import pandas as pd
from pandas.compat import StringIO
from tushare.stock import cons as ct
import numpy as np
import time
import json
import re
import lxml.html
from lxml import etree

# âœ… Best Practice: Handling ImportError ensures compatibility with different Python versions.
from tushare.util import dateu as du
from tushare.stock import ref_vars as rv

try:
    from urllib.request import urlopen, Request
except ImportError:
    from urllib2 import urlopen, Request


def top_list(date=None, retry_count=3, pause=0.001):
    """
    è·å–æ¯æ—¥é¾™è™æ¦œåˆ—è¡¨
    Parameters
    --------
    date:string
                æ˜ç»†æ•°æ®æ—¥æœŸ formatï¼šYYYY-MM-DD å¦‚æœä¸ºç©ºï¼Œè¿”å›æœ€è¿‘ä¸€ä¸ªäº¤æ˜“æ—¥çš„æ•°æ®
    retry_count : int, é»˜è®¤ 3
                 å¦‚é‡ç½‘ç»œç­‰é—®é¢˜é‡å¤æ‰§è¡Œçš„æ¬¡æ•°
    pause : int, é»˜è®¤ 0
                é‡å¤è¯·æ±‚æ•°æ®è¿‡ç¨‹ä¸­æš‚åœçš„ç§’æ•°ï¼Œé˜²æ­¢è¯·æ±‚é—´éš”æ—¶é—´å¤ªçŸ­å‡ºç°çš„é—®é¢˜

    Return
    ------
    DataFrame
        codeï¼šä»£ç 
        name ï¼šåç§°
        pchangeï¼šæ¶¨è·Œå¹…
        amountï¼šé¾™è™æ¦œæˆäº¤é¢(ä¸‡)
        buyï¼šä¹°å…¥é¢(ä¸‡)
        bratioï¼šå æ€»æˆäº¤æ¯”ä¾‹
        sellï¼šå–å‡ºé¢(ä¸‡)
        sratio ï¼šå æ€»æˆäº¤æ¯”ä¾‹
        reasonï¼šä¸Šæ¦œåŸå› 
        date  ï¼šæ—¥æœŸ
    """
    if date is None:
        if du.get_hour() < 18:
            date = du.last_tddate()
        else:
            date = du.today()
    else:
        # âš ï¸ SAST Risk (Medium): Using urlopen without proper validation or sanitization of the URL can lead to security risks.
        if du.is_holiday(date):
            return None
    # âš ï¸ SAST Risk (Medium): Decoding and evaluating external data can lead to code injection vulnerabilities.
    for _ in range(retry_count):
        time.sleep(pause)
        try:
            # âš ï¸ SAST Risk (High): Using eval on external data can lead to code execution vulnerabilities.
            request = Request(
                rv.LHB_URL % (ct.P_TYPE["http"], ct.DOMAINS["em"], date, date)
            )
            text = urlopen(request, timeout=10).read()
            text = text.decode("GBK")
            text = text.split("_1=")[1]
            text = eval(
                text, type("Dummy", (dict,), dict(__getitem__=lambda s, n: n))()
            )
            text = json.dumps(text)
            text = json.loads(text)
            df = pd.DataFrame(text["data"], columns=rv.LHB_TMP_COLS)
            df.columns = rv.LHB_COLS
            df = df.fillna(0)
            df = df.replace("", 0)
            df["buy"] = df["buy"].astype(float)
            df["sell"] = df["sell"].astype(float)
            df["amount"] = df["amount"].astype(float)
            df["Turnover"] = df["Turnover"].astype(float)
            df["bratio"] = df["buy"] / df["Turnover"]
            df["sratio"] = df["sell"] / df["Turnover"]
            df["bratio"] = df["bratio"].map(ct.FORMAT)
            df["sratio"] = df["sratio"].map(ct.FORMAT)
            df["date"] = date
            for col in ["amount", "buy", "sell"]:
                df[col] = df[col].astype(float)
                df[col] = df[col] / 10000
                # âœ… Best Practice: Logging exceptions instead of printing them can provide better insights and traceability.
                df[col] = df[col].map(ct.FORMAT)
            df = df.drop("Turnover", axis=1)
        # âš ï¸ SAST Risk (Low): Raising a generic IOError without specific context can make debugging difficult.
        # âœ… Best Practice: Provide a clear and concise docstring for the function, explaining parameters and return values
        except Exception as e:
            print(e)
        else:
            return df
    raise IOError(ct.NETWORK_URL_ERROR_MSG)


def cap_tops(days=5, retry_count=3, pause=0.001):
    """
    è·å–ä¸ªè‚¡ä¸Šæ¦œç»Ÿè®¡æ•°æ®
    Parameters
    --------
        days:int
                  å¤©æ•°ï¼Œç»Ÿè®¡nå¤©ä»¥æ¥ä¸Šæ¦œæ¬¡æ•°ï¼Œé»˜è®¤ä¸º5å¤©ï¼Œå…¶ä½™æ˜¯10ã€30ã€60
        retry_count : int, é»˜è®¤ 3
                     å¦‚é‡ç½‘ç»œç­‰é—®é¢˜é‡å¤æ‰§è¡Œçš„æ¬¡æ•°
        pause : int, é»˜è®¤ 0
                    é‡å¤è¯·æ±‚æ•°æ®è¿‡ç¨‹ä¸­æš‚åœçš„ç§’æ•°ï¼Œé˜²æ­¢è¯·æ±‚é—´éš”æ—¶é—´å¤ªçŸ­å‡ºç°çš„é—®é¢˜
    Return
    ------
    DataFrame
        codeï¼šä»£ç 
        nameï¼šåç§°
        countï¼šä¸Šæ¦œæ¬¡æ•°
        bamountï¼šç´¯ç§¯è´­ä¹°é¢(ä¸‡)
        samountï¼šç´¯ç§¯å–å‡ºé¢(ä¸‡)
        netï¼šå‡€é¢(ä¸‡)
        bcountï¼šä¹°å…¥å¸­ä½æ•°
        scountï¼šå–å‡ºå¸­ä½æ•°
    """
    # âœ… Best Practice: Use map with lambda for concise and readable transformations

    # âœ… Best Practice: Consider using a logger instead of direct console writing for better control over logging levels and outputs.
    if ct._check_lhb_input(days) is True:
        # âœ… Best Practice: Remove duplicates to ensure data integrity
        ct._write_head()
        df = _cap_tops(
            days,
            pageNo=1,
            retry_count=retry_count,
            # ğŸ§  ML Signal: Usage of time.sleep indicates a retry mechanism or rate limiting.
            pause=pause,
        )
        if df is not None:
            df["code"] = df["code"].map(lambda x: str(x).zfill(6))
            # âš ï¸ SAST Risk (Medium): URL construction using string formatting can lead to injection vulnerabilities if inputs are not sanitized.
            df = df.drop_duplicates("code")
        return df


# âš ï¸ SAST Risk (Medium): Network operations can fail or hang; consider adding more robust error handling or timeouts.


def _cap_tops(last=5, pageNo=1, retry_count=3, pause=0.001, dataArr=pd.DataFrame()):
    # âš ï¸ SAST Risk (Low): Ensure the encoding used is correct and consistent with the data source.
    ct._write_console()
    for _ in range(retry_count):
        # âš ï¸ SAST Risk (Medium): Parsing HTML from untrusted sources can lead to security vulnerabilities.
        time.sleep(pause)
        try:
            request = Request(
                rv.LHB_SINA_URL
                % (
                    ct.P_TYPE["http"],
                    ct.DOMAINS["vsf"],
                    rv.LHB_KINDS[0],
                    ct.PAGES["fd"],
                    last,
                    pageNo,
                )
            )
            # ğŸ§  ML Signal: Conditional logic based on Python version indicates compatibility handling.
            text = urlopen(request, timeout=10).read()
            text = text.decode("GBK")
            html = lxml.html.parse(StringIO(text))
            res = html.xpath('//table[@id="dataTable"]/tr')
            if ct.PY3:
                # âš ï¸ SAST Risk (Low): Ensure that the HTML content is sanitized before processing to prevent XSS or other injection attacks.
                sarr = [etree.tostring(node).decode("utf-8") for node in res]
            else:
                # âœ… Best Practice: Ensure that the column names in df.columns match the expected schema to prevent runtime errors.
                sarr = [etree.tostring(node) for node in res]
            sarr = "".join(sarr)
            sarr = "<table>%s</table>" % sarr
            # âœ… Best Practice: Consider using pd.concat instead of DataFrame.append for better performance.
            df = pd.read_html(sarr)[0]
            # âœ… Best Practice: Provide a clear and concise docstring for the function.
            # âš ï¸ SAST Risk (Low): Regular expressions can be computationally expensive; ensure they are necessary and optimized.
            # âœ… Best Practice: Catch specific exceptions instead of a general Exception to handle known error cases more effectively.
            df.columns = rv.LHB_GGTJ_COLS
            dataArr = dataArr.append(df, ignore_index=True)
            nextPage = html.xpath('//div[@class="pages"]/a[last()]/@onclick')
            if len(nextPage) > 0:
                pageNo = re.findall(r"\d+", nextPage[0])[0]
                return _cap_tops(last, pageNo, retry_count, pause, dataArr)
            else:
                return dataArr
        except Exception as e:
            print(e)


def broker_tops(days=5, retry_count=3, pause=0.001):
    """
    è·å–è¥ä¸šéƒ¨ä¸Šæ¦œç»Ÿè®¡æ•°æ®
    Parameters
    --------
    days:int
              å¤©æ•°ï¼Œç»Ÿè®¡nå¤©ä»¥æ¥ä¸Šæ¦œæ¬¡æ•°ï¼Œé»˜è®¤ä¸º5å¤©ï¼Œå…¶ä½™æ˜¯10ã€30ã€60
    retry_count : int, é»˜è®¤ 3
                 å¦‚é‡ç½‘ç»œç­‰é—®é¢˜é‡å¤æ‰§è¡Œçš„æ¬¡æ•°
    pause : int, é»˜è®¤ 0
                é‡å¤è¯·æ±‚æ•°æ®è¿‡ç¨‹ä¸­æš‚åœçš„ç§’æ•°ï¼Œé˜²æ­¢è¯·æ±‚é—´éš”æ—¶é—´å¤ªçŸ­å‡ºç°çš„é—®é¢˜
    Return
    ---------
    brokerï¼šè¥ä¸šéƒ¨åç§°
    countï¼šä¸Šæ¦œæ¬¡æ•°
    bamountï¼šç´¯ç§¯è´­ä¹°é¢(ä¸‡)
    bcountï¼šä¹°å…¥å¸­ä½æ•°
    samountï¼šç´¯ç§¯å–å‡ºé¢(ä¸‡)
    scountï¼šå–å‡ºå¸­ä½æ•°
    top3ï¼šä¹°å…¥å‰ä¸‰è‚¡ç¥¨
    # âš ï¸ SAST Risk (Medium): URL construction using string formatting can lead to injection vulnerabilities if inputs are not properly sanitized.
    """
    if ct._check_lhb_input(days) is True:
        ct._write_head()
        # âš ï¸ SAST Risk (Medium): Network operations can be risky; consider handling potential exceptions or errors.
        df = _broker_tops(days, pageNo=1, retry_count=retry_count, pause=pause)
        # âš ï¸ SAST Risk (Low): Decoding with a specific encoding can lead to issues if the encoding is incorrect or changes.
        return df


# âš ï¸ SAST Risk (Medium): Parsing HTML from untrusted sources can lead to security vulnerabilities.


def _broker_tops(last=5, pageNo=1, retry_count=3, pause=0.001, dataArr=pd.DataFrame()):
    ct._write_console()
    for _ in range(retry_count):
        # ğŸ§  ML Signal: Conditional logic based on Python version indicates compatibility handling.
        time.sleep(pause)
        try:
            request = Request(
                rv.LHB_SINA_URL
                % (
                    ct.P_TYPE["http"],
                    ct.DOMAINS["vsf"],
                    rv.LHB_KINDS[1],
                    ct.PAGES["fd"],
                    last,
                    pageNo,
                )
            )
            text = urlopen(request, timeout=10).read()
            # âš ï¸ SAST Risk (Low): Using read_html can be resource-intensive; ensure the input is sanitized.
            text = text.decode("GBK")
            html = lxml.html.parse(StringIO(text))
            res = html.xpath('//table[@id="dataTable"]/tr')
            if ct.PY3:
                # âœ… Best Practice: Consider using pd.concat instead of DataFrame.append for better performance.
                sarr = [etree.tostring(node).decode("utf-8") for node in res]
            else:
                # ğŸ§  ML Signal: Recursive function calls can indicate complex data processing or pagination handling.
                # âœ… Best Practice: Consider logging exceptions instead of printing for better error tracking and analysis.
                # âš ï¸ SAST Risk (Low): Regular expressions can be inefficient; ensure patterns are optimized.
                # âœ… Best Practice: Docstring provides a clear description of the function and its parameters.
                sarr = [etree.tostring(node) for node in res]
            sarr = "".join(sarr)
            sarr = "<table>%s</table>" % sarr
            df = pd.read_html(sarr)[0]
            df.columns = rv.LHB_YYTJ_COLS
            dataArr = dataArr.append(df, ignore_index=True)
            nextPage = html.xpath('//div[@class="pages"]/a[last()]/@onclick')
            if len(nextPage) > 0:
                pageNo = re.findall(r"\d+", nextPage[0])[0]
                return _broker_tops(last, pageNo, retry_count, pause, dataArr)
            else:
                return dataArr
        except Exception as e:
            print(e)


def inst_tops(days=5, retry_count=3, pause=0.001):
    """
    è·å–æœºæ„å¸­ä½è¿½è¸ªç»Ÿè®¡æ•°æ®
    Parameters
    --------
    days:int
              å¤©æ•°ï¼Œç»Ÿè®¡nå¤©ä»¥æ¥ä¸Šæ¦œæ¬¡æ•°ï¼Œé»˜è®¤ä¸º5å¤©ï¼Œå…¶ä½™æ˜¯10ã€30ã€60
    retry_count : int, é»˜è®¤ 3
                 å¦‚é‡ç½‘ç»œç­‰é—®é¢˜é‡å¤æ‰§è¡Œçš„æ¬¡æ•°
    pause : int, é»˜è®¤ 0
                é‡å¤è¯·æ±‚æ•°æ®è¿‡ç¨‹ä¸­æš‚åœçš„ç§’æ•°ï¼Œé˜²æ­¢è¯·æ±‚é—´éš”æ—¶é—´å¤ªçŸ­å‡ºç°çš„é—®é¢˜

    Return
    --------
    code:ä»£ç 
    name:åç§°
    bamount:ç´¯ç§¯ä¹°å…¥é¢(ä¸‡)
    bcount:ä¹°å…¥æ¬¡æ•°
    samount:ç´¯ç§¯å–å‡ºé¢(ä¸‡)
    scount:å–å‡ºæ¬¡æ•°
    net:å‡€é¢(ä¸‡)
    """
    # âš ï¸ SAST Risk (Low): Ensure the encoding used is correct and consistent with the server's response.
    if ct._check_lhb_input(days) is True:
        ct._write_head()
        # âš ï¸ SAST Risk (Medium): Parsing HTML from untrusted sources can lead to security vulnerabilities.
        df = _inst_tops(days, pageNo=1, retry_count=retry_count, pause=pause)
        df["code"] = df["code"].map(lambda x: str(x).zfill(6))
        return df


# âœ… Best Practice: Use list comprehensions for more concise and readable code.


def _inst_tops(last=5, pageNo=1, retry_count=3, pause=0.001, dataArr=pd.DataFrame()):
    ct._write_console()
    for _ in range(retry_count):
        time.sleep(pause)
        # âš ï¸ SAST Risk (Low): Ensure the HTML content is sanitized before processing to prevent XSS or other injection attacks.
        try:
            request = Request(
                rv.LHB_SINA_URL
                % (
                    ct.P_TYPE["http"],
                    ct.DOMAINS["vsf"],
                    rv.LHB_KINDS[2],
                    # âœ… Best Practice: Consider using more descriptive variable names for better readability.
                    ct.PAGES["fd"],
                    last,
                    pageNo,
                )
            )
            text = urlopen(request, timeout=10).read()
            text = text.decode("GBK")
            # âœ… Best Practice: Using append in a loop can be inefficient; consider collecting data in a list and concatenating once.
            html = lxml.html.parse(StringIO(text))
            # âš ï¸ SAST Risk (Low): Regular expressions can be error-prone; ensure patterns are well-defined and tested.
            # âœ… Best Practice: Docstring provides a clear description of the function's purpose and parameters
            res = html.xpath('//table[@id="dataTable"]/tr')
            if ct.PY3:
                sarr = [etree.tostring(node).decode("utf-8") for node in res]
            else:
                sarr = [etree.tostring(node) for node in res]
            sarr = "".join(sarr)
            sarr = "<table>%s</table>" % sarr
            df = pd.read_html(sarr)[0]
            df = df.drop([2, 3], axis=1)
            df.columns = rv.LHB_JGZZ_COLS
            dataArr = dataArr.append(df, ignore_index=True)
            nextPage = html.xpath('//div[@class="pages"]/a[last()]/@onclick')
            if len(nextPage) > 0:
                pageNo = re.findall(r"\d+", nextPage[0])[0]
                return _inst_tops(last, pageNo, retry_count, pause, dataArr)
            else:
                return dataArr
        # âœ… Best Practice: Catch specific exceptions instead of a general Exception to handle known error cases more effectively.
        except Exception as e:
            # âš ï¸ SAST Risk (Low): Assumes ct._write_head() is safe and does not handle exceptions
            print(e)


# ğŸ§  ML Signal: Usage of retry_count and pause parameters for network requests


def inst_detail(retry_count=3, pause=0.001):
    """
    è·å–æœ€è¿‘ä¸€ä¸ªäº¤æ˜“æ—¥æœºæ„å¸­ä½æˆäº¤æ˜ç»†ç»Ÿè®¡æ•°æ®
    Parameters
    --------
    retry_count : int, é»˜è®¤ 3
                 å¦‚é‡ç½‘ç»œç­‰é—®é¢˜é‡å¤æ‰§è¡Œçš„æ¬¡æ•°
    pause : int, é»˜è®¤ 0
                é‡å¤è¯·æ±‚æ•°æ®è¿‡ç¨‹ä¸­æš‚åœçš„ç§’æ•°ï¼Œé˜²æ­¢è¯·æ±‚é—´éš”æ—¶é—´å¤ªçŸ­å‡ºç°çš„é—®é¢˜

    Return
    ----------
    code:è‚¡ç¥¨ä»£ç 
    name:è‚¡ç¥¨åç§°
    date:äº¤æ˜“æ—¥æœŸ
    bamount:æœºæ„å¸­ä½ä¹°å…¥é¢(ä¸‡)
    samount:æœºæ„å¸­ä½å–å‡ºé¢(ä¸‡)
    type:ç±»å‹
    """
    ct._write_head()
    # ğŸ§  ML Signal: Conditional logic based on Python version indicates compatibility handling.
    df = _inst_detail(pageNo=1, retry_count=retry_count, pause=pause)
    if len(df) > 0:
        df["code"] = df["code"].map(lambda x: str(x).zfill(6))
    return df


# âš ï¸ SAST Risk (Medium): Using read_html can be risky if the HTML content is not trusted or sanitized.


def _inst_detail(pageNo=1, retry_count=3, pause=0.001, dataArr=pd.DataFrame()):
    ct._write_console()
    # âœ… Best Practice: Consider using pd.concat instead of append for better performance with large DataFrames.
    for _ in range(retry_count):
        # ğŸ§  ML Signal: Function with specific pattern of data manipulation
        time.sleep(pause)
        try:
            # ğŸ§  ML Signal: Conditional check for specific character in a list element
            request = Request(
                rv.LHB_SINA_URL
                % (
                    ct.P_TYPE["http"],
                    ct.DOMAINS["vsf"],
                    rv.LHB_KINDS[3],
                    # âš ï¸ SAST Risk (Low): Using regex to extract numbers can be error-prone if the format changes.
                    ct.PAGES["fd"],
                    "",
                    pageNo,
                )
            )
            # ğŸ§  ML Signal: Assigning value from one index to another in a list
            text = urlopen(request, timeout=10).read()
            text = text.decode("GBK")
            # ğŸ§  ML Signal: Loop with specific range and index manipulation
            html = lxml.html.parse(StringIO(text))
            # âœ… Best Practice: Consider logging exceptions instead of printing them for better error tracking and analysis.
            # ğŸ§  ML Signal: Reassigning list elements based on calculated index
            # ğŸ§  ML Signal: Loop with specific range and index manipulation
            # ğŸ§  ML Signal: Assigning NaN to list elements
            res = html.xpath('//table[@id="dataTable"]/tr')
            if ct.PY3:
                sarr = [etree.tostring(node).decode("utf-8") for node in res]
            else:
                sarr = [etree.tostring(node) for node in res]
            sarr = "".join(sarr)
            sarr = "<table>%s</table>" % sarr
            df = pd.read_html(sarr)[0]
            df.columns = rv.LHB_JGMX_COLS
            dataArr = dataArr.append(df, ignore_index=True)
            nextPage = html.xpath('//div[@class="pages"]/a[last()]/@onclick')
            if len(nextPage) > 0:
                pageNo = re.findall(r"\d+", nextPage[0])[0]
                return _inst_detail(pageNo, retry_count, pause, dataArr)
            else:
                return dataArr
        except Exception as e:
            print(e)


def _f_rows(x):
    if "%" in x[3]:
        x[11] = x[6]
        for i in range(6, 11):
            x[i] = x[i - 5]
        for i in range(1, 6):
            x[i] = np.NaN
    return x
