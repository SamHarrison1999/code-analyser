# -*- coding:utf-8 -*-

"""
è‚¡ç¥¨æŠ€æœ¯æŒ‡æ ‡æ¥å£
Created on 2018/07/26
@author: Wangzili
@group : **
@contact: 446406177@qq.com

æ‰€æœ‰æŒ‡æ ‡ä¸­å‚æ•°dfä¸ºé€šè¿‡get_k_dataè·å–çš„è‚¡ç¥¨æ•°æ®
"""
# âœ… Best Practice: Consider adding type hints for function parameters and return type
import pandas as pd

# ğŸ§  ML Signal: Importing pandas, numpy, and itertools indicates data manipulation and analysis tasks
import numpy as np
import itertools


def ma(df, n=10):
    """
    ç§»åŠ¨å¹³å‡çº¿ Moving Average
    MAï¼ˆNï¼‰=ï¼ˆç¬¬1æ—¥æ”¶ç›˜ä»·+ç¬¬2æ—¥æ”¶ç›˜ä»·â€”+â€¦â€¦+ç¬¬Næ—¥æ”¶ç›˜ä»·ï¼‰/N
    # âœ… Best Practice: Add type hints for function parameters and return type
    """
    # âš ï¸ SAST Risk (Low): Ensure 'df' contains 'close' column to avoid AttributeError
    pv = pd.DataFrame()
    pv["date"] = df["date"]
    pv["v"] = df.close.rolling(n).mean()
    # ğŸ§  ML Signal: Function returns a DataFrame with a moving average calculation
    return pv


# âœ… Best Practice: Consider adding type hints for function parameters and return type for better readability and maintainability.
# ğŸ§  ML Signal: Usage of rolling window operations on time series data


def _ma(series, n):
    """
    ç§»åŠ¨å¹³å‡
    """
    # âœ… Best Practice: Use descriptive variable names for better readability.
    return series.rolling(n).mean()


# ğŸ§  ML Signal: Usage of rolling window and standard deviation calculation, common in time series analysis.
def md(df, n=10):
    """
    ç§»åŠ¨æ ‡å‡†å·®
    STD=Sï¼ˆCLOSE,Nï¼‰=[âˆ‘ï¼ˆCLOSE-MA(CLOSEï¼ŒN)ï¼‰^2/N]^0.5
    # âœ… Best Practice: Use of descriptive function and variable names for clarity
    """
    # ğŸ§  ML Signal: Use of rolling window operation, common in time series analysis
    _md = pd.DataFrame()
    _md["date"] = df.date
    _md["md"] = df.close.rolling(n).std(ddof=0)
    return _md


# âœ… Best Practice: Use of pandas DataFrame to store and manipulate data
def _md(series, n):
    """
    æ ‡å‡†å·®MD
    """
    # ğŸ§  ML Signal: Use of exponential moving average, a common technique in time series analysis
    return series.rolling(n).std(ddof=0)  # æœ‰æ—¶å€™ä¼šç”¨ddof=1


# âœ… Best Practice: Use of pandas ewm method for calculating exponential moving average


def ema(df, n=12):
    """
    æŒ‡æ•°å¹³å‡æ•°æŒ‡æ ‡ Exponential Moving Average
    ä»Šæ—¥EMAï¼ˆNï¼‰=2/ï¼ˆN+1ï¼‰Ã—ä»Šæ—¥æ”¶ç›˜ä»·+(N-1)/ï¼ˆN+1ï¼‰Ã—æ˜¨æ—¥EMAï¼ˆNï¼‰
    EMA(X,N)=[2Ã—X+(N-1)Ã—EMA(ref(X),N]/(N+1)
    """
    _ema = pd.DataFrame()
    _ema["date"] = df["date"]
    _ema["ema"] = df.close.ewm(
        ignore_na=False, span=n, min_periods=0, adjust=False
    ).mean()
    return _ema


def _ema(series, n):
    """
    æŒ‡æ•°å¹³å‡æ•°
    # âœ… Best Practice: Use of a DataFrame to store and manipulate financial data
    """
    return series.ewm(ignore_na=False, span=n, min_periods=0, adjust=False).mean()


# âœ… Best Practice: Explicitly copying the 'date' column for clarity and maintainability


# ğŸ§  ML Signal: Calculation of financial indicators, useful for learning financial data processing
def macd(df, n=12, m=26, k=9):
    """
    å¹³æ»‘å¼‚åŒç§»åŠ¨å¹³å‡çº¿(Moving Average Convergence Divergence)
    ä»Šæ—¥EMAï¼ˆNï¼‰=2/ï¼ˆN+1ï¼‰Ã—ä»Šæ—¥æ”¶ç›˜ä»·+(N-1)/ï¼ˆN+1ï¼‰Ã—æ˜¨æ—¥EMAï¼ˆNï¼‰
    DIFF= EMAï¼ˆN1ï¼‰- EMAï¼ˆN2ï¼‰
    DEA(DIF,M)= 2/(M+1)Ã—DIF +[1-2/(M+1)]Ã—DEA(REF(DIF,1),M)
    MACDï¼ˆBARï¼‰=2Ã—ï¼ˆDIF-DEAï¼‰
    return:
          osc: MACD bar / OSC å·®å€¼æŸ±å½¢å›¾ DIFF - DEM
          diff: å·®ç¦»å€¼
          dea: è®¯å·çº¿
    """
    _macd = pd.DataFrame()
    # âš ï¸ SAST Risk (Low): Potential division by zero if (df.high.rolling(n).max() - df.low.rolling(n).min()) is zero
    _macd["date"] = df["date"]
    _macd["diff"] = _ema(df.close, n) - _ema(df.close, m)
    # ğŸ§  ML Signal: Usage of rolling window operations, common in time series analysis
    _macd["dea"] = _ema(_macd["diff"], k)
    _macd["macd"] = _macd["diff"] - _macd["dea"]
    # ğŸ§  ML Signal: Usage of simple moving average, common in financial calculations
    return _macd


def kdj(df, n=9):
    """
    éšæœºæŒ‡æ ‡KDJ
    Næ—¥RSV=ï¼ˆç¬¬Næ—¥æ”¶ç›˜ä»·-Næ—¥å†…æœ€ä½ä»·ï¼‰/ï¼ˆNæ—¥å†…æœ€é«˜ä»·-Næ—¥å†…æœ€ä½ä»·ï¼‰Ã—100%
    å½“æ—¥Kå€¼=2/3å‰1æ—¥Kå€¼+1/3Ã—å½“æ—¥RSV=SMAï¼ˆRSV,M1ï¼‰
    å½“æ—¥Då€¼=2/3å‰1æ—¥Då€¼+1/3Ã—å½“æ—¥K= SMAï¼ˆK,M2ï¼‰
    å½“æ—¥Jå€¼=3 Ã—å½“æ—¥Kå€¼-2Ã—å½“æ—¥Då€¼
    # ğŸ§  ML Signal: Usage of shift to calculate differences in time series data
    """
    _kdj = pd.DataFrame()
    # ğŸ§  ML Signal: Handling negative values by setting them to zero
    # âœ… Best Practice: Consider adding type hints for function parameters and return type for better readability and maintainability.
    _kdj["date"] = df["date"]
    # ğŸ§  ML Signal: Calculation of RSI using a custom SMA function
    # âš ï¸ SAST Risk (Low): Potential division by zero if sma returns zero
    rsv = (
        (df.close - df.low.rolling(n).min())
        / (df.high.rolling(n).max() - df.low.rolling(n).min())
        * 100
    )
    _kdj["k"] = sma(rsv, 3)
    _kdj["d"] = sma(_kdj.k, 3)
    _kdj["j"] = 3 * _kdj.k - 2 * _kdj.d
    # âœ… Best Practice: Return the DataFrame containing RSI values
    return _kdj


# ğŸ§  ML Signal: Usage of pandas DataFrame, which is common in data analysis and ML pipelines.


# ğŸ§  ML Signal: Storing 'date' column separately, indicating time-series data processing.
def rsi(df, n=6):
    """
    ç›¸å¯¹å¼ºå¼±æŒ‡æ ‡ï¼ˆRelative Strength Indexï¼Œç®€ç§°RSI
    LC= REF(CLOSE,1)
    RSI=SMA(MAX(CLOSE-LC,0),N,1)/SMA(ABS(CLOSE-LC),N1,1)Ã—100
    SMAï¼ˆC,N,Mï¼‰=M/NÃ—ä»Šæ—¥æ”¶ç›˜ä»·+(N-M)/NÃ—æ˜¨æ—¥SMAï¼ˆNï¼‰
    """
    # pd.set_option('display.max_rows', 1000)
    _rsi = pd.DataFrame()
    _rsi["date"] = df["date"]
    # âœ… Best Practice: Ensure the function returns a DataFrame with expected structure for consistency.
    px = df.close - df.close.shift(1)
    # âœ… Best Practice: Initialize a new DataFrame for storing results
    px[px < 0] = 0
    _rsi["rsi"] = sma(px, n) / sma((df["close"] - df["close"].shift(1)).abs(), n) * 100
    # âœ… Best Practice: Explicitly assign columns to the DataFrame for clarity
    # def tmax(x):
    #     if x < 0:
    # ğŸ§  ML Signal: Usage of moving average function, common in financial data analysis
    #         x = 0
    #     return x
    # ğŸ§  ML Signal: Calculation of standard deviation, a common statistical operation
    # _rsi['rsi'] = sma((df['close'] - df['close'].shift(1)).apply(tmax), n) / sma((df['close'] - df['close'].shift(1)).abs(), n) * 100
    # âœ… Best Practice: Use of descriptive column names for readability
    return _rsi


def vrsi(df, n=6):
    """
    é‡ç›¸å¯¹å¼ºå¼±æŒ‡æ ‡
    VRSI=SMAï¼ˆæœ€å¤§å€¼ï¼ˆæˆäº¤é‡-REFï¼ˆæˆäº¤é‡ï¼Œ1ï¼‰ï¼Œ0ï¼‰ï¼ŒN,1ï¼‰/SMAï¼ˆABSï¼ˆï¼ˆæˆäº¤é‡-REFï¼ˆæˆäº¤é‡ï¼Œ1ï¼‰ï¼ŒNï¼Œ1ï¼‰Ã—100%
    # âœ… Best Practice: Return the DataFrame for further use or analysis
    # âœ… Best Practice: Initialize a new DataFrame to store results, improving code organization and readability.
    """
    _vrsi = pd.DataFrame()
    # ğŸ§  ML Signal: Using 'date' as a key column suggests time series data, which is common in financial datasets.
    _vrsi["date"] = df["date"]
    px = df["volume"] - df["volume"].shift(1)
    # ğŸ§  ML Signal: Calculation of moving averages is a common pattern in financial data analysis.
    px[px < 0] = 0
    _vrsi["vrsi"] = (
        sma(px, n) / sma((df["volume"] - df["volume"].shift(1)).abs(), n) * 100
    )
    # ğŸ§  ML Signal: Calculation of standard deviation is a common statistical operation in data analysis.
    return _vrsi


# âœ… Best Practice: Consider adding type hints for function parameters and return type for better readability and maintainability.

# ğŸ§  ML Signal: Calculation of upper and lower bands is a common pattern in technical analysis.


def boll(df, n=26, k=2):
    """
    å¸ƒæ—çº¿æŒ‡æ ‡BOLL boll(26,2)	MID=MA(N)
    æ ‡å‡†å·®MD=æ ¹å·[âˆ‘ï¼ˆCLOSE-MA(CLOSEï¼ŒN)ï¼‰^2/N]
    UPPER=MIDï¼‹kÃ—MD
    LOWER=MIDï¼kÃ—MD
    """
    # âœ… Best Practice: Use consistent naming conventions for variables (e.g., 'highest' instead of 'higest').
    _boll = pd.DataFrame()
    # âœ… Best Practice: Consider adding type hints for function parameters and return type for better readability and maintainability.
    _boll["date"] = df.date
    # âš ï¸ SAST Risk (Low): Ensure 'df' contains 'high', 'close', and 'low' columns to prevent KeyError.
    _boll["mid"] = _ma(df.close, n)
    _mdd = _md(df.close, n)
    _boll["up"] = _boll.mid + k * _mdd
    _boll["low"] = _boll.mid - k * _mdd
    return _boll


# âœ… Best Practice: Use descriptive variable names for better readability.


def bbiboll(df, n=10, k=3):
    """
    BBIå¤šç©ºå¸ƒæ—çº¿	bbiboll(10,3)
    BBI={MA(3)+ MA(6)+ MA(12)+ MA(24)}/4
    æ ‡å‡†å·®MD=æ ¹å·[âˆ‘ï¼ˆBBI-MA(BBIï¼ŒN)ï¼‰^2/N]
    UPR= BBIï¼‹kÃ—MD
    DWN= BBIï¼kÃ—MD
    # âœ… Best Practice: Consider checking if 'date', 'high', 'low', 'close', and 'open' columns exist in df to avoid runtime errors.
    """
    # pd.set_option('display.max_rows', 1000)
    _bbiboll = pd.DataFrame()
    _bbiboll["date"] = df.date
    _bbiboll["bbi"] = (
        _ma(df.close, 3) + _ma(df.close, 6) + _ma(df.close, 12) + _ma(df.close, 24)
    ) / 4
    _bbiboll["md"] = _md(_bbiboll.bbi, n)
    _bbiboll["upr"] = _bbiboll.bbi + k * _bbiboll.md
    _bbiboll["dwn"] = _bbiboll.bbi - k * _bbiboll.md
    return _bbiboll


# ğŸ§  ML Signal: Use of lambda function for row-wise operations on DataFrame.


def wr(df, n=14):
    """
    å¨å»‰æŒ‡æ ‡ w&r
    WR=[æœ€é«˜å€¼ï¼ˆæœ€é«˜ä»·ï¼ŒNï¼‰-æ”¶ç›˜ä»·]/[æœ€é«˜å€¼ï¼ˆæœ€é«˜ä»·ï¼ŒNï¼‰-æœ€ä½å€¼ï¼ˆæœ€ä½ä»·ï¼ŒNï¼‰]Ã—100%
    # âš ï¸ SAST Risk (Low): Ensure _ma function is defined and handles edge cases like division by zero.
    """

    _wr = pd.DataFrame()
    _wr["date"] = df["date"]
    higest = df.high.rolling(n).max()
    _wr["wr"] = (higest - df.close) / (higest - df.low.rolling(n).min()) * 100
    return _wr


# âš ï¸ SAST Risk (Low): Assumes 'date' column exists in df without validation
def bias(df, n=12):
    """
    ä¹–ç¦»ç‡ bias
    bias=[(å½“æ—¥æ”¶ç›˜ä»·-12æ—¥å¹³å‡ä»·)/12æ—¥å¹³å‡ä»·]Ã—100%
    # âš ï¸ SAST Risk (Low): Assumes 'volume' column exists in df without validation
    """
    _bias = pd.DataFrame()
    # âš ï¸ SAST Risk (Low): Assumes 'close' column exists in df without validation
    _bias["date"] = df.date
    # âœ… Best Practice: Use of lambda for conditional logic in DataFrame
    _mav = df.close.rolling(n).mean()
    _bias["bias"] = (np.true_divide((df.close - _mav), _mav)) * 100
    # _bias["bias"] = np.vectorize(lambda x: round(Decimal(x), 4))(BIAS)
    return _bias


# âœ… Best Practice: Use of rolling window for time series calculations


def asi(df, n=5):
    """
    æŒ¯åŠ¨å‡é™æŒ‡æ ‡(ç´¯è®¡éœ‡åŠ¨å‡é™å› å­) ASI  # åŒèŠ±é¡ºç»™å‡ºçš„å…¬å¼ä¸å®Œæ•´å°±ä¸è´´å‡ºæ¥äº†
    """
    _asi = pd.DataFrame()
    # âœ… Best Practice: Initialize an empty DataFrame to store results
    _asi["date"] = df.date
    _m = pd.DataFrame()
    # ğŸ§  ML Signal: Using 'date' as a key feature for time series analysis
    _m["a"] = (df.high - df.close.shift()).abs()
    _m["b"] = (df.low - df.close.shift()).abs()
    # ğŸ§  ML Signal: Calculating volume ratio as a feature for stock analysis
    _m["c"] = (df.high - df.low.shift()).abs()
    # âš ï¸ SAST Risk (Low): Potential division by zero if _ma(df.volume, n).shift(1) contains zeros
    # ğŸ§  ML Signal: Function definition with default parameter value
    _m["d"] = (df.close.shift() - df.open.shift()).abs()
    # ğŸ§  ML Signal: Calculating rate of return as a feature for stock analysis
    # âœ… Best Practice: Return the DataFrame containing calculated features
    _m["r"] = _m.apply(
        lambda x: (
            x.a + 0.5 * x.b + 0.25 * x.d
            if max(x.a, x.b, x.c) == x.a
            else (
                x.b + 0.5 * x.a + 0.25 * x.d
                if max(x.a, x.b, x.c) == x.b
                else x.c + 0.25 * x.d
            )
        ),
        axis=1,
    )
    _m["x"] = (
        df.close
        - df.close.shift()
        + 0.5 * (df.close - df.open)
        + df.close.shift()
        - df.open.shift()
    )
    _m["k"] = np.maximum(_m.a, _m.b)
    _asi["si"] = 16 * (_m.x / _m.r) * _m.k
    _asi["asi"] = _ma(_asi.si, n)
    return _asi


# âš ï¸ SAST Risk (Low): No input validation for 'df', potential for unexpected errors


# âš ï¸ SAST Risk (Low): Assumes 'date' column exists in 'df', potential KeyError
def vr_rate(df, n=26):
    """
    æˆäº¤é‡å˜å¼‚ç‡ vr or vr_rate
    VR=ï¼ˆAVS+1/2CVSï¼‰/ï¼ˆBVS+1/2CVSï¼‰Ã—100
    å…¶ä¸­ï¼š
    AVSï¼šè¡¨ç¤ºNæ—¥å†…è‚¡ä»·ä¸Šæ¶¨æˆäº¤é‡ä¹‹å’Œ
    BVSï¼šè¡¨ç¤ºNæ—¥å†…è‚¡ä»·ä¸‹è·Œæˆäº¤é‡ä¹‹å’Œ
    CVSï¼šè¡¨ç¤ºNæ—¥å†…è‚¡ä»·ä¸æ¶¨ä¸è·Œæˆäº¤é‡ä¹‹å’Œ
    # âœ… Best Practice: Use parentheses for clarity in arithmetic operations
    """
    # âœ… Best Practice: Initialize an empty DataFrame with a clear purpose.
    _vr = pd.DataFrame()
    _vr["date"] = df["date"]
    # âœ… Best Practice: Ensure 'date' column exists in 'df' before assignment.
    _m = pd.DataFrame()
    _m["volume"] = df.volume
    # âœ… Best Practice: Ensure 'close' column exists in 'df' before performing operations.
    # âœ… Best Practice: Consider adding type hints for function parameters and return type for better readability and maintainability.
    _m["cs"] = df.close - df.close.shift(1)
    # âœ… Best Practice: Ensure '_ma' function is defined and handles edge cases.
    # âœ… Best Practice: Return the DataFrame with a clear structure.
    _m["avs"] = _m.apply(lambda x: x.volume if x.cs > 0 else 0, axis=1)
    _m["bvs"] = _m.apply(lambda x: x.volume if x.cs < 0 else 0, axis=1)
    _m["cvs"] = _m.apply(lambda x: x.volume if x.cs == 0 else 0, axis=1)
    _vr["vr"] = (
        (_m.avs.rolling(n).sum() + 1 / 2 * _m.cvs.rolling(n).sum())
        / (_m.bvs.rolling(n).sum() + 1 / 2 * _m.cvs.rolling(n).sum())
        * 100
    )
    return _vr


# ğŸ§  ML Signal: Usage of pandas DataFrame indicates data manipulation, which is common in ML data preprocessing.


def vr(df, n=5):
    """
    å¼€å¸‚åå¹³å‡æ¯åˆ†é’Ÿçš„æˆäº¤é‡ä¸è¿‡å»5ä¸ªäº¤æ˜“æ—¥å¹³å‡æ¯åˆ†é’Ÿæˆäº¤é‡ä¹‹æ¯”
    é‡æ¯”:=V/REF(MA(V,5),1);
    æ¶¨å¹…:=(C-REF(C,1))/REF(C,1)*100;
    1)é‡æ¯”å¤§äº1.8ï¼Œæ¶¨å¹…å°äº2%ï¼Œç°ä»·æ¶¨å¹…åœ¨0â€”2%ä¹‹é—´ï¼Œåœ¨ç›˜ä¸­é€‰è‚¡çš„
    é€‰è‚¡:é‡æ¯”>1.8 AND æ¶¨å¹…>0 AND æ¶¨å¹…<2;
    """
    _vr = pd.DataFrame()
    # âœ… Best Practice: Initialize a new DataFrame to store results, improving code organization and readability.
    # âœ… Best Practice: Returning a DataFrame is a clear and structured way to handle tabular data.
    _vr["date"] = df.date
    _vr["vr"] = df.volume / _ma(df.volume, n).shift(1)
    # âœ… Best Practice: Explicitly copying the 'date' column ensures that the resulting DataFrame retains the original date information.
    _vr["rr"] = (df.close - df.close.shift(1)) / df.close.shift(1) * 100
    return _vr


# âœ… Best Practice: Consider adding type hints for function parameters and return type for better readability and maintainability.
# ğŸ§  ML Signal: Calculation of moving averages is a common pattern in financial data analysis.

# âœ… Best Practice: Returning a DataFrame allows for easy integration with other data processing pipelines.
# âš ï¸ SAST Risk (Low): Ensure that the _ma function handles edge cases, such as when the DataFrame is empty or has fewer rows than the moving average period.


def arbr(df, n=26):
    """
    äººæ°”æ„æ„¿æŒ‡æ ‡	arbr(26)
    Næ—¥AR=Næ—¥å†…ï¼ˆHï¼Oï¼‰ä¹‹å’Œé™¤ä»¥Næ—¥å†…ï¼ˆOï¼Lï¼‰ä¹‹å’Œ
    å…¶ä¸­ï¼ŒHä¸ºå½“æ—¥æœ€é«˜ä»·ï¼ŒLä¸ºå½“æ—¥æœ€ä½ä»·ï¼ŒOä¸ºå½“æ—¥å¼€ç›˜ä»·ï¼ŒNä¸ºè®¾å®šçš„æ—¶é—´å‚æ•°ï¼Œä¸€èˆ¬åŸå§‹å‚æ•°æ—¥è®¾å®šä¸º26æ—¥
    Næ—¥BR=Næ—¥å†…ï¼ˆHï¼CYï¼‰ä¹‹å’Œé™¤ä»¥Næ—¥å†…ï¼ˆCYï¼Lï¼‰ä¹‹å’Œ
    å…¶ä¸­ï¼ŒHä¸ºå½“æ—¥æœ€é«˜ä»·ï¼ŒLä¸ºå½“æ—¥æœ€ä½ä»·ï¼ŒCYä¸ºå‰ä¸€äº¤æ˜“æ—¥çš„æ”¶ç›˜ä»·ï¼ŒNä¸ºè®¾å®šçš„æ—¶é—´å‚æ•°ï¼Œä¸€èˆ¬åŸå§‹å‚æ•°æ—¥è®¾å®šä¸º26æ—¥ã€‚
    """
    # ğŸ§  ML Signal: Accessing DataFrame columns by attribute is a common usage pattern in pandas.
    _arbr = pd.DataFrame()
    _arbr["date"] = df.date
    # ğŸ§  ML Signal: Calculating momentum by shifting data is a common pattern in time series analysis.
    # ğŸ§  ML Signal: Function definition with financial calculation logic
    _arbr["ar"] = (
        (df.high - df.open).rolling(n).sum() / (df.open - df.low).rolling(n).sum() * 100
    )
    # âš ï¸ SAST Risk (Low): Ensure _ma function is properly defined and handles edge cases like NaN values.
    # âœ… Best Practice: Consider adding error handling for potential issues with DataFrame operations.
    _arbr["br"] = (
        (df.high - df.close.shift(1)).rolling(n).sum()
        / (df.close.shift() - df.low).rolling(n).sum()
        * 100
    )
    return _arbr


def dpo(df, n=20, m=6):
    """
    åŒºé—´éœ‡è¡çº¿æŒ‡æ ‡	dpo(20,6)
    DPO=CLOSE-MAï¼ˆCLOSE, N/2+1ï¼‰
    MADPO=MAï¼ˆDPO,Mï¼‰
    """
    # âœ… Best Practice: Initialize a DataFrame to store results
    _dpo = pd.DataFrame()
    _dpo["date"] = df["date"]
    # âœ… Best Practice: Copy 'date' column to maintain alignment with input DataFrame
    _dpo["dpo"] = df.close - _ma(df.close, int(n / 2 + 1))
    _dpo["dopma"] = _ma(_dpo.dpo, m)
    # âœ… Best Practice: Initialize a temporary DataFrame for intermediate calculations
    return _dpo


# âœ… Best Practice: Copy 'date' column to maintain alignment with input DataFrame


def trix(df, n=12, m=20):
    """
    ä¸‰é‡æŒ‡æ•°å¹³æ»‘å¹³å‡	TRIX(12)
    TR= EMA(EMA(EMA(CLOSE,N),N),N)ï¼Œå³è¿›è¡Œä¸‰æ¬¡å¹³æ»‘å¤„ç†
    TRIX=(TR-æ˜¨æ—¥TR)/ æ˜¨æ—¥TRÃ—100
    TRMA=MAï¼ˆTRIXï¼ŒMï¼‰
    """
    # âœ… Best Practice: Use apply with lambda for row-wise operations
    # âœ… Best Practice: Calculate cumulative sum using expanding
    _trix = pd.DataFrame()
    # âœ… Best Practice: Initialize an empty DataFrame for results
    _trix["date"] = df.date
    # âœ… Best Practice: Return the resulting DataFrame
    tr = _ema(_ema(_ema(df.close, n), n), n)
    # âœ… Best Practice: Explicitly assign columns to DataFrame
    _trix["trix"] = (tr - tr.shift()) / tr.shift() * 100
    _trix["trma"] = _ma(_trix.trix, m)
    return _trix


# ğŸ§  ML Signal: Calculation of typical price

# ğŸ§  ML Signal: Use of rolling window for time series analysis
# âœ… Best Practice: Consider adding type hints for function parameters and return type for better readability and maintainability.


# âš ï¸ SAST Risk (Low): Potential for division by zero if rolling mean is zero
def bbi(df):
    """
    å¤šç©ºæŒ‡æ•°	BBI(3,6,12,24)
    BBI=ï¼ˆ3æ—¥å‡ä»·+6æ—¥å‡ä»·+12æ—¥å‡ä»·+24æ—¥å‡ä»·ï¼‰/4
    # ğŸ§  ML Signal: Use of lambda function for custom rolling operation
    """
    # âœ… Best Practice: Use more descriptive variable names for better readability.
    # âœ… Best Practice: Return the result DataFrame
    _bbi = pd.DataFrame()
    _bbi["date"] = df["date"]
    _bbi["bbi"] = (
        _ma(df.close, 3) + _ma(df.close, 6) + _ma(df.close, 12) + _ma(df.close, 24)
    ) / 4
    # âš ï¸ SAST Risk (Low): Ensure _ma function is properly validated to handle unexpected input.
    return _bbi


# âš ï¸ SAST Risk (Low): Division by zero risk if 'man' contains zero values.


def mtm(df, n=6, m=5):
    """
    åŠ¨åŠ›æŒ‡æ ‡	MTM(6,5)
    MTMï¼ˆNæ—¥ï¼‰=C-REF(C,N)å¼ä¸­ï¼ŒC=å½“æ—¥çš„æ”¶ç›˜ä»·ï¼ŒREF(C,N)=Næ—¥å‰çš„æ”¶ç›˜ä»·ï¼›Næ—¥æ˜¯åªè®¡ç®—äº¤æ˜“æ—¥æœŸï¼Œå‰”é™¤æ‰èŠ‚å‡æ—¥ã€‚
    MTMMAï¼ˆMTMï¼ŒN1ï¼‰= MAï¼ˆMTMï¼ŒN1ï¼‰
    Nè¡¨ç¤ºé—´éš”å¤©æ•°ï¼ŒN1è¡¨ç¤ºå¤©æ•°
    """
    _mtm = pd.DataFrame()
    _mtm["date"] = df.date
    _mtm["mtm"] = df.close - df.close.shift(n)
    _mtm["mtmma"] = _ma(_mtm.mtm, m)
    return _mtm


# âœ… Best Practice: Consider removing commented-out code to improve readability and maintainability


def obv(df):
    """
    èƒ½é‡æ½®  On Balance Volume
    å¤šç©ºæ¯”ç‡å‡€é¢= [ï¼ˆæ”¶ç›˜ä»·ï¼æœ€ä½ä»·ï¼‰ï¼ï¼ˆæœ€é«˜ä»·-æ”¶ç›˜ä»·ï¼‰] Ã·ï¼ˆ æœ€é«˜ä»·ï¼æœ€ä½ä»·ï¼‰Ã—V  # åŒèŠ±é¡ºè²Œä¼¼ç”¨çš„ä¸‹é¢å…¬å¼
    ä¸»å…¬å¼ï¼šå½“æ—¥OBV=å‰ä¸€æ—¥OBV+ä»Šæ—¥æˆäº¤é‡
    1.åŸºæœŸOBVå€¼ä¸º0ï¼Œå³è¯¥è‚¡ä¸Šå¸‚çš„ç¬¬ä¸€å¤©ï¼ŒOBVå€¼ä¸º0
    2.è‹¥å½“æ—¥æ”¶ç›˜ä»·ï¼ä¸Šæ—¥æ”¶ç›˜ä»·ï¼Œåˆ™å½“æ—¥OBV=å‰ä¸€æ—¥OBVï¼‹ä»Šæ—¥æˆäº¤é‡
    3.è‹¥å½“æ—¥æ”¶ç›˜ä»·ï¼œä¸Šæ—¥æ”¶ç›˜ä»·ï¼Œåˆ™å½“æ—¥OBV=å‰ä¸€æ—¥OBVï¼ä»Šæ—¥æˆäº¤é‡
    4.è‹¥å½“æ—¥æ”¶ç›˜ä»·ï¼ä¸Šæ—¥æ”¶ç›˜ä»·ï¼Œåˆ™å½“æ—¥OBV=å‰ä¸€æ—¥OBV
    """
    _obv = pd.DataFrame()
    _obv["date"] = df["date"]
    # tmp = np.true_divide(((df.close - df.low) - (df.high - df.close)), (df.high - df.low))
    # _obv['obvv'] = tmp * df.volume
    # âœ… Best Practice: Use of descriptive variable names for better readability
    # _obv["obv"] = _obv.obvv.expanding(1).sum() / 100
    _m = pd.DataFrame()
    # âœ… Best Practice: Explicitly defining columns for the DataFrame
    _m["date"] = df.date
    _m["cs"] = df.close - df.close.shift()
    # ğŸ§  ML Signal: Use of moving average, a common pattern in time series analysis
    _m["v"] = df.volume
    _m["vv"] = _m.apply(
        lambda x: x.v if x.cs > 0 else (-x.v if x.cs < 0 else 0), axis=1
    )
    # ğŸ§  ML Signal: Calculation of bias, a common feature in financial data analysis
    _obv["obv"] = _m.vv.expanding(1).sum()
    return _obv


# ğŸ§  ML Signal: Use of shift for lagging data, a common pattern in time series analysis
# âœ… Best Practice: Consider adding input validation for the 'df' parameter to ensure it contains the necessary columns.

# ğŸ§  ML Signal: Use of simple moving average, a common pattern in time series analysis


def cci(df, n=14):
    """
    é¡ºåŠ¿æŒ‡æ ‡
    TYP:=(HIGH+LOW+CLOSE)/3
    CCI:=(TYP-MA(TYP,N))/(0.015Ã—AVEDEV(TYP,N))
    """
    # âœ… Best Practice: Returning a DataFrame for structured data output
    _cci = pd.DataFrame()
    # âœ… Best Practice: Initialize DataFrame with specific columns to avoid potential KeyErrors.
    _cci["date"] = df["date"]
    typ = (df.high + df.low + df.close) / 3
    _cci["cci"] = (
        (typ - typ.rolling(n).mean())
        /
        # âš ï¸ SAST Risk (Low): Potential division by zero if df.close.shift(n) contains zero values.
        (
            0.015
            * typ.rolling(min_periods=1, center=False, window=n).apply(
                # âœ… Best Practice: Consider adding input validation for 'df' to ensure it contains the necessary columns.
                lambda x: np.fabs(x - x.mean()).mean()
            )
        )
    )
    # ğŸ§  ML Signal: Usage of moving average function _ma, which could be a custom implementation.
    return _cci


def priceosc(df, n=12, m=26):
    """
    ä»·æ ¼æŒ¯åŠ¨æŒ‡æ•°
    PRICEOSC=(MA(C,12)-MA(C,26))/MA(C,12) * 100
    # âœ… Best Practice: Ensure 'date' column exists in 'df' before assignment to prevent runtime errors.
    """
    # âœ… Best Practice: Add import statement for pandas to ensure the code runs without errors.
    _c = pd.DataFrame()
    # âš ï¸ SAST Risk (Low): Potential division by zero if df.volume.shift(n) contains zero values.
    # âœ… Best Practice: Ensure 'volume' column exists in 'df' before performing operations to prevent runtime errors.
    # ğŸ§  ML Signal: Returns a DataFrame with calculated VROC, which could be used for predictive modeling.
    _c["date"] = df["date"]
    man = _ma(df.close, n)
    _c["osc"] = (man - _ma(df.close, m)) / man * 100
    return _c


def sma(a, n, m=1):
    """
    å¹³æ»‘ç§»åŠ¨æŒ‡æ ‡ Smooth Moving Average
    # ğŸ§  ML Signal: Usage of rolling window operations, which are common in time series analysis.
    """
    """ # æ–¹æ³•ä¸€ï¼Œæ­¤æ–¹æ³•æœ‰ç¼ºé™·
    _sma = []
    for index, value in enumerate(a):
        if index == 0 or pd.isna(value) or np.isnan(value):
            tsma = 0
        else:
            # Y=(M*X+(N-M)*Y')/N
            tsma = (m * value + (n - m) * tsma) / n
        _sma.append(tsma)
    return pd.Series(_sma)
    # âœ… Best Practice: Explicitly assign columns to the DataFrame, enhancing code clarity.
    """
    """ # æ–¹æ³•äºŒ

    results = np.nan_to_num(a).copy()
    # FIXME this is very slow
    for i in range(1, len(a)):
        results[i] = (m * results[i] + (n - m) * results[i - 1]) / n
        # results[i] = ((n - 1) * results[i - 1] + results[i]) / n
    # return results
    """
    # b = np.nan_to_num(a).copy()
    # return ((n - m) * a.shift(1) + m * a) / n

    # ğŸ§  ML Signal: Use of financial indicators for time series analysis
    a = a.fillna(0)
    # âœ… Best Practice: Use of descriptive variable names improves code readability
    # âœ… Best Practice: Ensure the DataFrame has the necessary columns before processing
    b = a.ewm(min_periods=0, ignore_na=False, adjust=False, alpha=m / n).mean()
    return b


# ğŸ§  ML Signal: Use of shift for time series data manipulation


def dbcd(df, n=5, m=16, t=76):
    """
    å¼‚åŒç¦»å·®ä¹–ç¦»ç‡	dbcd(5,16,76)
    BIAS=(C-MA(C,N))/MA(C,N)
    DIF=(BIAS-REF(BIAS,M))
    DBCD=SMA(DIF,T,1) =ï¼ˆ1-1/Tï¼‰Ã—SMA(REF(DIF,1),T,1)+ 1/TÃ—DIF
    MM=MA(DBCD,5)
    # ğŸ§  ML Signal: Conditional logic for financial calculations
    # âš ï¸ SAST Risk (Low): Use of np.minimum and np.maximum can lead to unexpected results if df.low or df.close.shift(1) contain NaN values
    """
    _dbcd = pd.DataFrame()
    # âš ï¸ SAST Risk (Low): Use of np.minimum and np.maximum can lead to unexpected results if df.high or df.close.shift(1) contain NaN values
    _dbcd["date"] = df.date
    man = _ma(df.close, n)
    # âš ï¸ SAST Risk (Low): Subtracting shifted values without handling NaN can lead to unexpected results
    _bias = (df.close - man) / man
    # ğŸ§  ML Signal: Cumulative sum for time series data
    _dif = _bias - _bias.shift(m)
    _dbcd["dbcd"] = sma(_dif, t)
    # ğŸ§  ML Signal: Function definition with default parameter value
    # ğŸ§  ML Signal: Use of DataFrame.apply with a custom function indicates a pattern for row-wise operations
    _dbcd["mm"] = _ma(_dbcd.dbcd, n)
    # ğŸ§  ML Signal: Rolling window calculation for moving average
    # âœ… Best Practice: Return only the necessary columns to avoid data leakage
    # ğŸ§  ML Signal: Use of expanding().sum() indicates a pattern for cumulative sum operations
    # ğŸ§  ML Signal: Use of a custom moving average function _ma indicates a pattern for smoothing or trend analysis
    return _dbcd


def roc(df, n=12, m=6):
    """
    å˜åŠ¨é€Ÿç‡	roc(12,6)
    ROC=(ä»Šæ—¥æ”¶ç›˜ä»·-Næ—¥å‰çš„æ”¶ç›˜ä»·)/ Næ—¥å‰çš„æ”¶ç›˜ä»·Ã—100%
    ROCMA=MAï¼ˆROCï¼ŒMï¼‰
    ROC:(CLOSE-REF(CLOSE,N))/REF(CLOSE,N)Ã—100
    ROCMA:MA(ROC,M)
    """
    # âœ… Best Practice: Explicitly assign columns to DataFrame
    _roc = pd.DataFrame()
    _roc["date"] = df["date"]
    # âœ… Best Practice: Initialize an empty DataFrame for intermediate calculations
    _roc["roc"] = (df.close - df.close.shift(n)) / df.close.shift(n) * 100
    _roc["rocma"] = _ma(_roc.roc, m)
    # âœ… Best Practice: Calculate mean across specific columns for clarity
    return _roc


# âœ… Best Practice: Use descriptive column names for clarity


def vroc(df, n=12):
    """
    é‡å˜åŠ¨é€Ÿç‡
    VROC=(å½“æ—¥æˆäº¤é‡-Næ—¥å‰çš„æˆäº¤é‡)/ Næ—¥å‰çš„æˆäº¤é‡Ã—100%
    """
    _vroc = pd.DataFrame()
    _vroc["date"] = df["date"]
    # âœ… Best Practice: Use lambda for concise conditional logic
    # âœ… Best Practice: Use rolling window for moving calculations
    _vroc["vroc"] = (df.volume - df.volume.shift(n)) / df.volume.shift(n) * 100
    # âœ… Best Practice: Use descriptive variable names for better readability
    return _vroc


# âœ… Best Practice: Calculate final metric using clear mathematical operations


# âœ… Best Practice: Return the result DataFrame
# ğŸ§  ML Signal: Calculation of a financial indicator, useful for predictive models
def cr(df, n=26):
    """èƒ½é‡æŒ‡æ ‡
    CR=âˆ‘ï¼ˆH-PMï¼‰/âˆ‘ï¼ˆPM-Lï¼‰Ã—100
    PM:ä¸Šä¸€äº¤æ˜“æ—¥ä¸­ä»·ï¼ˆ(æœ€é«˜ã€æœ€ä½ã€æ”¶ç›˜ä»·çš„å‡å€¼)
    Hï¼šå½“å¤©æœ€é«˜ä»·
    Lï¼šå½“å¤©æœ€ä½ä»·
    """
    # âœ… Best Practice: Initialize an empty DataFrame to store results, improving code organization.
    _cr = pd.DataFrame()
    _cr["date"] = df.date
    # âœ… Best Practice: Explicitly assign columns to the DataFrame for clarity and maintainability.
    # pm = ((df['high'] + df['low'] + df['close']) / 3).shift(1)
    pm = (df[["high", "low", "close"]]).mean(axis=1).shift(1)
    # âš ï¸ SAST Risk (Low): Potential division by zero if df.high equals df.low.
    _cr["cr"] = (df.high - pm).rolling(n).sum() / (pm - df.low).rolling(n).sum() * 100
    # ğŸ§  ML Signal: Function definition for financial calculations
    # ğŸ§  ML Signal: Uses rolling window calculations, common in time series analysis.
    return _cr


# âœ… Best Practice: Use of helper function _ma for moving average calculation improves modularity.
# âœ… Best Practice: Return the DataFrame for further use or analysis.


def psy(df, n=12):
    """
    å¿ƒç†æŒ‡æ ‡	PSY(12)
    PSY=Næ—¥å†…ä¸Šæ¶¨å¤©æ•°/NÃ—100
    PSY:COUNT(CLOSE>REF(CLOSE,1),N)/NÃ—100
    MAPSY=PSYçš„Mæ—¥ç®€å•ç§»åŠ¨å¹³å‡
    """
    # âœ… Best Practice: Initialize a new DataFrame for results
    _psy = pd.DataFrame()
    _psy["date"] = df.date
    # âœ… Best Practice: Explicitly assign columns to the new DataFrame
    p = df.close - df.close.shift()
    p[p <= 0] = np.nan
    # âš ï¸ SAST Risk (Low): Potential misuse of DataFrame.shift() without checking for NaN values
    _psy["psy"] = p.rolling(n).count() / n * 100
    # âœ… Best Practice: Use descriptive column names for clarity
    return _psy


# âœ… Best Practice: Consider adding type hints for function parameters and return type for better readability and maintainability.
# âš ï¸ SAST Risk (Low): Potential misuse of DataFrame.shift() without checking for NaN values


# âš ï¸ SAST Risk (Low): Potential misuse of DataFrame.shift() without checking for NaN values
def wad(df, n=30):
    """
    å¨å»‰èšæ•£æŒ‡æ ‡	WAD(30)
    TRL=æ˜¨æ—¥æ”¶ç›˜ä»·ä¸ä»Šæ—¥æœ€ä½ä»·ä¸­ä»·æ ¼æœ€ä½è€…ï¼›TRH=æ˜¨æ—¥æ”¶ç›˜ä»·ä¸ä»Šæ—¥æœ€é«˜ä»·ä¸­ä»·æ ¼æœ€é«˜è€…
    å¦‚æœä»Šæ—¥çš„æ”¶ç›˜ä»·>æ˜¨æ—¥çš„æ”¶ç›˜ä»·ï¼Œåˆ™ä»Šæ—¥çš„A/D=ä»Šæ—¥çš„æ”¶ç›˜ä»·ï¼ä»Šæ—¥çš„TRL
    å¦‚æœä»Šæ—¥çš„æ”¶ç›˜ä»·<æ˜¨æ—¥çš„æ”¶ç›˜ä»·ï¼Œåˆ™ä»Šæ—¥çš„A/D=ä»Šæ—¥çš„æ”¶ç›˜ä»·ï¼ä»Šæ—¥çš„TRH
    å¦‚æœä»Šæ—¥çš„æ”¶ç›˜ä»·=æ˜¨æ—¥çš„æ”¶ç›˜ä»·ï¼Œåˆ™ä»Šæ—¥çš„A/D=0
    WAD=ä»Šæ—¥çš„A/D+æ˜¨æ—¥çš„WADï¼›MAWAD=WADçš„Mæ—¥ç®€å•ç§»åŠ¨å¹³å‡
    # ğŸ§  ML Signal: Using 'date' as a key column suggests time series data, which is common in financial datasets.
    """

    def dmd(x):
        # ğŸ§  ML Signal: Rolling mean calculations are often used in time series analysis and financial indicators.
        # ğŸ§  ML Signal: Function definition with default parameter, indicating a common pattern for ML models to learn from
        if x.c > 0:
            # ğŸ§  ML Signal: Rolling mean calculations are often used in time series analysis and financial indicators.
            # âœ… Best Practice: Consider handling potential NaN values resulting from rolling mean calculations.
            y = x.close - x.trl
        elif x.c < 0:
            y = x.close - x.trh
        else:
            y = 0
        return y

    _wad = pd.DataFrame()
    _wad["date"] = df["date"]
    _ad = pd.DataFrame()
    _ad["trl"] = np.minimum(df.low, df.close.shift(1))
    _ad["trh"] = np.maximum(df.high, df.close.shift(1))
    _ad["c"] = df.close - df.close.shift()
    # âœ… Best Practice: Using a DataFrame to store results, which is efficient for handling tabular data
    _ad["close"] = df.close
    _ad["ad"] = _ad.apply(dmd, axis=1)
    # âœ… Best Practice: Explicitly assigning columns to the DataFrame for clarity
    _wad["wad"] = _ad.ad.expanding(1).sum()
    _wad["mawad"] = _ma(_wad.wad, n)
    # ğŸ§  ML Signal: Calculation of typical price, a common feature in financial data analysis
    return _wad


# ğŸ§  ML Signal: Rolling window operation, a common pattern in time series analysis


def mfi(df, n=14):
    """
    èµ„é‡‘æµå‘æŒ‡æ ‡	mfi(14)
    MFï¼TYPÃ—æˆäº¤é‡ï¼›TYP:å½“æ—¥ä¸­ä»·ï¼ˆ(æœ€é«˜ã€æœ€ä½ã€æ”¶ç›˜ä»·çš„å‡å€¼)
    å¦‚æœå½“æ—¥TYP>æ˜¨æ—¥TYPï¼Œåˆ™å°†å½“æ—¥çš„MFå€¼è§†ä¸ºå½“æ—¥PMFå€¼ã€‚è€Œå½“æ—¥NMFå€¼ï¼0
    å¦‚æœå½“æ—¥TYP<=æ˜¨æ—¥TYPï¼Œåˆ™å°†å½“æ—¥çš„MFå€¼è§†ä¸ºå½“æ—¥NMFå€¼ã€‚è€Œå½“æ—¥PMFå€¼=0
    MR=âˆ‘PMF/âˆ‘NMF
    MFIï¼100-ï¼ˆ100Ã·(1ï¼‹MR)ï¼‰
    """
    # âœ… Best Practice: Using descriptive column names for clarity
    _mfi = pd.DataFrame()
    # âœ… Best Practice: Initialize an empty DataFrame with a clear purpose.
    _mfi["date"] = df.date
    # âœ… Best Practice: Using descriptive column names for clarity
    _m = pd.DataFrame()
    # âœ… Best Practice: Ensure 'df' has a 'date' column before accessing it.
    _m["typ"] = df[["high", "low", "close"]].mean(axis=1)
    # âœ… Best Practice: Using descriptive column names for clarity
    _m["mf"] = _m.typ * df.volume
    # âœ… Best Practice: Ensure 'df' has a 'volume' column before accessing it.
    # ğŸ§  ML Signal: Usage of moving average calculation on volume data.
    # âœ… Best Practice: Returning a DataFrame, which is a common practice for functions processing tabular data
    # âœ… Best Practice: Return a DataFrame with clear column names for better readability.
    _m["typ_shift"] = _m.typ - _m.typ.shift(1)
    _m["pmf"] = _m.apply(lambda x: x.mf if x.typ_shift > 0 else 0, axis=1)
    _m["nmf"] = _m.apply(lambda x: x.mf if x.typ_shift <= 0 else 0, axis=1)
    # _mfi['mfi'] = 100 - (100 / (1 + _m.pmf.rolling(n).sum() / _m.nmf.rolling(n).sum()))
    _m["mr"] = _m.pmf.rolling(n).sum() / _m.nmf.rolling(n).sum()
    _mfi["mfi"] = (
        100 * _m.mr / (1 + _m.mr)
    )  # åŒèŠ±é¡ºè‡ªå·±ç»™å‡ºçš„å…¬å¼å’Œå®é™…ç”¨çš„å…¬å¼ä¸ä¸€æ ·ï¼ŒçœŸæ“è›‹ï¼Œæµªè´¹ä¸¤ä¸ªå°æ—¶æ—¶é—´
    return _mfi


# âœ… Best Practice: Initialize a DataFrame to store results, improving code organization and readability


# ğŸ§  ML Signal: Using 'date' as a key column suggests time-series data processing
def pvt(df):
    """
    pvt	é‡ä»·è¶‹åŠ¿æŒ‡æ ‡	pvt
    å¦‚æœè®¾x=(ä»Šæ—¥æ”¶ç›˜ä»·â€”æ˜¨æ—¥æ”¶ç›˜ä»·)/æ˜¨æ—¥æ”¶ç›˜ä»·Ã—å½“æ—¥æˆäº¤é‡ï¼Œ
    é‚£ä¹ˆå½“æ—¥PVTæŒ‡æ ‡å€¼åˆ™ä¸ºä»ç¬¬ä¸€ä¸ªäº¤æ˜“æ—¥èµ·æ¯æ—¥Xå€¼çš„ç´¯åŠ ã€‚
    # ğŸ§  ML Signal: Calculation of 'macd' as a difference of 'diff' and 'dea' is a common financial analysis pattern
    """
    _pvt = pd.DataFrame()
    _pvt["date"] = df.date

    # âœ… Best Practice: Return the DataFrame to allow further processing or analysis
    x = (df.close - df.close.shift(1)) / df.close.shift(1) * df.volume
    # âœ… Best Practice: Use more descriptive variable names for better readability.
    _pvt["pvt"] = x.expanding(1).sum()
    return _pvt


# ğŸ§  ML Signal: Usage of moving average calculations, which are common in financial data analysis.
# âœ… Best Practice: Consider adding input validation for 'df' to ensure it contains 'amount' and 'close' columns


# âš ï¸ SAST Risk (Low): Ensure _ma function is properly validated to handle edge cases like empty data.
def wvad(df, n=24, m=6):
    """# ç®—æ³•æ˜¯å¯¹çš„ï¼ŒåŒèŠ±é¡ºè®¡ç®—wvadç”¨çš„n=6
    å¨å»‰å˜å¼‚ç¦»æ•£é‡	wvad(24,6)
    WVAD=N1æ—¥çš„âˆ‘ {(å½“æ—¥æ”¶ç›˜ä»·ï¼å½“æ—¥å¼€ç›˜ä»·)/(å½“æ—¥æœ€é«˜ä»·ï¼å½“æ—¥æœ€ä½ä»·)Ã—æˆäº¤é‡}
    MAWVAD=MAï¼ˆWVADï¼ŒN2ï¼‰
    # âœ… Best Practice: Initialize DataFrame with specific columns to avoid potential KeyErrors
    """
    _wvad = pd.DataFrame()
    # âš ï¸ SAST Risk (Low): Assumes 'amount' and 'close' columns exist in 'df', which may lead to KeyError
    _wvad["date"] = df.date
    # _wvad['wvad'] = (np.true_divide((df.close - df.open), (df.high - df.low)) * df.volume).rolling(n).sum()
    # ğŸ§  ML Signal: Usage of moving average function '_ma' indicates time series analysis
    _wvad["wvad"] = (
        (np.true_divide((df.close - df.open), (df.high - df.low)) * df.volume)
        .rolling(n)
        .sum()
    )
    _wvad["mawvad"] = _ma(_wvad.wvad, m)
    return _wvad


# âœ… Best Practice: Use a more descriptive variable name than '_vstd' for clarity.


def cdp(df):
    """
    é€†åŠ¿æ“ä½œ	cdp
    CDP=(æœ€é«˜ä»·+æœ€ä½ä»·+æ”¶ç›˜ä»·)/3  # åŒèŠ±é¡ºå®é™…ç”¨çš„(H+L+2*c)/4
    AH=CDP+(å‰æ—¥æœ€é«˜ä»·-å‰æ—¥æœ€ä½ä»·)
    NH=CDPÃ—2-æœ€ä½ä»·
    NL=CDPÃ—2-æœ€é«˜ä»·
    AL=CDP-(å‰æ—¥æœ€é«˜ä»·-å‰æ—¥æœ€ä½ä»·)
    """
    _cdp = pd.DataFrame()
    _cdp["date"] = df.date
    # _cdp['cdp'] = (df.high + df.low + df.close * 2).shift(1) / 4
    _cdp["cdp"] = df[["high", "low", "close", "close"]].shift().mean(axis=1)
    _cdp["ah"] = _cdp.cdp + (df.high.shift(1) - df.low.shift())
    _cdp["al"] = _cdp.cdp - (df.high.shift(1) - df.low.shift())
    _cdp["nh"] = _cdp.cdp * 2 - df.low.shift(1)
    _cdp["nl"] = _cdp.cdp * 2 - df.high.shift(1)
    return _cdp


# âœ… Best Practice: Use of pandas DataFrame for structured data manipulation


def env(df, n=14):
    """
    ENVæŒ‡æ ‡	ENV(14)
    Upper=MA(CLOSEï¼ŒN)Ã—1.06
    LOWER= MA(CLOSEï¼ŒN)Ã—0.94
    """
    # âœ… Best Practice: Use of lambda functions for concise operations
    _env = pd.DataFrame()
    _env["date"] = df.date
    _env["up"] = df.close.rolling(n).mean() * 1.06
    # âœ… Best Practice: Use of rolling window for time series analysis
    _env["low"] = df.close.rolling(n).mean() * 0.94
    return _env


# âœ… Best Practice: Consider adding type hints for function parameters and return type for better readability and maintainability.

# âœ… Best Practice: Use of lambda functions for concise operations


def mike(df, n=12):
    """
    éº¦å…‹æŒ‡æ ‡	mike(12)
    åˆå§‹ä»·ï¼ˆTYPï¼‰=ï¼ˆå½“æ—¥æœ€é«˜ä»·ï¼‹å½“æ—¥æœ€ä½ä»·ï¼‹å½“æ—¥æ”¶ç›˜ä»·ï¼‰/3
    HV=Næ—¥å†…åŒºé—´æœ€é«˜ä»·
    LV=Næ—¥å†…åŒºé—´æœ€ä½ä»·
    åˆçº§å‹åŠ›çº¿ï¼ˆWRï¼‰=TYPÃ—2-LV
    ä¸­çº§å‹åŠ›çº¿ï¼ˆMRï¼‰=TYP+HV-LV
    å¼ºåŠ›å‹åŠ›çº¿ï¼ˆSRï¼‰=2Ã—HV-LV
    åˆçº§æ”¯æ’‘çº¿ï¼ˆWSï¼‰=TYPÃ—2-HV
    ä¸­çº§æ”¯æ’‘çº¿ï¼ˆMSï¼‰=TYP-HV+LV
    å¼ºåŠ›æ”¯æ’‘çº¿ï¼ˆSSï¼‰=2Ã—LV-HV
    """
    _mike = pd.DataFrame()
    _mike["date"] = df.date
    typ = df[["high", "low", "close"]].mean(axis=1)
    # âœ… Best Practice: Use more descriptive variable names for better readability.
    hv = df.high.rolling(n).max()
    lv = df.low.rolling(n).min()
    _mike["wr"] = typ * 2 - lv
    # ğŸ§  ML Signal: Usage of time series data operations, such as shift, can be a signal for financial data analysis.
    _mike["mr"] = typ + hv - lv
    _mike["sr"] = 2 * hv - lv
    # ğŸ§  ML Signal: Custom implementation of moving average (sma) can indicate specific domain logic.
    _mike["ws"] = typ * 2 - hv
    # âœ… Best Practice: Consider adding type hints for function parameters and return type for better readability and maintainability.
    _mike["ms"] = typ - hv + lv
    # ğŸ§  ML Signal: Use of custom moving average function (_ma) can indicate specific domain logic.
    # ğŸ§  ML Signal: Repeated use of sma function suggests a pattern in data smoothing or trend analysis.
    _mike["ss"] = 2 * lv - hv
    return _mike


def vma(df, n=5):
    """
    é‡ç®€å•ç§»åŠ¨å¹³å‡	VMA(5)	VMA=MA(volume,N)
    VOLUMEè¡¨ç¤ºæˆäº¤é‡ï¼›Nè¡¨ç¤ºå¤©æ•°
    # ğŸ§  ML Signal: Accessing DataFrame columns, indicating a pattern of data processing.
    """
    _vma = pd.DataFrame()
    # ğŸ§  ML Signal: Calculation involving shifting data, a common pattern in time series analysis.
    _vma["date"] = df.date
    # ğŸ§  ML Signal: Usage of a custom function 'sma', indicating a pattern of applying statistical methods.
    # âœ… Best Practice: Returning a DataFrame, which is a common practice for functions processing tabular data.
    _vma["vma"] = _ma(df.volume, n)
    return _vma


def vmacd(df, qn=12, sn=26, m=9):
    """
    é‡æŒ‡æ•°å¹³æ»‘å¼‚åŒå¹³å‡	vmacd(12,26,9)
    ä»Šæ—¥EMAï¼ˆNï¼‰=2/ï¼ˆN+1ï¼‰Ã—ä»Šæ—¥æˆäº¤é‡+(N-1)/ï¼ˆN+1ï¼‰Ã—æ˜¨æ—¥EMAï¼ˆNï¼‰
    DIFF= EMAï¼ˆN1ï¼‰- EMAï¼ˆN2ï¼‰
    DEA(DIF,M)= 2/(M+1)Ã—DIF +[1-2/(M+1)]Ã—DEA(REF(DIF,1),M)
    MACDï¼ˆBARï¼‰=2Ã—ï¼ˆDIF-DEAï¼‰
    # ğŸ§  ML Signal: Calculating rate of change is a common pattern in financial analysis.
    """
    _vmacd = pd.DataFrame()
    # âš ï¸ SAST Risk (Low): Ensure 'sma' function is defined and handles edge cases like NaN values.
    _vmacd["date"] = df.date
    # âœ… Best Practice: Consider adding type hints for function parameters and return type for better readability and maintainability.
    _vmacd["diff"] = _ema(df.volume, qn) - _ema(df.volume, sn)
    # âš ï¸ SAST Risk (Low): Ensure '_ma' function is defined and handles edge cases like NaN values.
    _vmacd["dea"] = _ema(_vmacd["diff"], m)  # TODO: ä¸èƒ½ç”¨_vmacd.diff, ä¸çŸ¥é“ä¸ºä»€ä¹ˆ
    _vmacd["macd"] = _vmacd["diff"] - _vmacd["dea"]
    return _vmacd


def vosc(df, n=12, m=26):
    """
    æˆäº¤é‡éœ‡è¡	vosc(12,26)
    VOSC=ï¼ˆMAï¼ˆVOLUME,SHORTï¼‰- MAï¼ˆVOLUME,LONGï¼‰ï¼‰/MAï¼ˆVOLUME,SHORTï¼‰Ã—100
    """
    _c = pd.DataFrame()
    _c["date"] = df["date"]
    # âœ… Best Practice: Check if 'n' is within a valid range to prevent potential errors.
    _c["osc"] = (_ma(df.volume, n) - _ma(df.volume, m)) / _ma(df.volume, n) * 100
    return _c


# ğŸ§  ML Signal: Use of lambda function for element-wise operations on DataFrame.


def tapi(df, n=6):
    """# TODO: ç”±äºget_k_dataè¿”å›æ•°æ®ä¸­æ²¡æœ‰amountï¼Œå¯ä»¥ç”¨get_h_dataä¸­amountï¼Œç®—æ³•æ˜¯æ­£ç¡®çš„
    åŠ æƒæŒ‡æ•°æˆäº¤å€¼	tapi(6)
    TAPI=æ¯æ—¥æˆäº¤æ€»å€¼/å½“æ—¥åŠ æƒæŒ‡æ•°=a/PIï¼›Aè¡¨ç¤ºæ¯æ—¥çš„æˆäº¤é‡‘é¢ï¼ŒPIè¡¨ç¤ºå½“å¤©çš„è‚¡ä»·æŒ‡æ•°å³æŒ‡æ”¶ç›˜ä»·
    """
    # âœ… Best Practice: Use of copy to avoid modifying the original dataframe
    _tapi = pd.DataFrame()
    # _tapi['date'] = df.date
    # âœ… Best Practice: Setting index for efficient data manipulation
    _tapi["tapi"] = df.amount / df.close
    _tapi["matapi"] = _ma(_tapi.tapi, n)
    # âœ… Best Practice: Setting index for efficient data manipulation
    return _tapi


# âœ… Best Practice: Initializing a DataFrame with a specific index


def vstd(df, n=10):
    """
    æˆäº¤é‡æ ‡å‡†å·®	vstd(10)
    VSTD=STDï¼ˆVolume,Nï¼‰=[âˆ‘ï¼ˆVolume-MA(Volumeï¼ŒN)ï¼‰^2/N]^0.5
    """
    # ğŸ§  ML Signal: Use of lambda for conditional logic, a common pattern in data processing
    _vstd = pd.DataFrame()
    _vstd["date"] = df.date
    _vstd["vstd"] = df.volume.rolling(n).std(ddof=1)
    return _vstd


# ğŸ§  ML Signal: Rolling window calculation, often used in time series analysis
# âš ï¸ SAST Risk (Medium): Using `ts.get_k_data` without input validation can lead to potential data integrity issues.

# âœ… Best Practice: Dropping unnecessary columns to save memory


# âœ… Best Practice: Use of `copy()` to avoid modifying the original DataFrame.
def adtm(df, n=23, m=8):
    """
    åŠ¨æ€ä¹°å–æ°”æŒ‡æ ‡	adtm(23,8)
    å¦‚æœå¼€ç›˜ä»·â‰¤æ˜¨æ—¥å¼€ç›˜ä»·ï¼ŒDTM=0
    å¦‚æœå¼€ç›˜ä»·ï¼æ˜¨æ—¥å¼€ç›˜ä»·ï¼ŒDTM=(æœ€é«˜ä»·-å¼€ç›˜ä»·)å’Œ(å¼€ç›˜ä»·-æ˜¨æ—¥å¼€ç›˜ä»·)çš„è¾ƒå¤§å€¼
    å¦‚æœå¼€ç›˜ä»·â‰¥æ˜¨æ—¥å¼€ç›˜ä»·ï¼ŒDBM=0
    å¦‚æœå¼€ç›˜ä»·ï¼œæ˜¨æ—¥å¼€ç›˜ä»·ï¼ŒDBM=(å¼€ç›˜ä»·-æœ€ä½ä»·)
    STM=DTMåœ¨Næ—¥å†…çš„å’Œ
    SBM=DBMåœ¨Næ—¥å†…çš„å’Œ
    å¦‚æœSTM > SBM,ADTM=(STM-SBM)/STM
    å¦‚æœSTM < SBM , ADTM = (STM-SBM)/SBM
    å¦‚æœSTM = SBM,ADTM=0
    ADTMMA=MA(ADTM,M)
    # âœ… Best Practice: Using `apply` with a lambda for row-wise operations.
    """
    # âœ… Best Practice: Assigning NaN to irrelevant data points for clarity.
    _adtm = pd.DataFrame()
    _adtm["date"] = df.date
    _m = pd.DataFrame()
    _m["cc"] = df.open - df.open.shift(1)
    # âš ï¸ SAST Risk (Medium): Use of external library 'ts' without import statement
    # ğŸ§  ML Signal: Use of rolling window calculations, a common pattern in time series analysis.
    _m["ho"] = df.high - df.open
    _m["ol"] = df.open - df.low
    # âœ… Best Practice: Use of copy to avoid modifying the original DataFrame
    # âœ… Best Practice: Dropping intermediate columns to clean up the DataFrame.
    _m["dtm"] = _m.apply(lambda x: max(x.ho, x.cc) if x.cc > 0 else 0, axis=1)
    _m["dbm"] = _m.apply(lambda x: x.ol if x.cc < 0 else 0, axis=1)
    # âœ… Best Practice: Resetting index to return a clean DataFrame.
    # âœ… Best Practice: Setting 'date' as index for easier time-based operations
    _m["stm"] = _m.dtm.rolling(n).sum()
    _m["sbm"] = _m.dbm.rolling(n).sum()
    # âœ… Best Practice: Setting 'date' as index for easier time-based operations
    _m["ss"] = _m.stm - _m.sbm
    _adtm["adtm"] = _m.apply(
        lambda x: x.ss / x.stm if x.ss > 0 else (x.ss / x.sbm if x.ss < 0 else 0),
        axis=1,
    )
    # âœ… Best Practice: Initializing DataFrame with index for alignment
    _adtm["adtmma"] = _ma(_adtm.adtm, m)
    return _adtm


# ğŸ§  ML Signal: Calculation of difference between close and open prices


# ğŸ§  ML Signal: Calculation of difference between close and open prices
def mi(df, n=12):
    """
    åŠ¨é‡æŒ‡æ ‡	mi(12)
    A=CLOSE-REF(CLOSE,N)
    MI=SMA(A,N,1)
    """
    _mi = pd.DataFrame()
    _mi["date"] = df.date
    _mi["mi"] = sma(df.close - df.close.shift(n), n)
    return _mi


# âœ… Best Practice: Dropping intermediate calculation columns to save memory
# ğŸ§  ML Signal: Rolling window calculation for time series analysis

# âœ… Best Practice: Use more descriptive variable names for better readability.


# âœ… Best Practice: Resetting index to return a clean DataFrame
def micd(df, n=3, m=10, k=20):
    """
    å¼‚åŒç¦»å·®åŠ¨åŠ›æŒ‡æ•°	micd(3,10,20)
    MI=CLOSE-ref(CLOSE,1)AMI=SMA(MI,N1,1)
    DIF=MA(ref(AMI,1),N2)-MA(ref(AMI,1),N3)
    MICD=SMA(DIF,10,1)
    """
    _micd = pd.DataFrame()
    # ğŸ§  ML Signal: Usage of rolling window operations, which are common in time series analysis.
    # âœ… Best Practice: Consider adding type hints for function parameters and return type for better readability and maintainability.
    _micd["date"] = df.date
    # ğŸ§  ML Signal: Calculation of moving averages, a common pattern in financial data analysis.
    mi = df.close - df.close.shift(1)
    ami = sma(mi, n)
    dif = _ma(ami.shift(1), m) - _ma(ami.shift(1), k)
    _micd["micd"] = sma(dif, m)
    return _micd


# âœ… Best Practice: Use more descriptive variable names for better readability.


def rc(df, n=50):
    """
    å˜åŒ–ç‡æŒ‡æ•°	rc(50)
    RC=æ”¶ç›˜ä»·/REFï¼ˆæ”¶ç›˜ä»·ï¼ŒNï¼‰Ã—100
    ARC=EMAï¼ˆREFï¼ˆRCï¼Œ1ï¼‰ï¼ŒNï¼Œ1ï¼‰
    """
    _rc = pd.DataFrame()
    _rc["date"] = df.date
    _rc["rc"] = df.close / df.close.shift(n) * 100
    _rc["arc"] = sma(_rc.rc.shift(1), n)
    return _rc


# âœ… Best Practice: Use more descriptive variable names for better readability.


def rccd(df, n=59, m=21, k=28):
    """# TODO: è®¡ç®—ç»“æœé”™è¯¯å’ŒåŒèŠ±é¡ºä¸åŒï¼Œæ£€æŸ¥ä¸å‡ºæ¥ä¸ºä»€ä¹ˆ
    å¼‚åŒç¦»å·®å˜åŒ–ç‡æŒ‡æ•° rate of change convergence divergence	rccd(59,21,28)
    RC=æ”¶ç›˜ä»·/REFï¼ˆæ”¶ç›˜ä»·ï¼ŒNï¼‰Ã—100%
    ARC=EMA(REF(RC,1),N,1)
    DIF=MA(ref(ARC,1),N1)-MA MA(ref(ARC,1),N2)
    RCCD=SMA(DIF,N,1)
    """
    _rccd = pd.DataFrame()
    _rccd["date"] = df.date
    # âœ… Best Practice: Initialize a new DataFrame for storing results
    rc = df.close / df.close.shift(n) * 100
    arc = sma(rc.shift(), n)
    # âœ… Best Practice: Explicitly assign columns to the DataFrame
    dif = _ma(arc.shift(), m) - _ma(arc.shift(), k)
    # âœ… Best Practice: Consider adding type hints for function parameters and return type for better readability and maintainability.
    _rccd["rccd"] = sma(dif, n)
    # ğŸ§  ML Signal: Use of rolling window operations on time series data
    # âš ï¸ SAST Risk (Low): Assumes 'df' has 'close' and 'date' columns without validation
    return _rccd


def srmi(df, n=9):
    """
    SRMIMIä¿®æ­£æŒ‡æ ‡	srmi(9)
    å¦‚æœæ”¶ç›˜ä»·>Næ—¥å‰çš„æ”¶ç›˜ä»·ï¼ŒSRMIå°±ç­‰äºï¼ˆæ”¶ç›˜ä»·-Næ—¥å‰çš„æ”¶ç›˜ä»·ï¼‰/æ”¶ç›˜ä»·
    å¦‚æœæ”¶ç›˜ä»·<Næ—¥å‰çš„æ”¶ç›˜ä»·ï¼ŒSRMIå°±ç­‰äºï¼ˆæ”¶ç›˜ä»·-Næ—¥ç­¾çš„æ”¶ç›˜ä»·ï¼‰/Næ—¥å‰çš„æ”¶ç›˜ä»·
    å¦‚æœæ”¶ç›˜ä»·=Næ—¥å‰çš„æ”¶ç›˜ä»·ï¼ŒSRMIå°±ç­‰äº0
    # âœ… Best Practice: Consider adding input validation for the 'df' parameter to ensure it contains the expected columns.
    """
    # âš ï¸ SAST Risk (Low): Check for division by zero when p is zero to prevent runtime errors.
    _srmi = pd.DataFrame()
    _srmi["date"] = df.date
    _m = pd.DataFrame()
    _m["close"] = df.close
    # âœ… Best Practice: Initialize DataFrame with specific columns to avoid potential KeyError.
    _m["cp"] = df.close.shift(n)
    _m["cs"] = df.close - df.close.shift(n)
    _srmi["srmi"] = _m.apply(
        lambda x: x.cs / x.close if x.cs > 0 else (x.cs / x.cp if x.cs < 0 else 0),
        axis=1,
    )
    # âš ï¸ SAST Risk (Low): Potential for KeyError if 'close' column is missing in 'df'.
    return _srmi


def dptb(df, n=7):
    """
    å¤§ç›˜åŒæ­¥æŒ‡æ ‡	dptb(7)
    DPTB=ï¼ˆç»Ÿè®¡Nå¤©ä¸­ä¸ªè‚¡æ”¶ç›˜ä»·>å¼€ç›˜ä»·ï¼Œä¸”æŒ‡æ•°æ”¶ç›˜ä»·>å¼€ç›˜ä»·çš„å¤©æ•°æˆ–è€…ä¸ªè‚¡æ”¶ç›˜ä»·<å¼€ç›˜ä»·ï¼Œä¸”æŒ‡æ•°æ”¶ç›˜ä»·<å¼€ç›˜ä»·ï¼‰/N
    """
    ind = ts.get_k_data("sh000001", start=df.date.iloc[0], end=df.date.iloc[-1])
    sd = df.copy()
    sd.set_index("date", inplace=True)  # å¯èƒ½å‡ºç°åœç›˜ç­‰æƒ…å†µï¼Œæ‰€ä»¥å°†dateè®¾ä¸ºindex
    ind.set_index("date", inplace=True)
    # âœ… Best Practice: Include import statements for used libraries (e.g., pandas, itertools)
    _dptb = pd.DataFrame(index=df.date)
    q = ind.close - ind.open
    _dptb["p"] = sd.close - sd.open
    _dptb["q"] = q
    _dptb["m"] = _dptb.apply(
        lambda x: 1 if (x.p > 0 and x.q > 0) or (x.p < 0 and x.q < 0) else np.nan,
        axis=1,
    )
    _dptb["jdrs"] = _dptb.m.rolling(n).count() / n
    _dptb.drop(columns=["p", "q", "m"], inplace=True)
    # ğŸ§  ML Signal: Usage of DataFrame operations to calculate differences
    _dptb.reset_index(inplace=True)
    return _dptb


# ğŸ§  ML Signal: Use of list to accumulate results
def jdqs(df, n=20):
    """
    é˜¶æ®µå¼ºåŠ¿æŒ‡æ ‡	jdqs(20)
    JDQS=ï¼ˆç»Ÿè®¡Nå¤©ä¸­ä¸ªè‚¡æ”¶ç›˜ä»·>å¼€ç›˜ä»·ï¼Œä¸”æŒ‡æ•°æ”¶ç›˜ä»·<å¼€ç›˜ä»·çš„å¤©æ•°ï¼‰/ï¼ˆç»Ÿè®¡Nå¤©ä¸­æŒ‡æ•°æ”¶ç›˜ä»·<å¼€ç›˜ä»·çš„å¤©æ•°ï¼‰
    """
    ind = ts.get_k_data("sh000001", start=df.date.iloc[0], end=df.date.iloc[-1])
    sd = df.copy()
    sd.set_index("date", inplace=True)  # å¯èƒ½å‡ºç°åœç›˜ç­‰æƒ…å†µï¼Œæ‰€ä»¥å°†dateè®¾ä¸ºindex
    ind.set_index("date", inplace=True)
    _jdrs = pd.DataFrame(index=df.date)
    # âœ… Best Practice: Use of join with set_index for merging dataframes on a specific column
    q = ind.close - ind.open
    _jdrs["p"] = sd.close - sd.open
    _jdrs["q"] = q
    _jdrs["m"] = _jdrs.apply(lambda x: 1 if (x.p > 0 and x.q < 0) else np.nan, axis=1)
    # âœ… Best Practice: Importing libraries within the main guard to avoid unnecessary imports
    # ğŸ§  ML Signal: Fetching stock data using tushare API, indicating financial data analysis
    # âš ï¸ SAST Risk (High): Calling an undefined function 'rccd' will raise a NameError
    q[q > 0] = np.nan
    _jdrs["t"] = q
    _jdrs["jdrs"] = _jdrs.m.rolling(n).count() / _jdrs.t.rolling(n).count()
    _jdrs.drop(columns=["p", "q", "m", "t"], inplace=True)
    _jdrs.reset_index(inplace=True)
    return _jdrs


def jdrs(df, n=20):
    """
    é˜¶æ®µå¼±åŠ¿æŒ‡æ ‡	jdrs(20)
    JDRS=ï¼ˆç»Ÿè®¡Nå¤©ä¸­ä¸ªè‚¡æ”¶ç›˜ä»·<å¼€ç›˜ä»·ï¼Œä¸”æŒ‡æ•°æ”¶ç›˜ä»·>å¼€ç›˜ä»·çš„å¤©æ•°ï¼‰/ï¼ˆç»Ÿè®¡Nå¤©ä¸­æŒ‡æ•°æ”¶ç›˜ä»·>å¼€ç›˜ä»·çš„å¤©æ•°ï¼‰
    """
    ind = ts.get_k_data("sh000001", start=df.date.iloc[0], end=df.date.iloc[-1])
    sd = df.copy()
    sd.set_index("date", inplace=True)
    ind.set_index("date", inplace=True)
    _jdrs = pd.DataFrame(index=df.date)
    q = ind.close - ind.open
    _jdrs["p"] = sd.close - sd.open
    _jdrs["q"] = q
    _jdrs["m"] = _jdrs.apply(lambda x: 1 if (x.p < 0 and x.q > 0) else np.nan, axis=1)
    q[q < 0] = np.nan
    _jdrs["t"] = q
    _jdrs["jdrs"] = _jdrs.m.rolling(n).count() / _jdrs.t.rolling(n).count()
    _jdrs.drop(columns=["p", "q", "m", "t"], inplace=True)
    _jdrs.reset_index(inplace=True)
    return _jdrs


def zdzb(df, n=125, m=5, k=20):
    """
    ç­‘åº•æŒ‡æ ‡	zdzb(125,5,20)
    A=ï¼ˆç»Ÿè®¡N1æ—¥å†…æ”¶ç›˜ä»·>=å‰æ”¶ç›˜ä»·çš„å¤©æ•°ï¼‰/ï¼ˆç»Ÿè®¡N1æ—¥å†…æ”¶ç›˜ä»·<å‰æ”¶ç›˜ä»·çš„å¤©æ•°ï¼‰
    B=MAï¼ˆA,N2ï¼‰
    D=MAï¼ˆAï¼ŒN3ï¼‰
    """
    _zdzb = pd.DataFrame()
    _zdzb["date"] = df.date
    p = df.close - df.close.shift(1)
    q = p.copy()
    p[p < 0] = np.nan
    q[q >= 0] = np.nan
    _zdzb["a"] = p.rolling(n).count() / q.rolling(n).count()
    _zdzb["b"] = _zdzb.a.rolling(m).mean()
    _zdzb["d"] = _zdzb.a.rolling(k).mean()
    return _zdzb


def atr(df, n=14):
    """
    çœŸå®æ³¢å¹…	atr(14)
    TR:MAX(MAX((HIGH-LOW),ABS(REF(CLOSE,1)-HIGH)),ABS(REF(CLOSE,1)-LOW))
    ATR:MA(TR,N)
    """
    _atr = pd.DataFrame()
    _atr["date"] = df.date
    # _atr['tr'] = np.maximum(df.high - df.low, (df.close.shift(1) - df.low).abs())
    # _atr['tr'] = np.maximum.reduce([df.high - df.low, (df.close.shift(1) - df.high).abs(), (df.close.shift(1) - df.low).abs()])
    _atr["tr"] = np.vstack(
        [
            df.high - df.low,
            (df.close.shift(1) - df.high).abs(),
            (df.close.shift(1) - df.low).abs(),
        ]
    ).max(axis=0)
    _atr["atr"] = _atr.tr.rolling(n).mean()
    return _atr


def mass(df, n=9, m=25):
    """
    æ¢…ä¸çº¿	mass(9,25)
    AHL=MA(ï¼ˆH-Lï¼‰,N1)
    BHL= MAï¼ˆAHLï¼ŒN1ï¼‰
    MASS=SUMï¼ˆAHL/BHLï¼ŒN2ï¼‰
    Hï¼šè¡¨ç¤ºæœ€é«˜ä»·ï¼›Lï¼šè¡¨ç¤ºæœ€ä½ä»·
    """
    _mass = pd.DataFrame()
    _mass["date"] = df.date
    ahl = _ma((df.high - df.low), n)
    bhl = _ma(ahl, n)
    _mass["mass"] = (ahl / bhl).rolling(m).sum()
    return _mass


def vhf(df, n=28):
    """
    çºµæ¨ªæŒ‡æ ‡	vhf(28)
    VHF=ï¼ˆNæ—¥å†…æœ€å¤§æ”¶ç›˜ä»·ä¸Næ—¥å†…æœ€å°æ”¶ç›˜ä»·ä¹‹å‰çš„å·®ï¼‰/ï¼ˆNæ—¥æ”¶ç›˜ä»·ä¸å‰æ”¶ç›˜ä»·å·®çš„ç»å¯¹å€¼ä¹‹å’Œï¼‰
    """
    _vhf = pd.DataFrame()
    _vhf["date"] = df.date
    _vhf["vhf"] = (df.close.rolling(n).max() - df.close.rolling(n).min()) / (
        df.close - df.close.shift(1)
    ).abs().rolling(n).sum()
    return _vhf


def cvlt(df, n=10):
    """
    ä½³åº†ç¦»æ•£æŒ‡æ ‡	cvlt(10)
    cvlt=ï¼ˆæœ€é«˜ä»·ä¸æœ€ä½ä»·çš„å·®çš„æŒ‡æ•°ç§»åŠ¨å¹³å‡-å‰Næ—¥çš„æœ€é«˜ä»·ä¸æœ€ä½ä»·çš„å·®çš„æŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼‰/å‰Næ—¥çš„æœ€é«˜ä»·ä¸æœ€ä½ä»·çš„å·®çš„æŒ‡æ•°ç§»åŠ¨å¹³å‡
    """
    _cvlt = pd.DataFrame()
    _cvlt["date"] = df.date
    p = _ema(df.high.shift(n) - df.low.shift(n), n)
    _cvlt["cvlt"] = (_ema(df.high - df.low, n) - p) / p * 100
    return _cvlt


def up_n(df):
    """
    è¿æ¶¨å¤©æ•°	up_n	è¿ç»­ä¸Šæ¶¨å¤©æ•°ï¼Œå½“å¤©æ”¶ç›˜ä»·å¤§äºå¼€ç›˜ä»·å³ä¸ºä¸Šæ¶¨ä¸€å¤© # åŒèŠ±é¡ºå®é™…ç»“æœç”¨æ”¶ç›˜ä»·-å‰ä¸€å¤©æ”¶ç›˜ä»·
    """
    _up = pd.DataFrame()
    _up["date"] = df.date
    p = df.close - df.close.shift()
    p[p > 0] = 1
    p[p < 0] = 0
    m = []
    for k, g in itertools.groupby(p):
        t = 0
        for i in g:
            if k == 0:
                m.append(0)
            else:
                t += 1
                m.append(t)
    # _up['p'] = p
    _up["up"] = m
    return _up


def down_n(df):
    """
    è¿è·Œå¤©æ•°	down_n	è¿ç»­ä¸‹è·Œå¤©æ•°ï¼Œå½“å¤©æ”¶ç›˜ä»·å°äºå¼€ç›˜ä»·å³ä¸ºä¸‹è·Œä¸€å¤©
    """
    _down = pd.DataFrame()
    _down["date"] = df.date
    p = df.close - df.close.shift()
    p[p > 0] = 0
    p[p < 0] = 1
    m = []
    for k, g in itertools.groupby(p):
        t = 0
        for i in g:
            if k == 0:
                m.append(0)
            else:
                t += 1
                m.append(t)
    _down["down"] = m
    return _down


def join_frame(d1, d2, column="date"):
    # å°†ä¸¤ä¸ªDataFrame æŒ‰ç…§datetimeåˆå¹¶
    return d1.join(d2.set_index(column), on=column)


if __name__ == "__main__":
    import tushare as ts

    # data = ts.get_k_data("000063", start="2017-05-01")
    data = ts.get_k_data("601138", start="2017-05-01")
    # print(data)
    # maf = ma(data, n=[5, 10, 20])
    # å°†å‡çº¿åˆå¹¶åˆ°dataä¸­
    # print(join_frame(data, maf))

    # data = pd.DataFrame({"close": [1,2,3,4,5,6,7,8,9,0]})
    # print(ma(data))
    # mdf = md(data)
    # print(md(data, n=26))
    # print(join_frame(data, mdf))
    # emaf = ema(data)
    # print(ema(data, 5))
    # print(join_frame(data, emaf))
    # print(macd(data))
    # print(kdj(data))
    # print(vrsi(data, 6))
    # print(boll(data))
    # print(bbiboll(data))
    # print(wr(data))
    # print(bias(data))
    # print(asi(data))
    # print(vr_rate(data))
    # print(vr(data))
    # print(arbr(data))
    # print(dpo(data))
    # print(trix(data))
    # print(bbi(data))
    # print(ts.top_list(date="2019-01-17"))
    # print(mtm(data))
    # print(obv(data))
    # print(cci(data))
    # print(priceosc(data))
    # print(dbcd(data))
    # print(roc(data))
    # print(vroc(data))
    # print(cr(data))
    # print(psy(data))
    # print(wad(data))
    # print(mfi(data))
    # print(pvt(data))
    # print(wvad(data))
    # print(cdp(data))
    # print(env(data))
    # print(mike(data))
    # print(vr(data))
    # print(vma(data))
    # print(vmacd(data))
    # print(vosc(data))
    # print(tapi(data))
    # print(vstd(data))
    # print(adtm(data))
    # print(mi(data))
    # print(micd(data))
    # print(rc(data))
    print(rccd(data))
    # print(srmi(data))
    # print(dptb(data))
    # print(jdqs(data))
    # pd.set_option('display.max_rows', 1000)
    # print(jdrs(data))
    # print(join_frame(data, jdrs(data)))
    # print(data)
    # print(zdzb(data))
    # print(atr(data))
    # print(mass(data))
    # print(vhf(data))
    # print(cvlt(data))
    # print(up_n(data))
    # print(down_n(data))
