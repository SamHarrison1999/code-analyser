[
  {
    "line": 4,
    "text": "import polars as pl",
    "annotation": "\u2705 Best Practice: Use relative imports for internal modules to maintain package structure",
    "confidence": 1.0,
    "tokens": [
      11748,
      755,
      945,
      355,
      458
    ],
    "start_token": 0,
    "end_token": 5,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      3585,
      17944,
      329,
      5387,
      13103,
      284,
      5529,
      5301,
      4645
    ],
    "label": "best_practice",
    "reason": "Use relative imports for internal modules to maintain package structure"
  },
  {
    "line": 7,
    "text": "",
    "annotation": "\u2705 Best Practice: Use of default parameter value to handle optional argument",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 5,
    "end_token": 5,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      4277,
      11507,
      1988,
      284,
      5412,
      11902,
      4578
    ],
    "label": "best_practice",
    "reason": "Use of default parameter value to handle optional argument"
  },
  {
    "line": 9,
    "text": "def process_drop_na(df: pl.DataFrame, names: list[str] | None = None) -> pl.DataFrame:",
    "annotation": "\u2705 Best Practice: Dynamic selection of columns based on DataFrame structure",
    "confidence": 1.0,
    "tokens": [
      4299,
      1429,
      62,
      14781,
      62,
      2616,
      7,
      7568,
      25,
      458,
      13,
      6601,
      19778,
      11,
      3891,
      25,
      1351,
      58,
      2536,
      60,
      930,
      6045,
      796,
      6045,
      8,
      4613,
      458,
      13,
      6601,
      19778,
      25
    ],
    "start_token": 5,
    "end_token": 36,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      26977,
      6356,
      286,
      15180,
      1912,
      319,
      6060,
      19778,
      4645
    ],
    "label": "best_practice",
    "reason": "Dynamic selection of columns based on DataFrame structure"
  },
  {
    "line": 13,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Iterating over column names to apply transformations",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 36,
    "end_token": 36,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      40806,
      803,
      625,
      5721,
      3891,
      284,
      4174,
      38226
    ],
    "label": "ml_signal",
    "reason": "Iterating over column names to apply transformations"
  },
  {
    "line": 13,
    "text": "",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential risk if column names are not validated or sanitized",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 36,
    "end_token": 36,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      2526,
      611,
      5721,
      3891,
      389,
      407,
      31031,
      393,
      5336,
      36951
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential risk if column names are not validated or sanitized"
  },
  {
    "line": 15,
    "text": "        df = df.with_columns(",
    "annotation": "\ud83e\udde0 ML Signal: Use of fill_nan to handle missing values",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      47764,
      796,
      47764,
      13,
      4480,
      62,
      28665,
      82,
      7
    ],
    "start_token": 36,
    "end_token": 52,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      6070,
      62,
      12647,
      284,
      5412,
      4814,
      3815
    ],
    "label": "ml_signal",
    "reason": "Use of fill_nan to handle missing values"
  },
  {
    "line": 18,
    "text": "    df = df.drop_nulls(subset=names)",
    "annotation": "\ud83e\udde0 ML Signal: Use of drop_nulls to remove rows with missing values",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      47764,
      796,
      47764,
      13,
      14781,
      62,
      8423,
      82,
      7,
      7266,
      2617,
      28,
      14933,
      8
    ],
    "start_token": 52,
    "end_token": 69,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      4268,
      62,
      8423,
      82,
      284,
      4781,
      15274,
      351,
      4814,
      3815
    ],
    "label": "ml_signal",
    "reason": "Use of drop_nulls to remove rows with missing values"
  },
  {
    "line": 15,
    "text": "        df = df.with_columns(",
    "annotation": "\u2705 Best Practice: Include type hints for function parameters and return type for better readability and maintainability",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      47764,
      796,
      47764,
      13,
      4480,
      62,
      28665,
      82,
      7
    ],
    "start_token": 69,
    "end_token": 85,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      40348,
      2099,
      20269,
      329,
      2163,
      10007,
      290,
      1441,
      2099,
      329,
      1365,
      1100,
      1799,
      290,
      5529,
      1799
    ],
    "label": "best_practice",
    "reason": "Include type hints for function parameters and return type for better readability and maintainability"
  },
  {
    "line": 18,
    "text": "    df = df.drop_nulls(subset=names)",
    "annotation": "\ud83e\udde0 ML Signal: Conditional logic based on a boolean flag, indicating different processing paths",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      47764,
      796,
      47764,
      13,
      14781,
      62,
      8423,
      82,
      7,
      7266,
      2617,
      28,
      14933,
      8
    ],
    "start_token": 85,
    "end_token": 102,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      9724,
      1859,
      9156,
      1912,
      319,
      257,
      25131,
      6056,
      11,
      12739,
      1180,
      7587,
      13532
    ],
    "label": "ml_signal",
    "reason": "Conditional logic based on a boolean flag, indicating different processing paths"
  },
  {
    "line": 19,
    "text": "    return df",
    "annotation": "\u2705 Best Practice: Use method chaining for concise and readable code",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      1441,
      47764
    ],
    "start_token": 102,
    "end_token": 107,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      2446,
      442,
      1397,
      329,
      35327,
      290,
      31744,
      2438
    ],
    "label": "best_practice",
    "reason": "Use method chaining for concise and readable code"
  },
  {
    "line": 24,
    "text": "    if fill_label:",
    "annotation": "\u2705 Best Practice: List comprehension for concise and efficient column processing",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      611,
      6070,
      62,
      18242,
      25
    ],
    "start_token": 107,
    "end_token": 115,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      7343,
      35915,
      329,
      35327,
      290,
      6942,
      5721,
      7587
    ],
    "label": "best_practice",
    "reason": "List comprehension for concise and efficient column processing"
  },
  {
    "line": 25,
    "text": "        df = df.fill_null(fill_value)",
    "annotation": "\ud83e\udde0 ML Signal: Iterating over DataFrame columns, indicating column-wise operations",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      47764,
      796,
      47764,
      13,
      20797,
      62,
      8423,
      7,
      20797,
      62,
      8367,
      8
    ],
    "start_token": 115,
    "end_token": 134,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      40806,
      803,
      625,
      6060,
      19778,
      15180,
      11,
      12739,
      5721,
      12,
      3083,
      4560
    ],
    "label": "ml_signal",
    "reason": "Iterating over DataFrame columns, indicating column-wise operations"
  },
  {
    "line": 30,
    "text": "        )",
    "annotation": "\u2705 Best Practice: Explicit return of the DataFrame for clarity",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1267
    ],
    "start_token": 134,
    "end_token": 142,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      11884,
      1441,
      286,
      262,
      6060,
      19778,
      329,
      16287
    ],
    "label": "best_practice",
    "reason": "Explicit return of the DataFrame for clarity"
  },
  {
    "line": 25,
    "text": "        df = df.fill_null(fill_value)",
    "annotation": "\u2705 Best Practice: Type hinting for function parameters and return type improves code readability and maintainability.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      47764,
      796,
      47764,
      13,
      20797,
      62,
      8423,
      7,
      20797,
      62,
      8367,
      8
    ],
    "start_token": 142,
    "end_token": 161,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5994,
      9254,
      278,
      329,
      2163,
      10007,
      290,
      1441,
      2099,
      19575,
      2438,
      1100,
      1799,
      290,
      5529,
      1799,
      13
    ],
    "label": "best_practice",
    "reason": "Type hinting for function parameters and return type improves code readability and maintainability."
  },
  {
    "line": 32,
    "text": "",
    "annotation": "\u2705 Best Practice: Using type hinting for local variables enhances code readability.",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 161,
    "end_token": 161,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      8554,
      2099,
      9254,
      278,
      329,
      1957,
      9633,
      32479,
      2438,
      1100,
      1799,
      13
    ],
    "label": "best_practice",
    "reason": "Using type hinting for local variables enhances code readability."
  },
  {
    "line": 34,
    "text": "def process_cs_norm(",
    "annotation": "\ud83e\udde0 ML Signal: The use of different normalization methods based on a parameter can indicate a pattern for ML model training.",
    "confidence": 1.0,
    "tokens": [
      4299,
      1429,
      62,
      6359,
      62,
      27237,
      7
    ],
    "start_token": 161,
    "end_token": 168,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      383,
      779,
      286,
      1180,
      3487,
      1634,
      5050,
      1912,
      319,
      257,
      11507,
      460,
      7603,
      257,
      3912,
      329,
      10373,
      2746,
      3047,
      13
    ],
    "label": "ml_signal",
    "reason": "The use of different normalization methods based on a parameter can indicate a pattern for ML model training."
  },
  {
    "line": 39,
    "text": "    \"\"\"Cross-sectional normalization\"\"\"",
    "annotation": "\ud83e\udde0 ML Signal: Iterating over column names to apply transformations is a common pattern in data preprocessing.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      37227,
      21544,
      12,
      44330,
      3487,
      1634,
      37811
    ],
    "start_token": 168,
    "end_token": 178,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      40806,
      803,
      625,
      5721,
      3891,
      284,
      4174,
      38226,
      318,
      257,
      2219,
      3912,
      287,
      1366,
      662,
      36948,
      13
    ],
    "label": "ml_signal",
    "reason": "Iterating over column names to apply transformations is a common pattern in data preprocessing."
  },
  {
    "line": 48,
    "text": "                )",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Hardcoded constants like 1.4826 can lead to maintenance challenges if not documented.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1267
    ],
    "start_token": 178,
    "end_token": 194,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      6912,
      40976,
      38491,
      588,
      352,
      13,
      2780,
      2075,
      460,
      1085,
      284,
      9262,
      6459,
      611,
      407,
      12395,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Hardcoded constants like 1.4826 can lead to maintenance challenges if not documented."
  },
  {
    "line": 66,
    "text": "                    pl.col(col).std().over(\"datetime\").alias(\"std\"),",
    "annotation": "\u2705 Best Practice: Use of type hinting for variable _df improves code readability and maintainability.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      458,
      13,
      4033,
      7,
      4033,
      737,
      19282,
      22446,
      2502,
      7203,
      19608,
      8079,
      11074,
      26011,
      7203,
      19282,
      12340
    ],
    "start_token": 194,
    "end_token": 230,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      2099,
      9254,
      278,
      329,
      7885,
      4808,
      7568,
      19575,
      2438,
      1100,
      1799,
      290,
      5529,
      1799,
      13
    ],
    "label": "best_practice",
    "reason": "Use of type hinting for variable _df improves code readability and maintainability."
  },
  {
    "line": 69,
    "text": "",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential risk of incorrect datetime conversion if input is not validated.",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 230,
    "end_token": 230,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      2526,
      286,
      11491,
      4818,
      8079,
      11315,
      611,
      5128,
      318,
      407,
      31031,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential risk of incorrect datetime conversion if input is not validated."
  },
  {
    "line": 71,
    "text": "                (pl.col(col) - pl.col(\"mean\")) / pl.col(\"std\").alias(col)",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential risk of incorrect datetime conversion if input is not validated.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      357,
      489,
      13,
      4033,
      7,
      4033,
      8,
      532,
      458,
      13,
      4033,
      7203,
      32604,
      48774,
      1220,
      458,
      13,
      4033,
      7203,
      19282,
      11074,
      26011,
      7,
      4033,
      8
    ],
    "start_token": 230,
    "end_token": 270,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      2526,
      286,
      11491,
      4818,
      8079,
      11315,
      611,
      5128,
      318,
      407,
      31031,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential risk of incorrect datetime conversion if input is not validated."
  },
  {
    "line": 73,
    "text": "",
    "annotation": "\u2705 Best Practice: Use of filter method for DataFrame to handle date range filtering.",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 270,
    "end_token": 270,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      8106,
      2446,
      329,
      6060,
      19778,
      284,
      5412,
      3128,
      2837,
      25431,
      13
    ],
    "label": "best_practice",
    "reason": "Use of filter method for DataFrame to handle date range filtering."
  },
  {
    "line": 75,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Selecting specific columns for processing indicates feature selection.",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 270,
    "end_token": 270,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      9683,
      278,
      2176,
      15180,
      329,
      7587,
      9217,
      3895,
      6356,
      13
    ],
    "label": "ml_signal",
    "reason": "Selecting specific columns for processing indicates feature selection."
  },
  {
    "line": 77,
    "text": "def process_robust_zscore_norm(",
    "annotation": "\ud83e\udde0 ML Signal: Conversion to numpy array for numerical operations is a common pattern in data preprocessing.",
    "confidence": 1.0,
    "tokens": [
      4299,
      1429,
      62,
      22609,
      436,
      62,
      89,
      26675,
      62,
      27237,
      7
    ],
    "start_token": 270,
    "end_token": 281,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      44101,
      284,
      299,
      32152,
      7177,
      329,
      29052,
      4560,
      318,
      257,
      2219,
      3912,
      287,
      1366,
      662,
      36948,
      13
    ],
    "label": "ml_signal",
    "reason": "Conversion to numpy array for numerical operations is a common pattern in data preprocessing."
  },
  {
    "line": 78,
    "text": "    df: pl.DataFrame,",
    "annotation": "\ud83e\udde0 ML Signal: Calculation of median and median absolute deviation is a robust statistical method.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      47764,
      25,
      458,
      13,
      6601,
      19778,
      11
    ],
    "start_token": 281,
    "end_token": 291,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      2199,
      14902,
      286,
      14288,
      290,
      14288,
      4112,
      28833,
      318,
      257,
      12373,
      13905,
      2446,
      13
    ],
    "label": "ml_signal",
    "reason": "Calculation of median and median absolute deviation is a robust statistical method."
  },
  {
    "line": 82,
    "text": ") -> pl.DataFrame:",
    "annotation": "\u2705 Best Practice: Adding a small constant to avoid division by zero.",
    "confidence": 1.0,
    "tokens": [
      8,
      4613,
      458,
      13,
      6601,
      19778,
      25
    ],
    "start_token": 291,
    "end_token": 298,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      18247,
      257,
      1402,
      6937,
      284,
      3368,
      7297,
      416,
      6632,
      13
    ],
    "label": "best_practice",
    "reason": "Adding a small constant to avoid division by zero."
  },
  {
    "line": 84,
    "text": "    _df: pl.DataFrame = df.fill_nan(None)",
    "annotation": "\ud83e\udde0 ML Signal: Scaling factor for robust standard deviation is a specific preprocessing technique.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      4808,
      7568,
      25,
      458,
      13,
      6601,
      19778,
      796,
      47764,
      13,
      20797,
      62,
      12647,
      7,
      14202,
      8
    ],
    "start_token": 298,
    "end_token": 317,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      1446,
      4272,
      5766,
      329,
      12373,
      3210,
      28833,
      318,
      257,
      2176,
      662,
      36948,
      8173,
      13
    ],
    "label": "ml_signal",
    "reason": "Scaling factor for robust standard deviation is a specific preprocessing technique."
  },
  {
    "line": 87,
    "text": "        fit_start_time = to_datetime(fit_start_time)",
    "annotation": "\ud83e\udde0 ML Signal: Normalization of data is a common preprocessing step in ML pipelines.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      4197,
      62,
      9688,
      62,
      2435,
      796,
      284,
      62,
      19608,
      8079,
      7,
      11147,
      62,
      9688,
      62,
      2435,
      8
    ],
    "start_token": 317,
    "end_token": 341,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      14435,
      1634,
      286,
      1366,
      318,
      257,
      2219,
      662,
      36948,
      2239,
      287,
      10373,
      31108,
      13
    ],
    "label": "ml_signal",
    "reason": "Normalization of data is a common preprocessing step in ML pipelines."
  },
  {
    "line": 92,
    "text": "    X = _df.select(cols).to_numpy()",
    "annotation": "\ud83e\udde0 ML Signal: Clipping outliers is a common data preprocessing technique.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      1395,
      796,
      4808,
      7568,
      13,
      19738,
      7,
      4033,
      82,
      737,
      1462,
      62,
      77,
      32152,
      3419
    ],
    "start_token": 341,
    "end_token": 359,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      1012,
      4501,
      41528,
      3183,
      318,
      257,
      2219,
      1366,
      662,
      36948,
      8173,
      13
    ],
    "label": "ml_signal",
    "reason": "Clipping outliers is a common data preprocessing technique."
  },
  {
    "line": 95,
    "text": "    std_train = np.nanmedian(np.abs(X - mean_train), axis=0)",
    "annotation": "\u2705 Best Practice: Use of with_columns method to update DataFrame columns.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      14367,
      62,
      27432,
      796,
      45941,
      13,
      12647,
      1150,
      666,
      7,
      37659,
      13,
      8937,
      7,
      55,
      532,
      1612,
      62,
      27432,
      828,
      16488,
      28,
      15,
      8
    ],
    "start_token": 359,
    "end_token": 386,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      351,
      62,
      28665,
      82,
      2446,
      284,
      4296,
      6060,
      19778,
      15180,
      13
    ],
    "label": "best_practice",
    "reason": "Use of with_columns method to update DataFrame columns."
  },
  {
    "line": 85,
    "text": "",
    "annotation": "\u2705 Best Practice: Add a docstring to describe the function's purpose and parameters.",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 386,
    "end_token": 386,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      3060,
      257,
      2205,
      8841,
      284,
      6901,
      262,
      2163,
      338,
      4007,
      290,
      10007,
      13
    ],
    "label": "best_practice",
    "reason": "Add a docstring to describe the function's purpose and parameters."
  },
  {
    "line": 88,
    "text": "        fit_end_time = to_datetime(fit_end_time)",
    "annotation": "\u2705 Best Practice: Type hinting for _df improves code readability and maintainability.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      4197,
      62,
      437,
      62,
      2435,
      796,
      284,
      62,
      19608,
      8079,
      7,
      11147,
      62,
      437,
      62,
      2435,
      8
    ],
    "start_token": 386,
    "end_token": 410,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5994,
      9254,
      278,
      329,
      4808,
      7568,
      19575,
      2438,
      1100,
      1799,
      290,
      5529,
      1799,
      13
    ],
    "label": "best_practice",
    "reason": "Type hinting for _df improves code readability and maintainability."
  },
  {
    "line": 92,
    "text": "    X = _df.select(cols).to_numpy()",
    "annotation": "\ud83e\udde0 ML Signal: Usage of rank normalization pattern could be a feature for ML models.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      1395,
      796,
      4808,
      7568,
      13,
      19738,
      7,
      4033,
      82,
      737,
      1462,
      62,
      77,
      32152,
      3419
    ],
    "start_token": 410,
    "end_token": 428,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      29566,
      286,
      4279,
      3487,
      1634,
      3912,
      714,
      307,
      257,
      3895,
      329,
      10373,
      4981,
      13
    ],
    "label": "ml_signal",
    "reason": "Usage of rank normalization pattern could be a feature for ML models."
  },
  {
    "line": 92,
    "text": "    X = _df.select(cols).to_numpy()",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Ensure that the rank method and over clause are used correctly to avoid logical errors.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      1395,
      796,
      4808,
      7568,
      13,
      19738,
      7,
      4033,
      82,
      737,
      1462,
      62,
      77,
      32152,
      3419
    ],
    "start_token": 428,
    "end_token": 446,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      48987,
      326,
      262,
      4279,
      2446,
      290,
      625,
      13444,
      389,
      973,
      9380,
      284,
      3368,
      12219,
      8563,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Ensure that the rank method and over clause are used correctly to avoid logical errors."
  },
  {
    "line": 95,
    "text": "    std_train = np.nanmedian(np.abs(X - mean_train), axis=0)",
    "annotation": "\u2705 Best Practice: Using alias to rename columns improves code clarity.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      14367,
      62,
      27432,
      796,
      45941,
      13,
      12647,
      1150,
      666,
      7,
      37659,
      13,
      8937,
      7,
      55,
      532,
      1612,
      62,
      27432,
      828,
      16488,
      28,
      15,
      8
    ],
    "start_token": 446,
    "end_token": 473,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      8554,
      16144,
      284,
      36265,
      15180,
      19575,
      2438,
      16287,
      13
    ],
    "label": "best_practice",
    "reason": "Using alias to rename columns improves code clarity."
  }
]