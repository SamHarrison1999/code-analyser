# -*- coding: utf-8 -*-
# âœ… Best Practice: Grouping imports from the same module together improves readability.
import pandas as pd

# âœ… Best Practice: Grouping imports from the same module together improves readability.
from zvt.contract import IntervalLevel
from zvt.contract.api import df_to_db
# âœ… Best Practice: Grouping imports from the same module together improves readability.
from zvt.contract.recorder import FixedCycleDataRecorder
from zvt.domain import IndexMoneyFlow, Index, StockMoneyFlow
# âœ… Best Practice: Grouping imports from the same module together improves readability.
from zvt.utils.pd_utils import pd_is_not_null
# ğŸ§  ML Signal: Inheritance from a specific base class indicates a design pattern or framework usage
from zvt.utils.time_utils import to_time_str
# âœ… Best Practice: Grouping imports from the same module together improves readability.

# ğŸ§  ML Signal: Hardcoded string values can indicate configuration or categorical data

# âœ… Best Practice: Grouping imports from the same module together improves readability.
class JoinquantIndexMoneyFlowRecorder(FixedCycleDataRecorder):
    # ğŸ§  ML Signal: Use of specific schema class can indicate data structure or domain model
    # ğŸ§  ML Signal: Hardcoded string values can indicate configuration or categorical data
    entity_provider = "exchange"
    entity_schema = Index

    provider = "joinquant"
    data_schema = IndexMoneyFlow

    def __init__(
        self,
        force_update=True,
        sleeping_time=10,
        exchanges=None,
        entity_id=None,
        entity_ids=None,
        code=None,
        codes=None,
        day_data=False,
        entity_filters=None,
        ignore_failed=True,
        real_time=False,
        fix_duplicate_way="ignore",
        start_timestamp=None,
        # âœ… Best Practice: Use of a list to define default supported codes
        end_timestamp=None,
        level=IntervalLevel.LEVEL_1DAY,
        # âœ… Best Practice: Assign default codes if none are provided
        kdata_use_begin_time=False,
        one_day_trading_minutes=24 * 60,
        return_unfinished=False,
    # âœ… Best Practice: Use of set intersection to filter supported codes
    # âœ… Best Practice: Proper use of super() to initialize the parent class
    ) -> None:
        # ä¸Šè¯æŒ‡æ•°ï¼Œæ·±è¯æˆæŒ‡ï¼Œåˆ›ä¸šæ¿æŒ‡ï¼Œç§‘åˆ›æ¿
        support_codes = ["000001", "399001", "399006", "000688"]
        if not codes:
            codes = support_codes
        else:
            codes = list(set(codes) & set(support_codes))
        super().__init__(
            force_update,
            sleeping_time,
            exchanges,
            entity_id,
            entity_ids,
            code,
            codes,
            day_data,
            entity_filters,
            ignore_failed,
            real_time,
            fix_duplicate_way,
            start_timestamp,
            # ğŸ§  ML Signal: Conditional logic based on entity code
            end_timestamp,
            # ğŸ§  ML Signal: Querying data with specific filters
            level,
            kdata_use_begin_time,
            one_day_trading_minutes,
            return_unfinished,
        )

    def record(self, entity, start, end, size, timestamps):
        # ä¸Šè¯
        if entity.code == "000001":
            all_df = StockMoneyFlow.query_data(
                provider=self.provider, start_timestamp=start, filters=[StockMoneyFlow.entity_id.like("stock_sh%")]
            )
        # æ·±è¯
        elif entity.code == "399001":
            all_df = StockMoneyFlow.query_data(
                provider=self.provider, start_timestamp=start, filters=[StockMoneyFlow.entity_id.like("stock_sz%")]
            )
        # âœ… Best Practice: Check if DataFrame is not null before processing
        # åˆ›ä¸šæ¿
        # ğŸ§  ML Signal: Grouping data by timestamp
        # ğŸ§  ML Signal: Creating a series with specific data
        elif entity.code == "399006":
            all_df = StockMoneyFlow.query_data(
                provider=self.provider, start_timestamp=start, filters=[StockMoneyFlow.code.like("300%")]
            )
        # ç§‘åˆ›æ¿
        elif entity.code == "000688":
            all_df = StockMoneyFlow.query_data(
                provider=self.provider, start_timestamp=start, filters=[StockMoneyFlow.code.like("688%")]
            )

        if pd_is_not_null(all_df):
            g = all_df.groupby("timestamp")
            for timestamp, df in g:
                se = pd.Series(
                    {
                        "id": "{}_{}".format(entity.id, to_time_str(timestamp)),
                        "entity_id": entity.id,
                        "timestamp": timestamp,
                        "code": entity.code,
                        "name": entity.name,
                    }
                )
                for col in [
                    "net_main_inflows",
                    # ğŸ§  ML Signal: Summing up specific columns
                    "net_huge_inflows",
                    "net_big_inflows",
                    "net_medium_inflows",
                    "net_small_inflows",
                ]:
                    se[col] = df[col].sum()
                # ğŸ§  ML Signal: Calculating average rates

                for col in [
                    # âœ… Best Practice: Convert series to DataFrame for logging and database operations
                    "net_main_inflow_rate",
                    # ğŸ§  ML Signal: Running the recorder with a specific start timestamp
                    # ğŸ§  ML Signal: Logging the DataFrame
                    # âš ï¸ SAST Risk (Low): Ensure df_to_db handles SQL injection safely
                    # âœ… Best Practice: Define __all__ for module exports
                    "net_huge_inflow_rate",
                    "net_big_inflow_rate",
                    "net_medium_inflow_rate",
                    "net_small_inflow_rate",
                ]:
                    se[col] = df[col].sum() / len(df)

                index_df = se.to_frame().T

                self.logger.info(index_df)

                df_to_db(
                    df=index_df, data_schema=self.data_schema, provider=self.provider, force_update=self.force_update
                )

        return None


if __name__ == "__main__":
    JoinquantIndexMoneyFlowRecorder(start_timestamp="2020-12-01").run()


# the __all__ is generated
__all__ = ["JoinquantIndexMoneyFlowRecorder"]