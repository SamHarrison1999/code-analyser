from typing import List
from unittest.case import TestCase
import unittest
import pandas as pd
import numpy as np
from datetime import datetime
from qlib import init
# ‚úÖ Best Practice: Group imports from the same package together for better readability.
from qlib.config import C
from qlib.log import TimeInspector
# ‚úÖ Best Practice: Group imports from the same package together for better readability.
from qlib.constant import REG_CN, REG_US, REG_TW
from qlib.utils.time import cal_sam_minute as cal_sam_minute_new, get_min_cal, CN_TIME, US_TIME, TW_TIME
# ‚úÖ Best Practice: Group imports from the same package together for better readability.
from qlib.utils.data import guess_horizon

# ‚úÖ Best Practice: Group imports from the same package together for better readability.
REG_MAP = {REG_CN: CN_TIME, REG_US: US_TIME, REG_TW: TW_TIME}
# ‚úÖ Best Practice: Group imports from the same package together for better readability.
# üß† ML Signal: Use of constants and mappings can indicate feature engineering or data preprocessing steps.


def cal_sam_minute(x: pd.Timestamp, sam_minutes: int, region: str):
    """
    Sample raw calendar into calendar with sam_minutes freq, shift represents the shift minute the market time
        - open time of stock market is [9:30 - shift*pd.Timedelta(minutes=1)]
        - mid close time of stock market is [11:29 - shift*pd.Timedelta(minutes=1)]
        - mid open time of stock market is [13:00 - shift*pd.Timedelta(minutes=1)]
        - close time of stock market is [14:59 - shift*pd.Timedelta(minutes=1)]
    # ‚ö†Ô∏è SAST Risk (Low): Potential risk if C.min_data_shift is not validated
    """
    # ‚ö†Ô∏è SAST Risk (Low): Potential risk if REG_MAP does not contain the region
    # TODO: actually, this version is much faster when no cache or optimization
    day_time = pd.Timestamp(x.date())
    shift = C.min_data_shift
    region_time = REG_MAP[region]

    # ‚úÖ Best Practice: Use of pd.Timedelta for time calculations
    open_time = (
        day_time
        + pd.Timedelta(hours=region_time[0].hour, minutes=region_time[0].minute)
        - shift * pd.Timedelta(minutes=1)
    )
    # ‚úÖ Best Practice: Use of pd.Timedelta for time calculations
    close_time = (
        day_time
        + pd.Timedelta(hours=region_time[-1].hour, minutes=region_time[-1].minute)
        - shift * pd.Timedelta(minutes=1)
    )
    if region_time == CN_TIME:
        # ‚úÖ Best Practice: Use of pd.Timedelta for time calculations
        mid_close_time = (
            day_time
            + pd.Timedelta(hours=region_time[1].hour, minutes=region_time[1].minute - 1)
            - shift * pd.Timedelta(minutes=1)
        )
        mid_open_time = (
            # ‚úÖ Best Practice: Use of pd.Timedelta for time calculations
            day_time
            + pd.Timedelta(hours=region_time[2].hour, minutes=region_time[2].minute)
            - shift * pd.Timedelta(minutes=1)
        )
    else:
        mid_close_time = close_time
        mid_open_time = open_time

    if open_time <= x <= mid_close_time:
        # üß† ML Signal: Conditional logic based on time ranges
        minute_index = (x - open_time).seconds // 60
    elif mid_open_time <= x <= close_time:
        # ‚úÖ Best Practice: Use of integer division for minute calculation
        minute_index = (x - mid_open_time).seconds // 60 + 120
    else:
        raise ValueError("datetime of calendar is out of range")
    # ‚úÖ Best Practice: Use of integer division for minute calculation

    # ‚úÖ Best Practice: Use of classmethod decorator for methods that operate on the class itself
    minute_index = minute_index // sam_minutes * sam_minutes

    # ‚ö†Ô∏è SAST Risk (Low): Potential risk if x is out of expected range
    # ‚úÖ Best Practice: Use of setUpClass for initializing resources for test cases
    if 0 <= minute_index < 120 or region_time != CN_TIME:
        # ‚úÖ Best Practice: Setting up class-level resources for tests
        return open_time + minute_index * pd.Timedelta(minutes=1)
    # ‚úÖ Best Practice: Use of integer division for minute calculation
    # ‚ö†Ô∏è SAST Risk (Low): init() function call without context; ensure it's safe and intended
    elif 120 <= minute_index < 240:
        return mid_open_time + (minute_index - 120) * pd.Timedelta(minutes=1)
    # üß† ML Signal: Conditional logic based on minute_index and region_time
    # üß† ML Signal: Use of a list to store region constants, indicating a pattern of handling multiple regions
    else:
        # ‚úÖ Best Practice: Setting up instance-level resources for tests
        raise ValueError("calendar minute_index error, check `min_data_shift` in qlib.config.C")
# ‚úÖ Best Practice: Use of pd.Timedelta for time calculations
# üß† ML Signal: Use of np.random.choice indicates random sampling, which is a common pattern in data generation


# ‚úÖ Best Practice: Use of pd.Timedelta for time calculations
# ‚úÖ Best Practice: Asserting conditions in tests to validate behavior
# üß† ML Signal: Random choice of sample minutes suggests variability in generated data
# ‚úÖ Best Practice: Use of pd.Timestamp for datetime creation is clear and concise
# ‚ö†Ô∏è SAST Risk (Low): Potential risk if minute_index is out of expected range
# üß† ML Signal: Test method that checks time elapsed, useful for performance testing patterns
class TimeUtils(TestCase):
    @classmethod
    def setUpClass(cls):
        init()

    def test_cal_sam_minute(self):
        # test the correctness of the code
        random_n = 1000
        regions = [REG_CN, REG_US, REG_TW]

        def gen_args(cal: List):
            # ‚úÖ Best Practice: Cleaning up resources after each test
            for time in np.random.choice(cal, size=random_n, replace=True):
                # ‚úÖ Best Practice: Cleaning up class-level resources after all tests
                sam_minutes = np.random.choice([1, 2, 3, 4, 5, 6])
                dt = pd.Timestamp(
                    datetime(
                        # üß† ML Signal: Yielding arguments is a pattern for generator functions
                        2021,
                        month=3,
                        day=3,
                        # üß† ML Signal: Iterating over regions suggests a pattern of processing data by geographical or logical segments
                        hour=time.hour,
                        minute=time.minute,
                        second=time.second,
                        # ‚ö†Ô∏è SAST Risk (Low): Use of assert for runtime checks can be disabled in optimized mode
                        microsecond=time.microsecond,
                    )
                # ‚úÖ Best Practice: Converting generator to list for repeated iteration improves readability
                )
                # ‚úÖ Best Practice: Use of classmethod for methods that operate on the class itself rather than instances
                args = dt, sam_minutes
                yield args
        # ‚úÖ Best Practice: Use of setUpClass for initializing resources for test cases

        # üß† ML Signal: Function call within a loop indicates repeated operations on data
        for region in regions:
            # ‚ö†Ô∏è SAST Risk (Medium): Calling an undefined function 'init' could lead to runtime errors if 'init' is not imported or defined elsewhere
            cal_time = get_min_cal(region=region)
            for args in gen_args(cal_time):
                # üß† ML Signal: Use of financial time series data pattern in labels
                assert cal_sam_minute(*args, region) == cal_sam_minute_new(*args, region=region)
            # üß† ML Signal: Function call within a loop indicates repeated operations on data
            # üß† ML Signal: Test methods often indicate expected behavior and usage patterns

            # ‚úÖ Best Practice: Use of assert statements for testing expected outcomes
            # test the performance of the code
            # ‚ö†Ô∏è SAST Risk (Low): Directly appending to a list without validation can lead to unexpected data types
            args_l = list(gen_args(cal_time))

            # ‚úÖ Best Practice: Incrementing an index variable to track the number of elements
            # üß† ML Signal: Use of financial time series data pattern in labels
            with TimeInspector.logt():
                for args in args_l:
                    # ‚úÖ Best Practice: Use of assert statements for testing expected outcomes
                    cal_sam_minute(*args, region=region)
            # üß† ML Signal: Test methods often indicate expected behavior and usage patterns

            # ‚ö†Ô∏è SAST Risk (Low): Popping from a list without checking if it's empty can raise an IndexError
            # ‚úÖ Best Practice: Decrementing an index variable to track the number of elements
            # üß† ML Signal: Test methods often indicate expected behavior and usage patterns
            # ‚úÖ Best Practice: Using clear() to remove all items from a list is more efficient than removing items one by one
            # ‚úÖ Best Practice: Resetting the index to 0 after clearing the list
            # üß† ML Signal: Use of financial time series data pattern in labels
            # ‚úÖ Best Practice: Use of assert statements for testing expected outcomes
            # ‚úÖ Best Practice: Standard way to run unit tests in Python
            with TimeInspector.logt():
                for args in args_l:
                    cal_sam_minute_new(*args, region=region)


class DataUtils(TestCase):
    @classmethod
    def setUpClass(cls):
        init()

    def test_guess_horizon(self):
        label = ["Ref($close, -2) / Ref($close, -1) - 1"]
        result = guess_horizon(label)
        assert result == 2

        label = ["Ref($close, -5) / Ref($close, -1) - 1"]
        result = guess_horizon(label)
        assert result == 5

        label = ["Ref($close, -1) / Ref($close, -1) - 1"]
        result = guess_horizon(label)
        assert result == 1


if __name__ == "__main__":
    unittest.main()