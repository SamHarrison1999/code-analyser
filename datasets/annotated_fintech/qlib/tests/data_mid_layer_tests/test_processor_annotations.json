[
  {
    "line": 6,
    "text": "from qlib.data import D",
    "annotation": "\ud83e\udde0 ML Signal: Importing specific normalization processors indicates usage of data preprocessing techniques common in ML workflows",
    "confidence": 1.0,
    "tokens": [
      6738,
      10662,
      8019,
      13,
      7890,
      1330,
      360
    ],
    "start_token": 0,
    "end_token": 7,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      17267,
      278,
      2176,
      3487,
      1634,
      20399,
      9217,
      8748,
      286,
      1366,
      662,
      36948,
      7605,
      2219,
      287,
      10373,
      670,
      44041
    ],
    "label": "ml_signal",
    "reason": "Importing specific normalization processors indicates usage of data preprocessing techniques common in ML workflows"
  },
  {
    "line": 6,
    "text": "from qlib.data import D",
    "annotation": "\u2705 Best Practice: Class should have a docstring explaining its purpose and usage",
    "confidence": 1.0,
    "tokens": [
      6738,
      10662,
      8019,
      13,
      7890,
      1330,
      360
    ],
    "start_token": 7,
    "end_token": 14,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5016,
      815,
      423,
      257,
      2205,
      8841,
      11170,
      663,
      4007,
      290,
      8748
    ],
    "label": "best_practice",
    "reason": "Class should have a docstring explaining its purpose and usage"
  },
  {
    "line": 8,
    "text": "from qlib.data.dataset.processor import MinMaxNorm, ZScoreNorm, CSZScoreNorm, CSZFillna",
    "annotation": "\u2705 Best Practice: Class variables should have a comment or docstring explaining their purpose",
    "confidence": 1.0,
    "tokens": [
      6738,
      10662,
      8019,
      13,
      7890,
      13,
      19608,
      292,
      316,
      13,
      41341,
      1330,
      1855,
      11518,
      35393,
      11,
      1168,
      26595,
      35393,
      11,
      9429,
      57,
      26595,
      35393,
      11,
      9429,
      57,
      33762,
      2616
    ],
    "start_token": 14,
    "end_token": 43,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5016,
      9633,
      815,
      423,
      257,
      2912,
      393,
      2205,
      8841,
      11170,
      511,
      4007
    ],
    "label": "best_practice",
    "reason": "Class variables should have a comment or docstring explaining their purpose"
  },
  {
    "line": 10,
    "text": "",
    "annotation": "\u2705 Best Practice: Use of numpy functions for efficient min/max calculations",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 43,
    "end_token": 43,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      299,
      32152,
      5499,
      329,
      6942,
      949,
      14,
      9806,
      16765
    ],
    "label": "best_practice",
    "reason": "Use of numpy functions for efficient min/max calculations"
  },
  {
    "line": 13,
    "text": "",
    "annotation": "\u2705 Best Practice: Handling edge cases where min and max are equal",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 43,
    "end_token": 43,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      49500,
      5743,
      2663,
      810,
      949,
      290,
      3509,
      389,
      4961
    ],
    "label": "best_practice",
    "reason": "Handling edge cases where min and max are equal"
  },
  {
    "line": 17,
    "text": "            max_val = np.nanmax(df.values, axis=0)",
    "annotation": "\u2705 Best Practice: Setting default values to avoid division by zero",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      3509,
      62,
      2100,
      796,
      45941,
      13,
      12647,
      9806,
      7,
      7568,
      13,
      27160,
      11,
      16488,
      28,
      15,
      8
    ],
    "start_token": 43,
    "end_token": 71,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      25700,
      4277,
      3815,
      284,
      3368,
      7297,
      416,
      6632
    ],
    "label": "best_practice",
    "reason": "Setting default values to avoid division by zero"
  },
  {
    "line": 20,
    "text": "                if _con:",
    "annotation": "\u2705 Best Practice: Vectorized operations for performance",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      611,
      4808,
      1102,
      25
    ],
    "start_token": 71,
    "end_token": 90,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      20650,
      1143,
      4560,
      329,
      2854
    ],
    "label": "best_practice",
    "reason": "Vectorized operations for performance"
  },
  {
    "line": 23,
    "text": "            df.loc(axis=1)[df.columns] = (df.values - min_val) / (max_val - min_val)",
    "annotation": "\ud83e\udde0 ML Signal: Use of feature selection and data slicing",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      47764,
      13,
      17946,
      7,
      22704,
      28,
      16,
      38381,
      7568,
      13,
      28665,
      82,
      60,
      796,
      357,
      7568,
      13,
      27160,
      532,
      949,
      62,
      2100,
      8,
      1220,
      357,
      9806,
      62,
      2100,
      532,
      949,
      62,
      2100,
      8
    ],
    "start_token": 90,
    "end_token": 134,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      3895,
      6356,
      290,
      1366,
      49289
    ],
    "label": "ml_signal",
    "reason": "Use of feature selection and data slicing"
  },
  {
    "line": 25,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Adding a constant feature to the dataset",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 134,
    "end_token": 134,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      18247,
      257,
      6937,
      3895,
      284,
      262,
      27039
    ],
    "label": "ml_signal",
    "reason": "Adding a constant feature to the dataset"
  },
  {
    "line": 27,
    "text": "        origin_df[\"test\"] = 0",
    "annotation": "\u2705 Best Practice: Creating a copy of the dataframe to avoid modifying the original",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      8159,
      62,
      7568,
      14692,
      9288,
      8973,
      796,
      657
    ],
    "start_token": 134,
    "end_token": 149,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      30481,
      257,
      4866,
      286,
      262,
      1366,
      14535,
      284,
      3368,
      30620,
      262,
      2656
    ],
    "label": "best_practice",
    "reason": "Creating a copy of the dataframe to avoid modifying the original"
  },
  {
    "line": 29,
    "text": "        mmn = MinMaxNorm(fields_group=None, fit_start_time=\"2021-05-31\", fit_end_time=\"2021-06-11\")",
    "annotation": "\ud83e\udde0 ML Signal: Initialization of a MinMaxNorm object with specific parameters",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      8085,
      77,
      796,
      1855,
      11518,
      35393,
      7,
      25747,
      62,
      8094,
      28,
      14202,
      11,
      4197,
      62,
      9688,
      62,
      2435,
      2625,
      1238,
      2481,
      12,
      2713,
      12,
      3132,
      1600,
      4197,
      62,
      437,
      62,
      2435,
      2625,
      1238,
      2481,
      12,
      3312,
      12,
      1157,
      4943
    ],
    "start_token": 149,
    "end_token": 195,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      20768,
      1634,
      286,
      257,
      1855,
      11518,
      35393,
      2134,
      351,
      2176,
      10007
    ],
    "label": "ml_signal",
    "reason": "Initialization of a MinMaxNorm object with specific parameters"
  },
  {
    "line": 31,
    "text": "        mmn.__call__(df)",
    "annotation": "\ud83e\udde0 ML Signal: Fitting a normalization model to the data",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      8085,
      77,
      13,
      834,
      13345,
      834,
      7,
      7568,
      8
    ],
    "start_token": 195,
    "end_token": 211,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      376,
      2535,
      257,
      3487,
      1634,
      2746,
      284,
      262,
      1366
    ],
    "label": "ml_signal",
    "reason": "Fitting a normalization model to the data"
  },
  {
    "line": 33,
    "text": "        assert (df == origin_df).all().all()",
    "annotation": "\ud83e\udde0 ML Signal: Applying the normalization model to the data",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      6818,
      357,
      7568,
      6624,
      8159,
      62,
      7568,
      737,
      439,
      22446,
      439,
      3419
    ],
    "start_token": 211,
    "end_token": 230,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      2034,
      3157,
      262,
      3487,
      1634,
      2746,
      284,
      262,
      1366
    ],
    "label": "ml_signal",
    "reason": "Applying the normalization model to the data"
  },
  {
    "line": 35,
    "text": "    def test_ZScoreNorm(self):",
    "annotation": "\ud83e\udde0 ML Signal: Normalizing the original dataframe",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      825,
      1332,
      62,
      57,
      26595,
      35393,
      7,
      944,
      2599
    ],
    "start_token": 230,
    "end_token": 242,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      14435,
      2890,
      262,
      2656,
      1366,
      14535
    ],
    "label": "ml_signal",
    "reason": "Normalizing the original dataframe"
  },
  {
    "line": 37,
    "text": "            mean_train = np.nanmean(df.values, axis=0)",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential for false positives if dataframes are not identical",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1612,
      62,
      27432,
      796,
      45941,
      13,
      12647,
      32604,
      7,
      7568,
      13,
      27160,
      11,
      16488,
      28,
      15,
      8
    ],
    "start_token": 242,
    "end_token": 270,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      329,
      3991,
      38548,
      611,
      1366,
      37805,
      389,
      407,
      10411
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential for false positives if dataframes are not identical"
  },
  {
    "line": 29,
    "text": "        mmn = MinMaxNorm(fields_group=None, fit_start_time=\"2021-05-31\", fit_end_time=\"2021-06-11\")",
    "annotation": "\ud83e\udde0 ML Signal: Normalization is a common preprocessing step in ML pipelines",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      8085,
      77,
      796,
      1855,
      11518,
      35393,
      7,
      25747,
      62,
      8094,
      28,
      14202,
      11,
      4197,
      62,
      9688,
      62,
      2435,
      2625,
      1238,
      2481,
      12,
      2713,
      12,
      3132,
      1600,
      4197,
      62,
      437,
      62,
      2435,
      2625,
      1238,
      2481,
      12,
      3312,
      12,
      1157,
      4943
    ],
    "start_token": 270,
    "end_token": 316,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      14435,
      1634,
      318,
      257,
      2219,
      662,
      36948,
      2239,
      287,
      10373,
      31108
    ],
    "label": "ml_signal",
    "reason": "Normalization is a common preprocessing step in ML pipelines"
  },
  {
    "line": 32,
    "text": "        origin_df = normalize(origin_df)",
    "annotation": "\u2705 Best Practice: Handle division by zero by setting std to 1 where std is 0",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      8159,
      62,
      7568,
      796,
      3487,
      1096,
      7,
      47103,
      62,
      7568,
      8
    ],
    "start_token": 316,
    "end_token": 334,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      33141,
      7297,
      416,
      6632,
      416,
      4634,
      14367,
      284,
      352,
      810,
      14367,
      318,
      657
    ],
    "label": "best_practice",
    "reason": "Handle division by zero by setting std to 1 where std is 0"
  },
  {
    "line": 38,
    "text": "            std_train = np.nanstd(df.values, axis=0)",
    "annotation": "\u2705 Best Practice: Use of vectorized operations for performance",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      14367,
      62,
      27432,
      796,
      45941,
      13,
      12647,
      19282,
      7,
      7568,
      13,
      27160,
      11,
      16488,
      28,
      15,
      8
    ],
    "start_token": 334,
    "end_token": 362,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      15879,
      1143,
      4560,
      329,
      2854
    ],
    "label": "best_practice",
    "reason": "Use of vectorized operations for performance"
  },
  {
    "line": 41,
    "text": "                if _con:",
    "annotation": "\ud83e\udde0 ML Signal: Feature selection and data slicing for model input",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      611,
      4808,
      1102,
      25
    ],
    "start_token": 362,
    "end_token": 381,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      27018,
      6356,
      290,
      1366,
      49289,
      329,
      2746,
      5128
    ],
    "label": "ml_signal",
    "reason": "Feature selection and data slicing for model input"
  },
  {
    "line": 43,
    "text": "                    mean_train[_i] = 0",
    "annotation": "\ud83e\udde0 ML Signal: Adding a new feature/column to the dataset",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1612,
      62,
      27432,
      29795,
      72,
      60,
      796,
      657
    ],
    "start_token": 381,
    "end_token": 408,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      18247,
      257,
      649,
      3895,
      14,
      28665,
      284,
      262,
      27039
    ],
    "label": "ml_signal",
    "reason": "Adding a new feature/column to the dataset"
  },
  {
    "line": 45,
    "text": "            return df",
    "annotation": "\u2705 Best Practice: Use of copy to avoid modifying the original dataframe",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1441,
      47764
    ],
    "start_token": 408,
    "end_token": 421,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      4866,
      284,
      3368,
      30620,
      262,
      2656,
      1366,
      14535
    ],
    "label": "best_practice",
    "reason": "Use of copy to avoid modifying the original dataframe"
  },
  {
    "line": 47,
    "text": "        origin_df = D.features([self.TEST_INST], [\"$high\", \"$open\", \"$low\", \"$close\"]).tail(10)",
    "annotation": "\ud83e\udde0 ML Signal: Instantiation of a normalization object, common in ML workflows",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      8159,
      62,
      7568,
      796,
      360,
      13,
      40890,
      26933,
      944,
      13,
      51,
      6465,
      62,
      38604,
      4357,
      14631,
      3,
      8929,
      1600,
      17971,
      9654,
      1600,
      17971,
      9319,
      1600,
      17971,
      19836,
      8973,
      737,
      13199,
      7,
      940,
      8
    ],
    "start_token": 421,
    "end_token": 461,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      24470,
      3920,
      286,
      257,
      3487,
      1634,
      2134,
      11,
      2219,
      287,
      10373,
      670,
      44041
    ],
    "label": "ml_signal",
    "reason": "Instantiation of a normalization object, common in ML workflows"
  },
  {
    "line": 49,
    "text": "        df = origin_df.copy()",
    "annotation": "\ud83e\udde0 ML Signal: Fitting a model or transformation to the data",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      47764,
      796,
      8159,
      62,
      7568,
      13,
      30073,
      3419
    ],
    "start_token": 461,
    "end_token": 476,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      376,
      2535,
      257,
      2746,
      393,
      13389,
      284,
      262,
      1366
    ],
    "label": "ml_signal",
    "reason": "Fitting a model or transformation to the data"
  },
  {
    "line": 51,
    "text": "        zsn.fit(df)",
    "annotation": "\ud83e\udde0 ML Signal: Applying a transformation or model to the data",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1976,
      16184,
      13,
      11147,
      7,
      7568,
      8
    ],
    "start_token": 476,
    "end_token": 490,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      2034,
      3157,
      257,
      13389,
      393,
      2746,
      284,
      262,
      1366
    ],
    "label": "ml_signal",
    "reason": "Applying a transformation or model to the data"
  },
  {
    "line": 53,
    "text": "        origin_df = normalize(origin_df)",
    "annotation": "\ud83e\udde0 ML Signal: Reapplying normalization to compare results",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      8159,
      62,
      7568,
      796,
      3487,
      1096,
      7,
      47103,
      62,
      7568,
      8
    ],
    "start_token": 490,
    "end_token": 508,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      797,
      1324,
      3157,
      3487,
      1634,
      284,
      8996,
      2482
    ],
    "label": "ml_signal",
    "reason": "Reapplying normalization to compare results"
  },
  {
    "line": 55,
    "text": "",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential for false positives if dataframes are not identical",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 508,
    "end_token": 508,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      329,
      3991,
      38548,
      611,
      1366,
      37805,
      389,
      407,
      10411
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential for false positives if dataframes are not identical"
  },
  {
    "line": 46,
    "text": "",
    "annotation": "\u2705 Best Practice: Method names should follow snake_case convention for consistency and readability.",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 508,
    "end_token": 508,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      11789,
      3891,
      815,
      1061,
      17522,
      62,
      7442,
      9831,
      329,
      15794,
      290,
      1100,
      1799,
      13
    ],
    "label": "best_practice",
    "reason": "Method names should follow snake_case convention for consistency and readability."
  },
  {
    "line": 48,
    "text": "        origin_df[\"test\"] = 0",
    "annotation": "\ud83e\udde0 ML Signal: Usage of a specific market \"csi300\" could indicate a focus on a particular dataset or domain.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      8159,
      62,
      7568,
      14692,
      9288,
      8973,
      796,
      657
    ],
    "start_token": 508,
    "end_token": 523,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      29566,
      286,
      257,
      2176,
      1910,
      366,
      6359,
      72,
      6200,
      1,
      714,
      7603,
      257,
      2962,
      319,
      257,
      1948,
      27039,
      393,
      7386,
      13
    ],
    "label": "ml_signal",
    "reason": "Usage of a specific market \"csi300\" could indicate a focus on a particular dataset or domain."
  },
  {
    "line": 50,
    "text": "        zsn = ZScoreNorm(fields_group=None, fit_start_time=\"2021-05-31\", fit_end_time=\"2021-06-11\")",
    "annotation": "\ud83e\udde0 ML Signal: Grouping and slicing data in this manner may indicate a pattern of data preprocessing.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1976,
      16184,
      796,
      1168,
      26595,
      35393,
      7,
      25747,
      62,
      8094,
      28,
      14202,
      11,
      4197,
      62,
      9688,
      62,
      2435,
      2625,
      1238,
      2481,
      12,
      2713,
      12,
      3132,
      1600,
      4197,
      62,
      437,
      62,
      2435,
      2625,
      1238,
      2481,
      12,
      3312,
      12,
      1157,
      4943
    ],
    "start_token": 523,
    "end_token": 569,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      4912,
      278,
      290,
      49289,
      1366,
      287,
      428,
      5642,
      743,
      7603,
      257,
      3912,
      286,
      1366,
      662,
      36948,
      13
    ],
    "label": "ml_signal",
    "reason": "Grouping and slicing data in this manner may indicate a pattern of data preprocessing."
  },
  {
    "line": 52,
    "text": "        zsn.__call__(df)",
    "annotation": "\u2705 Best Practice: Use of .copy() to avoid modifying the original DataFrame.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1976,
      16184,
      13,
      834,
      13345,
      834,
      7,
      7568,
      8
    ],
    "start_token": 569,
    "end_token": 585,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      764,
      30073,
      3419,
      284,
      3368,
      30620,
      262,
      2656,
      6060,
      19778,
      13
    ],
    "label": "best_practice",
    "reason": "Use of .copy() to avoid modifying the original DataFrame."
  },
  {
    "line": 54,
    "text": "        assert (df == origin_df).all().all()",
    "annotation": "\ud83e\udde0 ML Signal: Invocation of CSZFillna suggests a pattern of handling missing data.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      6818,
      357,
      7568,
      6624,
      8159,
      62,
      7568,
      737,
      439,
      22446,
      439,
      3419
    ],
    "start_token": 585,
    "end_token": 604,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      10001,
      5040,
      286,
      9429,
      57,
      33762,
      2616,
      5644,
      257,
      3912,
      286,
      9041,
      4814,
      1366,
      13
    ],
    "label": "ml_signal",
    "reason": "Invocation of CSZFillna suggests a pattern of handling missing data."
  },
  {
    "line": 56,
    "text": "    def test_CSZFillna(self):",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Use of bitwise negation operator `~` on boolean result; consider using `not` for clarity.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      825,
      1332,
      62,
      7902,
      57,
      33762,
      2616,
      7,
      944,
      2599
    ],
    "start_token": 604,
    "end_token": 617,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      5765,
      286,
      1643,
      3083,
      2469,
      341,
      10088,
      4600,
      93,
      63,
      319,
      25131,
      1255,
      26,
      2074,
      1262,
      4600,
      1662,
      63,
      329,
      16287,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Use of bitwise negation operator `~` on boolean result; consider using `not` for clarity."
  },
  {
    "line": 53,
    "text": "        origin_df = normalize(origin_df)",
    "annotation": "\ud83e\udde0 ML Signal: Usage of a specific market \"csi300\" could indicate a focus on a particular dataset or domain.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      8159,
      62,
      7568,
      796,
      3487,
      1096,
      7,
      47103,
      62,
      7568,
      8
    ],
    "start_token": 617,
    "end_token": 635,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      29566,
      286,
      257,
      2176,
      1910,
      366,
      6359,
      72,
      6200,
      1,
      714,
      7603,
      257,
      2962,
      319,
      257,
      1948,
      27039,
      393,
      7386,
      13
    ],
    "label": "ml_signal",
    "reason": "Usage of a specific market \"csi300\" could indicate a focus on a particular dataset or domain."
  },
  {
    "line": 55,
    "text": "",
    "annotation": "\u2705 Best Practice: Using groupby with group_keys=False for cleaner DataFrame operations.",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 635,
    "end_token": 635,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      8554,
      1448,
      1525,
      351,
      1448,
      62,
      13083,
      28,
      25101,
      329,
      21723,
      6060,
      19778,
      4560,
      13
    ],
    "label": "best_practice",
    "reason": "Using groupby with group_keys=False for cleaner DataFrame operations."
  },
  {
    "line": 57,
    "text": "        origin_df = D.features(D.instruments(market=\"csi300\"), fields=[\"$high\", \"$open\", \"$low\", \"$close\"])",
    "annotation": "\u2705 Best Practice: Copying DataFrame to avoid modifying the original data.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      8159,
      62,
      7568,
      796,
      360,
      13,
      40890,
      7,
      35,
      13,
      259,
      2536,
      2886,
      7,
      10728,
      2625,
      6359,
      72,
      6200,
      12340,
      7032,
      28,
      14692,
      3,
      8929,
      1600,
      17971,
      9654,
      1600,
      17971,
      9319,
      1600,
      17971,
      19836,
      8973,
      8
    ],
    "start_token": 635,
    "end_token": 678,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      6955,
      1112,
      6060,
      19778,
      284,
      3368,
      30620,
      262,
      2656,
      1366,
      13
    ],
    "label": "best_practice",
    "reason": "Copying DataFrame to avoid modifying the original data."
  },
  {
    "line": 59,
    "text": "        df = origin_df.copy()",
    "annotation": "\ud83e\udde0 ML Signal: Invocation of CSZScoreNorm suggests a normalization or preprocessing step.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      47764,
      796,
      8159,
      62,
      7568,
      13,
      30073,
      3419
    ],
    "start_token": 678,
    "end_token": 693,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      10001,
      5040,
      286,
      9429,
      57,
      26595,
      35393,
      5644,
      257,
      3487,
      1634,
      393,
      662,
      36948,
      2239,
      13
    ],
    "label": "ml_signal",
    "reason": "Invocation of CSZScoreNorm suggests a normalization or preprocessing step."
  },
  {
    "line": 59,
    "text": "        df = origin_df.copy()",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Direct comparison of floating-point numbers can lead to precision issues.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      47764,
      796,
      8159,
      62,
      7568,
      13,
      30073,
      3419
    ],
    "start_token": 693,
    "end_token": 708,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      4128,
      7208,
      286,
      12462,
      12,
      4122,
      3146,
      460,
      1085,
      284,
      15440,
      2428,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Direct comparison of floating-point numbers can lead to precision issues."
  },
  {
    "line": 59,
    "text": "        df = origin_df.copy()",
    "annotation": "\u2705 Best Practice: Standard way to execute tests in Python.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      47764,
      796,
      8159,
      62,
      7568,
      13,
      30073,
      3419
    ],
    "start_token": 708,
    "end_token": 723,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      8997,
      835,
      284,
      12260,
      5254,
      287,
      11361,
      13
    ],
    "label": "best_practice",
    "reason": "Standard way to execute tests in Python."
  }
]