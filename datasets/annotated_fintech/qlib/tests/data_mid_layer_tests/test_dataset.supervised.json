[
  {
    "line": 4,
    "text": "import unittest",
    "annotation": "\ud83e\udde0 ML Signal: Importing specific test classes and modules indicates a pattern of testing practices",
    "confidence": 1.0,
    "tokens": [
      11748,
      555,
      715,
      395
    ],
    "start_token": 0,
    "end_token": 4,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      17267,
      278,
      2176,
      1332,
      6097,
      290,
      13103,
      9217,
      257,
      3912,
      286,
      4856,
      6593
    ],
    "label": "ml_signal",
    "reason": "Importing specific test classes and modules indicates a pattern of testing practices"
  },
  {
    "line": 6,
    "text": "import sys",
    "annotation": "\ud83e\udde0 ML Signal: Importing specific classes from a module indicates usage patterns of the library",
    "confidence": 0.5,
    "tokens": [
      11748,
      25064
    ],
    "start_token": 4,
    "end_token": 6,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      17267,
      278,
      2176,
      6097,
      422,
      257,
      8265,
      9217,
      8748,
      7572,
      286,
      262,
      5888
    ],
    "label": "ml_signal",
    "reason": "Importing specific classes from a module indicates usage patterns of the library"
  },
  {
    "line": 10,
    "text": "import pandas as pd",
    "annotation": "\ud83e\udde0 ML Signal: Importing specific classes from a module indicates usage patterns of the library",
    "confidence": 0.5,
    "tokens": [
      11748,
      19798,
      292,
      355,
      279,
      67
    ],
    "start_token": 6,
    "end_token": 12,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      17267,
      278,
      2176,
      6097,
      422,
      257,
      8265,
      9217,
      8748,
      7572,
      286,
      262,
      5888
    ],
    "label": "ml_signal",
    "reason": "Importing specific classes from a module indicates usage patterns of the library"
  },
  {
    "line": 10,
    "text": "import pandas as pd",
    "annotation": "\ud83e\udde0 ML Signal: Use of pytest for testing indicates a pattern for test automation",
    "confidence": 1.0,
    "tokens": [
      11748,
      19798,
      292,
      355,
      279,
      67
    ],
    "start_token": 12,
    "end_token": 18,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      12972,
      9288,
      329,
      4856,
      9217,
      257,
      3912,
      329,
      1332,
      22771
    ],
    "label": "ml_signal",
    "reason": "Use of pytest for testing indicates a pattern for test automation"
  },
  {
    "line": 45,
    "text": "        tsds_train = tsdh.prepare(\"train\", data_key=DataHandlerLP.DK_L)  # Test the correctness",
    "annotation": "\ud83e\udde0 ML Signal: Timing performance of data access",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      40379,
      9310,
      62,
      27432,
      796,
      256,
      21282,
      71,
      13,
      46012,
      533,
      7203,
      27432,
      1600,
      1366,
      62,
      2539,
      28,
      6601,
      25060,
      19930,
      13,
      48510,
      62,
      43,
      8,
      220,
      1303,
      6208,
      262,
      29409
    ],
    "start_token": 18,
    "end_token": 56,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5045,
      278,
      2854,
      286,
      1366,
      1895
    ],
    "label": "ml_signal",
    "reason": "Timing performance of data access"
  },
  {
    "line": 50,
    "text": "            _ = tsds_train[idx]",
    "annotation": "\ud83e\udde0 ML Signal: Checking shape of data batch",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      4808,
      796,
      40379,
      9310,
      62,
      27432,
      58,
      312,
      87,
      60
    ],
    "start_token": 56,
    "end_token": 77,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      39432,
      5485,
      286,
      1366,
      15458
    ],
    "label": "ml_signal",
    "reason": "Checking shape of data batch"
  },
  {
    "line": 52,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Timing performance of batch data access",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 77,
    "end_token": 77,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5045,
      278,
      2854,
      286,
      15458,
      1366,
      1895
    ],
    "label": "ml_signal",
    "reason": "Timing performance of batch data access"
  },
  {
    "line": 63,
    "text": "        # 1) sample by int index directly",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential floating-point comparison issue",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1303,
      352,
      8,
      6291,
      416,
      493,
      6376,
      3264
    ],
    "start_token": 77,
    "end_token": 92,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      12462,
      12,
      4122,
      7208,
      2071
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential floating-point comparison issue"
  },
  {
    "line": 77,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Checking shape of data in DataLoader",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 92,
    "end_token": 92,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      39432,
      5485,
      286,
      1366,
      287,
      6060,
      17401
    ],
    "label": "ml_signal",
    "reason": "Checking shape of data in DataLoader"
  },
  {
    "line": 80,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Accessing index information",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 92,
    "end_token": 92,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      8798,
      278,
      6376,
      1321
    ],
    "label": "ml_signal",
    "reason": "Accessing index information"
  },
  {
    "line": 76,
    "text": "        )",
    "annotation": "\u2705 Best Practice: Class name should follow CamelCase naming convention",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1267
    ],
    "start_token": 92,
    "end_token": 100,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5016,
      1438,
      815,
      1061,
      43281,
      20448,
      19264,
      9831
    ],
    "label": "best_practice",
    "reason": "Class name should follow CamelCase naming convention"
  },
  {
    "line": 85,
    "text": "            from qlib.model.utils import IndexSampler",
    "annotation": "\u2705 Best Practice: Use of numpy to generate random data for testing",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      422,
      10662,
      8019,
      13,
      19849,
      13,
      26791,
      1330,
      12901,
      16305,
      20053
    ],
    "start_token": 100,
    "end_token": 122,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      299,
      32152,
      284,
      7716,
      4738,
      1366,
      329,
      4856
    ],
    "label": "best_practice",
    "reason": "Use of numpy to generate random data for testing"
  },
  {
    "line": 87,
    "text": "            i = len(tsds) - 1",
    "annotation": "\u2705 Best Practice: Creating a DataFrame with a MultiIndex for structured data",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1312,
      796,
      18896,
      7,
      912,
      9310,
      8,
      532,
      352
    ],
    "start_token": 122,
    "end_token": 142,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      30481,
      257,
      6060,
      19778,
      351,
      257,
      15237,
      15732,
      329,
      20793,
      1366
    ],
    "label": "best_practice",
    "reason": "Creating a DataFrame with a MultiIndex for structured data"
  },
  {
    "line": 89,
    "text": "            tsds[i]",
    "annotation": "\ud83e\udde0 ML Signal: Usage of a custom data sampler class for time series data",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      40379,
      9310,
      58,
      72,
      60
    ],
    "start_token": 142,
    "end_token": 158,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      29566,
      286,
      257,
      2183,
      1366,
      6072,
      20053,
      1398,
      329,
      640,
      2168,
      1366
    ],
    "label": "ml_signal",
    "reason": "Usage of a custom data sampler class for time series data"
  },
  {
    "line": 93,
    "text": "            test_loader = DataLoader(s_w_i)",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Printing dataset contents may expose sensitive data",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1332,
      62,
      29356,
      796,
      6060,
      17401,
      7,
      82,
      62,
      86,
      62,
      72,
      8
    ],
    "start_token": 158,
    "end_token": 182,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      44118,
      27039,
      10154,
      743,
      15651,
      8564,
      1366
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Printing dataset contents may expose sensitive data"
  },
  {
    "line": 96,
    "text": "            for data, i in test_loader:",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Printing dataset contents may expose sensitive data",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      329,
      1366,
      11,
      1312,
      287,
      1332,
      62,
      29356,
      25
    ],
    "start_token": 182,
    "end_token": 202,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      44118,
      27039,
      10154,
      743,
      15651,
      8564,
      1366
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Printing dataset contents may expose sensitive data"
  },
  {
    "line": 98,
    "text": "            print(data.shape)",
    "annotation": "\u2705 Best Practice: Assertions to verify the length and content of the dataset",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      3601,
      7,
      7890,
      13,
      43358,
      8
    ],
    "start_token": 202,
    "end_token": 219,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      2195,
      861,
      507,
      284,
      11767,
      262,
      4129,
      290,
      2695,
      286,
      262,
      27039
    ],
    "label": "best_practice",
    "reason": "Assertions to verify the length and content of the dataset"
  },
  {
    "line": 99,
    "text": "            print(idx[i])",
    "annotation": "\u2705 Best Practice: Use of numpy functions for numerical checks",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      3601,
      7,
      312,
      87,
      58,
      72,
      12962
    ],
    "start_token": 219,
    "end_token": 237,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      299,
      32152,
      5499,
      329,
      29052,
      8794
    ],
    "label": "best_practice",
    "reason": "Use of numpy functions for numerical checks"
  },
  {
    "line": 102,
    "text": "class TestTSDataSampler(unittest.TestCase):",
    "annotation": "\u2705 Best Practice: Assertions to ensure dataset consistency",
    "confidence": 1.0,
    "tokens": [
      4871,
      6208,
      4694,
      6601,
      16305,
      20053,
      7,
      403,
      715,
      395,
      13,
      14402,
      20448,
      2599
    ],
    "start_token": 237,
    "end_token": 251,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      2195,
      861,
      507,
      284,
      4155,
      27039,
      15794
    ],
    "label": "best_practice",
    "reason": "Assertions to ensure dataset consistency"
  },
  {
    "line": 107,
    "text": "        datetime_list = [\"2000-01-31\", \"2000-02-29\", \"2000-03-31\", \"2000-04-30\", \"2000-05-31\"]",
    "annotation": "\ud83e\udde0 ML Signal: Use of random data generation",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      4818,
      8079,
      62,
      4868,
      796,
      14631,
      11024,
      12,
      486,
      12,
      3132,
      1600,
      366,
      11024,
      12,
      2999,
      12,
      1959,
      1600,
      366,
      11024,
      12,
      3070,
      12,
      3132,
      1600,
      366,
      11024,
      12,
      3023,
      12,
      1270,
      1600,
      366,
      11024,
      12,
      2713,
      12,
      3132,
      8973
    ],
    "start_token": 251,
    "end_token": 298,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      4738,
      1366,
      5270
    ],
    "label": "ml_signal",
    "reason": "Use of random data generation"
  },
  {
    "line": 110,
    "text": "            [pd.to_datetime(datetime_list), instruments], names=[\"datetime\", \"instrument\"]",
    "annotation": "\ud83e\udde0 ML Signal: Use of custom class TSDataSampler",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      685,
      30094,
      13,
      1462,
      62,
      19608,
      8079,
      7,
      19608,
      8079,
      62,
      4868,
      828,
      12834,
      4357,
      3891,
      28,
      14692,
      19608,
      8079,
      1600,
      366,
      259,
      43872,
      8973
    ],
    "start_token": 298,
    "end_token": 334,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      2183,
      1398,
      26136,
      6601,
      16305,
      20053
    ],
    "label": "ml_signal",
    "reason": "Use of custom class TSDataSampler"
  },
  {
    "line": 114,
    "text": "        dataset = TSDataSampler(test_df, datetime_list[0], datetime_list[-1], step_len=2)",
    "annotation": "\ud83e\udde0 ML Signal: Printing dataset for debugging",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      27039,
      796,
      26136,
      6601,
      16305,
      20053,
      7,
      9288,
      62,
      7568,
      11,
      4818,
      8079,
      62,
      4868,
      58,
      15,
      4357,
      4818,
      8079,
      62,
      4868,
      58,
      12,
      16,
      4357,
      2239,
      62,
      11925,
      28,
      17,
      8
    ],
    "start_token": 334,
    "end_token": 373,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      44118,
      27039,
      329,
      28769
    ],
    "label": "ml_signal",
    "reason": "Printing dataset for debugging"
  },
  {
    "line": 117,
    "text": "        print(dataset[0])",
    "annotation": "\ud83e\udde0 ML Signal: Printing dataset for debugging",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      3601,
      7,
      19608,
      292,
      316,
      58,
      15,
      12962
    ],
    "start_token": 373,
    "end_token": 388,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      44118,
      27039,
      329,
      28769
    ],
    "label": "ml_signal",
    "reason": "Printing dataset for debugging"
  },
  {
    "line": 120,
    "text": "        assert len(dataset[0]) == 2",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential for IndexError if dataset[i] is out of bounds",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      6818,
      18896,
      7,
      19608,
      292,
      316,
      58,
      15,
      12962,
      6624,
      362
    ],
    "start_token": 388,
    "end_token": 406,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      329,
      12901,
      12331,
      611,
      27039,
      58,
      72,
      60,
      318,
      503,
      286,
      22303
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential for IndexError if dataset[i] is out of bounds"
  },
  {
    "line": 121,
    "text": "        self.assertTrue(np.isnan(dataset[0][0]))",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential for IndexError if dataset[i] is out of bounds",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      30493,
      17821,
      7,
      37659,
      13,
      271,
      12647,
      7,
      19608,
      292,
      316,
      58,
      15,
      7131,
      15,
      60,
      4008
    ],
    "start_token": 406,
    "end_token": 432,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      329,
      12901,
      12331,
      611,
      27039,
      58,
      72,
      60,
      318,
      503,
      286,
      22303
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential for IndexError if dataset[i] is out of bounds"
  },
  {
    "line": 121,
    "text": "        self.assertTrue(np.isnan(dataset[0][0]))",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential for IndexError if dataset[0][1] or dataset[1][0] is out of bounds",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      30493,
      17821,
      7,
      37659,
      13,
      271,
      12647,
      7,
      19608,
      292,
      316,
      58,
      15,
      7131,
      15,
      60,
      4008
    ],
    "start_token": 432,
    "end_token": 458,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      329,
      12901,
      12331,
      611,
      27039,
      58,
      15,
      7131,
      16,
      60,
      393,
      27039,
      58,
      16,
      7131,
      15,
      60,
      318,
      503,
      286,
      22303
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential for IndexError if dataset[0][1] or dataset[1][0] is out of bounds"
  },
  {
    "line": 121,
    "text": "        self.assertTrue(np.isnan(dataset[0][0]))",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential for IndexError if dataset[0][2] or dataset[1][1] is out of bounds",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      30493,
      17821,
      7,
      37659,
      13,
      271,
      12647,
      7,
      19608,
      292,
      316,
      58,
      15,
      7131,
      15,
      60,
      4008
    ],
    "start_token": 458,
    "end_token": 484,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      329,
      12901,
      12331,
      611,
      27039,
      58,
      15,
      7131,
      17,
      60,
      393,
      27039,
      58,
      16,
      7131,
      16,
      60,
      318,
      503,
      286,
      22303
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential for IndexError if dataset[0][2] or dataset[1][1] is out of bounds"
  },
  {
    "line": 121,
    "text": "        self.assertTrue(np.isnan(dataset[0][0]))",
    "annotation": "\u2705 Best Practice: Use of __name__ guard for script execution",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      30493,
      17821,
      7,
      37659,
      13,
      271,
      12647,
      7,
      19608,
      292,
      316,
      58,
      15,
      7131,
      15,
      60,
      4008
    ],
    "start_token": 484,
    "end_token": 510,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      11593,
      3672,
      834,
      4860,
      329,
      4226,
      9706
    ],
    "label": "best_practice",
    "reason": "Use of __name__ guard for script execution"
  },
  {
    "line": 121,
    "text": "        self.assertTrue(np.isnan(dataset[0][0]))",
    "annotation": "\u2705 Best Practice: Use of high verbosity level for detailed test output",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      30493,
      17821,
      7,
      37659,
      13,
      271,
      12647,
      7,
      19608,
      292,
      316,
      58,
      15,
      7131,
      15,
      60,
      4008
    ],
    "start_token": 510,
    "end_token": 536,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      1029,
      15942,
      16579,
      1241,
      329,
      6496,
      1332,
      5072
    ],
    "label": "best_practice",
    "reason": "Use of high verbosity level for detailed test output"
  }
]