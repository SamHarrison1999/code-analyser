[
  {
    "line": 2,
    "text": "# Licensed under the MIT License.",
    "annotation": "\u2705 Best Practice: Ensures compatibility with future Python versions for type annotations",
    "confidence": 1.0,
    "tokens": [
      2,
      49962,
      739,
      262,
      17168,
      13789,
      13
    ],
    "start_token": 0,
    "end_token": 7,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      48221,
      942,
      17764,
      351,
      2003,
      11361,
      6300,
      329,
      2099,
      37647
    ],
    "label": "best_practice",
    "reason": "Ensures compatibility with future Python versions for type annotations"
  },
  {
    "line": 5,
    "text": "",
    "annotation": "\u2705 Best Practice: Explicit imports improve code readability and maintainability",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 7,
    "end_token": 7,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      11884,
      17944,
      2987,
      2438,
      1100,
      1799,
      290,
      5529,
      1799
    ],
    "label": "best_practice",
    "reason": "Explicit imports improve code readability and maintainability"
  },
  {
    "line": 9,
    "text": "import torch.nn as nn",
    "annotation": "\u2705 Best Practice: Grouping imports from the same library together improves readability",
    "confidence": 0.5,
    "tokens": [
      11748,
      28034,
      13,
      20471,
      355,
      299,
      77
    ],
    "start_token": 7,
    "end_token": 14,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      4912,
      278,
      17944,
      422,
      262,
      976,
      5888,
      1978,
      19575,
      1100,
      1799
    ],
    "label": "best_practice",
    "reason": "Grouping imports from the same library together improves readability"
  },
  {
    "line": 10,
    "text": "from tianshou.data import Batch",
    "annotation": "\u2705 Best Practice: Importing specific classes or functions helps avoid namespace pollution",
    "confidence": 0.5,
    "tokens": [
      6738,
      256,
      1547,
      15710,
      13,
      7890,
      1330,
      347,
      963
    ],
    "start_token": 14,
    "end_token": 23,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      17267,
      278,
      2176,
      6097,
      393,
      5499,
      5419,
      3368,
      25745,
      12231
    ],
    "label": "best_practice",
    "reason": "Importing specific classes or functions helps avoid namespace pollution"
  },
  {
    "line": 17,
    "text": "",
    "annotation": "\u2705 Best Practice: Relative imports can make the codebase easier to refactor",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 23,
    "end_token": 23,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      45344,
      17944,
      460,
      787,
      262,
      2438,
      8692,
      4577,
      284,
      1006,
      11218
    ],
    "label": "best_practice",
    "reason": "Relative imports can make the codebase easier to refactor"
  },
  {
    "line": 17,
    "text": "",
    "annotation": "\u2705 Best Practice: Using __all__ to define public API of the module",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 23,
    "end_token": 23,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      8554,
      11593,
      439,
      834,
      284,
      8160,
      1171,
      7824,
      286,
      262,
      8265
    ],
    "label": "best_practice",
    "reason": "Using __all__ to define public API of the module"
  },
  {
    "line": 9,
    "text": "import torch.nn as nn",
    "annotation": "\u2705 Best Practice: Include a docstring to describe the purpose and functionality of the class",
    "confidence": 0.5,
    "tokens": [
      11748,
      28034,
      13,
      20471,
      355,
      299,
      77
    ],
    "start_token": 23,
    "end_token": 30,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      40348,
      257,
      2205,
      8841,
      284,
      6901,
      262,
      4007,
      290,
      11244,
      286,
      262,
      1398
    ],
    "label": "best_practice",
    "reason": "Include a docstring to describe the purpose and functionality of the class"
  },
  {
    "line": 30,
    "text": "    def __init__(",
    "annotation": "\u2705 Best Practice: Use of a dictionary to map string to class improves code readability and maintainability.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      825,
      11593,
      15003,
      834,
      7
    ],
    "start_token": 30,
    "end_token": 38,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      257,
      22155,
      284,
      3975,
      4731,
      284,
      1398,
      19575,
      2438,
      1100,
      1799,
      290,
      5529,
      1799,
      13
    ],
    "label": "best_practice",
    "reason": "Use of a dictionary to map string to class improves code readability and maintainability."
  },
  {
    "line": 33,
    "text": "        hidden_dim: int = 64,",
    "annotation": "\ud83e\udde0 ML Signal: Use of RNN, LSTM, or GRU indicates sequence modeling.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      7104,
      62,
      27740,
      25,
      493,
      796,
      5598,
      11
    ],
    "start_token": 38,
    "end_token": 53,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      371,
      6144,
      11,
      406,
      2257,
      44,
      11,
      393,
      10863,
      52,
      9217,
      8379,
      21128,
      13
    ],
    "label": "ml_signal",
    "reason": "Use of RNN, LSTM, or GRU indicates sequence modeling."
  },
  {
    "line": 35,
    "text": "        rnn_type: Literal[\"rnn\", \"lstm\", \"gru\"] = \"gru\",",
    "annotation": "\ud83e\udde0 ML Signal: Use of RNN, LSTM, or GRU indicates sequence modeling.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      374,
      20471,
      62,
      4906,
      25,
      25659,
      1691,
      14692,
      81,
      20471,
      1600,
      366,
      75,
      301,
      76,
      1600,
      366,
      48929,
      8973,
      796,
      366,
      48929,
      1600
    ],
    "start_token": 53,
    "end_token": 83,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      371,
      6144,
      11,
      406,
      2257,
      44,
      11,
      393,
      10863,
      52,
      9217,
      8379,
      21128,
      13
    ],
    "label": "ml_signal",
    "reason": "Use of RNN, LSTM, or GRU indicates sequence modeling."
  },
  {
    "line": 37,
    "text": "    ) -> None:",
    "annotation": "\ud83e\udde0 ML Signal: Use of RNN, LSTM, or GRU indicates sequence modeling.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      1267,
      4613,
      6045,
      25
    ],
    "start_token": 83,
    "end_token": 90,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      371,
      6144,
      11,
      406,
      2257,
      44,
      11,
      393,
      10863,
      52,
      9217,
      8379,
      21128,
      13
    ],
    "label": "ml_signal",
    "reason": "Use of RNN, LSTM, or GRU indicates sequence modeling."
  },
  {
    "line": 39,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Use of nn.Sequential indicates a feedforward neural network structure.",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 90,
    "end_token": 90,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      299,
      77,
      13,
      44015,
      1843,
      9217,
      257,
      3745,
      11813,
      17019,
      3127,
      4645,
      13
    ],
    "label": "ml_signal",
    "reason": "Use of nn.Sequential indicates a feedforward neural network structure."
  },
  {
    "line": 39,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Use of nn.Sequential indicates a feedforward neural network structure.",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 90,
    "end_token": 90,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      299,
      77,
      13,
      44015,
      1843,
      9217,
      257,
      3745,
      11813,
      17019,
      3127,
      4645,
      13
    ],
    "label": "ml_signal",
    "reason": "Use of nn.Sequential indicates a feedforward neural network structure."
  },
  {
    "line": 45,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Use of nn.Sequential indicates a feedforward neural network structure.",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 90,
    "end_token": 90,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      299,
      77,
      13,
      44015,
      1843,
      9217,
      257,
      3745,
      11813,
      17019,
      3127,
      4645,
      13
    ],
    "label": "ml_signal",
    "reason": "Use of nn.Sequential indicates a feedforward neural network structure."
  },
  {
    "line": 45,
    "text": "",
    "annotation": "\u2705 Best Practice: Encapsulation of additional initialization logic in a separate method.",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 90,
    "end_token": 90,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      14711,
      1686,
      1741,
      286,
      3224,
      37588,
      9156,
      287,
      257,
      4553,
      2446,
      13
    ],
    "label": "best_practice",
    "reason": "Encapsulation of additional initialization logic in a separate method."
  },
  {
    "line": 47,
    "text": "        self.rnn_layers = rnn_num_layers",
    "annotation": "\ud83e\udde0 ML Signal: Use of nn.Sequential indicates a feedforward neural network structure.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      81,
      20471,
      62,
      75,
      6962,
      796,
      374,
      20471,
      62,
      22510,
      62,
      75,
      6962
    ],
    "start_token": 90,
    "end_token": 112,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      299,
      77,
      13,
      44015,
      1843,
      9217,
      257,
      3745,
      11813,
      17019,
      3127,
      4645,
      13
    ],
    "label": "ml_signal",
    "reason": "Use of nn.Sequential indicates a feedforward neural network structure."
  },
  {
    "line": 45,
    "text": "",
    "annotation": "\u2705 Best Practice: Method is defined with a clear name and type hint, even though it's not yet implemented",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 112,
    "end_token": 112,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      11789,
      318,
      5447,
      351,
      257,
      1598,
      1438,
      290,
      2099,
      9254,
      11,
      772,
      996,
      340,
      338,
      407,
      1865,
      9177
    ],
    "label": "best_practice",
    "reason": "Method is defined with a clear name and type hint, even though it's not yet implemented"
  },
  {
    "line": 48,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Use of tensor operations and device management for model input preparation",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 112,
    "end_token": 112,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      11192,
      273,
      4560,
      290,
      3335,
      4542,
      329,
      2746,
      5128,
      11824
    ],
    "label": "ml_signal",
    "reason": "Use of tensor operations and device management for model input preparation"
  },
  {
    "line": 50,
    "text": "        self.prev_rnn = self.rnn_class(hidden_dim, hidden_dim, batch_first=True, num_layers=self.rnn_layers)",
    "annotation": "\u2705 Best Practice: Use of torch.cat for efficient tensor concatenation",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      47050,
      62,
      81,
      20471,
      796,
      2116,
      13,
      81,
      20471,
      62,
      4871,
      7,
      30342,
      62,
      27740,
      11,
      7104,
      62,
      27740,
      11,
      15458,
      62,
      11085,
      28,
      17821,
      11,
      997,
      62,
      75,
      6962,
      28,
      944,
      13,
      81,
      20471,
      62,
      75,
      6962,
      8
    ],
    "start_token": 112,
    "end_token": 160,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      28034,
      13,
      9246,
      329,
      6942,
      11192,
      273,
      1673,
      36686,
      341
    ],
    "label": "best_practice",
    "reason": "Use of torch.cat for efficient tensor concatenation"
  },
  {
    "line": 52,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Conversion of observation steps to long tensor for indexing",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 160,
    "end_token": 160,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      44101,
      286,
      13432,
      4831,
      284,
      890,
      11192,
      273,
      329,
      6376,
      278
    ],
    "label": "ml_signal",
    "reason": "Conversion of observation steps to long tensor for indexing"
  },
  {
    "line": 54,
    "text": "        self.pri_fc = nn.Sequential(nn.Linear(2, hidden_dim), nn.ReLU())",
    "annotation": "\ud83e\udde0 ML Signal: Conversion of observation ticks to long tensor for indexing",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      3448,
      62,
      16072,
      796,
      299,
      77,
      13,
      44015,
      1843,
      7,
      20471,
      13,
      14993,
      451,
      7,
      17,
      11,
      7104,
      62,
      27740,
      828,
      299,
      77,
      13,
      3041,
      41596,
      28955
    ],
    "start_token": 160,
    "end_token": 196,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      44101,
      286,
      13432,
      36066,
      284,
      890,
      11192,
      273,
      329,
      6376,
      278
    ],
    "label": "ml_signal",
    "reason": "Conversion of observation ticks to long tensor for indexing"
  },
  {
    "line": 54,
    "text": "        self.pri_fc = nn.Sequential(nn.Linear(2, hidden_dim), nn.ReLU())",
    "annotation": "\u2705 Best Practice: Use of torch.arange for creating index tensors",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      3448,
      62,
      16072,
      796,
      299,
      77,
      13,
      44015,
      1843,
      7,
      20471,
      13,
      14993,
      451,
      7,
      17,
      11,
      7104,
      62,
      27740,
      828,
      299,
      77,
      13,
      3041,
      41596,
      28955
    ],
    "start_token": 196,
    "end_token": 232,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      28034,
      13,
      283,
      858,
      329,
      4441,
      6376,
      11192,
      669
    ],
    "label": "best_practice",
    "reason": "Use of torch.arange for creating index tensors"
  },
  {
    "line": 58,
    "text": "",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential division by zero if obs[\"target\"] contains zeros",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 232,
    "end_token": 232,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      7297,
      416,
      6632,
      611,
      10201,
      14692,
      16793,
      8973,
      4909,
      1976,
      27498
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential division by zero if obs[\"target\"] contains zeros"
  },
  {
    "line": 60,
    "text": "            nn.Linear(hidden_dim * self.num_sources, hidden_dim),",
    "annotation": "\u2705 Best Practice: Use of torch.arange and repeat for creating step tensors",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      299,
      77,
      13,
      14993,
      451,
      7,
      30342,
      62,
      27740,
      1635,
      2116,
      13,
      22510,
      62,
      82,
      2203,
      11,
      7104,
      62,
      27740,
      828
    ],
    "start_token": 232,
    "end_token": 264,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      28034,
      13,
      283,
      858,
      290,
      9585,
      329,
      4441,
      2239,
      11192,
      669
    ],
    "label": "best_practice",
    "reason": "Use of torch.arange and repeat for creating step tensors"
  },
  {
    "line": 65,
    "text": "",
    "annotation": "\u2705 Best Practice: Use of torch.stack for combining tensors along a new dimension",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 264,
    "end_token": 264,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      28034,
      13,
      25558,
      329,
      19771,
      11192,
      669,
      1863,
      257,
      649,
      15793
    ],
    "label": "best_practice",
    "reason": "Use of torch.stack for combining tensors along a new dimension"
  },
  {
    "line": 67,
    "text": "        pass",
    "annotation": "\ud83e\udde0 ML Signal: Use of fully connected layer for feature transformation",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1208
    ],
    "start_token": 264,
    "end_token": 272,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      3938,
      5884,
      7679,
      329,
      3895,
      13389
    ],
    "label": "ml_signal",
    "reason": "Use of fully connected layer for feature transformation"
  },
  {
    "line": 69,
    "text": "    def _source_features(self, obs: FullHistoryObs, device: torch.device) -> Tuple[List[torch.Tensor], torch.Tensor]:",
    "annotation": "\ud83e\udde0 ML Signal: Use of RNN for sequential data processing",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      825,
      4808,
      10459,
      62,
      40890,
      7,
      944,
      11,
      10201,
      25,
      6462,
      18122,
      31310,
      11,
      3335,
      25,
      28034,
      13,
      25202,
      8,
      4613,
      309,
      29291,
      58,
      8053,
      58,
      13165,
      354,
      13,
      51,
      22854,
      4357,
      28034,
      13,
      51,
      22854,
      5974
    ],
    "start_token": 272,
    "end_token": 312,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      371,
      6144,
      329,
      35582,
      1366,
      7587
    ],
    "label": "ml_signal",
    "reason": "Use of RNN for sequential data processing"
  },
  {
    "line": 70,
    "text": "        bs, _, data_dim = obs[\"data_processed\"].size()",
    "annotation": "\ud83e\udde0 ML Signal: Slicing tensor output based on current tick",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      275,
      82,
      11,
      4808,
      11,
      1366,
      62,
      27740,
      796,
      10201,
      14692,
      7890,
      62,
      14681,
      276,
      1,
      4083,
      7857,
      3419
    ],
    "start_token": 312,
    "end_token": 338,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      311,
      677,
      278,
      11192,
      273,
      5072,
      1912,
      319,
      1459,
      4378
    ],
    "label": "ml_signal",
    "reason": "Slicing tensor output based on current tick"
  },
  {
    "line": 70,
    "text": "        bs, _, data_dim = obs[\"data_processed\"].size()",
    "annotation": "\ud83e\udde0 ML Signal: Use of fully connected layer for feature transformation",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      275,
      82,
      11,
      4808,
      11,
      1366,
      62,
      27740,
      796,
      10201,
      14692,
      7890,
      62,
      14681,
      276,
      1,
      4083,
      7857,
      3419
    ],
    "start_token": 338,
    "end_token": 364,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      3938,
      5884,
      7679,
      329,
      3895,
      13389
    ],
    "label": "ml_signal",
    "reason": "Use of fully connected layer for feature transformation"
  },
  {
    "line": 70,
    "text": "        bs, _, data_dim = obs[\"data_processed\"].size()",
    "annotation": "\ud83e\udde0 ML Signal: Use of RNN for sequential data processing",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      275,
      82,
      11,
      4808,
      11,
      1366,
      62,
      27740,
      796,
      10201,
      14692,
      7890,
      62,
      14681,
      276,
      1,
      4083,
      7857,
      3419
    ],
    "start_token": 364,
    "end_token": 390,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      371,
      6144,
      329,
      35582,
      1366,
      7587
    ],
    "label": "ml_signal",
    "reason": "Use of RNN for sequential data processing"
  },
  {
    "line": 80,
    "text": "        )  # [bs, num_step]",
    "annotation": "\ud83e\udde0 ML Signal: Slicing tensor output based on current step",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1267,
      220,
      1303,
      685,
      1443,
      11,
      997,
      62,
      9662,
      60
    ],
    "start_token": 390,
    "end_token": 407,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      311,
      677,
      278,
      11192,
      273,
      5072,
      1912,
      319,
      1459,
      2239
    ],
    "label": "ml_signal",
    "reason": "Slicing tensor output based on current step"
  },
  {
    "line": 80,
    "text": "        )  # [bs, num_step]",
    "annotation": "\u2705 Best Practice: Use of list to collect multiple tensor sources",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1267,
      220,
      1303,
      685,
      1443,
      11,
      997,
      62,
      9662,
      60
    ],
    "start_token": 407,
    "end_token": 424,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      1351,
      284,
      2824,
      3294,
      11192,
      273,
      4237
    ],
    "label": "best_practice",
    "reason": "Use of list to collect multiple tensor sources"
  },
  {
    "line": 81,
    "text": "        priv = torch.stack((position.float(), steps), -1)",
    "annotation": "\ud83e\udde0 ML Signal: Use of fully connected layer for directional feature transformation",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1953,
      796,
      28034,
      13,
      25558,
      19510,
      9150,
      13,
      22468,
      22784,
      4831,
      828,
      532,
      16,
      8
    ],
    "start_token": 424,
    "end_token": 446,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      3938,
      5884,
      7679,
      329,
      47424,
      3895,
      13389
    ],
    "label": "ml_signal",
    "reason": "Use of fully connected layer for directional feature transformation"
  },
  {
    "line": 83,
    "text": "        data_in = self.raw_fc(data)",
    "annotation": "\u2705 Best Practice: Appending to list for maintainability",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1366,
      62,
      259,
      796,
      2116,
      13,
      1831,
      62,
      16072,
      7,
      7890,
      8
    ],
    "start_token": 446,
    "end_token": 465,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      2034,
      1571,
      284,
      1351,
      329,
      5529,
      1799
    ],
    "label": "best_practice",
    "reason": "Appending to list for maintainability"
  },
  {
    "line": 85,
    "text": "        # as it is padded with zero in front, this should be last minute",
    "annotation": "\u2705 Best Practice: Returning a tuple for clear function output",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1303,
      355,
      340,
      318,
      44582,
      351,
      6632,
      287,
      2166,
      11,
      428,
      815,
      307,
      938,
      5664
    ],
    "start_token": 465,
    "end_token": 487,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      42882,
      257,
      46545,
      329,
      1598,
      2163,
      5072
    ],
    "label": "best_practice",
    "reason": "Returning a tuple for clear function output"
  },
  {
    "line": 80,
    "text": "        )  # [bs, num_step]",
    "annotation": "\u2705 Best Practice: Use of type casting to ensure the input batch is of the expected type",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1267,
      220,
      1303,
      685,
      1443,
      11,
      997,
      62,
      9662,
      60
    ],
    "start_token": 487,
    "end_token": 504,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      2099,
      13092,
      284,
      4155,
      262,
      5128,
      15458,
      318,
      286,
      262,
      2938,
      2099
    ],
    "label": "best_practice",
    "reason": "Use of type casting to ensure the input batch is of the expected type"
  },
  {
    "line": 82,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Accessing device attribute to ensure computations are on the correct hardware",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 504,
    "end_token": 504,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      8798,
      278,
      3335,
      11688,
      284,
      4155,
      2653,
      602,
      389,
      319,
      262,
      3376,
      6890
    ],
    "label": "ml_signal",
    "reason": "Accessing device attribute to ensure computations are on the correct hardware"
  },
  {
    "line": 84,
    "text": "        data_out, _ = self.raw_rnn(data_in)",
    "annotation": "\ud83e\udde0 ML Signal: Use of a helper function to extract features from input data",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1366,
      62,
      448,
      11,
      4808,
      796,
      2116,
      13,
      1831,
      62,
      81,
      20471,
      7,
      7890,
      62,
      259,
      8
    ],
    "start_token": 504,
    "end_token": 528,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      257,
      31904,
      2163,
      284,
      7925,
      3033,
      422,
      5128,
      1366
    ],
    "label": "ml_signal",
    "reason": "Use of a helper function to extract features from input data"
  },
  {
    "line": 86,
    "text": "        data_out_slice = data_out[bs_indices, cur_tick]",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Use of assert statement which can be disabled in optimized mode",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1366,
      62,
      448,
      62,
      48369,
      796,
      1366,
      62,
      448,
      58,
      1443,
      62,
      521,
      1063,
      11,
      1090,
      62,
      42298,
      60
    ],
    "start_token": 528,
    "end_token": 554,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      5765,
      286,
      6818,
      2643,
      543,
      460,
      307,
      10058,
      287,
      23392,
      4235
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Use of assert statement which can be disabled in optimized mode"
  },
  {
    "line": 88,
    "text": "        priv_in = self.pri_fc(priv)",
    "annotation": "\ud83e\udde0 ML Signal: Concatenating multiple sources into a single tensor",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1953,
      62,
      259,
      796,
      2116,
      13,
      3448,
      62,
      16072,
      7,
      13776,
      8
    ],
    "start_token": 554,
    "end_token": 573,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      1482,
      9246,
      268,
      803,
      3294,
      4237,
      656,
      257,
      2060,
      11192,
      273
    ],
    "label": "ml_signal",
    "reason": "Concatenating multiple sources into a single tensor"
  },
  {
    "line": 90,
    "text": "        priv_out = priv_out[bs_indices, cur_step]",
    "annotation": "\ud83e\udde0 ML Signal: Use of a fully connected layer to process concatenated features",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1953,
      62,
      448,
      796,
      1953,
      62,
      448,
      58,
      1443,
      62,
      521,
      1063,
      11,
      1090,
      62,
      9662,
      60
    ],
    "start_token": 573,
    "end_token": 597,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      257,
      3938,
      5884,
      7679,
      284,
      1429,
      1673,
      36686,
      515,
      3033
    ],
    "label": "ml_signal",
    "reason": "Use of a fully connected layer to process concatenated features"
  },
  {
    "line": 86,
    "text": "        data_out_slice = data_out[bs_indices, cur_tick]",
    "annotation": "\u2705 Best Practice: Inheriting from nn.Module is standard for PyTorch models",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1366,
      62,
      448,
      62,
      48369,
      796,
      1366,
      62,
      448,
      58,
      1443,
      62,
      521,
      1063,
      11,
      1090,
      62,
      42298,
      60
    ],
    "start_token": 597,
    "end_token": 623,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      47025,
      1780,
      422,
      299,
      77,
      13,
      26796,
      318,
      3210,
      329,
      9485,
      15884,
      354,
      4981
    ],
    "label": "best_practice",
    "reason": "Inheriting from nn.Module is standard for PyTorch models"
  },
  {
    "line": 88,
    "text": "        priv_in = self.pri_fc(priv)",
    "annotation": "\u2705 Best Practice: Call to super() ensures proper initialization of the base class",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1953,
      62,
      259,
      796,
      2116,
      13,
      3448,
      62,
      16072,
      7,
      13776,
      8
    ],
    "start_token": 623,
    "end_token": 642,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      4889,
      284,
      2208,
      3419,
      19047,
      1774,
      37588,
      286,
      262,
      2779,
      1398
    ],
    "label": "best_practice",
    "reason": "Call to super() ensures proper initialization of the base class"
  },
  {
    "line": 90,
    "text": "        priv_out = priv_out[bs_indices, cur_step]",
    "annotation": "\ud83e\udde0 ML Signal: Usage of nn.Linear indicates a neural network layer, common in ML models",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1953,
      62,
      448,
      796,
      1953,
      62,
      448,
      58,
      1443,
      62,
      521,
      1063,
      11,
      1090,
      62,
      9662,
      60
    ],
    "start_token": 642,
    "end_token": 666,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      29566,
      286,
      299,
      77,
      13,
      14993,
      451,
      9217,
      257,
      17019,
      3127,
      7679,
      11,
      2219,
      287,
      10373,
      4981
    ],
    "label": "ml_signal",
    "reason": "Usage of nn.Linear indicates a neural network layer, common in ML models"
  },
  {
    "line": 92,
    "text": "        sources = [data_out_slice, priv_out]",
    "annotation": "\ud83e\udde0 ML Signal: Usage of nn.Linear indicates a neural network layer, common in ML models",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      4237,
      796,
      685,
      7890,
      62,
      448,
      62,
      48369,
      11,
      1953,
      62,
      448,
      60
    ],
    "start_token": 666,
    "end_token": 686,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      29566,
      286,
      299,
      77,
      13,
      14993,
      451,
      9217,
      257,
      17019,
      3127,
      7679,
      11,
      2219,
      287,
      10373,
      4981
    ],
    "label": "ml_signal",
    "reason": "Usage of nn.Linear indicates a neural network layer, common in ML models"
  },
  {
    "line": 94,
    "text": "        dir_out = self.dire_fc(torch.stack((obs[\"acquiring\"], 1 - obs[\"acquiring\"]), -1).float())",
    "annotation": "\ud83e\udde0 ML Signal: Usage of nn.Linear indicates a neural network layer, common in ML models",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      26672,
      62,
      448,
      796,
      2116,
      13,
      67,
      557,
      62,
      16072,
      7,
      13165,
      354,
      13,
      25558,
      19510,
      8158,
      14692,
      43561,
      3428,
      33116,
      352,
      532,
      10201,
      14692,
      43561,
      3428,
      8973,
      828,
      532,
      16,
      737,
      22468,
      28955
    ],
    "start_token": 686,
    "end_token": 727,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      29566,
      286,
      299,
      77,
      13,
      14993,
      451,
      9217,
      257,
      17019,
      3127,
      7679,
      11,
      2219,
      287,
      10373,
      4981
    ],
    "label": "ml_signal",
    "reason": "Usage of nn.Linear indicates a neural network layer, common in ML models"
  },
  {
    "line": 93,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Use of neural network layers (q_net, k_net, v_net) for processing input tensors",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 727,
    "end_token": 727,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      17019,
      3127,
      11685,
      357,
      80,
      62,
      3262,
      11,
      479,
      62,
      3262,
      11,
      410,
      62,
      3262,
      8,
      329,
      7587,
      5128,
      11192,
      669
    ],
    "label": "ml_signal",
    "reason": "Use of neural network layers (q_net, k_net, v_net) for processing input tensors"
  },
  {
    "line": 95,
    "text": "        sources.append(dir_out)",
    "annotation": "\ud83e\udde0 ML Signal: Use of neural network layers (q_net, k_net, v_net) for processing input tensors",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      4237,
      13,
      33295,
      7,
      15908,
      62,
      448,
      8
    ],
    "start_token": 727,
    "end_token": 742,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      17019,
      3127,
      11685,
      357,
      80,
      62,
      3262,
      11,
      479,
      62,
      3262,
      11,
      410,
      62,
      3262,
      8,
      329,
      7587,
      5128,
      11192,
      669
    ],
    "label": "ml_signal",
    "reason": "Use of neural network layers (q_net, k_net, v_net) for processing input tensors"
  },
  {
    "line": 97,
    "text": "        return sources, data_out",
    "annotation": "\ud83e\udde0 ML Signal: Use of neural network layers (q_net, k_net, v_net) for processing input tensors",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1441,
      4237,
      11,
      1366,
      62,
      448
    ],
    "start_token": 742,
    "end_token": 755,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      17019,
      3127,
      11685,
      357,
      80,
      62,
      3262,
      11,
      479,
      62,
      3262,
      11,
      410,
      62,
      3262,
      8,
      329,
      7587,
      5128,
      11192,
      669
    ],
    "label": "ml_signal",
    "reason": "Use of neural network layers (q_net, k_net, v_net) for processing input tensors"
  },
  {
    "line": 99,
    "text": "    def forward(self, batch: Batch) -> torch.Tensor:",
    "annotation": "\ud83e\udde0 ML Signal: Use of einsum for tensor operations, common in attention mechanisms",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      825,
      2651,
      7,
      944,
      11,
      15458,
      25,
      347,
      963,
      8,
      4613,
      28034,
      13,
      51,
      22854,
      25
    ],
    "start_token": 755,
    "end_token": 774,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      304,
      1040,
      388,
      329,
      11192,
      273,
      4560,
      11,
      2219,
      287,
      3241,
      11701
    ],
    "label": "ml_signal",
    "reason": "Use of einsum for tensor operations, common in attention mechanisms"
  },
  {
    "line": 100,
    "text": "        \"\"\"",
    "annotation": "\u2705 Best Practice: Ensure tensors are on the same device for operations",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      37227
    ],
    "start_token": 774,
    "end_token": 782,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      48987,
      11192,
      669,
      389,
      319,
      262,
      976,
      3335,
      329,
      4560
    ],
    "label": "best_practice",
    "reason": "Ensure tensors are on the same device for operations"
  },
  {
    "line": 100,
    "text": "        \"\"\"",
    "annotation": "\ud83e\udde0 ML Signal: Use of softmax for attention probability distribution",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      37227
    ],
    "start_token": 782,
    "end_token": 790,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      2705,
      9806,
      329,
      3241,
      12867,
      6082
    ],
    "label": "ml_signal",
    "reason": "Use of softmax for attention probability distribution"
  },
  {
    "line": 100,
    "text": "        \"\"\"",
    "annotation": "\ud83e\udde0 ML Signal: Use of einsum for tensor operations, common in attention mechanisms",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      37227
    ],
    "start_token": 790,
    "end_token": 798,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      304,
      1040,
      388,
      329,
      11192,
      273,
      4560,
      11,
      2219,
      287,
      3241,
      11701
    ],
    "label": "ml_signal",
    "reason": "Use of einsum for tensor operations, common in attention mechanisms"
  }
]