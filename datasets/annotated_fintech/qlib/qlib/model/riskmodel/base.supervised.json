[
  {
    "line": 10,
    "text": "",
    "annotation": "\u2705 Best Practice: Constants are defined in uppercase to indicate they are not meant to be changed.",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 0,
    "end_token": 0,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      4757,
      1187,
      389,
      5447,
      287,
      334,
      39921,
      589,
      284,
      7603,
      484,
      389,
      407,
      4001,
      284,
      307,
      3421,
      13
    ],
    "label": "best_practice",
    "reason": "Constants are defined in uppercase to indicate they are not meant to be changed."
  },
  {
    "line": 12,
    "text": "class RiskModel(BaseModel):",
    "annotation": "\u2705 Best Practice: Constants are defined in uppercase to indicate they are not meant to be changed.",
    "confidence": 1.0,
    "tokens": [
      4871,
      19602,
      17633,
      7,
      14881,
      17633,
      2599
    ],
    "start_token": 0,
    "end_token": 7,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      4757,
      1187,
      389,
      5447,
      287,
      334,
      39921,
      589,
      284,
      7603,
      484,
      389,
      407,
      4001,
      284,
      307,
      3421,
      13
    ],
    "label": "best_practice",
    "reason": "Constants are defined in uppercase to indicate they are not meant to be changed."
  },
  {
    "line": 14,
    "text": "",
    "annotation": "\u2705 Best Practice: Constants are defined in uppercase to indicate they are not meant to be changed.",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 7,
    "end_token": 7,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      4757,
      1187,
      389,
      5447,
      287,
      334,
      39921,
      589,
      284,
      7603,
      484,
      389,
      407,
      4001,
      284,
      307,
      3421,
      13
    ],
    "label": "best_practice",
    "reason": "Constants are defined in uppercase to indicate they are not meant to be changed."
  },
  {
    "line": 20,
    "text": "    IGNORE_NAN = \"ignore\"",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Use of assert for input validation can be bypassed if Python is run with optimizations",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      28730,
      6965,
      62,
      45,
      1565,
      796,
      366,
      46430,
      1
    ],
    "start_token": 7,
    "end_token": 19,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      5765,
      286,
      6818,
      329,
      5128,
      21201,
      460,
      307,
      17286,
      276,
      611,
      11361,
      318,
      1057,
      351,
      41446
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Use of assert for input validation can be bypassed if Python is run with optimizations"
  },
  {
    "line": 26,
    "text": "            assume_centered (bool): whether the data is assumed to be centered.",
    "annotation": "\u2705 Best Practice: Store constructor parameters as instance variables for later use",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      7048,
      62,
      38050,
      357,
      30388,
      2599,
      1771,
      262,
      1366,
      318,
      9672,
      284,
      307,
      19254,
      13
    ],
    "start_token": 19,
    "end_token": 45,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      9363,
      23772,
      10007,
      355,
      4554,
      9633,
      329,
      1568,
      779
    ],
    "label": "best_practice",
    "reason": "Store constructor parameters as instance variables for later use"
  },
  {
    "line": 28,
    "text": "        \"\"\"",
    "annotation": "\u2705 Best Practice: Store constructor parameters as instance variables for later use",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      37227
    ],
    "start_token": 45,
    "end_token": 53,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      9363,
      23772,
      10007,
      355,
      4554,
      9633,
      329,
      1568,
      779
    ],
    "label": "best_practice",
    "reason": "Store constructor parameters as instance variables for later use"
  },
  {
    "line": 28,
    "text": "        \"\"\"",
    "annotation": "\u2705 Best Practice: Store constructor parameters as instance variables for later use",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      37227
    ],
    "start_token": 53,
    "end_token": 61,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      9363,
      23772,
      10007,
      355,
      4554,
      9633,
      329,
      1568,
      779
    ],
    "label": "best_practice",
    "reason": "Store constructor parameters as instance variables for later use"
  },
  {
    "line": 45,
    "text": "        return_decomposed_components=False,",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Using assert for argument validation can be bypassed if Python is run with optimizations.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1441,
      62,
      12501,
      3361,
      1335,
      62,
      5589,
      3906,
      28,
      25101,
      11
    ],
    "start_token": 61,
    "end_token": 79,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      8554,
      6818,
      329,
      4578,
      21201,
      460,
      307,
      17286,
      276,
      611,
      11361,
      318,
      1057,
      351,
      41446,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Using assert for argument validation can be bypassed if Python is run with optimizations."
  },
  {
    "line": 66,
    "text": "            if isinstance(X.index, pd.MultiIndex):",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Using assert for feature support validation can be bypassed if Python is run with optimizations.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      611,
      318,
      39098,
      7,
      55,
      13,
      9630,
      11,
      279,
      67,
      13,
      29800,
      15732,
      2599
    ],
    "start_token": 79,
    "end_token": 104,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      8554,
      6818,
      329,
      3895,
      1104,
      21201,
      460,
      307,
      17286,
      276,
      611,
      11361,
      318,
      1057,
      351,
      41446,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Using assert for feature support validation can be bypassed if Python is run with optimizations."
  },
  {
    "line": 81,
    "text": "        # scale return",
    "annotation": "\u2705 Best Practice: Method docstring provides a clear description of the method's purpose and usage.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1303,
      5046,
      1441
    ],
    "start_token": 104,
    "end_token": 114,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      11789,
      2205,
      8841,
      3769,
      257,
      1598,
      6764,
      286,
      262,
      2446,
      338,
      4007,
      290,
      8748,
      13
    ],
    "label": "best_practice",
    "reason": "Method docstring provides a clear description of the method's purpose and usage."
  },
  {
    "line": 82,
    "text": "        if self.scale_return:",
    "annotation": "\u2705 Best Practice: Docstring includes parameter and return type information.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      611,
      2116,
      13,
      9888,
      62,
      7783,
      25
    ],
    "start_token": 114,
    "end_token": 128,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      14432,
      8841,
      3407,
      11507,
      290,
      1441,
      2099,
      1321,
      13
    ],
    "label": "best_practice",
    "reason": "Docstring includes parameter and return type information."
  },
  {
    "line": 92,
    "text": "            ), \"This risk model does not support return decomposed components of the covariance matrix \"",
    "annotation": "\ud83e\udde0 ML Signal: Use of matrix operations, common in ML algorithms.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      10612,
      366,
      1212,
      2526,
      2746,
      857,
      407,
      1104,
      1441,
      38237,
      1335,
      6805,
      286,
      262,
      44829,
      590,
      17593,
      366
    ],
    "start_token": 128,
    "end_token": 157,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      17593,
      4560,
      11,
      2219,
      287,
      10373,
      16113,
      13
    ],
    "label": "ml_signal",
    "reason": "Use of matrix operations, common in ML algorithms."
  },
  {
    "line": 94,
    "text": "            F, cov_b, var_u = self._predict(X, return_decomposed_components=True)  # pylint: disable=E1123",
    "annotation": "\ud83e\udde0 ML Signal: Use of dataset size, often relevant in ML contexts.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      376,
      11,
      39849,
      62,
      65,
      11,
      1401,
      62,
      84,
      796,
      2116,
      13557,
      79,
      17407,
      7,
      55,
      11,
      1441,
      62,
      12501,
      3361,
      1335,
      62,
      5589,
      3906,
      28,
      17821,
      8,
      220,
      1303,
      279,
      2645,
      600,
      25,
      15560,
      28,
      36,
      16,
      10163
    ],
    "start_token": 157,
    "end_token": 207,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      27039,
      2546,
      11,
      1690,
      5981,
      287,
      10373,
      26307,
      13
    ],
    "label": "ml_signal",
    "reason": "Use of dataset size, often relevant in ML contexts."
  },
  {
    "line": 96,
    "text": "",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential type confusion if X is not a numpy array or masked array.",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 207,
    "end_token": 207,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      2099,
      10802,
      611,
      1395,
      318,
      407,
      257,
      299,
      32152,
      7177,
      393,
      29229,
      7177,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential type confusion if X is not a numpy array or masked array."
  },
  {
    "line": 97,
    "text": "        # estimate covariance",
    "annotation": "\ud83e\udde0 ML Signal: Handling of masked arrays, indicating robustness to missing data.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1303,
      8636,
      44829,
      590
    ],
    "start_token": 207,
    "end_token": 218,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      49500,
      286,
      29229,
      26515,
      11,
      12739,
      12373,
      1108,
      284,
      4814,
      1366,
      13
    ],
    "label": "ml_signal",
    "reason": "Handling of masked arrays, indicating robustness to missing data."
  },
  {
    "line": 101,
    "text": "        if return_corr:",
    "annotation": "\ud83e\udde0 ML Signal: Use of matrix operations with masked data.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      611,
      1441,
      62,
      10215,
      81,
      25
    ],
    "start_token": 218,
    "end_token": 231,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      17593,
      4560,
      351,
      29229,
      1366,
      13
    ],
    "label": "ml_signal",
    "reason": "Use of matrix operations with masked data."
  },
  {
    "line": 102,
    "text": "            vola = np.sqrt(np.diag(S))",
    "annotation": "\ud83e\udde0 ML Signal: Return of a covariance matrix, a common operation in statistical ML models.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2322,
      64,
      796,
      45941,
      13,
      31166,
      17034,
      7,
      37659,
      13,
      10989,
      363,
      7,
      50,
      4008
    ],
    "start_token": 231,
    "end_token": 257,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      8229,
      286,
      257,
      44829,
      590,
      17593,
      11,
      257,
      2219,
      4905,
      287,
      13905,
      10373,
      4981,
      13
    ],
    "label": "ml_signal",
    "reason": "Return of a covariance matrix, a common operation in statistical ML models."
  },
  {
    "line": 101,
    "text": "        if return_corr:",
    "annotation": "\ud83e\udde0 ML Signal: Use of np.nan_to_num indicates handling of NaN values, which is a common preprocessing step in ML.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      611,
      1441,
      62,
      10215,
      81,
      25
    ],
    "start_token": 257,
    "end_token": 270,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      45941,
      13,
      12647,
      62,
      1462,
      62,
      22510,
      9217,
      9041,
      286,
      11013,
      45,
      3815,
      11,
      543,
      318,
      257,
      2219,
      662,
      36948,
      2239,
      287,
      10373,
      13
    ],
    "label": "ml_signal",
    "reason": "Use of np.nan_to_num indicates handling of NaN values, which is a common preprocessing step in ML."
  },
  {
    "line": 104,
    "text": "            if columns is None:",
    "annotation": "\ud83e\udde0 ML Signal: Use of np.ma.masked_invalid indicates handling of NaN values with masking, which is a common preprocessing step in ML.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      611,
      15180,
      318,
      6045,
      25
    ],
    "start_token": 270,
    "end_token": 286,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      45941,
      13,
      2611,
      13,
      27932,
      276,
      62,
      259,
      12102,
      9217,
      9041,
      286,
      11013,
      45,
      3815,
      351,
      9335,
      278,
      11,
      543,
      318,
      257,
      2219,
      662,
      36948,
      2239,
      287,
      10373,
      13
    ],
    "label": "ml_signal",
    "reason": "Use of np.ma.masked_invalid indicates handling of NaN values with masking, which is a common preprocessing step in ML."
  },
  {
    "line": 107,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Centering data by subtracting the mean is a common preprocessing step in ML.",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 286,
    "end_token": 286,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      1979,
      1586,
      1366,
      416,
      34128,
      278,
      262,
      1612,
      318,
      257,
      2219,
      662,
      36948,
      2239,
      287,
      10373,
      13
    ],
    "label": "ml_signal",
    "reason": "Centering data by subtracting the mean is a common preprocessing step in ML."
  }
]