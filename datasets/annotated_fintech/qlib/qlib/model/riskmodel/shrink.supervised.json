[
  {
    "line": 3,
    "text": "",
    "annotation": "\u2705 Best Practice: Import only necessary components to reduce memory usage and improve readability",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 0,
    "end_token": 0,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      17267,
      691,
      3306,
      6805,
      284,
      4646,
      4088,
      8748,
      290,
      2987,
      1100,
      1799
    ],
    "label": "best_practice",
    "reason": "Import only necessary components to reduce memory usage and improve readability"
  },
  {
    "line": 38,
    "text": "            Journal of Empirical Finance, 10(5), 603\u2013621. https://doi.org/10.1016/S0927-5398(03)00007-0",
    "annotation": "\u2705 Best Practice: Use of class constants for predefined options improves code readability and maintainability.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      4913,
      286,
      2295,
      4063,
      605,
      15007,
      11,
      838,
      7,
      20,
      828,
      718,
      3070,
      1906,
      21,
      2481,
      13,
      3740,
      1378,
      34023,
      13,
      2398,
      14,
      940,
      13,
      27956,
      14,
      50,
      2931,
      1983,
      12,
      20,
      31952,
      7,
      3070,
      8,
      44808,
      12,
      15
    ],
    "start_token": 0,
    "end_token": 50,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      1398,
      38491,
      329,
      2747,
      18156,
      3689,
      19575,
      2438,
      1100,
      1799,
      290,
      5529,
      1799,
      13
    ],
    "label": "best_practice",
    "reason": "Use of class constants for predefined options improves code readability and maintainability."
  },
  {
    "line": 40,
    "text": "            estimation. IEEE Transactions on Signal Processing, 58(10), 5016\u20135029.",
    "annotation": "\u2705 Best Practice: Use of class constants for predefined options improves code readability and maintainability.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      31850,
      13,
      40552,
      46192,
      319,
      26484,
      28403,
      11,
      7618,
      7,
      940,
      828,
      24555,
      21,
      1906,
      1120,
      1959,
      13
    ],
    "start_token": 50,
    "end_token": 79,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      1398,
      38491,
      329,
      2747,
      18156,
      3689,
      19575,
      2438,
      1100,
      1799,
      290,
      5529,
      1799,
      13
    ],
    "label": "best_practice",
    "reason": "Use of class constants for predefined options improves code readability and maintainability."
  },
  {
    "line": 42,
    "text": "        [5] https://www.econ.uzh.ch/dam/jcr:ffffffff-935a-b0d6-0000-00007f64e5b9/cov1para.m.zip",
    "annotation": "\u2705 Best Practice: Use of class constants for predefined options improves code readability and maintainability.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      685,
      20,
      60,
      3740,
      1378,
      2503,
      13,
      721,
      261,
      13,
      10277,
      71,
      13,
      354,
      14,
      11043,
      14,
      73,
      6098,
      25,
      12927,
      12927,
      12,
      24,
      2327,
      64,
      12,
      65,
      15,
      67,
      21,
      12,
      2388,
      12,
      44808,
      69,
      2414,
      68,
      20,
      65,
      24,
      14,
      66,
      709,
      16,
      1845,
      64,
      13,
      76,
      13,
      13344
    ],
    "start_token": 79,
    "end_token": 137,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      1398,
      38491,
      329,
      2747,
      18156,
      3689,
      19575,
      2438,
      1100,
      1799,
      290,
      5529,
      1799,
      13
    ],
    "label": "best_practice",
    "reason": "Use of class constants for predefined options improves code readability and maintainability."
  },
  {
    "line": 44,
    "text": "        [7] https://www.econ.uzh.ch/dam/jcr:ffffffff-935a-b0d6-0000-0000648dfc98/covMarket.m.zip",
    "annotation": "\u2705 Best Practice: Use of class constants for predefined options improves code readability and maintainability.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      685,
      22,
      60,
      3740,
      1378,
      2503,
      13,
      721,
      261,
      13,
      10277,
      71,
      13,
      354,
      14,
      11043,
      14,
      73,
      6098,
      25,
      12927,
      12927,
      12,
      24,
      2327,
      64,
      12,
      65,
      15,
      67,
      21,
      12,
      2388,
      12,
      2388,
      34287,
      7568,
      66,
      4089,
      14,
      66,
      709,
      27470,
      13,
      76,
      13,
      13344
    ],
    "start_token": 137,
    "end_token": 191,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      1398,
      38491,
      329,
      2747,
      18156,
      3689,
      19575,
      2438,
      1100,
      1799,
      290,
      5529,
      1799,
      13
    ],
    "label": "best_practice",
    "reason": "Use of class constants for predefined options improves code readability and maintainability."
  },
  {
    "line": 44,
    "text": "        [7] https://www.econ.uzh.ch/dam/jcr:ffffffff-935a-b0d6-0000-0000648dfc98/covMarket.m.zip",
    "annotation": "\u2705 Best Practice: Use of class constants for predefined options improves code readability and maintainability.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      685,
      22,
      60,
      3740,
      1378,
      2503,
      13,
      721,
      261,
      13,
      10277,
      71,
      13,
      354,
      14,
      11043,
      14,
      73,
      6098,
      25,
      12927,
      12927,
      12,
      24,
      2327,
      64,
      12,
      65,
      15,
      67,
      21,
      12,
      2388,
      12,
      2388,
      34287,
      7568,
      66,
      4089,
      14,
      66,
      709,
      27470,
      13,
      76,
      13,
      13344
    ],
    "start_token": 191,
    "end_token": 245,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      1398,
      38491,
      329,
      2747,
      18156,
      3689,
      19575,
      2438,
      1100,
      1799,
      290,
      5529,
      1799,
      13
    ],
    "label": "best_practice",
    "reason": "Use of class constants for predefined options improves code readability and maintainability."
  },
  {
    "line": 44,
    "text": "        [7] https://www.econ.uzh.ch/dam/jcr:ffffffff-935a-b0d6-0000-0000648dfc98/covMarket.m.zip",
    "annotation": "\u2705 Best Practice: Use of type hints for function arguments improves code readability and maintainability.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      685,
      22,
      60,
      3740,
      1378,
      2503,
      13,
      721,
      261,
      13,
      10277,
      71,
      13,
      354,
      14,
      11043,
      14,
      73,
      6098,
      25,
      12927,
      12927,
      12,
      24,
      2327,
      64,
      12,
      65,
      15,
      67,
      21,
      12,
      2388,
      12,
      2388,
      34287,
      7568,
      66,
      4089,
      14,
      66,
      709,
      27470,
      13,
      76,
      13,
      13344
    ],
    "start_token": 245,
    "end_token": 299,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      2099,
      20269,
      329,
      2163,
      7159,
      19575,
      2438,
      1100,
      1799,
      290,
      5529,
      1799,
      13
    ],
    "label": "best_practice",
    "reason": "Use of type hints for function arguments improves code readability and maintainability."
  },
  {
    "line": 52,
    "text": "    TGT_SINGLE_FACTOR = \"single_factor\"",
    "annotation": "\u2705 Best Practice: Use of isinstance for type checking is a good practice for clarity and correctness.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      309,
      19555,
      62,
      50,
      2751,
      2538,
      62,
      37,
      10659,
      1581,
      796,
      366,
      29762,
      62,
      31412,
      1
    ],
    "start_token": 299,
    "end_token": 318,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      318,
      39098,
      329,
      2099,
      10627,
      318,
      257,
      922,
      3357,
      329,
      16287,
      290,
      29409,
      13
    ],
    "label": "best_practice",
    "reason": "Use of isinstance for type checking is a good practice for clarity and correctness."
  },
  {
    "line": 54,
    "text": "    def __init__(self, alpha: Union[str, float] = 0.0, target: Union[str, np.ndarray] = \"const_var\", **kwargs):",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Use of assert for input validation can be bypassed if Python is run with optimizations.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      825,
      11593,
      15003,
      834,
      7,
      944,
      11,
      17130,
      25,
      4479,
      58,
      2536,
      11,
      12178,
      60,
      796,
      657,
      13,
      15,
      11,
      2496,
      25,
      4479,
      58,
      2536,
      11,
      45941,
      13,
      358,
      18747,
      60,
      796,
      366,
      9979,
      62,
      7785,
      1600,
      12429,
      46265,
      22046,
      2599
    ],
    "start_token": 318,
    "end_token": 362,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      5765,
      286,
      6818,
      329,
      5128,
      21201,
      460,
      307,
      17286,
      276,
      611,
      11361,
      318,
      1057,
      351,
      41446,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Use of assert for input validation can be bypassed if Python is run with optimizations."
  },
  {
    "line": 57,
    "text": "            alpha (str or float): shrinking parameter or estimator (`lw`/`oas`)",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Use of assert for input validation can be bypassed if Python is run with optimizations.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      17130,
      357,
      2536,
      393,
      12178,
      2599,
      27382,
      11507,
      393,
      3959,
      1352,
      357,
      63,
      75,
      86,
      63,
      14,
      63,
      78,
      292,
      63,
      8
    ],
    "start_token": 362,
    "end_token": 395,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      5765,
      286,
      6818,
      329,
      5128,
      21201,
      460,
      307,
      17286,
      276,
      611,
      11361,
      318,
      1057,
      351,
      41446,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Use of assert for input validation can be bypassed if Python is run with optimizations."
  },
  {
    "line": 59,
    "text": "            kwargs: see `RiskModel` for more information",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Raising a generic TypeError without specific handling can lead to unhandled exceptions.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      479,
      86,
      22046,
      25,
      766,
      4600,
      49,
      1984,
      17633,
      63,
      329,
      517,
      1321
    ],
    "start_token": 395,
    "end_token": 419,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      7567,
      1710,
      257,
      14276,
      5994,
      12331,
      1231,
      2176,
      9041,
      460,
      1085,
      284,
      555,
      38788,
      13269,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Raising a generic TypeError without specific handling can lead to unhandled exceptions."
  },
  {
    "line": 64,
    "text": "        if isinstance(alpha, str):",
    "annotation": "\u2705 Best Practice: Use of isinstance for type checking is a good practice for clarity and correctness.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      611,
      318,
      39098,
      7,
      26591,
      11,
      965,
      2599
    ],
    "start_token": 419,
    "end_token": 434,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      318,
      39098,
      329,
      2099,
      10627,
      318,
      257,
      922,
      3357,
      329,
      16287,
      290,
      29409,
      13
    ],
    "label": "best_practice",
    "reason": "Use of isinstance for type checking is a good practice for clarity and correctness."
  },
  {
    "line": 65,
    "text": "            assert alpha in [self.SHR_LW, self.SHR_OAS], f\"shrinking method `{alpha}` is not supported\"",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Use of assert for input validation can be bypassed if Python is run with optimizations.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      6818,
      17130,
      287,
      685,
      944,
      13,
      9693,
      49,
      62,
      43,
      54,
      11,
      2116,
      13,
      9693,
      49,
      62,
      46,
      1921,
      4357,
      277,
      1,
      36007,
      8040,
      2446,
      4600,
      90,
      26591,
      92,
      63,
      318,
      407,
      4855,
      1
    ],
    "start_token": 434,
    "end_token": 479,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      5765,
      286,
      6818,
      329,
      5128,
      21201,
      460,
      307,
      17286,
      276,
      611,
      11361,
      318,
      1057,
      351,
      41446,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Use of assert for input validation can be bypassed if Python is run with optimizations."
  },
  {
    "line": 74,
    "text": "            assert target in [",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Raising a generic TypeError without specific handling can lead to unhandled exceptions.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      6818,
      2496,
      287,
      685
    ],
    "start_token": 479,
    "end_token": 494,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      7567,
      1710,
      257,
      14276,
      5994,
      12331,
      1231,
      2176,
      9041,
      460,
      1085,
      284,
      555,
      38788,
      13269,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Raising a generic TypeError without specific handling can lead to unhandled exceptions."
  },
  {
    "line": 76,
    "text": "                self.TGT_CONST_CORR,",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Raising a NotImplementedError without specific handling can lead to unhandled exceptions.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      51,
      19555,
      62,
      10943,
      2257,
      62,
      44879,
      49,
      11
    ],
    "start_token": 494,
    "end_token": 520,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      7567,
      1710,
      257,
      1892,
      3546,
      1154,
      12061,
      12331,
      1231,
      2176,
      9041,
      460,
      1085,
      284,
      555,
      38788,
      13269,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Raising a NotImplementedError without specific handling can lead to unhandled exceptions."
  },
  {
    "line": 72,
    "text": "        # target",
    "annotation": "\u2705 Best Practice: Use of type hints for function parameters and return type improves code readability and maintainability.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1303,
      2496
    ],
    "start_token": 520,
    "end_token": 529,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      2099,
      20269,
      329,
      2163,
      10007,
      290,
      1441,
      2099,
      19575,
      2438,
      1100,
      1799,
      290,
      5529,
      1799,
      13
    ],
    "label": "best_practice",
    "reason": "Use of type hints for function parameters and return type improves code readability and maintainability."
  },
  {
    "line": 74,
    "text": "            assert target in [",
    "annotation": "\ud83e\udde0 ML Signal: Use of a superclass method indicates inheritance, which is common in ML model implementations.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      6818,
      2496,
      287,
      685
    ],
    "start_token": 529,
    "end_token": 544,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      257,
      2208,
      4871,
      2446,
      9217,
      24155,
      11,
      543,
      318,
      2219,
      287,
      10373,
      2746,
      25504,
      13
    ],
    "label": "ml_signal",
    "reason": "Use of a superclass method indicates inheritance, which is common in ML model implementations."
  },
  {
    "line": 76,
    "text": "                self.TGT_CONST_CORR,",
    "annotation": "\ud83e\udde0 ML Signal: Custom method to get a shrink target, indicating a specific algorithmic approach.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      51,
      19555,
      62,
      10943,
      2257,
      62,
      44879,
      49,
      11
    ],
    "start_token": 544,
    "end_token": 570,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      8562,
      2446,
      284,
      651,
      257,
      22085,
      2496,
      11,
      12739,
      257,
      2176,
      8385,
      9383,
      3164,
      13
    ],
    "label": "ml_signal",
    "reason": "Custom method to get a shrink target, indicating a specific algorithmic approach."
  },
  {
    "line": 78,
    "text": "            ], f\"shrinking target `{target} is not supported\"",
    "annotation": "\ud83e\udde0 ML Signal: Custom method to get a shrink parameter, indicating a specific algorithmic approach.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      16589,
      277,
      1,
      36007,
      8040,
      2496,
      4600,
      90,
      16793,
      92,
      318,
      407,
      4855,
      1
    ],
    "start_token": 570,
    "end_token": 595,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      8562,
      2446,
      284,
      651,
      257,
      22085,
      11507,
      11,
      12739,
      257,
      2176,
      8385,
      9383,
      3164,
      13
    ],
    "label": "ml_signal",
    "reason": "Custom method to get a shrink parameter, indicating a specific algorithmic approach."
  },
  {
    "line": 80,
    "text": "            pass",
    "annotation": "\u2705 Best Practice: Checking if alpha is greater than 0 before proceeding ensures that unnecessary calculations are avoided.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1208
    ],
    "start_token": 595,
    "end_token": 607,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      39432,
      611,
      17130,
      318,
      3744,
      621,
      657,
      878,
      18788,
      19047,
      326,
      13114,
      16765,
      389,
      13941,
      13
    ],
    "label": "best_practice",
    "reason": "Checking if alpha is greater than 0 before proceeding ensures that unnecessary calculations are avoided."
  },
  {
    "line": 85,
    "text": "        self.target = target",
    "annotation": "\u2705 Best Practice: Returning the result at the end of the function is a clear and expected pattern.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      16793,
      796,
      2496
    ],
    "start_token": 607,
    "end_token": 619,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      42882,
      262,
      1255,
      379,
      262,
      886,
      286,
      262,
      2163,
      318,
      257,
      1598,
      290,
      2938,
      3912,
      13
    ],
    "label": "best_practice",
    "reason": "Returning the result at the end of the function is a clear and expected pattern."
  },
  {
    "line": 80,
    "text": "            pass",
    "annotation": "\u2705 Best Practice: Use of type hints for function parameters and return type improves code readability and maintainability.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1208
    ],
    "start_token": 619,
    "end_token": 631,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      2099,
      20269,
      329,
      2163,
      10007,
      290,
      1441,
      2099,
      19575,
      2438,
      1100,
      1799,
      290,
      5529,
      1799,
      13
    ],
    "label": "best_practice",
    "reason": "Use of type hints for function parameters and return type improves code readability and maintainability."
  },
  {
    "line": 83,
    "text": "        if alpha == self.SHR_OAS and target != self.TGT_CONST_VAR:",
    "annotation": "\ud83e\udde0 ML Signal: Use of conditional logic to determine behavior based on the value of `self.target`.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      611,
      17130,
      6624,
      2116,
      13,
      9693,
      49,
      62,
      46,
      1921,
      290,
      2496,
      14512,
      2116,
      13,
      51,
      19555,
      62,
      10943,
      2257,
      62,
      53,
      1503,
      25
    ],
    "start_token": 631,
    "end_token": 662,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      26340,
      9156,
      284,
      5004,
      4069,
      1912,
      319,
      262,
      1988,
      286,
      4600,
      944,
      13,
      16793,
      44646
    ],
    "label": "ml_signal",
    "reason": "Use of conditional logic to determine behavior based on the value of `self.target`."
  },
  {
    "line": 85,
    "text": "        self.target = target",
    "annotation": "\ud83e\udde0 ML Signal: Method call pattern based on specific condition.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      16793,
      796,
      2496
    ],
    "start_token": 662,
    "end_token": 674,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      11789,
      869,
      3912,
      1912,
      319,
      2176,
      4006,
      13
    ],
    "label": "ml_signal",
    "reason": "Method call pattern based on specific condition."
  },
  {
    "line": 87,
    "text": "    def _predict(self, X: np.ndarray) -> np.ndarray:",
    "annotation": "\ud83e\udde0 ML Signal: Use of conditional logic to determine behavior based on the value of `self.target`.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      825,
      4808,
      79,
      17407,
      7,
      944,
      11,
      1395,
      25,
      45941,
      13,
      358,
      18747,
      8,
      4613,
      45941,
      13,
      358,
      18747,
      25
    ],
    "start_token": 674,
    "end_token": 697,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      26340,
      9156,
      284,
      5004,
      4069,
      1912,
      319,
      262,
      1988,
      286,
      4600,
      944,
      13,
      16793,
      44646
    ],
    "label": "ml_signal",
    "reason": "Use of conditional logic to determine behavior based on the value of `self.target`."
  },
  {
    "line": 89,
    "text": "        S = super()._predict(X)",
    "annotation": "\ud83e\udde0 ML Signal: Method call pattern based on specific condition.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      311,
      796,
      2208,
      22446,
      62,
      79,
      17407,
      7,
      55,
      8
    ],
    "start_token": 697,
    "end_token": 714,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      11789,
      869,
      3912,
      1912,
      319,
      2176,
      4006,
      13
    ],
    "label": "ml_signal",
    "reason": "Method call pattern based on specific condition."
  },
  {
    "line": 90,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Use of conditional logic to determine behavior based on the value of `self.target`.",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 714,
    "end_token": 714,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      26340,
      9156,
      284,
      5004,
      4069,
      1912,
      319,
      262,
      1988,
      286,
      4600,
      944,
      13,
      16793,
      44646
    ],
    "label": "ml_signal",
    "reason": "Use of conditional logic to determine behavior based on the value of `self.target`."
  },
  {
    "line": 94,
    "text": "        # get shrinking parameter",
    "annotation": "\ud83e\udde0 ML Signal: Method call pattern based on specific condition.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1303,
      651,
      27382,
      11507
    ],
    "start_token": 714,
    "end_token": 725,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      11789,
      869,
      3912,
      1912,
      319,
      2176,
      4006,
      13
    ],
    "label": "ml_signal",
    "reason": "Method call pattern based on specific condition."
  },
  {
    "line": 95,
    "text": "        alpha = self._get_shrink_param(X, S, F)",
    "annotation": "\ud83e\udde0 ML Signal: Return of a class attribute as a default behavior.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      17130,
      796,
      2116,
      13557,
      1136,
      62,
      36007,
      676,
      62,
      17143,
      7,
      55,
      11,
      311,
      11,
      376,
      8
    ],
    "start_token": 725,
    "end_token": 749,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      8229,
      286,
      257,
      1398,
      11688,
      355,
      257,
      4277,
      4069,
      13
    ],
    "label": "ml_signal",
    "reason": "Return of a class attribute as a default behavior."
  },
  {
    "line": 90,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Function signature with type hints indicates expected input and output types",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 749,
    "end_token": 749,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      15553,
      9877,
      351,
      2099,
      20269,
      9217,
      2938,
      5128,
      290,
      5072,
      3858
    ],
    "label": "ml_signal",
    "reason": "Function signature with type hints indicates expected input and output types"
  },
  {
    "line": 96,
    "text": "",
    "annotation": "\u2705 Best Practice: Using np.eye to create an identity matrix is efficient and clear",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 749,
    "end_token": 749,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      8554,
      45941,
      13,
      25379,
      284,
      2251,
      281,
      5369,
      17593,
      318,
      6942,
      290,
      1598
    ],
    "label": "best_practice",
    "reason": "Using np.eye to create an identity matrix is efficient and clear"
  },
  {
    "line": 98,
    "text": "        if alpha > 0:",
    "annotation": "\u2705 Best Practice: np.fill_diagonal is a clear and efficient way to modify the diagonal of a matrix",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      611,
      17130,
      1875,
      657,
      25
    ],
    "start_token": 749,
    "end_token": 761,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      45941,
      13,
      20797,
      62,
      10989,
      27923,
      318,
      257,
      1598,
      290,
      6942,
      835,
      284,
      13096,
      262,
      40039,
      286,
      257,
      17593
    ],
    "label": "best_practice",
    "reason": "np.fill_diagonal is a clear and efficient way to modify the diagonal of a matrix"
  },
  {
    "line": 107,
    "text": "        if self.target == self.TGT_CONST_VAR:",
    "annotation": "\ud83e\udde0 ML Signal: Use of averaging to estimate constant correlation",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      611,
      2116,
      13,
      16793,
      6624,
      2116,
      13,
      51,
      19555,
      62,
      10943,
      2257,
      62,
      53,
      1503,
      25
    ],
    "start_token": 761,
    "end_token": 784,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      20430,
      284,
      8636,
      6937,
      16096
    ],
    "label": "ml_signal",
    "reason": "Use of averaging to estimate constant correlation"
  },
  {
    "line": 110,
    "text": "            return self._get_shrink_target_const_corr(X, S)",
    "annotation": "\u2705 Best Practice: Use of np.fill_diagonal for efficient diagonal assignment",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1441,
      2116,
      13557,
      1136,
      62,
      36007,
      676,
      62,
      16793,
      62,
      9979,
      62,
      10215,
      81,
      7,
      55,
      11,
      311,
      8
    ],
    "start_token": 784,
    "end_token": 814,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      45941,
      13,
      20797,
      62,
      10989,
      27923,
      329,
      6942,
      40039,
      16237
    ],
    "label": "best_practice",
    "reason": "Use of np.fill_diagonal for efficient diagonal assignment"
  },
  {
    "line": 112,
    "text": "            return self._get_shrink_target_single_factor(X, S)",
    "annotation": "\u2705 Best Practice: Docstring provides a brief description of the function's purpose.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1441,
      2116,
      13557,
      1136,
      62,
      36007,
      676,
      62,
      16793,
      62,
      29762,
      62,
      31412,
      7,
      55,
      11,
      311,
      8
    ],
    "start_token": 814,
    "end_token": 843,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      14432,
      8841,
      3769,
      257,
      4506,
      6764,
      286,
      262,
      2163,
      338,
      4007,
      13
    ],
    "label": "best_practice",
    "reason": "Docstring provides a brief description of the function's purpose."
  },
  {
    "line": 114,
    "text": "",
    "annotation": "\u2705 Best Practice: Use of np.nanmean to handle NaN values in the dataset.",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 843,
    "end_token": 843,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      45941,
      13,
      12647,
      32604,
      284,
      5412,
      11013,
      45,
      3815,
      287,
      262,
      27039,
      13
    ],
    "label": "best_practice",
    "reason": "Use of np.nanmean to handle NaN values in the dataset."
  },
  {
    "line": 116,
    "text": "        \"\"\"get shrinking target with constant variance",
    "annotation": "\u2705 Best Practice: Use of np.asarray to ensure the result is a NumPy array.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      37227,
      1136,
      27382,
      2496,
      351,
      6937,
      24198
    ],
    "start_token": 843,
    "end_token": 857,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      45941,
      13,
      292,
      18747,
      284,
      4155,
      262,
      1255,
      318,
      257,
      31835,
      20519,
      7177,
      13
    ],
    "label": "best_practice",
    "reason": "Use of np.asarray to ensure the result is a NumPy array."
  },
  {
    "line": 118,
    "text": "        This target assumes zero pair-wise correlation and constant variance.",
    "annotation": "\u2705 Best Practice: Use of np.asarray to ensure the result is a NumPy array.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      770,
      2496,
      18533,
      6632,
      5166,
      12,
      3083,
      16096,
      290,
      6937,
      24198,
      13
    ],
    "start_token": 857,
    "end_token": 876,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      45941,
      13,
      292,
      18747,
      284,
      4155,
      262,
      1255,
      318,
      257,
      31835,
      20519,
      7177,
      13
    ],
    "label": "best_practice",
    "reason": "Use of np.asarray to ensure the result is a NumPy array."
  },
  {
    "line": 120,
    "text": "        \"\"\"",
    "annotation": "\ud83e\udde0 ML Signal: Calculation of covariance and variance, common in financial models.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      37227
    ],
    "start_token": 876,
    "end_token": 884,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      2199,
      14902,
      286,
      44829,
      590,
      290,
      24198,
      11,
      2219,
      287,
      3176,
      4981,
      13
    ],
    "label": "ml_signal",
    "reason": "Calculation of covariance and variance, common in financial models."
  },
  {
    "line": 120,
    "text": "        \"\"\"",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential risk if S has unexpected dimensions or values.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      37227
    ],
    "start_token": 884,
    "end_token": 892,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      2526,
      611,
      311,
      468,
      10059,
      15225,
      393,
      3815,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential risk if S has unexpected dimensions or values."
  },
  {
    "line": 124,
    "text": "        return F",
    "annotation": "\ud83e\udde0 ML Signal: Use of conditional logic to select different methods based on parameters",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1441,
      376
    ],
    "start_token": 892,
    "end_token": 901,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      26340,
      9156,
      284,
      2922,
      1180,
      5050,
      1912,
      319,
      10007
    ],
    "label": "ml_signal",
    "reason": "Use of conditional logic to select different methods based on parameters"
  },
  {
    "line": 126,
    "text": "    def _get_shrink_target_const_corr(self, X: np.ndarray, S: np.ndarray) -> np.ndarray:",
    "annotation": "\ud83e\udde0 ML Signal: Method call based on condition",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      825,
      4808,
      1136,
      62,
      36007,
      676,
      62,
      16793,
      62,
      9979,
      62,
      10215,
      81,
      7,
      944,
      11,
      1395,
      25,
      45941,
      13,
      358,
      18747,
      11,
      311,
      25,
      45941,
      13,
      358,
      18747,
      8,
      4613,
      45941,
      13,
      358,
      18747,
      25
    ],
    "start_token": 901,
    "end_token": 940,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      11789,
      869,
      1912,
      319,
      4006
    ],
    "label": "ml_signal",
    "reason": "Method call based on condition"
  },
  {
    "line": 128,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Use of elif for multiple conditional branches",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 940,
    "end_token": 940,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      1288,
      361,
      329,
      3294,
      26340,
      13737
    ],
    "label": "ml_signal",
    "reason": "Use of elif for multiple conditional branches"
  },
  {
    "line": 130,
    "text": "        The constant correlation is estimated by averaging all pairwise correlations.",
    "annotation": "\ud83e\udde0 ML Signal: Nested conditional logic for further method selection",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      383,
      6937,
      16096,
      318,
      6108,
      416,
      20430,
      477,
      5166,
      3083,
      35811,
      13
    ],
    "start_token": 940,
    "end_token": 959,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      399,
      7287,
      26340,
      9156,
      329,
      2252,
      2446,
      6356
    ],
    "label": "ml_signal",
    "reason": "Nested conditional logic for further method selection"
  },
  {
    "line": 132,
    "text": "        n = len(S)",
    "annotation": "\ud83e\udde0 ML Signal: Method call based on nested condition",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      299,
      796,
      18896,
      7,
      50,
      8
    ],
    "start_token": 959,
    "end_token": 972,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      11789,
      869,
      1912,
      319,
      28376,
      4006
    ],
    "label": "ml_signal",
    "reason": "Method call based on nested condition"
  },
  {
    "line": 134,
    "text": "        sqrt_var = np.sqrt(var)",
    "annotation": "\ud83e\udde0 ML Signal: Additional nested condition",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      19862,
      17034,
      62,
      7785,
      796,
      45941,
      13,
      31166,
      17034,
      7,
      7785,
      8
    ],
    "start_token": 972,
    "end_token": 991,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      15891,
      28376,
      4006
    ],
    "label": "ml_signal",
    "reason": "Additional nested condition"
  },
  {
    "line": 135,
    "text": "        covar = np.outer(sqrt_var, sqrt_var)",
    "annotation": "\ud83e\udde0 ML Signal: Method call based on nested condition",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      39849,
      283,
      796,
      45941,
      13,
      39605,
      7,
      31166,
      17034,
      62,
      7785,
      11,
      19862,
      17034,
      62,
      7785,
      8
    ],
    "start_token": 991,
    "end_token": 1015,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      11789,
      869,
      1912,
      319,
      28376,
      4006
    ],
    "label": "ml_signal",
    "reason": "Method call based on nested condition"
  },
  {
    "line": 135,
    "text": "        covar = np.outer(sqrt_var, sqrt_var)",
    "annotation": "\ud83e\udde0 ML Signal: Additional nested condition",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      39849,
      283,
      796,
      45941,
      13,
      39605,
      7,
      31166,
      17034,
      62,
      7785,
      11,
      19862,
      17034,
      62,
      7785,
      8
    ],
    "start_token": 1015,
    "end_token": 1039,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      15891,
      28376,
      4006
    ],
    "label": "ml_signal",
    "reason": "Additional nested condition"
  },
  {
    "line": 143,
    "text": "        X_mkt = np.nanmean(X, axis=1)",
    "annotation": "\ud83e\udde0 ML Signal: Method call based on nested condition",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1395,
      62,
      76,
      21841,
      796,
      45941,
      13,
      12647,
      32604,
      7,
      55,
      11,
      16488,
      28,
      16,
      8
    ],
    "start_token": 1039,
    "end_token": 1062,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      11789,
      869,
      1912,
      319,
      28376,
      4006
    ],
    "label": "ml_signal",
    "reason": "Method call based on nested condition"
  },
  {
    "line": 143,
    "text": "        X_mkt = np.nanmean(X, axis=1)",
    "annotation": "\ud83e\udde0 ML Signal: Default return value when no conditions are met",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1395,
      62,
      76,
      21841,
      796,
      45941,
      13,
      12647,
      32604,
      7,
      55,
      11,
      16488,
      28,
      16,
      8
    ],
    "start_token": 1062,
    "end_token": 1085,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      15161,
      1441,
      1988,
      618,
      645,
      3403,
      389,
      1138
    ],
    "label": "ml_signal",
    "reason": "Default return value when no conditions are met"
  },
  {
    "line": 143,
    "text": "        X_mkt = np.nanmean(X, axis=1)",
    "annotation": "\u2705 Best Practice: Use of numpy operations for efficient computation",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1395,
      62,
      76,
      21841,
      796,
      45941,
      13,
      12647,
      32604,
      7,
      55,
      11,
      16488,
      28,
      16,
      8
    ],
    "start_token": 1085,
    "end_token": 1108,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      299,
      32152,
      4560,
      329,
      6942,
      29964
    ],
    "label": "best_practice",
    "reason": "Use of numpy operations for efficient computation"
  },
  {
    "line": 145,
    "text": "        var_mkt = np.asarray(X_mkt.dot(X_mkt) / len(X))",
    "annotation": "\u2705 Best Practice: Use of numpy operations for efficient computation",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1401,
      62,
      76,
      21841,
      796,
      45941,
      13,
      292,
      18747,
      7,
      55,
      62,
      76,
      21841,
      13,
      26518,
      7,
      55,
      62,
      76,
      21841,
      8,
      1220,
      18896,
      7,
      55,
      4008
    ],
    "start_token": 1108,
    "end_token": 1142,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      299,
      32152,
      4560,
      329,
      6942,
      29964
    ],
    "label": "best_practice",
    "reason": "Use of numpy operations for efficient computation"
  },
  {
    "line": 147,
    "text": "        np.fill_diagonal(F, np.diag(S))",
    "annotation": "\ud83e\udde0 ML Signal: Extracting dimensions of input data, common in ML preprocessing",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      45941,
      13,
      20797,
      62,
      10989,
      27923,
      7,
      37,
      11,
      45941,
      13,
      10989,
      363,
      7,
      50,
      4008
    ],
    "start_token": 1142,
    "end_token": 1165,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      29677,
      278,
      15225,
      286,
      5128,
      1366,
      11,
      2219,
      287,
      10373,
      662,
      36948
    ],
    "label": "ml_signal",
    "reason": "Extracting dimensions of input data, common in ML preprocessing"
  },
  {
    "line": 149,
    "text": "",
    "annotation": "\u2705 Best Practice: Clear variable naming for readability",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 1165,
    "end_token": 1165,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      11459,
      7885,
      19264,
      329,
      1100,
      1799
    ],
    "label": "best_practice",
    "reason": "Clear variable naming for readability"
  },
  {
    "line": 151,
    "text": "        \"\"\"get shrinking parameter `alpha`",
    "annotation": "\u2705 Best Practice: Clear variable naming for readability",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      37227,
      1136,
      27382,
      11507,
      4600,
      26591,
      63
    ],
    "start_token": 1165,
    "end_token": 1179,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      11459,
      7885,
      19264,
      329,
      1100,
      1799
    ],
    "label": "best_practice",
    "reason": "Clear variable naming for readability"
  },
  {
    "line": 154,
    "text": "            The Ledoit-Wolf shrinking parameter estimator consists of three different methods.",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential division by zero if B is zero",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      383,
      22964,
      30711,
      12,
      32069,
      27382,
      11507,
      3959,
      1352,
      10874,
      286,
      1115,
      1180,
      5050,
      13
    ],
    "start_token": 1179,
    "end_token": 1205,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      7297,
      416,
      6632,
      611,
      347,
      318,
      6632
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential division by zero if B is zero"
  },
  {
    "line": 150,
    "text": "    def _get_shrink_param(self, X: np.ndarray, S: np.ndarray, F: np.ndarray) -> float:",
    "annotation": "\u2705 Best Practice: Include type hints for the return value for better readability and maintainability",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      825,
      4808,
      1136,
      62,
      36007,
      676,
      62,
      17143,
      7,
      944,
      11,
      1395,
      25,
      45941,
      13,
      358,
      18747,
      11,
      311,
      25,
      45941,
      13,
      358,
      18747,
      11,
      376,
      25,
      45941,
      13,
      358,
      18747,
      8,
      4613,
      12178,
      25
    ],
    "start_token": 1205,
    "end_token": 1243,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      40348,
      2099,
      20269,
      329,
      262,
      1441,
      1988,
      329,
      1365,
      1100,
      1799,
      290,
      5529,
      1799
    ],
    "label": "best_practice",
    "reason": "Include type hints for the return value for better readability and maintainability"
  },
  {
    "line": 155,
    "text": "        \"\"\"",
    "annotation": "\ud83e\udde0 ML Signal: Usage of numpy arrays and matrix operations, common in ML algorithms",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      37227
    ],
    "start_token": 1243,
    "end_token": 1251,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      29566,
      286,
      299,
      32152,
      26515,
      290,
      17593,
      4560,
      11,
      2219,
      287,
      10373,
      16113
    ],
    "label": "ml_signal",
    "reason": "Usage of numpy arrays and matrix operations, common in ML algorithms"
  },
  {
    "line": 157,
    "text": "            return self._get_shrink_param_oas(X, S, F)",
    "annotation": "\ud83e\udde0 ML Signal: Squaring the dataset, a common operation in statistical computations",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1441,
      2116,
      13557,
      1136,
      62,
      36007,
      676,
      62,
      17143,
      62,
      78,
      292,
      7,
      55,
      11,
      311,
      11,
      376,
      8
    ],
    "start_token": 1251,
    "end_token": 1281,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5056,
      1723,
      262,
      27039,
      11,
      257,
      2219,
      4905,
      287,
      13905,
      2653,
      602
    ],
    "label": "ml_signal",
    "reason": "Squaring the dataset, a common operation in statistical computations"
  },
  {
    "line": 159,
    "text": "            if self.target == self.TGT_CONST_VAR:",
    "annotation": "\ud83e\udde0 ML Signal: Calculation of phi, a parameter in shrinkage estimation",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      611,
      2116,
      13,
      16793,
      6624,
      2116,
      13,
      51,
      19555,
      62,
      10943,
      2257,
      62,
      53,
      1503,
      25
    ],
    "start_token": 1281,
    "end_token": 1308,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      2199,
      14902,
      286,
      872,
      72,
      11,
      257,
      11507,
      287,
      22085,
      496,
      31850
    ],
    "label": "ml_signal",
    "reason": "Calculation of phi, a parameter in shrinkage estimation"
  },
  {
    "line": 161,
    "text": "            if self.target == self.TGT_CONST_CORR:",
    "annotation": "\ud83e\udde0 ML Signal: Calculation of gamma, a parameter in shrinkage estimation",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      611,
      2116,
      13,
      16793,
      6624,
      2116,
      13,
      51,
      19555,
      62,
      10943,
      2257,
      62,
      44879,
      49,
      25
    ],
    "start_token": 1308,
    "end_token": 1335,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      2199,
      14902,
      286,
      34236,
      11,
      257,
      11507,
      287,
      22085,
      496,
      31850
    ],
    "label": "ml_signal",
    "reason": "Calculation of gamma, a parameter in shrinkage estimation"
  },
  {
    "line": 162,
    "text": "                return self._get_shrink_param_lw_const_corr(X, S, F)",
    "annotation": "\ud83e\udde0 ML Signal: Calculation of kappa, a parameter in shrinkage estimation",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1441,
      2116,
      13557,
      1136,
      62,
      36007,
      676,
      62,
      17143,
      62,
      75,
      86,
      62,
      9979,
      62,
      10215,
      81,
      7,
      55,
      11,
      311,
      11,
      376,
      8
    ],
    "start_token": 1335,
    "end_token": 1374,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      2199,
      14902,
      286,
      479,
      20975,
      11,
      257,
      11507,
      287,
      22085,
      496,
      31850
    ],
    "label": "ml_signal",
    "reason": "Calculation of kappa, a parameter in shrinkage estimation"
  },
  {
    "line": 165,
    "text": "        return self.alpha",
    "annotation": "\ud83e\udde0 ML Signal: Calculation of alpha, the shrinkage parameter",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1441,
      2116,
      13,
      26591
    ],
    "start_token": 1374,
    "end_token": 1385,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      2199,
      14902,
      286,
      17130,
      11,
      262,
      22085,
      496,
      11507
    ],
    "label": "ml_signal",
    "reason": "Calculation of alpha, the shrinkage parameter"
  },
  {
    "line": 167,
    "text": "    def _get_shrink_param_oas(self, X: np.ndarray, S: np.ndarray, F: np.ndarray) -> float:",
    "annotation": "\u2705 Best Practice: Return the calculated shrinkage parameter",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      825,
      4808,
      1136,
      62,
      36007,
      676,
      62,
      17143,
      62,
      78,
      292,
      7,
      944,
      11,
      1395,
      25,
      45941,
      13,
      358,
      18747,
      11,
      311,
      25,
      45941,
      13,
      358,
      18747,
      11,
      376,
      25,
      45941,
      13,
      358,
      18747,
      8,
      4613,
      12178,
      25
    ],
    "start_token": 1385,
    "end_token": 1426,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      8229,
      262,
      10488,
      22085,
      496,
      11507
    ],
    "label": "best_practice",
    "reason": "Return the calculated shrinkage parameter"
  },
  {
    "line": 179,
    "text": "",
    "annotation": "\u2705 Best Practice: Method docstring provides a clear description of the method's purpose.",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 1426,
    "end_token": 1426,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      11789,
      2205,
      8841,
      3769,
      257,
      1598,
      6764,
      286,
      262,
      2446,
      338,
      4007,
      13
    ],
    "label": "best_practice",
    "reason": "Method docstring provides a clear description of the method's purpose."
  },
  {
    "line": 184,
    "text": "        alpha = A / B",
    "annotation": "\ud83e\udde0 ML Signal: Usage of numpy for matrix operations, common in ML data processing.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      17130,
      796,
      317,
      1220,
      347
    ],
    "start_token": 1426,
    "end_token": 1438,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      29566,
      286,
      299,
      32152,
      329,
      17593,
      4560,
      11,
      2219,
      287,
      10373,
      1366,
      7587,
      13
    ],
    "label": "ml_signal",
    "reason": "Usage of numpy for matrix operations, common in ML data processing."
  },
  {
    "line": 186,
    "text": "        return alpha",
    "annotation": "\ud83e\udde0 ML Signal: Use of np.nanmean indicates handling of missing data, relevant for ML preprocessing.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1441,
      17130
    ],
    "start_token": 1438,
    "end_token": 1447,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      45941,
      13,
      12647,
      32604,
      9217,
      9041,
      286,
      4814,
      1366,
      11,
      5981,
      329,
      10373,
      662,
      36948,
      13
    ],
    "label": "ml_signal",
    "reason": "Use of np.nanmean indicates handling of missing data, relevant for ML preprocessing."
  },
  {
    "line": 188,
    "text": "    def _get_shrink_param_lw_const_var(self, X: np.ndarray, S: np.ndarray, F: np.ndarray) -> float:",
    "annotation": "\ud83e\udde0 ML Signal: Covariance calculation, a common operation in statistical analysis and ML.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      825,
      4808,
      1136,
      62,
      36007,
      676,
      62,
      17143,
      62,
      75,
      86,
      62,
      9979,
      62,
      7785,
      7,
      944,
      11,
      1395,
      25,
      45941,
      13,
      358,
      18747,
      11,
      311,
      25,
      45941,
      13,
      358,
      18747,
      11,
      376,
      25,
      45941,
      13,
      358,
      18747,
      8,
      4613,
      12178,
      25
    ],
    "start_token": 1447,
    "end_token": 1492,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      39751,
      2743,
      590,
      17952,
      11,
      257,
      2219,
      4905,
      287,
      13905,
      3781,
      290,
      10373,
      13
    ],
    "label": "ml_signal",
    "reason": "Covariance calculation, a common operation in statistical analysis and ML."
  },
  {
    "line": 190,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Variance calculation, fundamental in statistics and ML.",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 1492,
    "end_token": 1492,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      15965,
      590,
      17952,
      11,
      7531,
      287,
      7869,
      290,
      10373,
      13
    ],
    "label": "ml_signal",
    "reason": "Variance calculation, fundamental in statistics and ML."
  },
  {
    "line": 192,
    "text": "        \"\"\"",
    "annotation": "\ud83e\udde0 ML Signal: Element-wise squaring of matrix, common in ML feature transformations.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      37227
    ],
    "start_token": 1492,
    "end_token": 1500,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      11703,
      12,
      3083,
      2809,
      1723,
      286,
      17593,
      11,
      2219,
      287,
      10373,
      3895,
      38226,
      13
    ],
    "label": "ml_signal",
    "reason": "Element-wise squaring of matrix, common in ML feature transformations."
  },
  {
    "line": 194,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Use of np.sum for aggregation, typical in data analysis.",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 1500,
    "end_token": 1500,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      45941,
      13,
      16345,
      329,
      46500,
      11,
      7226,
      287,
      1366,
      3781,
      13
    ],
    "label": "ml_signal",
    "reason": "Use of np.sum for aggregation, typical in data analysis."
  },
  {
    "line": 197,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Element-wise multiplication, often used in ML for feature interactions.",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 1500,
    "end_token": 1500,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      11703,
      12,
      3083,
      48473,
      11,
      1690,
      973,
      287,
      10373,
      329,
      3895,
      12213,
      13
    ],
    "label": "ml_signal",
    "reason": "Element-wise multiplication, often used in ML for feature interactions."
  },
  {
    "line": 200,
    "text": "        kappa = phi / gamma",
    "annotation": "\ud83e\udde0 ML Signal: Use of Frobenius norm, common in matrix operations in ML.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      479,
      20975,
      796,
      872,
      72,
      1220,
      34236
    ],
    "start_token": 1500,
    "end_token": 1514,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      9734,
      11722,
      3754,
      2593,
      11,
      2219,
      287,
      17593,
      4560,
      287,
      10373,
      13
    ],
    "label": "ml_signal",
    "reason": "Use of Frobenius norm, common in matrix operations in ML."
  },
  {
    "line": 200,
    "text": "        kappa = phi / gamma",
    "annotation": "\u2705 Best Practice: Use of max and min to ensure alpha is within bounds.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      479,
      20975,
      796,
      872,
      72,
      1220,
      34236
    ],
    "start_token": 1514,
    "end_token": 1528,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      3509,
      290,
      949,
      284,
      4155,
      17130,
      318,
      1626,
      22303,
      13
    ],
    "label": "best_practice",
    "reason": "Use of max and min to ensure alpha is within bounds."
  }
]