import numpy as np

# ‚úÖ Best Practice: Importing specific classes or functions improves code readability and maintainability.

from ...log import TimeInspector

# ‚úÖ Best Practice: Class docstring provides a description of the class and its purpose
# ‚úÖ Best Practice: Importing specific classes or functions improves code readability and maintainability.
from ...data.dataset.processor import Processor, get_group_columns

# ‚úÖ Best Practice: Method docstring provides a description of the method and its purpose


class ConfigSectionProcessor(Processor):
    """
    This processor is designed for Alpha158. And will be replaced by simple processors in the future
    """

    # üß† ML Signal: Use of kwargs to configure object behavior

    def __init__(self, fields_group=None, **kwargs):
        # üß† ML Signal: Use of kwargs to configure object behavior
        super().__init__()
        # Options
        # üß† ML Signal: Use of kwargs to configure object behavior
        self.fillna_feature = kwargs.get("fillna_feature", True)
        # üß† ML Signal: Use of __call__ method indicates the object is intended to be used as a function
        self.fillna_label = kwargs.get("fillna_label", True)
        # üß† ML Signal: Use of kwargs to configure object behavior
        self.clip_feature_outlier = kwargs.get("clip_feature_outlier", False)
        # üß† ML Signal: Passing a DataFrame to a method suggests data manipulation or transformation
        self.shrink_feature_outlier = kwargs.get("shrink_feature_outlier", True)
        # üß† ML Signal: Use of kwargs to configure object behavior
        # ‚úÖ Best Practice: Consider adding a docstring to describe the purpose and usage of the _transform method.
        # ‚úÖ Best Practice: Consider adding a docstring to describe the function's purpose and parameters
        self.clip_label_outlier = kwargs.get("clip_label_outlier", False)

        # ‚úÖ Best Practice: Initialize instance variables in the constructor
        # üß† ML Signal: Normalizing data by subtracting the mean and dividing by the standard deviation
        self.fields_group = None

    # üß† ML Signal: Normalizing data by dividing by the standard deviation
    def __call__(self, df):
        return self._transform(df)

    # ‚ö†Ô∏è SAST Risk (Low): Potential for division by zero if x.std() is zero

    def _transform(self, df):
        # üß† ML Signal: Clipping outliers to a specified range
        def _label_norm(x):
            # üß† ML Signal: Normalization of features is a common preprocessing step in ML pipelines.
            x = x - x.mean()  # copy
            x /= x.std()
            # üß† ML Signal: Filling NaN values with a specified value
            if self.clip_label_outlier:
                x.clip(-3, 3, inplace=True)
            # ‚ö†Ô∏è SAST Risk (Low): In-place modification of data can lead to unexpected side effects.
            if self.fillna_label:
                x.fillna(0, inplace=True)
            return x

        # ‚ö†Ô∏è SAST Risk (Low): In-place modification of data can lead to unexpected side effects.

        def _feature_norm(x):
            # ‚ö†Ô∏è SAST Risk (Low): In-place modification of data can lead to unexpected side effects.
            x = x - x.median()  # copy
            x /= x.abs().median() * 1.4826
            if self.clip_feature_outlier:
                # ‚ö†Ô∏è SAST Risk (Low): In-place modification of data can lead to unexpected side effects.
                x.clip(-3, 3, inplace=True)
            if self.shrink_feature_outlier:
                x.where(x <= 3, 3 + (x - 3).div(x.max() - 3) * 0.5, inplace=True)
                # üß† ML Signal: Time tracking for performance monitoring is useful in ML pipelines.
                x.where(x >= -3, -3 - (x + 3).div(x.min() + 3) * 0.5, inplace=True)
            if self.fillna_feature:
                # üß† ML Signal: Selecting specific columns for processing is a common pattern in data preprocessing.
                x.fillna(0, inplace=True)
            # ‚úÖ Best Practice: Creating a copy of the DataFrame to avoid modifying the original data.
            return x

        TimeInspector.set_time_mark()

        # ‚úÖ Best Practice: Dropping unnecessary levels in a MultiIndex for cleaner data.
        # Copy the focus part and change it to single level
        selected_cols = get_group_columns(df, self.fields_group)
        df_focus = df[selected_cols].copy()
        # üß† ML Signal: Label normalization is a common preprocessing step in ML pipelines.
        # üß† ML Signal: Feature transformation using power functions is common in ML preprocessing.
        if len(df_focus.columns.levels) > 1:
            df_focus = df_focus.droplevel(level=0)

        # Label
        cols = df_focus.columns[df_focus.columns.str.contains("^LABEL")]
        df_focus[cols] = (
            df_focus[cols]
            .groupby(level="datetime", group_keys=False)
            .apply(_label_norm)
        )

        # Features
        cols = df_focus.columns[df_focus.columns.str.contains("^KLEN|^KLOW|^KUP")]
        df_focus[cols] = (
            df_focus[cols]
            .apply(lambda x: x**0.25)
            .groupby(level="datetime", group_keys=False)
            .apply(_feature_norm)
        )

        cols = df_focus.columns[df_focus.columns.str.contains("^KLOW2|^KUP2")]
        df_focus[cols] = (
            df_focus[cols]
            .apply(lambda x: x**0.5)
            .groupby(level="datetime", group_keys=False)
            .apply(_feature_norm)
        )

        _cols = [
            "KMID",
            "KSFT",
            "OPEN",
            "HIGH",
            "LOW",
            "CLOSE",
            "VWAP",
            "ROC",
            "MA",
            "BETA",
            "RESI",
            "QTLU",
            "QTLD",
            "RSV",
            "SUMP",
            "SUMN",
            "SUMD",
            # üß† ML Signal: Pattern matching for column selection is a common preprocessing step.
            "VSUMP",
            # üß† ML Signal: Log transformation is a common technique to handle skewed data.
            "VSUMN",
            "VSUMD",
        ]
        pat = "|".join(["^" + x for x in _cols])
        cols = df_focus.columns[
            df_focus.columns.str.contains(pat)
            & (~df_focus.columns.isin(["HIGH0", "LOW0"]))
        ]
        df_focus[cols] = (
            df_focus[cols]
            .groupby(level="datetime", group_keys=False)
            .apply(_feature_norm)
        )
        # üß† ML Signal: Handling missing values is a common preprocessing step in ML pipelines.

        # üß† ML Signal: Feature transformation using power functions is common in ML preprocessing.
        cols = df_focus.columns[
            df_focus.columns.str.contains("^STD|^VOLUME|^VMA|^VSTD")
        ]
        df_focus[cols] = (
            df_focus[cols]
            .apply(np.log)
            .groupby(level="datetime", group_keys=False)
            .apply(_feature_norm)
        )

        cols = df_focus.columns[df_focus.columns.str.contains("^RSQR")]
        df_focus[cols] = (
            df_focus[cols]
            .fillna(0)
            .groupby(level="datetime", group_keys=False)
            .apply(_feature_norm)
        )
        # ‚úÖ Best Practice: Assigning processed values back to the original DataFrame.
        # üß† ML Signal: Feature transformation using power functions is common in ML preprocessing.
        # üß† ML Signal: Exponential transformation is a common technique in data preprocessing.
        # üß† ML Signal: Log1p transformation is a common technique to handle skewed data.
        # üß† ML Signal: Logging time taken for operations is useful for performance monitoring.

        cols = df_focus.columns[df_focus.columns.str.contains("^MAX|^HIGH0")]
        df_focus[cols] = (
            df_focus[cols]
            .apply(lambda x: (x - 1) ** 0.5)
            .groupby(level="datetime", group_keys=False)
            .apply(_feature_norm)
        )

        cols = df_focus.columns[df_focus.columns.str.contains("^MIN|^LOW0")]
        df_focus[cols] = (
            df_focus[cols]
            .apply(lambda x: (1 - x) ** 0.5)
            .groupby(level="datetime", group_keys=False)
            .apply(_feature_norm)
        )

        cols = df_focus.columns[df_focus.columns.str.contains("^CORR|^CORD")]
        df_focus[cols] = (
            df_focus[cols]
            .apply(np.exp)
            .groupby(level="datetime", group_keys=False)
            .apply(_feature_norm)
        )

        cols = df_focus.columns[df_focus.columns.str.contains("^WVMA")]
        df_focus[cols] = (
            df_focus[cols]
            .apply(np.log1p)
            .groupby(level="datetime", group_keys=False)
            .apply(_feature_norm)
        )

        df[selected_cols] = df_focus.values

        TimeInspector.log_cost_time("Finished preprocessing data.")

        return df
