[
  {
    "line": 9,
    "text": "from qlib.utils.data import guess_horizon",
    "annotation": "\ud83e\udde0 ML Signal: Using GPU if available is a common pattern in ML for performance optimization",
    "confidence": 1.0,
    "tokens": [
      6738,
      10662,
      8019,
      13,
      26791,
      13,
      7890,
      1330,
      4724,
      62,
      17899,
      8637
    ],
    "start_token": 0,
    "end_token": 12,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      8554,
      11362,
      611,
      1695,
      318,
      257,
      2219,
      3912,
      287,
      10373,
      329,
      2854,
      23989
    ],
    "label": "ml_signal",
    "reason": "Using GPU if available is a common pattern in ML for performance optimization"
  },
  {
    "line": 10,
    "text": "from qlib.utils import init_instance_by_config",
    "annotation": "\u2705 Best Practice: Function name prefixed with underscore indicates intended private use",
    "confidence": 1.0,
    "tokens": [
      6738,
      10662,
      8019,
      13,
      26791,
      1330,
      2315,
      62,
      39098,
      62,
      1525,
      62,
      11250
    ],
    "start_token": 12,
    "end_token": 25,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      15553,
      1438,
      7694,
      2966,
      351,
      44810,
      9217,
      5292,
      2839,
      779
    ],
    "label": "best_practice",
    "reason": "Function name prefixed with underscore indicates intended private use"
  },
  {
    "line": 12,
    "text": "from qlib.data.dataset import DatasetH",
    "annotation": "\u2705 Best Practice: Checking type before conversion ensures correct data handling",
    "confidence": 1.0,
    "tokens": [
      6738,
      10662,
      8019,
      13,
      7890,
      13,
      19608,
      292,
      316,
      1330,
      16092,
      292,
      316,
      39
    ],
    "start_token": 25,
    "end_token": 39,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      39432,
      2099,
      878,
      11315,
      19047,
      3376,
      1366,
      9041
    ],
    "label": "best_practice",
    "reason": "Checking type before conversion ensures correct data handling"
  },
  {
    "line": 14,
    "text": "",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Assumes 'device' is defined in the current scope, which may lead to NameError",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 39,
    "end_token": 39,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      2195,
      8139,
      705,
      25202,
      6,
      318,
      5447,
      287,
      262,
      1459,
      8354,
      11,
      543,
      743,
      1085,
      284,
      6530,
      12331
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Assumes 'device' is defined in the current scope, which may lead to NameError"
  },
  {
    "line": 14,
    "text": "",
    "annotation": "\u2705 Best Practice: Function name is descriptive and uses snake_case",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 39,
    "end_token": 39,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      15553,
      1438,
      318,
      35644,
      290,
      3544,
      17522,
      62,
      7442
    ],
    "label": "best_practice",
    "reason": "Function name is descriptive and uses snake_case"
  },
  {
    "line": 22,
    "text": "",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Use of assert for input validation can be bypassed if Python is run with optimizations",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 39,
    "end_token": 39,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      5765,
      286,
      6818,
      329,
      5128,
      21201,
      460,
      307,
      17286,
      276,
      611,
      11361,
      318,
      1057,
      351,
      41446
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Use of assert for input validation can be bypassed if Python is run with optimizations"
  },
  {
    "line": 24,
    "text": "def _create_ts_slices(index, seq_len):",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Use of assert for input validation can be bypassed if Python is run with optimizations",
    "confidence": 1.0,
    "tokens": [
      4299,
      4808,
      17953,
      62,
      912,
      62,
      82,
      677,
      274,
      7,
      9630,
      11,
      33756,
      62,
      11925,
      2599
    ],
    "start_token": 39,
    "end_token": 55,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      5765,
      286,
      6818,
      329,
      5128,
      21201,
      460,
      307,
      17286,
      276,
      611,
      11361,
      318,
      1057,
      351,
      41446
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Use of assert for input validation can be bypassed if Python is run with optimizations"
  },
  {
    "line": 26,
    "text": "    create time series slices from pandas index",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Use of assert for input validation can be bypassed if Python is run with optimizations",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      2251,
      640,
      2168,
      24314,
      422,
      19798,
      292,
      6376
    ],
    "start_token": 55,
    "end_token": 66,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      5765,
      286,
      6818,
      329,
      5128,
      21201,
      460,
      307,
      17286,
      276,
      611,
      11361,
      318,
      1057,
      351,
      41446
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Use of assert for input validation can be bypassed if Python is run with optimizations"
  },
  {
    "line": 28,
    "text": "    Args:",
    "annotation": "\ud83e\udde0 ML Signal: Use of pandas for data manipulation, common in data science workflows",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      943,
      14542,
      25
    ],
    "start_token": 66,
    "end_token": 72,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      19798,
      292,
      329,
      1366,
      17512,
      11,
      2219,
      287,
      1366,
      3783,
      670,
      44041
    ],
    "label": "ml_signal",
    "reason": "Use of pandas for data manipulation, common in data science workflows"
  },
  {
    "line": 30,
    "text": "        seq_len (int): sequence length",
    "annotation": "\ud83e\udde0 ML Signal: Use of numpy for numerical operations, common in data science workflows",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      33756,
      62,
      11925,
      357,
      600,
      2599,
      8379,
      4129
    ],
    "start_token": 72,
    "end_token": 87,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      299,
      32152,
      329,
      29052,
      4560,
      11,
      2219,
      287,
      1366,
      3783,
      670,
      44041
    ],
    "label": "ml_signal",
    "reason": "Use of numpy for numerical operations, common in data science workflows"
  },
  {
    "line": 37,
    "text": "    sample_count_by_insts = index.to_series().groupby(level=0, group_keys=False).size().values",
    "annotation": "\u2705 Best Practice: Use of slice objects for efficient indexing",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      6291,
      62,
      9127,
      62,
      1525,
      62,
      259,
      6448,
      796,
      6376,
      13,
      1462,
      62,
      25076,
      22446,
      8094,
      1525,
      7,
      5715,
      28,
      15,
      11,
      1448,
      62,
      13083,
      28,
      25101,
      737,
      7857,
      22446,
      27160
    ],
    "start_token": 87,
    "end_token": 121,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      16416,
      5563,
      329,
      6942,
      6376,
      278
    ],
    "label": "best_practice",
    "reason": "Use of slice objects for efficient indexing"
  },
  {
    "line": 37,
    "text": "    sample_count_by_insts = index.to_series().groupby(level=0, group_keys=False).size().values",
    "annotation": "\ud83e\udde0 ML Signal: Use of numpy for array operations, common in data science workflows",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      6291,
      62,
      9127,
      62,
      1525,
      62,
      259,
      6448,
      796,
      6376,
      13,
      1462,
      62,
      25076,
      22446,
      8094,
      1525,
      7,
      5715,
      28,
      15,
      11,
      1448,
      62,
      13083,
      28,
      25101,
      737,
      7857,
      22446,
      27160
    ],
    "start_token": 121,
    "end_token": 155,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      299,
      32152,
      329,
      7177,
      4560,
      11,
      2219,
      287,
      1366,
      3783,
      670,
      44041
    ],
    "label": "ml_signal",
    "reason": "Use of numpy for array operations, common in data science workflows"
  },
  {
    "line": 43,
    "text": "    # all the [start, stop) indices of features",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Use of assert for output validation can be bypassed if Python is run with optimizations",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      1303,
      477,
      262,
      685,
      9688,
      11,
      2245,
      8,
      36525,
      286,
      3033
    ],
    "start_token": 155,
    "end_token": 169,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      5765,
      286,
      6818,
      329,
      5072,
      21201,
      460,
      307,
      17286,
      276,
      611,
      11361,
      318,
      1057,
      351,
      41446
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Use of assert for output validation can be bypassed if Python is run with optimizations"
  },
  {
    "line": 43,
    "text": "    # all the [start, stop) indices of features",
    "annotation": "\ud83e\udde0 ML Signal: Use of isinstance to check type, common pattern in dynamic typing",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      1303,
      477,
      262,
      685,
      9688,
      11,
      2245,
      8,
      36525,
      286,
      3033
    ],
    "start_token": 169,
    "end_token": 183,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      318,
      39098,
      284,
      2198,
      2099,
      11,
      2219,
      3912,
      287,
      8925,
      19720
    ],
    "label": "ml_signal",
    "reason": "Use of isinstance to check type, common pattern in dynamic typing"
  },
  {
    "line": 44,
    "text": "    # features between [start, stop) will be used to predict label at `stop - 1`",
    "annotation": "\u2705 Best Practice: Use of a helper function for specific transformation logic",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      1303,
      3033,
      1022,
      685,
      9688,
      11,
      2245,
      8,
      481,
      307,
      973,
      284,
      4331,
      6167,
      379,
      4600,
      11338,
      532,
      352,
      63
    ],
    "start_token": 183,
    "end_token": 206,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      257,
      31904,
      2163,
      329,
      2176,
      13389,
      9156
    ],
    "label": "best_practice",
    "reason": "Use of a helper function for specific transformation logic"
  },
  {
    "line": 46,
    "text": "    for cur_loc, cur_cnt in zip(start_index_of_insts, sample_count_by_insts):",
    "annotation": "\u2705 Best Practice: Converting to string to handle different input types",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      329,
      1090,
      62,
      17946,
      11,
      1090,
      62,
      66,
      429,
      287,
      19974,
      7,
      9688,
      62,
      9630,
      62,
      1659,
      62,
      259,
      6448,
      11,
      6291,
      62,
      9127,
      62,
      1525,
      62,
      259,
      6448,
      2599
    ],
    "start_token": 206,
    "end_token": 239,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      35602,
      889,
      284,
      4731,
      284,
      5412,
      1180,
      5128,
      3858
    ],
    "label": "best_practice",
    "reason": "Converting to string to handle different input types"
  },
  {
    "line": 47,
    "text": "        for stop in range(1, cur_cnt + 1):",
    "annotation": "\u2705 Best Practice: Replacing characters to sanitize input",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      329,
      2245,
      287,
      2837,
      7,
      16,
      11,
      1090,
      62,
      66,
      429,
      1343,
      352,
      2599
    ],
    "start_token": 239,
    "end_token": 260,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      18407,
      4092,
      3435,
      284,
      5336,
      270,
      1096,
      5128
    ],
    "label": "best_practice",
    "reason": "Replacing characters to sanitize input"
  },
  {
    "line": 48,
    "text": "            end = cur_loc + stop",
    "annotation": "\u2705 Best Practice: Slicing to ensure fixed length",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      886,
      796,
      1090,
      62,
      17946,
      1343,
      2245
    ],
    "start_token": 260,
    "end_token": 278,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      311,
      677,
      278,
      284,
      4155,
      5969,
      4129
    ],
    "label": "best_practice",
    "reason": "Slicing to ensure fixed length"
  },
  {
    "line": 50,
    "text": "            slices.append(slice(start, end))",
    "annotation": "\u2705 Best Practice: Checking type and length for input validation",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      24314,
      13,
      33295,
      7,
      48369,
      7,
      9688,
      11,
      886,
      4008
    ],
    "start_token": 278,
    "end_token": 299,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      39432,
      2099,
      290,
      4129,
      329,
      5128,
      21201
    ],
    "label": "best_practice",
    "reason": "Checking type and length for input validation"
  },
  {
    "line": 47,
    "text": "        for stop in range(1, cur_cnt + 1):",
    "annotation": "\u2705 Best Practice: Use of a helper function for string manipulation improves code readability and reusability.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      329,
      2245,
      287,
      2837,
      7,
      16,
      11,
      1090,
      62,
      66,
      429,
      1343,
      352,
      2599
    ],
    "start_token": 299,
    "end_token": 320,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      257,
      31904,
      2163,
      329,
      4731,
      17512,
      19575,
      2438,
      1100,
      1799,
      290,
      302,
      385,
      1799,
      13
    ],
    "label": "best_practice",
    "reason": "Use of a helper function for string manipulation improves code readability and reusability."
  },
  {
    "line": 48,
    "text": "            end = cur_loc + stop",
    "annotation": "\u2705 Best Practice: Converting input to string ensures consistent behavior for different input types.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      886,
      796,
      1090,
      62,
      17946,
      1343,
      2245
    ],
    "start_token": 320,
    "end_token": 338,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      35602,
      889,
      5128,
      284,
      4731,
      19047,
      6414,
      4069,
      329,
      1180,
      5128,
      3858,
      13
    ],
    "label": "best_practice",
    "reason": "Converting input to string ensures consistent behavior for different input types."
  },
  {
    "line": 51,
    "text": "    slices = np.array(slices, dtype=\"object\")",
    "annotation": "\ud83e\udde0 ML Signal: Function definition with a single parameter",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      24314,
      796,
      45941,
      13,
      18747,
      7,
      82,
      677,
      274,
      11,
      288,
      4906,
      2625,
      15252,
      4943
    ],
    "start_token": 338,
    "end_token": 356,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      15553,
      6770,
      351,
      257,
      2060,
      11507
    ],
    "label": "ml_signal",
    "reason": "Function definition with a single parameter"
  },
  {
    "line": 53,
    "text": "    assert len(slices) == len(index)  # the i-th slice = index[i]",
    "annotation": "\ud83e\udde0 ML Signal: Function returns its input, indicating an identity function",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      6818,
      18896,
      7,
      82,
      677,
      274,
      8,
      6624,
      18896,
      7,
      9630,
      8,
      220,
      1303,
      262,
      1312,
      12,
      400,
      16416,
      796,
      6376,
      58,
      72,
      60
    ],
    "start_token": 356,
    "end_token": 383,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      15553,
      5860,
      663,
      5128,
      11,
      12739,
      281,
      5369,
      2163
    ],
    "label": "ml_signal",
    "reason": "Function returns its input, indicating an identity function"
  },
  {
    "line": 54,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Returning a function object, indicating a higher-order function pattern",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 383,
    "end_token": 383,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      42882,
      257,
      2163,
      2134,
      11,
      12739,
      257,
      2440,
      12,
      2875,
      2163,
      3912
    ],
    "label": "ml_signal",
    "reason": "Returning a function object, indicating a higher-order function pattern"
  },
  {
    "line": 53,
    "text": "    assert len(slices) == len(index)  # the i-th slice = index[i]",
    "annotation": "\u2705 Best Practice: Function docstring provides clear explanation of parameters and purpose",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      6818,
      18896,
      7,
      82,
      677,
      274,
      8,
      6624,
      18896,
      7,
      9630,
      8,
      220,
      1303,
      262,
      1312,
      12,
      400,
      16416,
      796,
      6376,
      58,
      72,
      60
    ],
    "start_token": 383,
    "end_token": 410,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      15553,
      2205,
      8841,
      3769,
      1598,
      7468,
      286,
      10007,
      290,
      4007
    ],
    "label": "best_practice",
    "reason": "Function docstring provides clear explanation of parameters and purpose"
  },
  {
    "line": 61,
    "text": "    This method is used to parse date arguments as target type.",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Use of assert for input validation can be disabled in optimized mode",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      770,
      2446,
      318,
      973,
      284,
      21136,
      3128,
      7159,
      355,
      2496,
      2099,
      13
    ],
    "start_token": 410,
    "end_token": 425,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      5765,
      286,
      6818,
      329,
      5128,
      21201,
      460,
      307,
      10058,
      287,
      23392,
      4235
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Use of assert for input validation can be disabled in optimized mode"
  },
  {
    "line": 64,
    "text": "        get_date_parse_fn('20120101')('2017-01-01') => '20170101'",
    "annotation": "\u2705 Best Practice: Use of np.zeros with dtype specified for consistent data type",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      651,
      62,
      4475,
      62,
      29572,
      62,
      22184,
      10786,
      1264,
      1264,
      486,
      6,
      5769,
      6,
      5539,
      12,
      486,
      12,
      486,
      11537,
      5218,
      705,
      5539,
      486,
      486,
      6
    ],
    "start_token": 425,
    "end_token": 458,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      45941,
      13,
      9107,
      418,
      351,
      288,
      4906,
      7368,
      329,
      6414,
      1366,
      2099
    ],
    "label": "best_practice",
    "reason": "Use of np.zeros with dtype specified for consistent data type"
  },
  {
    "line": 67,
    "text": "    if isinstance(target, int):",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Use of assert for input validation can be disabled in optimized mode",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      611,
      318,
      39098,
      7,
      16793,
      11,
      493,
      2599
    ],
    "start_token": 458,
    "end_token": 469,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      5765,
      286,
      6818,
      329,
      5128,
      21201,
      460,
      307,
      10058,
      287,
      23392,
      4235
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Use of assert for input validation can be disabled in optimized mode"
  },
  {
    "line": 69,
    "text": "        def _fn(x):",
    "annotation": "\ud83e\udde0 ML Signal: Use of np.concatenate for data manipulation",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      825,
      4808,
      22184,
      7,
      87,
      2599
    ],
    "start_token": 469,
    "end_token": 482,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      45941,
      13,
      1102,
      9246,
      268,
      378,
      329,
      1366,
      17512
    ],
    "label": "ml_signal",
    "reason": "Use of np.concatenate for data manipulation"
  },
  {
    "line": 83,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Custom dataset class for time series data, useful for ML model training",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 482,
    "end_token": 482,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      8562,
      27039,
      1398,
      329,
      640,
      2168,
      1366,
      11,
      4465,
      329,
      10373,
      2746,
      3047
    ],
    "label": "ml_signal",
    "reason": "Custom dataset class for time series data, useful for ML model training"
  },
  {
    "line": 83,
    "text": "",
    "annotation": "\u2705 Best Practice: Docstring provides clear documentation of class purpose and arguments",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 482,
    "end_token": 482,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      14432,
      8841,
      3769,
      1598,
      10314,
      286,
      1398,
      4007,
      290,
      7159
    ],
    "label": "best_practice",
    "reason": "Docstring provides clear documentation of class purpose and arguments"
  },
  {
    "line": 98,
    "text": "    if len(x) != seq_len:  # padding zeros",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential type confusion if handler is not dict or str",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      611,
      18896,
      7,
      87,
      8,
      14512,
      33756,
      62,
      11925,
      25,
      220,
      1303,
      24511,
      1976,
      27498
    ],
    "start_token": 482,
    "end_token": 500,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      2099,
      10802,
      611,
      21360,
      318,
      407,
      8633,
      393,
      965
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential type confusion if handler is not dict or str"
  },
  {
    "line": 100,
    "text": "    return x",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): init_instance_by_config may execute arbitrary code if handler is user-controlled",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      1441,
      2124
    ],
    "start_token": 500,
    "end_token": 505,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      2315,
      62,
      39098,
      62,
      1525,
      62,
      11250,
      743,
      12260,
      14977,
      2438,
      611,
      21360,
      318,
      2836,
      12,
      14401
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "init_instance_by_config may execute arbitrary code if handler is user-controlled"
  },
  {
    "line": 103,
    "text": "class MTSDatasetH(DatasetH):",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): getattr with default None can lead to unexpected behavior if fields is not present",
    "confidence": 0.5,
    "tokens": [
      4871,
      337,
      4694,
      27354,
      292,
      316,
      39,
      7,
      27354,
      292,
      316,
      39,
      2599
    ],
    "start_token": 505,
    "end_token": 518,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      651,
      35226,
      351,
      4277,
      6045,
      460,
      1085,
      284,
      10059,
      4069,
      611,
      7032,
      318,
      407,
      1944
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "getattr with default None can lead to unexpected behavior if fields is not present"
  },
  {
    "line": 106,
    "text": "    Args:",
    "annotation": "\ud83e\udde0 ML Signal: guess_horizon function usage indicates dynamic horizon determination",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      943,
      14542,
      25
    ],
    "start_token": 518,
    "end_token": 524,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      4724,
      62,
      17899,
      8637,
      2163,
      8748,
      9217,
      8925,
      17810,
      12123
    ],
    "label": "ml_signal",
    "reason": "guess_horizon function usage indicates dynamic horizon determination"
  },
  {
    "line": 108,
    "text": "        segments (dict): data split segments",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): AssertionError can expose internal logic if not handled",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      17894,
      357,
      11600,
      2599,
      1366,
      6626,
      17894
    ],
    "start_token": 524,
    "end_token": 538,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      2195,
      861,
      295,
      12331,
      460,
      15651,
      5387,
      9156,
      611,
      407,
      12118
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "AssertionError can expose internal logic if not handled"
  },
  {
    "line": 110,
    "text": "        horizon (int): label horizon",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): AssertionError can expose internal logic if not handled",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      17810,
      357,
      600,
      2599,
      6167,
      17810
    ],
    "start_token": 538,
    "end_token": 551,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      2195,
      861,
      295,
      12331,
      460,
      15651,
      5387,
      9156,
      611,
      407,
      12118
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "AssertionError can expose internal logic if not handled"
  },
  {
    "line": 112,
    "text": "        memory_mode (str): memory mode (daily or sample)",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): AssertionError can expose internal logic if not handled",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      4088,
      62,
      14171,
      357,
      2536,
      2599,
      4088,
      4235,
      357,
      29468,
      393,
      6291,
      8
    ],
    "start_token": 551,
    "end_token": 571,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      2195,
      861,
      295,
      12331,
      460,
      15651,
      5387,
      9156,
      611,
      407,
      12118
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "AssertionError can expose internal logic if not handled"
  },
  {
    "line": 114,
    "text": "        n_samples (int): number of samples in the same day",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): AssertionError can expose internal logic if not handled",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      299,
      62,
      82,
      12629,
      357,
      600,
      2599,
      1271,
      286,
      8405,
      287,
      262,
      976,
      1110
    ],
    "start_token": 571,
    "end_token": 592,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      2195,
      861,
      295,
      12331,
      460,
      15651,
      5387,
      9156,
      611,
      407,
      12118
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "AssertionError can expose internal logic if not handled"
  },
  {
    "line": 116,
    "text": "        drop_last (bool): whether drop last batch < batch_size",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Warnings can be ignored or missed by the user",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      4268,
      62,
      12957,
      357,
      30388,
      2599,
      1771,
      4268,
      938,
      15458,
      1279,
      15458,
      62,
      7857
    ],
    "start_token": 592,
    "end_token": 613,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      39567,
      654,
      460,
      307,
      9514,
      393,
      6825,
      416,
      262,
      2836
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Warnings can be ignored or missed by the user"
  },
  {
    "line": 119,
    "text": "",
    "annotation": "\u2705 Best Practice: Use of self to store instance variables",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 613,
    "end_token": 613,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      2116,
      284,
      3650,
      4554,
      9633
    ],
    "label": "best_practice",
    "reason": "Use of self to store instance variables"
  },
  {
    "line": 129,
    "text": "        n_samples=None,",
    "annotation": "\u2705 Best Practice: Grouping related parameters into a tuple for easy access",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      299,
      62,
      82,
      12629,
      28,
      14202,
      11
    ],
    "start_token": 613,
    "end_token": 627,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      4912,
      278,
      3519,
      10007,
      656,
      257,
      46545,
      329,
      2562,
      1895
    ],
    "label": "best_practice",
    "reason": "Grouping related parameters into a tuple for easy access"
  },
  {
    "line": 131,
    "text": "        drop_last=False,",
    "annotation": "\u2705 Best Practice: Calling superclass constructor to ensure proper initialization",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      4268,
      62,
      12957,
      28,
      25101,
      11
    ],
    "start_token": 627,
    "end_token": 640,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      32677,
      2208,
      4871,
      23772,
      284,
      4155,
      1774,
      37588
    ],
    "label": "best_practice",
    "reason": "Calling superclass constructor to ensure proper initialization"
  },
  {
    "line": 122,
    "text": "        handler,",
    "annotation": "\u2705 Best Practice: Call to superclass method ensures proper initialization and behavior.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      21360,
      11
    ],
    "start_token": 640,
    "end_token": 649,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      4889,
      284,
      2208,
      4871,
      2446,
      19047,
      1774,
      37588,
      290,
      4069,
      13
    ],
    "label": "best_practice",
    "reason": "Call to superclass method ensures proper initialization and behavior."
  },
  {
    "line": 125,
    "text": "        horizon=0,",
    "annotation": "\u2705 Best Practice: Conditional check for None before using a variable.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      17810,
      28,
      15,
      11
    ],
    "start_token": 649,
    "end_token": 660,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      9724,
      1859,
      2198,
      329,
      6045,
      878,
      1262,
      257,
      7885,
      13
    ],
    "label": "best_practice",
    "reason": "Conditional check for None before using a variable."
  },
  {
    "line": 128,
    "text": "        batch_size=-1,",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Accessing a potentially private attribute `_learn`.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      15458,
      62,
      7857,
      10779,
      16,
      11
    ],
    "start_token": 660,
    "end_token": 673,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      8798,
      278,
      257,
      6196,
      2839,
      11688,
      4600,
      62,
      35720,
      44646
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Accessing a potentially private attribute `_learn`."
  },
  {
    "line": 131,
    "text": "        drop_last=False,",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Catching a broad exception, which can hide other issues.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      4268,
      62,
      12957,
      28,
      25101,
      11
    ],
    "start_token": 673,
    "end_token": 686,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      327,
      19775,
      257,
      3154,
      6631,
      11,
      543,
      460,
      7808,
      584,
      2428,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Catching a broad exception, which can hide other issues."
  },
  {
    "line": 133,
    "text": "        **kwargs,",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Accessing a potentially private attribute `_data`.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      12429,
      46265,
      22046,
      11
    ],
    "start_token": 686,
    "end_token": 697,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      8798,
      278,
      257,
      6196,
      2839,
      11688,
      4600,
      62,
      7890,
      44646
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Accessing a potentially private attribute `_data`."
  },
  {
    "line": 135,
    "text": "        if horizon == 0:",
    "annotation": "\u2705 Best Practice: Swapping index levels for proper data organization.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      611,
      17810,
      6624,
      657,
      25
    ],
    "start_token": 697,
    "end_token": 709,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      2451,
      5912,
      6376,
      2974,
      329,
      1774,
      1366,
      4009,
      13
    ],
    "label": "best_practice",
    "reason": "Swapping index levels for proper data organization."
  },
  {
    "line": 137,
    "text": "            if isinstance(handler, (dict, str)):",
    "annotation": "\u2705 Best Practice: Sorting index for efficient data access.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      611,
      318,
      39098,
      7,
      30281,
      11,
      357,
      11600,
      11,
      965,
      8,
      2599
    ],
    "start_token": 709,
    "end_token": 732,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      311,
      24707,
      6376,
      329,
      6942,
      1366,
      1895,
      13
    ],
    "label": "best_practice",
    "reason": "Sorting index for efficient data access."
  },
  {
    "line": 139,
    "text": "            assert \"label\" in getattr(handler.data_loader, \"fields\", None)",
    "annotation": "\ud83e\udde0 ML Signal: Extracting features and converting to float32, common in ML preprocessing.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      6818,
      366,
      18242,
      1,
      287,
      651,
      35226,
      7,
      30281,
      13,
      7890,
      62,
      29356,
      11,
      366,
      25747,
      1600,
      6045,
      8
    ],
    "start_token": 732,
    "end_token": 762,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      29677,
      278,
      3033,
      290,
      23202,
      284,
      12178,
      2624,
      11,
      2219,
      287,
      10373,
      662,
      36948,
      13
    ],
    "label": "ml_signal",
    "reason": "Extracting features and converting to float32, common in ML preprocessing."
  },
  {
    "line": 141,
    "text": "            horizon = guess_horizon([label])",
    "annotation": "\ud83e\udde0 ML Signal: Handling NaN values, a common preprocessing step in ML.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      17810,
      796,
      4724,
      62,
      17899,
      8637,
      26933,
      18242,
      12962
    ],
    "start_token": 762,
    "end_token": 782,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      49500,
      11013,
      45,
      3815,
      11,
      257,
      2219,
      662,
      36948,
      2239,
      287,
      10373,
      13
    ],
    "label": "ml_signal",
    "reason": "Handling NaN values, a common preprocessing step in ML."
  },
  {
    "line": 143,
    "text": "        assert num_states == 0 or horizon > 0, \"please specify `horizon` to avoid data leakage\"",
    "annotation": "\ud83e\udde0 ML Signal: Extracting labels and converting to float32, common in ML preprocessing.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      6818,
      997,
      62,
      27219,
      6624,
      657,
      393,
      17810,
      1875,
      657,
      11,
      366,
      29688,
      11986,
      4600,
      17899,
      8637,
      63,
      284,
      3368,
      1366,
      47988,
      1
    ],
    "start_token": 782,
    "end_token": 812,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      29677,
      278,
      14722,
      290,
      23202,
      284,
      12178,
      2624,
      11,
      2219,
      287,
      10373,
      662,
      36948,
      13
    ],
    "label": "ml_signal",
    "reason": "Extracting labels and converting to float32, common in ML preprocessing."
  },
  {
    "line": 147,
    "text": "",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential data shape mismatch warning.",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 812,
    "end_token": 812,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      1366,
      5485,
      46318,
      6509,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential data shape mismatch warning."
  },
  {
    "line": 148,
    "text": "        if batch_size > 0 and n_samples is not None:",
    "annotation": "\u26a0\ufe0f SAST Risk (Medium): Assertion used for input validation, could be disabled in production.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      611,
      15458,
      62,
      7857,
      1875,
      657,
      290,
      299,
      62,
      82,
      12629,
      318,
      407,
      6045,
      25
    ],
    "start_token": 812,
    "end_token": 834,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      31205,
      2599,
      2195,
      861,
      295,
      973,
      329,
      5128,
      21201,
      11,
      714,
      307,
      10058,
      287,
      3227,
      13
    ],
    "label": "sast_risk",
    "severity": "Medium",
    "reason": "Assertion used for input validation, could be disabled in production."
  },
  {
    "line": 151,
    "text": "        self.seq_len = seq_len",
    "annotation": "\ud83e\udde0 ML Signal: Creating time series slices, indicative of sequence modeling.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      41068,
      62,
      11925,
      796,
      33756,
      62,
      11925
    ],
    "start_token": 834,
    "end_token": 850,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      30481,
      640,
      2168,
      24314,
      11,
      29105,
      286,
      8379,
      21128,
      13
    ],
    "label": "ml_signal",
    "reason": "Creating time series slices, indicative of sequence modeling."
  },
  {
    "line": 153,
    "text": "        self.num_states = num_states",
    "annotation": "\u2705 Best Practice: Using dictionary comprehension for efficient initialization.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      22510,
      62,
      27219,
      796,
      997,
      62,
      27219
    ],
    "start_token": 850,
    "end_token": 866,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      8554,
      22155,
      35915,
      329,
      6942,
      37588,
      13
    ],
    "label": "best_practice",
    "reason": "Using dictionary comprehension for efficient initialization."
  },
  {
    "line": 157,
    "text": "        self.shuffle = shuffle",
    "annotation": "\ud83e\udde0 ML Signal: Converting daily slices to numpy array, common in ML for batch processing.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      1477,
      18137,
      796,
      36273
    ],
    "start_token": 866,
    "end_token": 879,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      35602,
      889,
      4445,
      24314,
      284,
      299,
      32152,
      7177,
      11,
      2219,
      287,
      10373,
      329,
      15458,
      7587,
      13
    ],
    "label": "ml_signal",
    "reason": "Converting daily slices to numpy array, common in ML for batch processing."
  },
  {
    "line": 159,
    "text": "        self.input_size = input_size",
    "annotation": "\u2705 Best Practice: Using pandas Series for easy manipulation and access.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      15414,
      62,
      7857,
      796,
      5128,
      62,
      7857
    ],
    "start_token": 879,
    "end_token": 895,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      8554,
      19798,
      292,
      7171,
      329,
      2562,
      17512,
      290,
      1895,
      13
    ],
    "label": "best_practice",
    "reason": "Using pandas Series for easy manipulation and access."
  },
  {
    "line": 162,
    "text": "        super().__init__(handler, segments, **kwargs)",
    "annotation": "\ud83e\udde0 ML Signal: Initializing memory for state tracking, common in stateful models.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2208,
      22446,
      834,
      15003,
      834,
      7,
      30281,
      11,
      17894,
      11,
      12429,
      46265,
      22046,
      8
    ],
    "start_token": 895,
    "end_token": 916,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      20768,
      2890,
      4088,
      329,
      1181,
      9646,
      11,
      2219,
      287,
      1181,
      913,
      4981,
      13
    ],
    "label": "ml_signal",
    "reason": "Initializing memory for state tracking, common in stateful models."
  },
  {
    "line": 165,
    "text": "        super().setup_data(**kwargs)",
    "annotation": "\ud83e\udde0 ML Signal: Initializing memory for daily state tracking, common in stateful models.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2208,
      22446,
      40406,
      62,
      7890,
      7,
      1174,
      46265,
      22046,
      8
    ],
    "start_token": 916,
    "end_token": 933,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      20768,
      2890,
      4088,
      329,
      4445,
      1181,
      9646,
      11,
      2219,
      287,
      1181,
      913,
      4981,
      13
    ],
    "label": "ml_signal",
    "reason": "Initializing memory for daily state tracking, common in stateful models."
  },
  {
    "line": 168,
    "text": "            self.handler.setup_data(**handler_kwargs)",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential for unhandled memory_mode values.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      30281,
      13,
      40406,
      62,
      7890,
      7,
      1174,
      30281,
      62,
      46265,
      22046,
      8
    ],
    "start_token": 933,
    "end_token": 958,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      329,
      555,
      38788,
      4088,
      62,
      14171,
      3815,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential for unhandled memory_mode values."
  },
  {
    "line": 170,
    "text": "        # pre-fetch data and change index to <code, date>",
    "annotation": "\ud83e\udde0 ML Signal: Initializing zero arrays for padding or state initialization.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1303,
      662,
      12,
      69,
      7569,
      1366,
      290,
      1487,
      6376,
      284,
      1279,
      8189,
      11,
      3128,
      29
    ],
    "start_token": 958,
    "end_token": 980,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      20768,
      2890,
      6632,
      26515,
      329,
      24511,
      393,
      1181,
      37588,
      13
    ],
    "label": "ml_signal",
    "reason": "Initializing zero arrays for padding or state initialization."
  },
  {
    "line": 153,
    "text": "        self.num_states = num_states",
    "annotation": "\ud83e\udde0 ML Signal: Use of a helper function to parse dates, indicating a pattern for date handling",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      22510,
      62,
      27219,
      796,
      997,
      62,
      27219
    ],
    "start_token": 980,
    "end_token": 996,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      257,
      31904,
      2163,
      284,
      21136,
      9667,
      11,
      12739,
      257,
      3912,
      329,
      3128,
      9041
    ],
    "label": "ml_signal",
    "reason": "Use of a helper function to parse dates, indicating a pattern for date handling"
  },
  {
    "line": 160,
    "text": "        self.params = (batch_size, n_samples, drop_last, shuffle)  # for train/eval switch",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Use of NotImplementedError for unsupported input types",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      37266,
      796,
      357,
      43501,
      62,
      7857,
      11,
      299,
      62,
      82,
      12629,
      11,
      4268,
      62,
      12957,
      11,
      36273,
      8,
      220,
      1303,
      329,
      4512,
      14,
      18206,
      5078
    ],
    "start_token": 996,
    "end_token": 1030,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      5765,
      286,
      1892,
      3546,
      1154,
      12061,
      12331,
      329,
      24222,
      5128,
      3858
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Use of NotImplementedError for unsupported input types"
  },
  {
    "line": 162,
    "text": "        super().__init__(handler, segments, **kwargs)",
    "annotation": "\ud83e\udde0 ML Signal: Conversion of start and stop to timestamps, indicating a pattern for date range processing",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2208,
      22446,
      834,
      15003,
      834,
      7,
      30281,
      11,
      17894,
      11,
      12429,
      46265,
      22046,
      8
    ],
    "start_token": 1030,
    "end_token": 1051,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      44101,
      286,
      923,
      290,
      2245,
      284,
      4628,
      395,
      9430,
      11,
      12739,
      257,
      3912,
      329,
      3128,
      2837,
      7587
    ],
    "label": "ml_signal",
    "reason": "Conversion of start and stop to timestamps, indicating a pattern for date range processing"
  },
  {
    "line": 165,
    "text": "        super().setup_data(**kwargs)",
    "annotation": "\u2705 Best Practice: Use of copy to avoid modifying the original object",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2208,
      22446,
      40406,
      62,
      7890,
      7,
      1174,
      46265,
      22046,
      8
    ],
    "start_token": 1051,
    "end_token": 1068,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      4866,
      284,
      3368,
      30620,
      262,
      2656,
      2134
    ],
    "label": "best_practice",
    "reason": "Use of copy to avoid modifying the original object"
  },
  {
    "line": 172,
    "text": "        try:",
    "annotation": "\ud83e\udde0 ML Signal: Filtering based on date range, indicating a pattern for time series data processing",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1949,
      25
    ],
    "start_token": 1068,
    "end_token": 1077,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      7066,
      20212,
      1912,
      319,
      3128,
      2837,
      11,
      12739,
      257,
      3912,
      329,
      640,
      2168,
      1366,
      7587
    ],
    "label": "ml_signal",
    "reason": "Filtering based on date range, indicating a pattern for time series data processing"
  },
  {
    "line": 174,
    "text": "            # FIXME: currently we cannot support switching from `_learn` to `_infer` for inference",
    "annotation": "\ud83e\udde0 ML Signal: Method accessing an internal attribute, indicating encapsulation usage",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1303,
      44855,
      11682,
      25,
      3058,
      356,
      2314,
      1104,
      15430,
      422,
      4600,
      62,
      35720,
      63,
      284,
      4600,
      62,
      259,
      2232,
      63,
      329,
      32278
    ],
    "start_token": 1077,
    "end_token": 1110,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      11789,
      22534,
      281,
      5387,
      11688,
      11,
      12739,
      32652,
      1741,
      8748
    ],
    "label": "ml_signal",
    "reason": "Method accessing an internal attribute, indicating encapsulation usage"
  },
  {
    "line": 175,
    "text": "        except Exception:",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential for KeyError if index is not present in _index",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2845,
      35528,
      25
    ],
    "start_token": 1110,
    "end_token": 1120,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      329,
      7383,
      12331,
      611,
      6376,
      318,
      407,
      1944,
      287,
      4808,
      9630
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential for KeyError if index is not present in _index"
  },
  {
    "line": 177,
    "text": "            df = self.handler._data.copy()",
    "annotation": "\ud83e\udde0 ML Signal: Accessing a dictionary-like structure by key",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      47764,
      796,
      2116,
      13,
      30281,
      13557,
      7890,
      13,
      30073,
      3419
    ],
    "start_token": 1120,
    "end_token": 1141,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      8798,
      278,
      257,
      22155,
      12,
      2339,
      4645,
      416,
      1994
    ],
    "label": "ml_signal",
    "reason": "Accessing a dictionary-like structure by key"
  },
  {
    "line": 176,
    "text": "            warnings.warn(\"cannot access `_learn`, will load raw data\")",
    "annotation": "\u2705 Best Practice: Consider adding a docstring to describe the purpose and usage of the function",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      14601,
      13,
      40539,
      7203,
      66,
      34574,
      1895,
      4600,
      62,
      35720,
      47671,
      481,
      3440,
      8246,
      1366,
      4943
    ],
    "start_token": 1141,
    "end_token": 1168,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      12642,
      4375,
      257,
      2205,
      8841,
      284,
      6901,
      262,
      4007,
      290,
      8748,
      286,
      262,
      2163
    ],
    "label": "best_practice",
    "reason": "Consider adding a docstring to describe the purpose and usage of the function"
  },
  {
    "line": 178,
    "text": "        df.index = df.index.swaplevel()",
    "annotation": "\ud83e\udde0 ML Signal: Usage of pandas Index, indicating data manipulation or analysis",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      47764,
      13,
      9630,
      796,
      47764,
      13,
      9630,
      13,
      2032,
      499,
      5715,
      3419
    ],
    "start_token": 1168,
    "end_token": 1187,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      29566,
      286,
      19798,
      292,
      12901,
      11,
      12739,
      1366,
      17512,
      393,
      3781
    ],
    "label": "ml_signal",
    "reason": "Usage of pandas Index, indicating data manipulation or analysis"
  },
  {
    "line": 179,
    "text": "        df.sort_index(inplace=True)",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential KeyError if daily_index is not in _daily_index",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      47764,
      13,
      30619,
      62,
      9630,
      7,
      259,
      5372,
      28,
      17821,
      8
    ],
    "start_token": 1187,
    "end_token": 1205,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      7383,
      12331,
      611,
      4445,
      62,
      9630,
      318,
      407,
      287,
      4808,
      29468,
      62,
      9630
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential KeyError if daily_index is not in _daily_index"
  },
  {
    "line": 179,
    "text": "        df.sort_index(inplace=True)",
    "annotation": "\u2705 Best Practice: Check for invalid state before proceeding with operations",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      47764,
      13,
      30619,
      62,
      9630,
      7,
      259,
      5372,
      28,
      17821,
      8
    ],
    "start_token": 1205,
    "end_token": 1223,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      6822,
      329,
      12515,
      1181,
      878,
      18788,
      351,
      4560
    ],
    "label": "best_practice",
    "reason": "Check for invalid state before proceeding with operations"
  },
  {
    "line": 182,
    "text": "        self._data = df[\"feature\"].values.astype(\"float32\")",
    "annotation": "\ud83e\udde0 ML Signal: Handling of torch.Tensor to numpy conversion",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13557,
      7890,
      796,
      47764,
      14692,
      30053,
      1,
      4083,
      27160,
      13,
      459,
      2981,
      7203,
      22468,
      2624,
      4943
    ],
    "start_token": 1223,
    "end_token": 1247,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      49500,
      286,
      28034,
      13,
      51,
      22854,
      284,
      299,
      32152,
      11315
    ],
    "label": "ml_signal",
    "reason": "Handling of torch.Tensor to numpy conversion"
  },
  {
    "line": 184,
    "text": "        self._label = df[\"label\"].squeeze().values.astype(\"float32\")",
    "annotation": "\u2705 Best Practice: Detach tensor from computation graph before converting to numpy",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13557,
      18242,
      796,
      47764,
      14692,
      18242,
      1,
      4083,
      16485,
      1453,
      2736,
      22446,
      27160,
      13,
      459,
      2981,
      7203,
      22468,
      2624,
      4943
    ],
    "start_token": 1247,
    "end_token": 1275,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      4614,
      620,
      11192,
      273,
      422,
      29964,
      4823,
      878,
      23202,
      284,
      299,
      32152
    ],
    "label": "best_practice",
    "reason": "Detach tensor from computation graph before converting to numpy"
  },
  {
    "line": 186,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Usage of custom memory management",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 1275,
    "end_token": 1275,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      29566,
      286,
      2183,
      4088,
      4542
    ],
    "label": "ml_signal",
    "reason": "Usage of custom memory management"
  },
  {
    "line": 185,
    "text": "        self._index = df.index",
    "annotation": "\u2705 Best Practice: Check for invalid state before performing operations",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13557,
      9630,
      796,
      47764,
      13,
      9630
    ],
    "start_token": 1275,
    "end_token": 1289,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      6822,
      329,
      12515,
      1181,
      878,
      9489,
      4560
    ],
    "label": "best_practice",
    "reason": "Check for invalid state before performing operations"
  },
  {
    "line": 187,
    "text": "        if self.input_size is not None and self.input_size != self._data.shape[1]:",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Raising a generic exception without additional context",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      611,
      2116,
      13,
      15414,
      62,
      7857,
      318,
      407,
      6045,
      290,
      2116,
      13,
      15414,
      62,
      7857,
      14512,
      2116,
      13557,
      7890,
      13,
      43358,
      58,
      16,
      5974
    ],
    "start_token": 1289,
    "end_token": 1320,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      7567,
      1710,
      257,
      14276,
      6631,
      1231,
      3224,
      4732
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Raising a generic exception without additional context"
  },
  {
    "line": 189,
    "text": "            assert self._data.shape[1] % self.input_size == 0, \"data mismatch, please check `input_size`\"",
    "annotation": "\ud83e\udde0 ML Signal: Pattern of resetting or clearing data structures",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      6818,
      2116,
      13557,
      7890,
      13,
      43358,
      58,
      16,
      60,
      4064,
      2116,
      13,
      15414,
      62,
      7857,
      6624,
      657,
      11,
      366,
      7890,
      46318,
      11,
      3387,
      2198,
      4600,
      15414,
      62,
      7857,
      63,
      1
    ],
    "start_token": 1320,
    "end_token": 1361,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      23939,
      286,
      13259,
      889,
      393,
      17304,
      1366,
      8573
    ],
    "label": "ml_signal",
    "reason": "Pattern of resetting or clearing data structures"
  },
  {
    "line": 190,
    "text": "",
    "annotation": "\u2705 Best Practice: Consider adding a docstring to describe the parameters and return value",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 1361,
    "end_token": 1361,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      12642,
      4375,
      257,
      2205,
      8841,
      284,
      6901,
      262,
      10007,
      290,
      1441,
      1988
    ],
    "label": "best_practice",
    "reason": "Consider adding a docstring to describe the parameters and return value"
  },
  {
    "line": 191,
    "text": "        # create batch slices",
    "annotation": "\ud83e\udde0 ML Signal: Method name 'train' suggests this is part of a machine learning model training process",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1303,
      2251,
      15458,
      24314
    ],
    "start_token": 1361,
    "end_token": 1372,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      11789,
      1438,
      705,
      27432,
      6,
      5644,
      428,
      318,
      636,
      286,
      257,
      4572,
      4673,
      2746,
      3047,
      1429
    ],
    "label": "ml_signal",
    "reason": "Method name 'train' suggests this is part of a machine learning model training process"
  },
  {
    "line": 193,
    "text": "",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Unpacking without validation could lead to runtime errors if 'self.params' does not have exactly four elements",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 1372,
    "end_token": 1372,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      791,
      41291,
      1231,
      21201,
      714,
      1085,
      284,
      19124,
      8563,
      611,
      705,
      944,
      13,
      37266,
      6,
      857,
      407,
      423,
      3446,
      1440,
      4847
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Unpacking without validation could lead to runtime errors if 'self.params' does not have exactly four elements"
  },
  {
    "line": 194,
    "text": "        # create daily slices",
    "annotation": "\u2705 Best Practice: Consider validating 'self.params' to ensure it contains the expected number of elements",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1303,
      2251,
      4445,
      24314
    ],
    "start_token": 1372,
    "end_token": 1383,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      12642,
      4938,
      803,
      705,
      944,
      13,
      37266,
      6,
      284,
      4155,
      340,
      4909,
      262,
      2938,
      1271,
      286,
      4847
    ],
    "label": "best_practice",
    "reason": "Consider validating 'self.params' to ensure it contains the expected number of elements"
  },
  {
    "line": 193,
    "text": "",
    "annotation": "\u2705 Best Practice: Consider adding type hints for method parameters and return type",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 1383,
    "end_token": 1383,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      12642,
      4375,
      2099,
      20269,
      329,
      2446,
      10007,
      290,
      1441,
      2099
    ],
    "label": "best_practice",
    "reason": "Consider adding type hints for method parameters and return type"
  },
  {
    "line": 195,
    "text": "        daily_slices = {date: [] for date in sorted(self._index.unique(level=1))}  # sorted by date",
    "annotation": "\u2705 Best Practice: Use a constant or named variable for the magic number -1",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      4445,
      62,
      82,
      677,
      274,
      796,
      1391,
      4475,
      25,
      17635,
      329,
      3128,
      287,
      23243,
      7,
      944,
      13557,
      9630,
      13,
      34642,
      7,
      5715,
      28,
      16,
      4008,
      92,
      220,
      1303,
      23243,
      416,
      3128
    ],
    "start_token": 1383,
    "end_token": 1421,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      257,
      6937,
      393,
      3706,
      7885,
      329,
      262,
      5536,
      1271,
      532,
      16
    ],
    "label": "best_practice",
    "reason": "Use a constant or named variable for the magic number -1"
  },
  {
    "line": 197,
    "text": "            daily_slices[date].append(self._batch_slices[i])",
    "annotation": "\u2705 Best Practice: Consider adding comments to explain why certain default values are set",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      4445,
      62,
      82,
      677,
      274,
      58,
      4475,
      4083,
      33295,
      7,
      944,
      13557,
      43501,
      62,
      82,
      677,
      274,
      58,
      72,
      12962
    ],
    "start_token": 1421,
    "end_token": 1452,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      12642,
      4375,
      3651,
      284,
      4727,
      1521,
      1728,
      4277,
      3815,
      389,
      900
    ],
    "label": "best_practice",
    "reason": "Consider adding comments to explain why certain default values are set"
  },
  {
    "line": 198,
    "text": "        self._daily_slices = np.array(list(daily_slices.values()), dtype=\"object\")",
    "annotation": "\ud83e\udde0 ML Signal: Method name with underscore suggests a private method, indicating encapsulation.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13557,
      29468,
      62,
      82,
      677,
      274,
      796,
      45941,
      13,
      18747,
      7,
      4868,
      7,
      29468,
      62,
      82,
      677,
      274,
      13,
      27160,
      3419,
      828,
      288,
      4906,
      2625,
      15252,
      4943
    ],
    "start_token": 1452,
    "end_token": 1487,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      11789,
      1438,
      351,
      44810,
      5644,
      257,
      2839,
      2446,
      11,
      12739,
      32652,
      1741,
      13
    ],
    "label": "ml_signal",
    "reason": "Method name with underscore suggests a private method, indicating encapsulation."
  },
  {
    "line": 200,
    "text": "",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Using negative values for batch_size might lead to unexpected behavior.",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 1487,
    "end_token": 1487,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      8554,
      4633,
      3815,
      329,
      15458,
      62,
      7857,
      1244,
      1085,
      284,
      10059,
      4069,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Using negative values for batch_size might lead to unexpected behavior."
  },
  {
    "line": 202,
    "text": "        if self.memory_mode == \"sample\":",
    "annotation": "\u2705 Best Practice: Use of copy() to avoid modifying the original list.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      611,
      2116,
      13,
      31673,
      62,
      14171,
      6624,
      366,
      39873,
      1298
    ],
    "start_token": 1487,
    "end_token": 1504,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      4866,
      3419,
      284,
      3368,
      30620,
      262,
      2656,
      1351,
      13
    ],
    "label": "best_practice",
    "reason": "Use of copy() to avoid modifying the original list."
  },
  {
    "line": 206,
    "text": "        else:",
    "annotation": "\u2705 Best Practice: Use of copy() to avoid modifying the original list.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2073,
      25
    ],
    "start_token": 1504,
    "end_token": 1513,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      4866,
      3419,
      284,
      3368,
      30620,
      262,
      2656,
      1351,
      13
    ],
    "label": "best_practice",
    "reason": "Use of copy() to avoid modifying the original list."
  },
  {
    "line": 209,
    "text": "        # padding tensor",
    "annotation": "\u2705 Best Practice: Returning a tuple for multiple values is a common Python idiom.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1303,
      24511,
      11192,
      273
    ],
    "start_token": 1513,
    "end_token": 1524,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      42882,
      257,
      46545,
      329,
      3294,
      3815,
      318,
      257,
      2219,
      11361,
      4686,
      29005,
      13
    ],
    "label": "best_practice",
    "reason": "Returning a tuple for multiple values is a common Python idiom."
  },
  {
    "line": 206,
    "text": "        else:",
    "annotation": "\u2705 Best Practice: Descriptive variable names improve code readability.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2073,
      25
    ],
    "start_token": 1524,
    "end_token": 1533,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      2935,
      6519,
      425,
      7885,
      3891,
      2987,
      2438,
      1100,
      1799,
      13
    ],
    "label": "best_practice",
    "reason": "Descriptive variable names improve code readability."
  },
  {
    "line": 208,
    "text": "",
    "annotation": "\u2705 Best Practice: Using if-else for clear conditional logic.",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 1533,
    "end_token": 1533,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      8554,
      611,
      12,
      17772,
      329,
      1598,
      26340,
      9156,
      13
    ],
    "label": "best_practice",
    "reason": "Using if-else for clear conditional logic."
  },
  {
    "line": 210,
    "text": "        self._zeros = np.zeros((self.seq_len, max(self.num_states, self._data.shape[1])), dtype=np.float32)",
    "annotation": "\ud83e\udde0 ML Signal: Usage of integer division to determine length.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13557,
      9107,
      418,
      796,
      45941,
      13,
      9107,
      418,
      19510,
      944,
      13,
      41068,
      62,
      11925,
      11,
      3509,
      7,
      944,
      13,
      22510,
      62,
      27219,
      11,
      2116,
      13557,
      7890,
      13,
      43358,
      58,
      16,
      12962,
      828,
      288,
      4906,
      28,
      37659,
      13,
      22468,
      2624,
      8
    ],
    "start_token": 1533,
    "end_token": 1581,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      29566,
      286,
      18253,
      7297,
      284,
      5004,
      4129,
      13
    ],
    "label": "ml_signal",
    "reason": "Usage of integer division to determine length."
  },
  {
    "line": 212,
    "text": "    def _prepare_seg(self, slc, **kwargs):",
    "annotation": "\ud83e\udde0 ML Signal: Calculation pattern for determining number of batches.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      825,
      4808,
      46012,
      533,
      62,
      325,
      70,
      7,
      944,
      11,
      1017,
      66,
      11,
      12429,
      46265,
      22046,
      2599
    ],
    "start_token": 1581,
    "end_token": 1601,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      2199,
      14902,
      3912,
      329,
      13213,
      1271,
      286,
      37830,
      13
    ],
    "label": "ml_signal",
    "reason": "Calculation pattern for determining number of batches."
  },
  {
    "line": 213,
    "text": "        fn = _get_date_parse_fn(self._index[0][1])",
    "annotation": "\ud83e\udde0 ML Signal: Shuffling data is a common practice in ML to ensure model generalization.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      24714,
      796,
      4808,
      1136,
      62,
      4475,
      62,
      29572,
      62,
      22184,
      7,
      944,
      13557,
      9630,
      58,
      15,
      7131,
      16,
      12962
    ],
    "start_token": 1601,
    "end_token": 1627,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      911,
      1648,
      1359,
      1366,
      318,
      257,
      2219,
      3357,
      287,
      10373,
      284,
      4155,
      2746,
      2276,
      1634,
      13
    ],
    "label": "ml_signal",
    "reason": "Shuffling data is a common practice in ML to ensure model generalization."
  },
  {
    "line": 217,
    "text": "            start, stop = slc",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential for index out of range if batch_size is not properly validated.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      923,
      11,
      2245,
      796,
      1017,
      66
    ],
    "start_token": 1627,
    "end_token": 1644,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      329,
      6376,
      503,
      286,
      2837,
      611,
      15458,
      62,
      7857,
      318,
      407,
      6105,
      31031,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential for index out of range if batch_size is not properly validated."
  },
  {
    "line": 228,
    "text": "        obj._zeros = self._zeros",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Negative batch_size could lead to unexpected behavior.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      26181,
      13557,
      9107,
      418,
      796,
      2116,
      13557,
      9107,
      418
    ],
    "start_token": 1644,
    "end_token": 1660,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      36183,
      15458,
      62,
      7857,
      714,
      1085,
      284,
      10059,
      4069,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Negative batch_size could lead to unexpected behavior."
  },
  {
    "line": 233,
    "text": "        obj._daily_slices = self._daily_slices[mask]",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Slicing with negative indices can lead to unexpected results.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      26181,
      13557,
      29468,
      62,
      82,
      677,
      274,
      796,
      2116,
      13557,
      29468,
      62,
      82,
      677,
      274,
      58,
      27932,
      60
    ],
    "start_token": 1660,
    "end_token": 1685,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      311,
      677,
      278,
      351,
      4633,
      36525,
      460,
      1085,
      284,
      10059,
      2482,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Slicing with negative indices can lead to unexpected results."
  },
  {
    "line": 236,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Random sampling is often used in ML for data augmentation or balancing.",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 1685,
    "end_token": 1685,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      14534,
      19232,
      318,
      1690,
      973,
      287,
      10373,
      329,
      1366,
      16339,
      14374,
      393,
      22486,
      13
    ],
    "label": "ml_signal",
    "reason": "Random sampling is often used in ML for data augmentation or balancing."
  },
  {
    "line": 244,
    "text": "        if self.num_states == 0:",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Reshaping data without validation can lead to unexpected shapes.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      611,
      2116,
      13,
      22510,
      62,
      27219,
      6624,
      657,
      25
    ],
    "start_token": 1685,
    "end_token": 1701,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      1874,
      71,
      9269,
      1366,
      1231,
      21201,
      460,
      1085,
      284,
      10059,
      15268,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Reshaping data without validation can lead to unexpected shapes."
  },
  {
    "line": 252,
    "text": "            raise ValueError(\"cannot clear memory as `num_states==0`\")",
    "annotation": "\u2705 Best Practice: Converting data to tensors is a common practice for ML model input.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      5298,
      11052,
      12331,
      7203,
      66,
      34574,
      1598,
      4088,
      355,
      4600,
      22510,
      62,
      27219,
      855,
      15,
      63,
      4943
    ],
    "start_token": 1701,
    "end_token": 1729,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      35602,
      889,
      1366,
      284,
      11192,
      669,
      318,
      257,
      2219,
      3357,
      329,
      10373,
      2746,
      5128,
      13
    ],
    "label": "best_practice",
    "reason": "Converting data to tensors is a common practice for ML model input."
  }
]