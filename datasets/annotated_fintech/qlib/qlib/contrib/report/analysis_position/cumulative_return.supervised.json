[
  {
    "line": 5,
    "text": "from typing import Iterable",
    "annotation": "\u2705 Best Practice: Grouping related imports together improves readability and maintainability.",
    "confidence": 0.5,
    "tokens": [
      6738,
      19720,
      1330,
      40806,
      540
    ],
    "start_token": 0,
    "end_token": 5,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      4912,
      278,
      3519,
      17944,
      1978,
      19575,
      1100,
      1799,
      290,
      5529,
      1799,
      13
    ],
    "label": "best_practice",
    "reason": "Grouping related imports together improves readability and maintainability."
  },
  {
    "line": 7,
    "text": "import pandas as pd",
    "annotation": "\ud83e\udde0 ML Signal: Function signature with multiple parameters, including optional ones",
    "confidence": 0.5,
    "tokens": [
      11748,
      19798,
      292,
      355,
      279,
      67
    ],
    "start_token": 5,
    "end_token": 11,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      15553,
      9877,
      351,
      3294,
      10007,
      11,
      1390,
      11902,
      3392
    ],
    "label": "ml_signal",
    "reason": "Function signature with multiple parameters, including optional ones"
  },
  {
    "line": 22,
    "text": "    \"\"\"",
    "annotation": "\ud83e\udde0 ML Signal: Use of a helper function to get data",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      37227
    ],
    "start_token": 11,
    "end_token": 15,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      257,
      31904,
      2163,
      284,
      651,
      1366
    ],
    "label": "ml_signal",
    "reason": "Use of a helper function to get data"
  },
  {
    "line": 22,
    "text": "    \"\"\"",
    "annotation": "\u2705 Best Practice: Use of .copy() to avoid modifying the original DataFrame",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      37227
    ],
    "start_token": 15,
    "end_token": 19,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      764,
      30073,
      3419,
      284,
      3368,
      30620,
      262,
      2656,
      6060,
      19778
    ],
    "label": "best_practice",
    "reason": "Use of .copy() to avoid modifying the original DataFrame"
  },
  {
    "line": 32,
    "text": "        position=position,",
    "annotation": "\u2705 Best Practice: Clear and concise DataFrame column operations",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2292,
      28,
      9150,
      11
    ],
    "start_token": 19,
    "end_token": 30,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      11459,
      290,
      35327,
      6060,
      19778,
      5721,
      4560
    ],
    "label": "best_practice",
    "reason": "Clear and concise DataFrame column operations"
  },
  {
    "line": 34,
    "text": "        label_data=label_data,",
    "annotation": "\u2705 Best Practice: Use of .dropna() to handle missing data",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      6167,
      62,
      7890,
      28,
      18242,
      62,
      7890,
      11
    ],
    "start_token": 30,
    "end_token": 45,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      764,
      14781,
      2616,
      3419,
      284,
      5412,
      4814,
      1366
    ],
    "label": "best_practice",
    "reason": "Use of .dropna() to handle missing data"
  },
  {
    "line": 36,
    "text": "        end_date=end_date,",
    "annotation": "\ud83e\udde0 ML Signal: Grouping data by a specific level",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      886,
      62,
      4475,
      28,
      437,
      62,
      4475,
      11
    ],
    "start_token": 45,
    "end_token": 60,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      4912,
      278,
      1366,
      416,
      257,
      2176,
      1241
    ],
    "label": "ml_signal",
    "reason": "Grouping data by a specific level"
  },
  {
    "line": 42,
    "text": "    result_list = []",
    "annotation": "\ud83e\udde0 ML Signal: Filtering data based on a specific column value",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      1255,
      62,
      4868,
      796,
      17635
    ],
    "start_token": 60,
    "end_token": 68,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      7066,
      20212,
      1366,
      1912,
      319,
      257,
      2176,
      5721,
      1988
    ],
    "label": "ml_signal",
    "reason": "Filtering data based on a specific column value"
  },
  {
    "line": 46,
    "text": "",
    "annotation": "\u2705 Best Practice: Use of vectorized operations for performance",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 68,
    "end_token": 68,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      15879,
      1143,
      4560,
      329,
      2854
    ],
    "label": "best_practice",
    "reason": "Use of vectorized operations for performance"
  },
  {
    "line": 48,
    "text": "        _buy_df = day_df[day_df[\"status\"] == 1]",
    "annotation": "\u2705 Best Practice: Conditional expression for division to avoid ZeroDivisionError",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      4808,
      17846,
      62,
      7568,
      796,
      1110,
      62,
      7568,
      58,
      820,
      62,
      7568,
      14692,
      13376,
      8973,
      6624,
      352,
      60
    ],
    "start_token": 68,
    "end_token": 93,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      9724,
      1859,
      5408,
      329,
      7297,
      284,
      3368,
      12169,
      24095,
      1166,
      12331
    ],
    "label": "best_practice",
    "reason": "Conditional expression for division to avoid ZeroDivisionError"
  },
  {
    "line": 65,
    "text": "                hold_value=hold_value,",
    "annotation": "\u2705 Best Practice: Use of a dictionary to store related data",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1745,
      62,
      8367,
      28,
      2946,
      62,
      8367,
      11
    ],
    "start_token": 93,
    "end_token": 116,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      257,
      22155,
      284,
      3650,
      3519,
      1366
    ],
    "label": "best_practice",
    "reason": "Use of a dictionary to store related data"
  },
  {
    "line": 75,
    "text": "                buy_minus_sell_mean=buy_mean - sell_mean,",
    "annotation": "\ud83e\udde0 ML Signal: Conversion of list of dictionaries to DataFrame",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2822,
      62,
      40191,
      62,
      7255,
      62,
      32604,
      28,
      17846,
      62,
      32604,
      532,
      3677,
      62,
      32604,
      11
    ],
    "start_token": 116,
    "end_token": 147,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      44101,
      286,
      1351,
      286,
      48589,
      3166,
      284,
      6060,
      19778
    ],
    "label": "ml_signal",
    "reason": "Conversion of list of dictionaries to DataFrame"
  },
  {
    "line": 78,
    "text": "            )",
    "annotation": "\u2705 Best Practice: Use of .cumsum() for cumulative calculations",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1267
    ],
    "start_token": 147,
    "end_token": 159,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      764,
      66,
      5700,
      388,
      3419,
      329,
      23818,
      16765
    ],
    "label": "best_practice",
    "reason": "Use of .cumsum() for cumulative calculations"
  },
  {
    "line": 86,
    "text": "    return r_df",
    "annotation": "\u2705 Best Practice: Consider adding type hints for start_date and end_date for better clarity.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      1441,
      374,
      62,
      7568
    ],
    "start_token": 159,
    "end_token": 166,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      12642,
      4375,
      2099,
      20269,
      329,
      923,
      62,
      4475,
      290,
      886,
      62,
      4475,
      329,
      1365,
      16287,
      13
    ],
    "label": "best_practice",
    "reason": "Consider adding type hints for start_date and end_date for better clarity."
  },
  {
    "line": 90,
    "text": "    position: dict,",
    "annotation": "\ud83e\udde0 ML Signal: Iterating over a fixed list of strings to generate subplots.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      2292,
      25,
      8633,
      11
    ],
    "start_token": 166,
    "end_token": 173,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      40806,
      803,
      625,
      257,
      5969,
      1351,
      286,
      13042,
      284,
      7716,
      850,
      489,
      1747,
      13
    ],
    "label": "ml_signal",
    "reason": "Iterating over a fixed list of strings to generate subplots."
  },
  {
    "line": 145,
    "text": "                    \"type\": \"line\",",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential risk if SubplotsGraph is not properly validated or sanitized.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      366,
      4906,
      1298,
      366,
      1370,
      1600
    ],
    "start_token": 173,
    "end_token": 198,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      2526,
      611,
      3834,
      489,
      1747,
      37065,
      318,
      407,
      6105,
      31031,
      393,
      5336,
      36951,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential risk if SubplotsGraph is not properly validated or sanitized."
  },
  {
    "line": 161,
    "text": "            [{\"rowspan\": 1}, None],",
    "annotation": "\u2705 Best Practice: Docstring provides a clear description of the function and its parameters.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      685,
      4895,
      808,
      12626,
      1298,
      352,
      5512,
      6045,
      4357
    ],
    "start_token": 198,
    "end_token": 218,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      14432,
      8841,
      3769,
      257,
      1598,
      6764,
      286,
      262,
      2163,
      290,
      663,
      10007,
      13
    ],
    "label": "best_practice",
    "reason": "Docstring provides a clear description of the function and its parameters."
  },
  {
    "line": 213,
    "text": "                pred_df_dates = pred_df.index.get_level_values(level='datetime')",
    "annotation": "\u2705 Best Practice: Using deepcopy to avoid modifying the original position data.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2747,
      62,
      7568,
      62,
      19581,
      796,
      2747,
      62,
      7568,
      13,
      9630,
      13,
      1136,
      62,
      5715,
      62,
      27160,
      7,
      5715,
      11639,
      19608,
      8079,
      11537
    ],
    "start_token": 218,
    "end_token": 256,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      8554,
      2769,
      30073,
      284,
      3368,
      30620,
      262,
      2656,
      2292,
      1366,
      13
    ],
    "label": "best_practice",
    "reason": "Using deepcopy to avoid modifying the original position data."
  },
  {
    "line": 215,
    "text": "                features_df.columns = ['label']",
    "annotation": "\u2705 Best Practice: Copying DataFrame to avoid modifying the original data.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      3033,
      62,
      7568,
      13,
      28665,
      82,
      796,
      37250,
      18242,
      20520
    ],
    "start_token": 256,
    "end_token": 281,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      6955,
      1112,
      6060,
      19778,
      284,
      3368,
      30620,
      262,
      2656,
      1366,
      13
    ],
    "label": "best_practice",
    "reason": "Copying DataFrame to avoid modifying the original data."
  },
  {
    "line": 217,
    "text": "                qcr.analysis_position.cumulative_return_graph(positions, report_normal_df, features_df)",
    "annotation": "\u2705 Best Practice: Ensuring the label_data has a consistent column name.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      10662,
      6098,
      13,
      20930,
      62,
      9150,
      13,
      36340,
      13628,
      62,
      7783,
      62,
      34960,
      7,
      1930,
      1756,
      11,
      989,
      62,
      11265,
      62,
      7568,
      11,
      3033,
      62,
      7568,
      8
    ],
    "start_token": 281,
    "end_token": 323,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      48221,
      870,
      262,
      6167,
      62,
      7890,
      468,
      257,
      6414,
      5721,
      1438,
      13
    ],
    "label": "best_practice",
    "reason": "Ensuring the label_data has a consistent column name."
  },
  {
    "line": 219,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Function call to generate figures based on input data.",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 323,
    "end_token": 323,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      15553,
      869,
      284,
      7716,
      5538,
      1912,
      319,
      5128,
      1366,
      13
    ],
    "label": "ml_signal",
    "reason": "Function call to generate figures based on input data."
  },
  {
    "line": 219,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Conditional logic to determine output format.",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 323,
    "end_token": 323,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      9724,
      1859,
      9156,
      284,
      5004,
      5072,
      5794,
      13
    ],
    "label": "ml_signal",
    "reason": "Conditional logic to determine output format."
  },
  {
    "line": 219,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Returning figures for further processing or display.",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 323,
    "end_token": 323,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      42882,
      5538,
      329,
      2252,
      7587,
      393,
      3359,
      13
    ],
    "label": "ml_signal",
    "reason": "Returning figures for further processing or display."
  }
]