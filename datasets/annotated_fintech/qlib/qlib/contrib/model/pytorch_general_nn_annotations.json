[
  {
    "line": 39,
    "text": "",
    "annotation": "\u2705 Best Practice: Docstring provides a clear explanation of the class purpose and parameters",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 0,
    "end_token": 0,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      14432,
      8841,
      3769,
      257,
      1598,
      7468,
      286,
      262,
      1398,
      4007,
      290,
      10007
    ],
    "label": "best_practice",
    "reason": "Docstring provides a clear explanation of the class purpose and parameters"
  },
  {
    "line": 60,
    "text": "        weight_decay=0.0,",
    "annotation": "\u2705 Best Practice: Use of a logger for information and debugging",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      3463,
      62,
      12501,
      323,
      28,
      15,
      13,
      15,
      11
    ],
    "start_token": 0,
    "end_token": 16,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      257,
      49706,
      329,
      1321,
      290,
      28769
    ],
    "label": "best_practice",
    "reason": "Use of a logger for information and debugging"
  },
  {
    "line": 63,
    "text": "        GPU=0,",
    "annotation": "\ud83e\udde0 ML Signal: Number of epochs is a common hyperparameter in ML models",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      11362,
      28,
      15,
      11
    ],
    "start_token": 16,
    "end_token": 27,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      7913,
      286,
      36835,
      82,
      318,
      257,
      2219,
      8718,
      17143,
      2357,
      287,
      10373,
      4981
    ],
    "label": "ml_signal",
    "reason": "Number of epochs is a common hyperparameter in ML models"
  },
  {
    "line": 65,
    "text": "        pt_model_uri=\"qlib.contrib.model.pytorch_gru_ts.GRUModel\",",
    "annotation": "\ud83e\udde0 ML Signal: Learning rate is a common hyperparameter in ML models",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      42975,
      62,
      19849,
      62,
      9900,
      2625,
      80,
      8019,
      13,
      3642,
      822,
      13,
      19849,
      13,
      9078,
      13165,
      354,
      62,
      48929,
      62,
      912,
      13,
      10761,
      52,
      17633,
      1600
    ],
    "start_token": 27,
    "end_token": 60,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      18252,
      2494,
      318,
      257,
      2219,
      8718,
      17143,
      2357,
      287,
      10373,
      4981
    ],
    "label": "ml_signal",
    "reason": "Learning rate is a common hyperparameter in ML models"
  },
  {
    "line": 67,
    "text": "            \"d_feat\": 6,",
    "annotation": "\ud83e\udde0 ML Signal: Metric is a common hyperparameter in ML models",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      366,
      67,
      62,
      27594,
      1298,
      718,
      11
    ],
    "start_token": 60,
    "end_token": 78,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      3395,
      1173,
      318,
      257,
      2219,
      8718,
      17143,
      2357,
      287,
      10373,
      4981
    ],
    "label": "ml_signal",
    "reason": "Metric is a common hyperparameter in ML models"
  },
  {
    "line": 69,
    "text": "            \"num_layers\": 2,",
    "annotation": "\ud83e\udde0 ML Signal: Batch size is a common hyperparameter in ML models",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      366,
      22510,
      62,
      75,
      6962,
      1298,
      362,
      11
    ],
    "start_token": 78,
    "end_token": 97,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      347,
      963,
      2546,
      318,
      257,
      2219,
      8718,
      17143,
      2357,
      287,
      10373,
      4981
    ],
    "label": "ml_signal",
    "reason": "Batch size is a common hyperparameter in ML models"
  },
  {
    "line": 71,
    "text": "        },",
    "annotation": "\ud83e\udde0 ML Signal: Early stopping is a common technique in ML models",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      8964
    ],
    "start_token": 97,
    "end_token": 105,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      12556,
      12225,
      318,
      257,
      2219,
      8173,
      287,
      10373,
      4981
    ],
    "label": "ml_signal",
    "reason": "Early stopping is a common technique in ML models"
  },
  {
    "line": 73,
    "text": "        # Set logger.",
    "annotation": "\ud83e\udde0 ML Signal: Optimizer choice is a common hyperparameter in ML models",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1303,
      5345,
      49706,
      13
    ],
    "start_token": 105,
    "end_token": 116,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      30011,
      7509,
      3572,
      318,
      257,
      2219,
      8718,
      17143,
      2357,
      287,
      10373,
      4981
    ],
    "label": "ml_signal",
    "reason": "Optimizer choice is a common hyperparameter in ML models"
  },
  {
    "line": 75,
    "text": "        self.logger.info(\"GeneralPTNN pytorch version...\")",
    "annotation": "\ud83e\udde0 ML Signal: Loss function is a common hyperparameter in ML models",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      6404,
      1362,
      13,
      10951,
      7203,
      12218,
      11571,
      6144,
      12972,
      13165,
      354,
      2196,
      9313,
      8
    ],
    "start_token": 116,
    "end_token": 139,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      22014,
      2163,
      318,
      257,
      2219,
      8718,
      17143,
      2357,
      287,
      10373,
      4981
    ],
    "label": "ml_signal",
    "reason": "Loss function is a common hyperparameter in ML models"
  },
  {
    "line": 75,
    "text": "        self.logger.info(\"GeneralPTNN pytorch version...\")",
    "annotation": "\ud83e\udde0 ML Signal: Weight decay is a common hyperparameter in ML models",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      6404,
      1362,
      13,
      10951,
      7203,
      12218,
      11571,
      6144,
      12972,
      13165,
      354,
      2196,
      9313,
      8
    ],
    "start_token": 139,
    "end_token": 162,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      14331,
      22119,
      318,
      257,
      2219,
      8718,
      17143,
      2357,
      287,
      10373,
      4981
    ],
    "label": "ml_signal",
    "reason": "Weight decay is a common hyperparameter in ML models"
  },
  {
    "line": 75,
    "text": "        self.logger.info(\"GeneralPTNN pytorch version...\")",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential GPU index out of range if not checked",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      6404,
      1362,
      13,
      10951,
      7203,
      12218,
      11571,
      6144,
      12972,
      13165,
      354,
      2196,
      9313,
      8
    ],
    "start_token": 162,
    "end_token": 185,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      11362,
      6376,
      503,
      286,
      2837,
      611,
      407,
      10667
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential GPU index out of range if not checked"
  },
  {
    "line": 75,
    "text": "        self.logger.info(\"GeneralPTNN pytorch version...\")",
    "annotation": "\ud83e\udde0 ML Signal: Random seed is often used for reproducibility in ML models",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      6404,
      1362,
      13,
      10951,
      7203,
      12218,
      11571,
      6144,
      12972,
      13165,
      354,
      2196,
      9313,
      8
    ],
    "start_token": 185,
    "end_token": 208,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      14534,
      9403,
      318,
      1690,
      973,
      329,
      8186,
      66,
      2247,
      287,
      10373,
      4981
    ],
    "label": "ml_signal",
    "reason": "Random seed is often used for reproducibility in ML models"
  },
  {
    "line": 75,
    "text": "        self.logger.info(\"GeneralPTNN pytorch version...\")",
    "annotation": "\ud83e\udde0 ML Signal: Model initialization is a common pattern in ML models",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      6404,
      1362,
      13,
      10951,
      7203,
      12218,
      11571,
      6144,
      12972,
      13165,
      354,
      2196,
      9313,
      8
    ],
    "start_token": 208,
    "end_token": 231,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      9104,
      37588,
      318,
      257,
      2219,
      3912,
      287,
      10373,
      4981
    ],
    "label": "ml_signal",
    "reason": "Model initialization is a common pattern in ML models"
  },
  {
    "line": 112,
    "text": "                batch_size,",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): AttributeError if 'use_gpu' is not defined",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      15458,
      62,
      7857,
      11
    ],
    "start_token": 231,
    "end_token": 250,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      3460,
      4163,
      12331,
      611,
      705,
      1904,
      62,
      46999,
      6,
      318,
      407,
      5447
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "AttributeError if 'use_gpu' is not defined"
  },
  {
    "line": 121,
    "text": "                pt_model_uri,",
    "annotation": "\ud83e\udde0 ML Signal: Setting random seed for reproducibility",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      42975,
      62,
      19849,
      62,
      9900,
      11
    ],
    "start_token": 250,
    "end_token": 271,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      25700,
      4738,
      9403,
      329,
      8186,
      66,
      2247
    ],
    "label": "ml_signal",
    "reason": "Setting random seed for reproducibility"
  },
  {
    "line": 125,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Model size logging is useful for understanding resource requirements",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 271,
    "end_token": 271,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      9104,
      2546,
      18931,
      318,
      4465,
      329,
      4547,
      8271,
      5359
    ],
    "label": "ml_signal",
    "reason": "Model size logging is useful for understanding resource requirements"
  },
  {
    "line": 128,
    "text": "            torch.manual_seed(self.seed)",
    "annotation": "\ud83e\udde0 ML Signal: Adam optimizer is a common choice in ML models",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      28034,
      13,
      805,
      723,
      62,
      28826,
      7,
      944,
      13,
      28826,
      8
    ],
    "start_token": 271,
    "end_token": 293,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      7244,
      6436,
      7509,
      318,
      257,
      2219,
      3572,
      287,
      10373,
      4981
    ],
    "label": "ml_signal",
    "reason": "Adam optimizer is a common choice in ML models"
  },
  {
    "line": 131,
    "text": "        self.logger.info(\"model size: {:.4f} MB\".format(count_parameters(self.dnn_model)))",
    "annotation": "\ud83e\udde0 ML Signal: Gradient Descent optimizer is a common choice in ML models",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      6404,
      1362,
      13,
      10951,
      7203,
      19849,
      2546,
      25,
      46110,
      13,
      19,
      69,
      92,
      10771,
      1911,
      18982,
      7,
      9127,
      62,
      17143,
      7307,
      7,
      944,
      13,
      67,
      20471,
      62,
      19849,
      22305
    ],
    "start_token": 293,
    "end_token": 331,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      17701,
      1153,
      2935,
      1087,
      6436,
      7509,
      318,
      257,
      2219,
      3572,
      287,
      10373,
      4981
    ],
    "label": "ml_signal",
    "reason": "Gradient Descent optimizer is a common choice in ML models"
  },
  {
    "line": 134,
    "text": "            self.train_optimizer = optim.Adam(self.dnn_model.parameters(), lr=self.lr, weight_decay=weight_decay)",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Use of NotImplementedError for unsupported optimizers",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      27432,
      62,
      40085,
      7509,
      796,
      6436,
      13,
      23159,
      7,
      944,
      13,
      67,
      20471,
      62,
      19849,
      13,
      17143,
      7307,
      22784,
      300,
      81,
      28,
      944,
      13,
      14050,
      11,
      3463,
      62,
      12501,
      323,
      28,
      6551,
      62,
      12501,
      323,
      8
    ],
    "start_token": 331,
    "end_token": 380,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      5765,
      286,
      1892,
      3546,
      1154,
      12061,
      12331,
      329,
      24222,
      6436,
      11341
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Use of NotImplementedError for unsupported optimizers"
  },
  {
    "line": 136,
    "text": "            self.train_optimizer = optim.SGD(self.dnn_model.parameters(), lr=self.lr, weight_decay=weight_decay)",
    "annotation": "\ud83e\udde0 ML Signal: Learning rate scheduler is a common technique in ML models",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      27432,
      62,
      40085,
      7509,
      796,
      6436,
      13,
      38475,
      35,
      7,
      944,
      13,
      67,
      20471,
      62,
      19849,
      13,
      17143,
      7307,
      22784,
      300,
      81,
      28,
      944,
      13,
      14050,
      11,
      3463,
      62,
      12501,
      323,
      28,
      6551,
      62,
      12501,
      323,
      8
    ],
    "start_token": 380,
    "end_token": 430,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      18252,
      2494,
      6038,
      18173,
      318,
      257,
      2219,
      8173,
      287,
      10373,
      4981
    ],
    "label": "ml_signal",
    "reason": "Learning rate scheduler is a common technique in ML models"
  },
  {
    "line": 141,
    "text": "        self.lr_scheduler = ReduceLROnPlateau(",
    "annotation": "\ud83e\udde0 ML Signal: Moving model to device (CPU/GPU) is a common pattern in ML models",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      14050,
      62,
      1416,
      704,
      18173,
      796,
      44048,
      35972,
      2202,
      3646,
      378,
      559,
      7
    ],
    "start_token": 430,
    "end_token": 452,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      26768,
      2746,
      284,
      3335,
      357,
      36037,
      14,
      33346,
      8,
      318,
      257,
      2219,
      3912,
      287,
      10373,
      4981
    ],
    "label": "ml_signal",
    "reason": "Moving model to device (CPU/GPU) is a common pattern in ML models"
  },
  {
    "line": 124,
    "text": "        )",
    "annotation": "\ud83e\udde0 ML Signal: Checks if the computation is set to run on a GPU, indicating hardware usage preference",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1267
    ],
    "start_token": 452,
    "end_token": 460,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      47719,
      611,
      262,
      29964,
      318,
      900,
      284,
      1057,
      319,
      257,
      11362,
      11,
      12739,
      6890,
      8748,
      12741
    ],
    "label": "ml_signal",
    "reason": "Checks if the computation is set to run on a GPU, indicating hardware usage preference"
  },
  {
    "line": 126,
    "text": "        if self.seed is not None:",
    "annotation": "\u2705 Best Practice: Direct comparison with torch.device ensures clarity in device checking",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      611,
      2116,
      13,
      28826,
      318,
      407,
      6045,
      25
    ],
    "start_token": 460,
    "end_token": 475,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      4128,
      7208,
      351,
      28034,
      13,
      25202,
      19047,
      16287,
      287,
      3335,
      10627
    ],
    "label": "best_practice",
    "reason": "Direct comparison with torch.device ensures clarity in device checking"
  },
  {
    "line": 126,
    "text": "        if self.seed is not None:",
    "annotation": "\u2705 Best Practice: Consider adding type hints for function parameters and return type",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      611,
      2116,
      13,
      28826,
      318,
      407,
      6045,
      25
    ],
    "start_token": 475,
    "end_token": 490,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      12642,
      4375,
      2099,
      20269,
      329,
      2163,
      10007,
      290,
      1441,
      2099
    ],
    "label": "best_practice",
    "reason": "Consider adding type hints for function parameters and return type"
  },
  {
    "line": 128,
    "text": "            torch.manual_seed(self.seed)",
    "annotation": "\ud83e\udde0 ML Signal: Use of mean squared error (MSE) loss function",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      28034,
      13,
      805,
      723,
      62,
      28826,
      7,
      944,
      13,
      28826,
      8
    ],
    "start_token": 490,
    "end_token": 512,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      1612,
      44345,
      4049,
      357,
      44,
      5188,
      8,
      2994,
      2163
    ],
    "label": "ml_signal",
    "reason": "Use of mean squared error (MSE) loss function"
  },
  {
    "line": 129,
    "text": "",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Ensure 'weight' is validated to prevent unexpected behavior",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 512,
    "end_token": 512,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      48987,
      705,
      6551,
      6,
      318,
      31031,
      284,
      2948,
      10059,
      4069
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Ensure 'weight' is validated to prevent unexpected behavior"
  },
  {
    "line": 131,
    "text": "        self.logger.info(\"model size: {:.4f} MB\".format(count_parameters(self.dnn_model)))",
    "annotation": "\ud83e\udde0 ML Signal: Use of torch.mean for averaging loss",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      6404,
      1362,
      13,
      10951,
      7203,
      19849,
      2546,
      25,
      46110,
      13,
      19,
      69,
      92,
      10771,
      1911,
      18982,
      7,
      9127,
      62,
      17143,
      7307,
      7,
      944,
      13,
      67,
      20471,
      62,
      19849,
      22305
    ],
    "start_token": 512,
    "end_token": 550,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      28034,
      13,
      32604,
      329,
      20430,
      2994
    ],
    "label": "ml_signal",
    "reason": "Use of torch.mean for averaging loss"
  },
  {
    "line": 130,
    "text": "        self.logger.info(\"model:\\n{:}\".format(self.dnn_model))",
    "annotation": "\u2705 Best Practice: Use of torch.isnan to create a mask for valid labels",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      6404,
      1362,
      13,
      10951,
      7203,
      19849,
      7479,
      77,
      90,
      25,
      92,
      1911,
      18982,
      7,
      944,
      13,
      67,
      20471,
      62,
      19849,
      4008
    ],
    "start_token": 550,
    "end_token": 580,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      28034,
      13,
      271,
      12647,
      284,
      2251,
      257,
      9335,
      329,
      4938,
      14722
    ],
    "label": "best_practice",
    "reason": "Use of torch.isnan to create a mask for valid labels"
  },
  {
    "line": 133,
    "text": "        if optimizer.lower() == \"adam\":",
    "annotation": "\u2705 Best Practice: Default weight initialization with torch.ones_like",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      611,
      6436,
      7509,
      13,
      21037,
      3419,
      6624,
      366,
      324,
      321,
      1298
    ],
    "start_token": 580,
    "end_token": 598,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      15161,
      3463,
      37588,
      351,
      28034,
      13,
      1952,
      62,
      2339
    ],
    "label": "best_practice",
    "reason": "Default weight initialization with torch.ones_like"
  },
  {
    "line": 136,
    "text": "            self.train_optimizer = optim.SGD(self.dnn_model.parameters(), lr=self.lr, weight_decay=weight_decay)",
    "annotation": "\ud83e\udde0 ML Signal: Use of mean squared error (mse) as a loss function",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      27432,
      62,
      40085,
      7509,
      796,
      6436,
      13,
      38475,
      35,
      7,
      944,
      13,
      67,
      20471,
      62,
      19849,
      13,
      17143,
      7307,
      22784,
      300,
      81,
      28,
      944,
      13,
      14050,
      11,
      3463,
      62,
      12501,
      323,
      28,
      6551,
      62,
      12501,
      323,
      8
    ],
    "start_token": 598,
    "end_token": 648,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      1612,
      44345,
      4049,
      357,
      76,
      325,
      8,
      355,
      257,
      2994,
      2163
    ],
    "label": "ml_signal",
    "reason": "Use of mean squared error (mse) as a loss function"
  },
  {
    "line": 138,
    "text": "            raise NotImplementedError(\"optimizer {} is not supported!\".format(optimizer))",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential for unhandled exception if self.loss is not \"mse\"",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      5298,
      1892,
      3546,
      1154,
      12061,
      12331,
      7203,
      40085,
      7509,
      23884,
      318,
      407,
      4855,
      48220,
      18982,
      7,
      40085,
      7509,
      4008
    ],
    "start_token": 648,
    "end_token": 678,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      329,
      555,
      38788,
      6631,
      611,
      2116,
      13,
      22462,
      318,
      407,
      366,
      76,
      325,
      1
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential for unhandled exception if self.loss is not \"mse\""
  },
  {
    "line": 136,
    "text": "            self.train_optimizer = optim.SGD(self.dnn_model.parameters(), lr=self.lr, weight_decay=weight_decay)",
    "annotation": "\ud83e\udde0 ML Signal: Function definition for metric calculation, indicating a pattern for evaluating model performance",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      27432,
      62,
      40085,
      7509,
      796,
      6436,
      13,
      38475,
      35,
      7,
      944,
      13,
      67,
      20471,
      62,
      19849,
      13,
      17143,
      7307,
      22784,
      300,
      81,
      28,
      944,
      13,
      14050,
      11,
      3463,
      62,
      12501,
      323,
      28,
      6551,
      62,
      12501,
      323,
      8
    ],
    "start_token": 678,
    "end_token": 728,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      15553,
      6770,
      329,
      18663,
      17952,
      11,
      12739,
      257,
      3912,
      329,
      22232,
      2746,
      2854
    ],
    "label": "ml_signal",
    "reason": "Function definition for metric calculation, indicating a pattern for evaluating model performance"
  },
  {
    "line": 138,
    "text": "            raise NotImplementedError(\"optimizer {} is not supported!\".format(optimizer))",
    "annotation": "\ud83e\udde0 ML Signal: Use of torch.isfinite to create a mask, indicating handling of non-finite values in tensors",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      5298,
      1892,
      3546,
      1154,
      12061,
      12331,
      7203,
      40085,
      7509,
      23884,
      318,
      407,
      4855,
      48220,
      18982,
      7,
      40085,
      7509,
      4008
    ],
    "start_token": 728,
    "end_token": 758,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      28034,
      13,
      4468,
      9504,
      284,
      2251,
      257,
      9335,
      11,
      12739,
      9041,
      286,
      1729,
      12,
      69,
      9504,
      3815,
      287,
      11192,
      669
    ],
    "label": "ml_signal",
    "reason": "Use of torch.isfinite to create a mask, indicating handling of non-finite values in tensors"
  },
  {
    "line": 140,
    "text": "        # === ReduceLROnPlateau learning rate scheduler ===",
    "annotation": "\ud83e\udde0 ML Signal: Conditional logic based on metric type, showing a pattern for selecting evaluation criteria",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1303,
      24844,
      44048,
      35972,
      2202,
      3646,
      378,
      559,
      4673,
      2494,
      6038,
      18173,
      24844
    ],
    "start_token": 758,
    "end_token": 778,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      9724,
      1859,
      9156,
      1912,
      319,
      18663,
      2099,
      11,
      4478,
      257,
      3912,
      329,
      17246,
      12660,
      9987
    ],
    "label": "ml_signal",
    "reason": "Conditional logic based on metric type, showing a pattern for selecting evaluation criteria"
  },
  {
    "line": 142,
    "text": "            self.train_optimizer, mode=\"min\", factor=0.5, patience=5, min_lr=1e-6, threshold=1e-5",
    "annotation": "\ud83e\udde0 ML Signal: Use of a loss function, indicating a pattern for model evaluation",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      27432,
      62,
      40085,
      7509,
      11,
      4235,
      2625,
      1084,
      1600,
      5766,
      28,
      15,
      13,
      20,
      11,
      16336,
      28,
      20,
      11,
      949,
      62,
      14050,
      28,
      16,
      68,
      12,
      21,
      11,
      11387,
      28,
      16,
      68,
      12,
      20
    ],
    "start_token": 778,
    "end_token": 825,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      257,
      2994,
      2163,
      11,
      12739,
      257,
      3912,
      329,
      2746,
      12660
    ],
    "label": "ml_signal",
    "reason": "Use of a loss function, indicating a pattern for model evaluation"
  },
  {
    "line": 142,
    "text": "            self.train_optimizer, mode=\"min\", factor=0.5, patience=5, min_lr=1e-6, threshold=1e-5",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential information disclosure through error messages",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      27432,
      62,
      40085,
      7509,
      11,
      4235,
      2625,
      1084,
      1600,
      5766,
      28,
      15,
      13,
      20,
      11,
      16336,
      28,
      20,
      11,
      949,
      62,
      14050,
      28,
      16,
      68,
      12,
      21,
      11,
      11387,
      28,
      16,
      68,
      12,
      20
    ],
    "start_token": 825,
    "end_token": 872,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      1321,
      13019,
      832,
      4049,
      6218
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential information disclosure through error messages"
  },
  {
    "line": 155,
    "text": "    def loss_fn(self, pred, label, weight=None):",
    "annotation": "\u2705 Best Practice: Check the dimensionality of the data to handle different input shapes.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      825,
      2994,
      62,
      22184,
      7,
      944,
      11,
      2747,
      11,
      6167,
      11,
      3463,
      28,
      14202,
      2599
    ],
    "start_token": 872,
    "end_token": 890,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      6822,
      262,
      15793,
      1483,
      286,
      262,
      1366,
      284,
      5412,
      1180,
      5128,
      15268,
      13
    ],
    "label": "best_practice",
    "reason": "Check the dimensionality of the data to handle different input shapes."
  },
  {
    "line": 157,
    "text": "",
    "annotation": "\u2705 Best Practice: Use slicing to separate features and labels, ensuring code clarity.",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 890,
    "end_token": 890,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      49289,
      284,
      4553,
      3033,
      290,
      14722,
      11,
      13359,
      2438,
      16287,
      13
    ],
    "label": "best_practice",
    "reason": "Use slicing to separate features and labels, ensuring code clarity."
  },
  {
    "line": 160,
    "text": "",
    "annotation": "\u2705 Best Practice: Handle different data shapes with separate conditions.",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 890,
    "end_token": 890,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      33141,
      1180,
      1366,
      15268,
      351,
      4553,
      3403,
      13
    ],
    "label": "best_practice",
    "reason": "Handle different data shapes with separate conditions."
  },
  {
    "line": 165,
    "text": "",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Raising a generic exception without specific handling can lead to unhandled exceptions.",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 890,
    "end_token": 890,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      7567,
      1710,
      257,
      14276,
      6631,
      1231,
      2176,
      9041,
      460,
      1085,
      284,
      555,
      38788,
      13269,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Raising a generic exception without specific handling can lead to unhandled exceptions."
  },
  {
    "line": 167,
    "text": "        mask = torch.isfinite(label)",
    "annotation": "\u2705 Best Practice: Return a tuple for clear and consistent output.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      9335,
      796,
      28034,
      13,
      4468,
      9504,
      7,
      18242,
      8
    ],
    "start_token": 890,
    "end_token": 906,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      8229,
      257,
      46545,
      329,
      1598,
      290,
      6414,
      5072,
      13
    ],
    "label": "best_practice",
    "reason": "Return a tuple for clear and consistent output."
  },
  {
    "line": 166,
    "text": "    def metric_fn(self, pred, label):",
    "annotation": "\ud83e\udde0 ML Signal: Iterating over data_loader indicates a training loop",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      825,
      18663,
      62,
      22184,
      7,
      944,
      11,
      2747,
      11,
      6167,
      2599
    ],
    "start_token": 906,
    "end_token": 920,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      40806,
      803,
      625,
      1366,
      62,
      29356,
      9217,
      257,
      3047,
      9052
    ],
    "label": "ml_signal",
    "reason": "Iterating over data_loader indicates a training loop"
  },
  {
    "line": 168,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Extracting features and labels is common in ML training",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 920,
    "end_token": 920,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      29677,
      278,
      3033,
      290,
      14722,
      318,
      2219,
      287,
      10373,
      3047
    ],
    "label": "ml_signal",
    "reason": "Extracting features and labels is common in ML training"
  },
  {
    "line": 170,
    "text": "            return self.loss_fn(pred[mask], label[mask])",
    "annotation": "\ud83e\udde0 ML Signal: Model prediction step",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1441,
      2116,
      13,
      22462,
      62,
      22184,
      7,
      28764,
      58,
      27932,
      4357,
      6167,
      58,
      27932,
      12962
    ],
    "start_token": 920,
    "end_token": 946,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      9104,
      17724,
      2239
    ],
    "label": "ml_signal",
    "reason": "Model prediction step"
  },
  {
    "line": 172,
    "text": "        raise ValueError(\"unknown metric `%s`\" % self.metric)",
    "annotation": "\ud83e\udde0 ML Signal: Loss calculation is a key step in training",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      5298,
      11052,
      12331,
      7203,
      34680,
      18663,
      4600,
      4,
      82,
      63,
      1,
      4064,
      2116,
      13,
      4164,
      1173,
      8
    ],
    "start_token": 946,
    "end_token": 970,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      22014,
      17952,
      318,
      257,
      1994,
      2239,
      287,
      3047
    ],
    "label": "ml_signal",
    "reason": "Loss calculation is a key step in training"
  },
  {
    "line": 174,
    "text": "    def _get_fl(self, data: torch.Tensor):",
    "annotation": "\ud83e\udde0 ML Signal: Optimizer step preparation",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      825,
      4808,
      1136,
      62,
      2704,
      7,
      944,
      11,
      1366,
      25,
      28034,
      13,
      51,
      22854,
      2599
    ],
    "start_token": 970,
    "end_token": 988,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      30011,
      7509,
      2239,
      11824
    ],
    "label": "ml_signal",
    "reason": "Optimizer step preparation"
  },
  {
    "line": 176,
    "text": "        get feature and label from data",
    "annotation": "\ud83e\udde0 ML Signal: Backpropagation step",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      651,
      3895,
      290,
      6167,
      422,
      1366
    ],
    "start_token": 988,
    "end_token": 1001,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5157,
      22930,
      363,
      341,
      2239
    ],
    "label": "ml_signal",
    "reason": "Backpropagation step"
  },
  {
    "line": 178,
    "text": "",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Gradient clipping can prevent exploding gradients but should be used with caution",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 1001,
    "end_token": 1001,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      17701,
      1153,
      45013,
      460,
      2948,
      30990,
      3915,
      2334,
      475,
      815,
      307,
      973,
      351,
      13041
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Gradient clipping can prevent exploding gradients but should be used with caution"
  },
  {
    "line": 180,
    "text": "        ----------",
    "annotation": "\ud83e\udde0 ML Signal: Optimizer step to update model parameters",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      24200,
      438
    ],
    "start_token": 1001,
    "end_token": 1010,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      30011,
      7509,
      2239,
      284,
      4296,
      2746,
      10007
    ],
    "label": "ml_signal",
    "reason": "Optimizer step to update model parameters"
  },
  {
    "line": 175,
    "text": "        \"\"\"",
    "annotation": "\ud83e\udde0 ML Signal: Method for evaluating model performance on a dataset",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      37227
    ],
    "start_token": 1010,
    "end_token": 1018,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      11789,
      329,
      22232,
      2746,
      2854,
      319,
      257,
      27039
    ],
    "label": "ml_signal",
    "reason": "Method for evaluating model performance on a dataset"
  },
  {
    "line": 177,
    "text": "        - Handle the different data shape of time series and tabular data",
    "annotation": "\u2705 Best Practice: Initialize lists to store batch-wise losses and scores",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      532,
      33141,
      262,
      1180,
      1366,
      5485,
      286,
      640,
      2168,
      290,
      7400,
      934,
      1366
    ],
    "start_token": 1018,
    "end_token": 1038,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      20768,
      1096,
      8341,
      284,
      3650,
      15458,
      12,
      3083,
      9089,
      290,
      8198
    ],
    "label": "best_practice",
    "reason": "Initialize lists to store batch-wise losses and scores"
  },
  {
    "line": 181,
    "text": "        data : torch.Tensor",
    "annotation": "\ud83e\udde0 ML Signal: Data preprocessing step to extract features and labels",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1366,
      1058,
      28034,
      13,
      51,
      22854
    ],
    "start_token": 1038,
    "end_token": 1051,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      6060,
      662,
      36948,
      2239,
      284,
      7925,
      3033,
      290,
      14722
    ],
    "label": "ml_signal",
    "reason": "Data preprocessing step to extract features and labels"
  },
  {
    "line": 184,
    "text": "            - 2dim: [batch_size, feature_dim]",
    "annotation": "\ud83e\udde0 ML Signal: Model inference without gradient computation",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      532,
      362,
      27740,
      25,
      685,
      43501,
      62,
      7857,
      11,
      3895,
      62,
      27740,
      60
    ],
    "start_token": 1051,
    "end_token": 1075,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      9104,
      32278,
      1231,
      31312,
      29964
    ],
    "label": "ml_signal",
    "reason": "Model inference without gradient computation"
  },
  {
    "line": 186,
    "text": "        Returns",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential device mismatch if `weight` is not on the correct device",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      16409
    ],
    "start_token": 1075,
    "end_token": 1083,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      3335,
      46318,
      611,
      4600,
      6551,
      63,
      318,
      407,
      319,
      262,
      3376,
      3335
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential device mismatch if `weight` is not on the correct device"
  },
  {
    "line": 187,
    "text": "        -------",
    "annotation": "\u2705 Best Practice: Store loss as a scalar value",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      35656
    ],
    "start_token": 1083,
    "end_token": 1091,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      9363,
      2994,
      355,
      257,
      16578,
      283,
      1988
    ],
    "label": "best_practice",
    "reason": "Store loss as a scalar value"
  },
  {
    "line": 187,
    "text": "        -------",
    "annotation": "\ud83e\udde0 ML Signal: Calculation of performance metric",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      35656
    ],
    "start_token": 1091,
    "end_token": 1099,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      2199,
      14902,
      286,
      2854,
      18663
    ],
    "label": "ml_signal",
    "reason": "Calculation of performance metric"
  },
  {
    "line": 192,
    "text": "            feature = data[:, :, 0:-1].to(self.device)",
    "annotation": "\u2705 Best Practice: Store score as a scalar value",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      3895,
      796,
      1366,
      58,
      45299,
      1058,
      11,
      657,
      21912,
      16,
      4083,
      1462,
      7,
      944,
      13,
      25202,
      8
    ],
    "start_token": 1099,
    "end_token": 1127,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      9363,
      4776,
      355,
      257,
      16578,
      283,
      1988
    ],
    "label": "best_practice",
    "reason": "Store score as a scalar value"
  },
  {
    "line": 194,
    "text": "        elif data.dim() == 2:",
    "annotation": "\u2705 Best Practice: Return average loss and score for the epoch",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1288,
      361,
      1366,
      13,
      27740,
      3419,
      6624,
      362,
      25
    ],
    "start_token": 1127,
    "end_token": 1143,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      8229,
      2811,
      2994,
      290,
      4776,
      329,
      262,
      36835
    ],
    "label": "best_practice",
    "reason": "Return average loss and score for the epoch"
  },
  {
    "line": 194,
    "text": "        elif data.dim() == 2:",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Using mutable default argument 'evals_result' can lead to unexpected behavior",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1288,
      361,
      1366,
      13,
      27740,
      3419,
      6624,
      362,
      25
    ],
    "start_token": 1143,
    "end_token": 1159,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      8554,
      4517,
      540,
      4277,
      4578,
      705,
      1990,
      874,
      62,
      20274,
      6,
      460,
      1085,
      284,
      10059,
      4069
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Using mutable default argument 'evals_result' can lead to unexpected behavior"
  },
  {
    "line": 266,
    "text": "            dl_train = dl_train.values",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential memory leak if GPU memory is not properly managed",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      288,
      75,
      62,
      27432,
      796,
      288,
      75,
      62,
      27432,
      13,
      27160
    ],
    "start_token": 1159,
    "end_token": 1181,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      4088,
      13044,
      611,
      11362,
      4088,
      318,
      407,
      6105,
      5257
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential memory leak if GPU memory is not properly managed"
  },
  {
    "line": 275,
    "text": "        )",
    "annotation": "\u2705 Best Practice: Use of descriptive logging to track the number of test samples",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1267
    ],
    "start_token": 1181,
    "end_token": 1189,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      35644,
      18931,
      284,
      2610,
      262,
      1271,
      286,
      1332,
      8405
    ],
    "label": "best_practice",
    "reason": "Use of descriptive logging to track the number of test samples"
  },
  {
    "line": 279,
    "text": "            shuffle=False,",
    "annotation": "\u2705 Best Practice: Handling missing data with forward and backward fill",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      36273,
      28,
      25101,
      11
    ],
    "start_token": 1189,
    "end_token": 1204,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      49500,
      4814,
      1366,
      351,
      2651,
      290,
      19528,
      6070
    ],
    "label": "best_practice",
    "reason": "Handling missing data with forward and backward fill"
  },
  {
    "line": 285,
    "text": "        save_path = get_or_create_path(save_path)",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential for large memory usage if batch_size is not set",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      3613,
      62,
      6978,
      796,
      651,
      62,
      273,
      62,
      17953,
      62,
      6978,
      7,
      21928,
      62,
      6978,
      8
    ],
    "start_token": 1204,
    "end_token": 1227,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      329,
      1588,
      4088,
      8748,
      611,
      15458,
      62,
      7857,
      318,
      407,
      900
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential for large memory usage if batch_size is not set"
  },
  {
    "line": 291,
    "text": "        evals_result[\"train\"] = []",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Ensure device compatibility for feature tensors",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      819,
      874,
      62,
      20274,
      14692,
      27432,
      8973,
      796,
      17635
    ],
    "start_token": 1227,
    "end_token": 1243,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      48987,
      3335,
      17764,
      329,
      3895,
      11192,
      669
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Ensure device compatibility for feature tensors"
  },
  {
    "line": 294,
    "text": "        # train",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Ensure model is in eval mode to prevent gradient computation",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1303,
      4512
    ],
    "start_token": 1243,
    "end_token": 1252,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      48987,
      2746,
      318,
      287,
      5418,
      4235,
      284,
      2948,
      31312,
      29964
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Ensure model is in eval mode to prevent gradient computation"
  },
  {
    "line": 295,
    "text": "        self.logger.info(\"training...\")",
    "annotation": "\u2705 Best Practice: Returning predictions as a pandas Series for easy handling",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      6404,
      1362,
      13,
      10951,
      7203,
      34409,
      9313,
      8
    ],
    "start_token": 1252,
    "end_token": 1269,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      42882,
      16277,
      355,
      257,
      19798,
      292,
      7171,
      329,
      2562,
      9041
    ],
    "label": "best_practice",
    "reason": "Returning predictions as a pandas Series for easy handling"
  }
]