annotation,annotation_tokens,confidence,end_token,label,line,reason,severity,start_token,text,tokens
‚úÖ Best Practice: Handle ImportError to ensure the program can run even if tensorboard is not installed.,"[26486, 227, 6705, 19939, 25, 33141, 17267, 12331, 284, 4155, 262, 1430, 460, 1057, 772, 611, 11192, 273, 3526, 318, 407, 6589, 13]",0.5,0,best_practice,17,Handle ImportError to ensure the program can run even if tensorboard is not installed.,,0,,[]
"üß† ML Signal: Use of GPU if available, indicating a preference for performance optimization in ML tasks.","[8582, 100, 254, 10373, 26484, 25, 5765, 286, 11362, 611, 1695, 11, 12739, 257, 12741, 329, 2854, 23989, 287, 10373, 8861, 13]",0.5,8,ml_signal,23,"Use of GPU if available, indicating a preference for performance optimization in ML tasks.",,0,from tqdm import tqdm,"[6738, 256, 80, 36020, 1330, 256, 80, 36020]"
"üß† ML Signal: The class is designed to handle different model configurations and training parameters, which can be used to train ML models.","[8582, 100, 254, 10373, 26484, 25, 383, 1398, 318, 3562, 284, 5412, 1180, 2746, 25412, 290, 3047, 10007, 11, 543, 460, 307, 973, 284, 4512, 10373, 4981, 13]",0.5,23,ml_signal,50,"The class is designed to handle different model configurations and training parameters, which can be used to train ML models.",,8,        logdir (str): local log directory,"[220, 220, 220, 220, 220, 220, 220, 2604, 15908, 357, 2536, 2599, 1957, 2604, 8619]"
‚ö†Ô∏è SAST Risk (Low): The use of a random seed can lead to reproducibility issues if not handled properly.,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 383, 779, 286, 257, 4738, 9403, 460, 1085, 284, 8186, 66, 2247, 2428, 611, 407, 12118, 6105, 13]",0.5,38,sast_risk,50,The use of a random seed can lead to reproducibility issues if not handled properly.,Low,23,        logdir (str): local log directory,"[220, 220, 220, 220, 220, 220, 220, 2604, 15908, 357, 2536, 2599, 1957, 2604, 8619]"
‚úÖ Best Practice: Documenting all parameters in the docstring improves code readability and maintainability.,"[26486, 227, 6705, 19939, 25, 16854, 278, 477, 10007, 287, 262, 2205, 8841, 19575, 2438, 1100, 1799, 290, 5529, 1799, 13]",0.5,53,best_practice,50,Documenting all parameters in the docstring improves code readability and maintainability.,,38,        logdir (str): local log directory,"[220, 220, 220, 220, 220, 220, 220, 2604, 15908, 357, 2536, 2599, 1957, 2604, 8619]"
"üß† ML Signal: Logging is used, which can be a feature for monitoring model training","[8582, 100, 254, 10373, 26484, 25, 5972, 2667, 318, 973, 11, 543, 460, 307, 257, 3895, 329, 9904, 2746, 3047]",0.5,64,ml_signal,75,"Logging is used, which can be a feature for monitoring model training",,53,"        seed=None,","[220, 220, 220, 220, 220, 220, 220, 9403, 28, 14202, 11]"
‚ö†Ô∏è SAST Risk (Low): Use of assert for input validation can be disabled in optimized mode,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 5765, 286, 6818, 329, 5128, 21201, 460, 307, 10058, 287, 23392, 4235]",1.0,77,sast_risk,77,Use of assert for input validation can be disabled in optimized mode,Low,64,"        eval_train=False,","[220, 220, 220, 220, 220, 220, 220, 5418, 62, 27432, 28, 25101, 11]"
‚ö†Ô∏è SAST Risk (Low): Use of assert for input validation can be disabled in optimized mode,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 5765, 286, 6818, 329, 5128, 21201, 460, 307, 10058, 287, 23392, 4235]",1.0,89,sast_risk,79,Use of assert for input validation can be disabled in optimized mode,Low,77,"        pretrain=False,","[220, 220, 220, 220, 220, 220, 220, 2181, 3201, 28, 25101, 11]"
‚ö†Ô∏è SAST Risk (Low): Use of assert for input validation can be disabled in optimized mode,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 5765, 286, 6818, 329, 5128, 21201, 460, 307, 10058, 287, 23392, 4235]",1.0,102,sast_risk,82,Use of assert for input validation can be disabled in optimized mode,Low,89,"        freeze_model=False,","[220, 220, 220, 220, 220, 220, 220, 16611, 62, 19849, 28, 25101, 11]"
‚ö†Ô∏è SAST Risk (Low): Use of assert for input validation can be disabled in optimized mode,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 5765, 286, 6818, 329, 5128, 21201, 460, 307, 10058, 287, 23392, 4235]",1.0,117,sast_risk,83,Use of assert for input validation can be disabled in optimized mode,Low,102,"        freeze_predictors=False,","[220, 220, 220, 220, 220, 220, 220, 16611, 62, 79, 17407, 669, 28, 25101, 11]"
‚úÖ Best Practice: Warn users about ignored parameters to avoid confusion,"[26486, 227, 6705, 19939, 25, 39567, 2985, 546, 9514, 10007, 284, 3368, 10802]",0.5,139,best_practice,87,Warn users about ignored parameters to avoid confusion,,117,"        self.logger = get_module_logger(""TRA"")","[220, 220, 220, 220, 220, 220, 220, 2116, 13, 6404, 1362, 796, 651, 62, 21412, 62, 6404, 1362, 7203, 51, 3861, 4943]"
‚úÖ Best Practice: Seed initialization for reproducibility,"[26486, 227, 6705, 19939, 25, 23262, 37588, 329, 8186, 66, 2247]",0.5,174,best_practice,90,Seed initialization for reproducibility,,139,"        assert transport_method in [""none"", ""router"", ""oracle""], f""invalid transport method {transport_method}""","[220, 220, 220, 220, 220, 220, 220, 6818, 4839, 62, 24396, 287, 14631, 23108, 1600, 366, 472, 353, 1600, 366, 273, 6008, 33116, 277, 1, 259, 12102, 4839, 2446, 1391, 7645, 634, 62, 24396, 36786]"
"üß† ML Signal: Model configuration parameters are stored, indicating model setup","[8582, 100, 254, 10373, 26484, 25, 9104, 8398, 10007, 389, 8574, 11, 12739, 2746, 9058]",0.5,197,ml_signal,94,"Model configuration parameters are stored, indicating model setup",,174,"        ), ""daily transport can only support TPE as `src_info`""","[220, 220, 220, 220, 220, 220, 220, 10612, 366, 29468, 4839, 460, 691, 1104, 309, 11401, 355, 4600, 10677, 62, 10951, 63, 1]"
"üß† ML Signal: Training configuration parameters are stored, indicating training setup","[8582, 100, 254, 10373, 26484, 25, 13614, 8398, 10007, 389, 8574, 11, 12739, 3047, 9058]",0.5,219,ml_signal,96,"Training configuration parameters are stored, indicating training setup",,197,"        if transport_method == ""router"" and not eval_train:","[220, 220, 220, 220, 220, 220, 220, 611, 4839, 62, 24396, 6624, 366, 472, 353, 1, 290, 407, 5418, 62, 27432, 25]"
"üß† ML Signal: Model type is stored, indicating the architecture used","[8582, 100, 254, 10373, 26484, 25, 9104, 2099, 318, 8574, 11, 12739, 262, 10959, 973]",0.5,219,ml_signal,98,"Model type is stored, indicating the architecture used",,219,,[]
"üß† ML Signal: Learning rate is stored, indicating the training hyperparameter","[8582, 100, 254, 10373, 26484, 25, 18252, 2494, 318, 8574, 11, 12739, 262, 3047, 8718, 17143, 2357]",0.5,238,ml_signal,100,"Learning rate is stored, indicating the training hyperparameter",,219,            np.random.seed(seed),"[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 45941, 13, 25120, 13, 28826, 7, 28826, 8]"
"üß† ML Signal: Number of epochs is stored, indicating the training duration","[8582, 100, 254, 10373, 26484, 25, 7913, 286, 36835, 82, 318, 8574, 11, 12739, 262, 3047, 9478]",0.5,238,ml_signal,102,"Number of epochs is stored, indicating the training duration",,238,,[]
"üß† ML Signal: Early stopping criteria is stored, indicating training control","[8582, 100, 254, 10373, 26484, 25, 12556, 12225, 9987, 318, 8574, 11, 12739, 3047, 1630]",0.5,254,ml_signal,104,"Early stopping criteria is stored, indicating training control",,238,        self.tra_config = tra_config,"[220, 220, 220, 220, 220, 220, 220, 2116, 13, 9535, 62, 11250, 796, 1291, 62, 11250]"
"üß† ML Signal: Update frequency is stored, indicating training update strategy","[8582, 100, 254, 10373, 26484, 25, 10133, 8373, 318, 8574, 11, 12739, 3047, 4296, 4811]",0.5,267,ml_signal,106,"Update frequency is stored, indicating training update strategy",,254,        self.lr = lr,"[220, 220, 220, 220, 220, 220, 220, 2116, 13, 14050, 796, 300, 81]"
"üß† ML Signal: Maximum steps per epoch is stored, indicating training control","[8582, 100, 254, 10373, 26484, 25, 22246, 4831, 583, 36835, 318, 8574, 11, 12739, 3047, 1630]",0.5,283,ml_signal,108,"Maximum steps per epoch is stored, indicating training control",,267,        self.early_stop = early_stop,"[220, 220, 220, 220, 220, 220, 220, 2116, 13, 11458, 62, 11338, 796, 1903, 62, 11338]"
"üß† ML Signal: Regularization parameter is stored, indicating model regularization","[8582, 100, 254, 10373, 26484, 25, 23603, 1634, 11507, 318, 8574, 11, 12739, 2746, 3218, 1634]",0.5,309,ml_signal,110,"Regularization parameter is stored, indicating model regularization",,283,        self.max_steps_per_epoch = max_steps_per_epoch,"[220, 220, 220, 220, 220, 220, 220, 2116, 13, 9806, 62, 20214, 62, 525, 62, 538, 5374, 796, 3509, 62, 20214, 62, 525, 62, 538, 5374]"
"üß† ML Signal: Rho parameter is stored, indicating model configuration","[8582, 100, 254, 10373, 26484, 25, 371, 8873, 11507, 318, 8574, 11, 12739, 2746, 8398]",0.5,323,ml_signal,112,"Rho parameter is stored, indicating model configuration",,309,        self.rho = rho,"[220, 220, 220, 220, 220, 220, 220, 2116, 13, 81, 8873, 796, 374, 8873]"
"üß† ML Signal: Alpha parameter is stored, indicating model configuration","[8582, 100, 254, 10373, 26484, 25, 12995, 11507, 318, 8574, 11, 12739, 2746, 8398]",0.5,335,ml_signal,114,"Alpha parameter is stored, indicating model configuration",,323,        self.seed = seed,"[220, 220, 220, 220, 220, 220, 220, 2116, 13, 28826, 796, 9403]"
"üß† ML Signal: Seed is stored, indicating reproducibility setup","[8582, 100, 254, 10373, 26484, 25, 23262, 318, 8574, 11, 12739, 8186, 66, 2247, 9058]",0.5,351,ml_signal,116,"Seed is stored, indicating reproducibility setup",,335,        self.eval_train = eval_train,"[220, 220, 220, 220, 220, 220, 220, 2116, 13, 18206, 62, 27432, 796, 5418, 62, 27432]"
"üß† ML Signal: Log directory is stored, indicating logging setup","[8582, 100, 254, 10373, 26484, 25, 5972, 8619, 318, 8574, 11, 12739, 18931, 9058]",0.5,365,ml_signal,118,"Log directory is stored, indicating logging setup",,351,        self.pretrain = pretrain,"[220, 220, 220, 220, 220, 220, 220, 2116, 13, 5310, 3201, 796, 2181, 3201]"
"üß† ML Signal: Evaluation on training data flag is stored, indicating evaluation strategy","[8582, 100, 254, 10373, 26484, 25, 34959, 319, 3047, 1366, 6056, 318, 8574, 11, 12739, 12660, 4811]",0.5,383,ml_signal,120,"Evaluation on training data flag is stored, indicating evaluation strategy",,365,        self.reset_router = reset_router,"[220, 220, 220, 220, 220, 220, 220, 2116, 13, 42503, 62, 472, 353, 796, 13259, 62, 472, 353]"
"üß† ML Signal: Evaluation on test data flag is stored, indicating evaluation strategy","[8582, 100, 254, 10373, 26484, 25, 34959, 319, 1332, 1366, 6056, 318, 8574, 11, 12739, 12660, 4811]",0.5,404,ml_signal,122,"Evaluation on test data flag is stored, indicating evaluation strategy",,383,        self.freeze_predictors = freeze_predictors,"[220, 220, 220, 220, 220, 220, 220, 2116, 13, 5787, 2736, 62, 79, 17407, 669, 796, 16611, 62, 79, 17407, 669]"
"üß† ML Signal: Pretraining flag is stored, indicating training strategy","[8582, 100, 254, 10373, 26484, 25, 37123, 24674, 6056, 318, 8574, 11, 12739, 3047, 4811]",0.5,427,ml_signal,124,"Pretraining flag is stored, indicating training strategy",,404,"        self.use_daily_transport = memory_mode == ""daily""","[220, 220, 220, 220, 220, 220, 220, 2116, 13, 1904, 62, 29468, 62, 7645, 634, 796, 4088, 62, 14171, 6624, 366, 29468, 1]"
"üß† ML Signal: Initial state is stored, indicating model initialization","[8582, 100, 254, 10373, 26484, 25, 20768, 1181, 318, 8574, 11, 12739, 2746, 37588]",0.5,427,ml_signal,126,"Initial state is stored, indicating model initialization",,427,,[]
"üß† ML Signal: Reset router flag is stored, indicating model configuration","[8582, 100, 254, 10373, 26484, 25, 30027, 20264, 6056, 318, 8574, 11, 12739, 2746, 8398]",0.5,443,ml_signal,128,"Reset router flag is stored, indicating model configuration",,427,        if self.logdir is not None:,"[220, 220, 220, 220, 220, 220, 220, 611, 2116, 13, 6404, 15908, 318, 407, 6045, 25]"
"üß† ML Signal: Freeze model flag is stored, indicating training strategy","[8582, 100, 254, 10373, 26484, 25, 34917, 2746, 6056, 318, 8574, 11, 12739, 3047, 4811]",0.5,479,ml_signal,130,"Freeze model flag is stored, indicating training strategy",,443,"                self.logger.warning(f""logdir {self.logdir} is not empty"")","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 2116, 13, 6404, 1362, 13, 43917, 7, 69, 1, 6404, 15908, 1391, 944, 13, 6404, 15908, 92, 318, 407, 6565, 4943]"
"üß† ML Signal: Freeze predictors flag is stored, indicating training strategy","[8582, 100, 254, 10373, 26484, 25, 34917, 4331, 669, 6056, 318, 8574, 11, 12739, 3047, 4811]",0.5,497,ml_signal,132,"Freeze predictors flag is stored, indicating training strategy",,479,            if SummaryWriter is not None:,"[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 611, 21293, 34379, 318, 407, 6045, 25]"
"üß† ML Signal: Transport method is stored, indicating model configuration","[8582, 100, 254, 10373, 26484, 25, 19940, 2446, 318, 8574, 11, 12739, 2746, 8398]",0.5,497,ml_signal,134,"Transport method is stored, indicating model configuration",,497,,[]
"üß† ML Signal: Memory mode is stored, indicating model configuration","[8582, 100, 254, 10373, 26484, 25, 14059, 4235, 318, 8574, 11, 12739, 2746, 8398]",0.5,497,ml_signal,136,"Memory mode is stored, indicating model configuration",,497,,[]
"üß† ML Signal: Transport function is determined, indicating model configuration","[8582, 100, 254, 10373, 26484, 25, 19940, 2163, 318, 5295, 11, 12739, 2746, 8398]",0.5,518,ml_signal,138,"Transport function is determined, indicating model configuration",,497,"        self.logger.info(""init TRAModel..."")","[220, 220, 220, 220, 220, 220, 220, 2116, 13, 6404, 1362, 13, 10951, 7203, 15003, 7579, 2390, 375, 417, 9313, 8]"
"üß† ML Signal: Writer for logging is initialized, indicating logging setup","[8582, 100, 254, 10373, 26484, 25, 26606, 329, 18931, 318, 23224, 11, 12739, 18931, 9058]",0.5,548,ml_signal,140,"Writer for logging is initialized, indicating logging setup",,518,        self.model = eval(self.model_type)(**self.model_config).to(device),"[220, 220, 220, 220, 220, 220, 220, 2116, 13, 19849, 796, 5418, 7, 944, 13, 19849, 62, 4906, 5769, 1174, 944, 13, 19849, 62, 11250, 737, 1462, 7, 25202, 8]"
‚úÖ Best Practice: Check if log directory exists before creating it,"[26486, 227, 6705, 19939, 25, 6822, 611, 2604, 8619, 7160, 878, 4441, 340]",0.5,548,best_practice,142,Check if log directory exists before creating it,,548,,[]
‚úÖ Best Practice: Warn users about existing log directory to avoid data loss,"[26486, 227, 6705, 19939, 25, 39567, 2985, 546, 4683, 2604, 8619, 284, 3368, 1366, 2994]",0.5,548,best_practice,145,Warn users about existing log directory to avoid data loss,,548,,[]
‚úÖ Best Practice: Conditional initialization of optional components,"[26486, 227, 6705, 19939, 25, 9724, 1859, 37588, 286, 11902, 6805]",0.5,579,best_practice,148,Conditional initialization of optional components,,548,"            state_dict = torch.load(self.init_state, map_location=""cpu"")","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 1181, 62, 11600, 796, 28034, 13, 2220, 7, 944, 13, 15003, 62, 5219, 11, 3975, 62, 24886, 2625, 36166, 4943]"
"üß† ML Signal: Model initialization function is called, indicating model setup","[8582, 100, 254, 10373, 26484, 25, 9104, 37588, 2163, 318, 1444, 11, 12739, 2746, 9058]",0.5,601,ml_signal,151,"Model initialization function is called, indicating model setup",,579,            self.logger.warning(str(res)),"[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 2116, 13, 6404, 1362, 13, 43917, 7, 2536, 7, 411, 4008]"
üß† ML Signal: Logging initialization of the model can be used to track model lifecycle events.,"[8582, 100, 254, 10373, 26484, 25, 5972, 2667, 37588, 286, 262, 2746, 460, 307, 973, 284, 2610, 2746, 3868, 47510, 2995, 13]",0.5,617,ml_signal,119,Logging initialization of the model can be used to track model lifecycle events.,,601,        self.init_state = init_state,"[220, 220, 220, 220, 220, 220, 220, 2116, 13, 15003, 62, 5219, 796, 2315, 62, 5219]"
‚ö†Ô∏è SAST Risk (High): Use of eval() with potentially untrusted input can lead to code execution vulnerabilities.,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 11922, 2599, 5765, 286, 5418, 3419, 351, 6196, 1418, 81, 8459, 5128, 460, 1085, 284, 2438, 9706, 23805, 13]",0.5,634,sast_risk,121,Use of eval() with potentially untrusted input can lead to code execution vulnerabilities.,High,617,        self.freeze_model = freeze_model,"[220, 220, 220, 220, 220, 220, 220, 2116, 13, 5787, 2736, 62, 19849, 796, 16611, 62, 19849]"
‚úÖ Best Practice: Consider using logging instead of print for consistency and better control over output.,"[26486, 227, 6705, 19939, 25, 12642, 1262, 18931, 2427, 286, 3601, 329, 15794, 290, 1365, 1630, 625, 5072, 13]",0.5,651,best_practice,123,Consider using logging instead of print for consistency and better control over output.,,634,        self.transport_method = transport_method,"[220, 220, 220, 220, 220, 220, 220, 2116, 13, 7645, 634, 62, 24396, 796, 4839, 62, 24396]"
‚úÖ Best Practice: Consider using logging instead of print for consistency and better control over output.,"[26486, 227, 6705, 19939, 25, 12642, 1262, 18931, 2427, 286, 3601, 329, 15794, 290, 1365, 1630, 625, 5072, 13]",0.5,651,best_practice,126,Consider using logging instead of print for consistency and better control over output.,,651,,[]
üß† ML Signal: Logging state loading can be used to track model state changes.,"[8582, 100, 254, 10373, 26484, 25, 5972, 2667, 1181, 11046, 460, 307, 973, 284, 2610, 2746, 1181, 2458, 13]",0.5,675,ml_signal,129,Logging state loading can be used to track model state changes.,,651,            if os.path.exists(self.logdir):,"[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 611, 28686, 13, 6978, 13, 1069, 1023, 7, 944, 13, 6404, 15908, 2599]"
‚ö†Ô∏è SAST Risk (Medium): Loading a state dict from a file can be risky if the file is not trusted.,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 31205, 2599, 12320, 257, 1181, 8633, 422, 257, 2393, 460, 307, 17564, 611, 262, 2393, 318, 407, 13467, 13]",1.0,703,sast_risk,131,Loading a state dict from a file can be risky if the file is not trusted.,Medium,675,"            os.makedirs(self.logdir, exist_ok=True)","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 28686, 13, 76, 4335, 17062, 7, 944, 13, 6404, 15908, 11, 2152, 62, 482, 28, 17821, 8]"
‚ö†Ô∏è SAST Risk (Medium): Function name suggests potential unsafe operation; ensure it is safe.,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 31205, 2599, 15553, 1438, 5644, 2785, 21596, 4905, 26, 4155, 340, 318, 3338, 13]",0.5,703,sast_risk,134,Function name suggests potential unsafe operation; ensure it is safe.,Medium,703,,[]
üß† ML Signal: Logging results of state loading can be used to track model state changes.,"[8582, 100, 254, 10373, 26484, 25, 5972, 2667, 2482, 286, 1181, 11046, 460, 307, 973, 284, 2610, 2746, 1181, 2458, 13]",0.5,703,ml_signal,136,Logging results of state loading can be used to track model state changes.,,703,,[]
üß† ML Signal: Logging parameter reset can be used to track model parameter changes.,"[8582, 100, 254, 10373, 26484, 25, 5972, 2667, 11507, 13259, 460, 307, 973, 284, 2610, 2746, 11507, 2458, 13]",0.5,703,ml_signal,139,Logging parameter reset can be used to track model parameter changes.,,703,,[]
üß† ML Signal: Logging parameter freezing can be used to track model training state changes.,"[8582, 100, 254, 10373, 26484, 25, 5972, 2667, 11507, 20884, 460, 307, 973, 284, 2610, 2746, 3047, 1181, 2458, 13]",0.5,716,ml_signal,144,Logging parameter freezing can be used to track model training state changes.,,703,        print(self.tra),"[220, 220, 220, 220, 220, 220, 220, 3601, 7, 944, 13, 9535, 8]"
üß† ML Signal: Logging parameter freezing can be used to track model training state changes.,"[8582, 100, 254, 10373, 26484, 25, 5972, 2667, 11507, 20884, 460, 307, 973, 284, 2610, 2746, 3047, 1181, 2458, 13]",0.5,744,ml_signal,149,Logging parameter freezing can be used to track model training state changes.,,716,"            self.model.load_state_dict(state_dict[""model""])","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 2116, 13, 19849, 13, 2220, 62, 5219, 62, 11600, 7, 5219, 62, 11600, 14692, 19849, 8973, 8]"
üß† ML Signal: Logging model parameters can be used to track model size and complexity.,"[8582, 100, 254, 10373, 26484, 25, 5972, 2667, 2746, 10007, 460, 307, 973, 284, 2610, 2746, 2546, 290, 13357, 13]",0.5,759,ml_signal,153,Logging model parameters can be used to track model size and complexity.,,744,        if self.reset_router:,"[220, 220, 220, 220, 220, 220, 220, 611, 2116, 13, 42503, 62, 472, 353, 25]"
üß† ML Signal: Logging model parameters can be used to track model size and complexity.,"[8582, 100, 254, 10373, 26484, 25, 5972, 2667, 2746, 10007, 460, 307, 973, 284, 2610, 2746, 2546, 290, 13357, 13]",0.5,781,ml_signal,155,Logging model parameters can be used to track model size and complexity.,,759,            self.tra.fc.reset_parameters(),"[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 2116, 13, 9535, 13, 16072, 13, 42503, 62, 17143, 7307, 3419]"
üß† ML Signal: Initialization of optimizer can be used to track training configuration.,"[8582, 100, 254, 10373, 26484, 25, 20768, 1634, 286, 6436, 7509, 460, 307, 973, 284, 2610, 3047, 8398, 13]",0.5,781,ml_signal,157,Initialization of optimizer can be used to track training configuration.,,781,,[]
üß† ML Signal: Tracking the fitted state of the model can be used to monitor training progress.,"[8582, 100, 254, 10373, 26484, 25, 37169, 262, 18235, 1181, 286, 262, 2746, 460, 307, 973, 284, 5671, 3047, 4371, 13]",0.5,806,ml_signal,159,Tracking the fitted state of the model can be used to monitor training progress.,,781,"            self.logger.warning(f""freeze model parameters"")","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 2116, 13, 6404, 1362, 13, 43917, 7, 69, 1, 5787, 2736, 2746, 10007, 4943]"
üß† ML Signal: Tracking the global step can be used to monitor training progress.,"[8582, 100, 254, 10373, 26484, 25, 37169, 262, 3298, 2239, 460, 307, 973, 284, 5671, 3047, 4371, 13]",0.5,829,ml_signal,161,Tracking the global step can be used to monitor training progress.,,806,                param.requires_grad_(False),"[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 5772, 13, 47911, 62, 9744, 41052, 25101, 8]"
"üß† ML Signal: Model evaluation mode is set, indicating a testing phase","[8582, 100, 254, 10373, 26484, 25, 9104, 12660, 4235, 318, 900, 11, 12739, 257, 4856, 7108]",0.5,859,ml_signal,229,"Model evaluation mode is set, indicating a testing phase",,829,                lamb = 0 if is_pretrain else self.lamb * decay,"[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 19343, 796, 657, 611, 318, 62, 5310, 3201, 2073, 2116, 13, 2543, 65, 1635, 22119]"
üß† ML Signal: Evaluation mode for another model or component,"[8582, 100, 254, 10373, 26484, 25, 34959, 4235, 329, 1194, 2746, 393, 7515]",0.5,888,ml_signal,231,Evaluation mode for another model or component,,859,                if self._writer is not None and not is_pretrain:,"[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 611, 2116, 13557, 16002, 318, 407, 6045, 290, 407, 318, 62, 5310, 3201, 25]"
üß† ML Signal: Dataset is set to evaluation mode,"[8582, 100, 254, 10373, 26484, 25, 16092, 292, 316, 318, 900, 284, 12660, 4235]",0.5,933,ml_signal,233,Dataset is set to evaluation mode,,888,"                    self._writer.add_scalar(""training/reg_loss"", loss.item(), self.global_step)","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 2116, 13557, 16002, 13, 2860, 62, 1416, 282, 283, 7203, 34409, 14, 2301, 62, 22462, 1600, 2994, 13, 9186, 22784, 2116, 13, 20541, 62, 9662, 8]"
üß† ML Signal: Iterating over batches in the dataset,"[8582, 100, 254, 10373, 26484, 25, 40806, 803, 625, 37830, 287, 262, 27039]",0.5,946,ml_signal,239,Iterating over batches in the dataset,,933,            else:,"[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 2073, 25]"
üß† ML Signal: Conditional logic based on a class attribute,"[8582, 100, 254, 10373, 26484, 25, 9724, 1859, 9156, 1912, 319, 257, 1398, 11688]",1.0,946,ml_signal,242,Conditional logic based on a class attribute,,946,,[]
‚ö†Ô∏è SAST Risk (Low): Potential for large memory usage if batch size is large,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 32480, 329, 1588, 4088, 8748, 611, 15458, 2546, 318, 1588]",0.5,970,sast_risk,243,Potential for large memory usage if batch size is large,Low,946,            (loss / self.update_freq).backward(),"[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 357, 22462, 1220, 2116, 13, 19119, 62, 19503, 80, 737, 1891, 904, 3419]"
üß† ML Signal: Forward pass through the model,"[8582, 100, 254, 10373, 26484, 25, 19530, 1208, 832, 262, 2746]",0.5,994,ml_signal,243,Forward pass through the model,,970,            (loss / self.update_freq).backward(),"[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 357, 22462, 1220, 2116, 13, 19119, 62, 19503, 80, 737, 1891, 904, 3419]"
üß† ML Signal: Another model/component forward pass,"[8582, 100, 254, 10373, 26484, 25, 6023, 2746, 14, 42895, 2651, 1208]",0.5,1018,ml_signal,243,Another model/component forward pass,,994,            (loss / self.update_freq).backward(),"[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 357, 22462, 1220, 2116, 13, 19119, 62, 19503, 80, 737, 1891, 904, 3419]"
üß† ML Signal: Conditional logic for different training phases or methods,"[8582, 100, 254, 10373, 26484, 25, 9724, 1859, 9156, 329, 1180, 3047, 21164, 393, 5050]",0.5,1044,ml_signal,254,Conditional logic for different training phases or methods,,1018,        if self.use_daily_transport and len(P_all) > 0:,"[220, 220, 220, 220, 220, 220, 220, 611, 2116, 13, 1904, 62, 29468, 62, 7645, 634, 290, 18896, 7, 47, 62, 439, 8, 1875, 657, 25]"
üß† ML Signal: Assigning data back to the dataset,"[8582, 100, 254, 10373, 26484, 25, 2195, 38944, 1366, 736, 284, 262, 27039]",0.5,1086,ml_signal,263,Assigning data back to the dataset,,1044,"                self._writer.add_image(""prob"", plot(prob_all), epoch, dataformats=""HWC"")","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 2116, 13557, 16002, 13, 2860, 62, 9060, 7203, 1676, 65, 1600, 7110, 7, 1676, 65, 62, 439, 828, 36835, 11, 1366, 687, 1381, 2625, 39, 27353, 4943]"
‚ö†Ô∏è SAST Risk (Low): Potentially large DataFrame creation,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 6902, 3746, 1588, 6060, 19778, 6282]",0.5,1101,sast_risk,266,Potentially large DataFrame creation,Low,1086,        total_loss /= total_count,"[220, 220, 220, 220, 220, 220, 220, 2472, 62, 22462, 1220, 28, 2472, 62, 9127]"
üß† ML Signal: Averaging predictions,"[8582, 100, 254, 10373, 26484, 25, 317, 332, 3039, 16277]",0.5,1132,ml_signal,269,Averaging predictions,,1101,"            self._writer.add_scalar(""training/loss"", total_loss, epoch)","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 2116, 13557, 16002, 13, 2860, 62, 1416, 282, 283, 7203, 34409, 14, 22462, 1600, 2472, 62, 22462, 11, 36835, 8]"
‚ö†Ô∏è SAST Risk (Low): Potentially large array concatenation,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 6902, 3746, 1588, 7177, 1673, 36686, 341]",0.5,1163,sast_risk,269,Potentially large array concatenation,Low,1132,"            self._writer.add_scalar(""training/loss"", total_loss, epoch)","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 2116, 13557, 16002, 13, 2860, 62, 1416, 282, 283, 7203, 34409, 14, 22462, 1600, 2472, 62, 22462, 11, 36835, 8]"
‚ö†Ô∏è SAST Risk (Low): Potentially large DataFrame creation,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 6902, 3746, 1588, 6060, 19778, 6282]",0.5,1176,sast_risk,275,Potentially large DataFrame creation,Low,1163,        self.tra.eval(),"[220, 220, 220, 220, 220, 220, 220, 2116, 13, 9535, 13, 18206, 3419]"
üß† ML Signal: Collecting evaluation metrics,"[8582, 100, 254, 10373, 26484, 25, 9745, 278, 12660, 20731]",1.0,1189,ml_signal,276,Collecting evaluation metrics,,1176,        data_set.eval(),"[220, 220, 220, 220, 220, 220, 220, 1366, 62, 2617, 13, 18206, 3419]"
‚ö†Ô∏è SAST Risk (Low): Potentially large DataFrame creation,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 6902, 3746, 1588, 6060, 19778, 6282]",0.5,1207,sast_risk,282,Potentially large DataFrame creation,Low,1189,        for batch in tqdm(data_set):,"[220, 220, 220, 220, 220, 220, 220, 329, 15458, 287, 256, 80, 36020, 7, 7890, 62, 2617, 2599]"
‚ö†Ô∏è SAST Risk (Low): Potentially large DataFrame creation,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 6902, 3746, 1588, 6060, 19778, 6282]",0.5,1240,sast_risk,284,Potentially large DataFrame creation,Low,1207,"            index = batch[""daily_index""] if self.use_daily_transport else batch[""index""]","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 6376, 796, 15458, 14692, 29468, 62, 9630, 8973, 611, 2116, 13, 1904, 62, 29468, 62, 7645, 634, 2073, 15458, 14692, 9630, 8973]"
üß† ML Signal: Logging metrics conditionally,"[8582, 100, 254, 10373, 26484, 25, 5972, 2667, 20731, 4006, 453]",1.0,1264,ml_signal,292,Logging metrics conditionally,,1240,"                    all_preds,","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 477, 62, 28764, 82, 11]"
‚ö†Ô∏è SAST Risk (Low): Potentially large DataFrame concatenation,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 6902, 3746, 1588, 6060, 19778, 1673, 36686, 341]",0.5,1285,sast_risk,297,Potentially large DataFrame concatenation,Low,1264,"                    count,","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 954, 11]"
‚úÖ Best Practice: Sorting index for consistent ordering,"[26486, 227, 6705, 19939, 25, 311, 24707, 6376, 329, 6414, 16216]",0.5,1301,best_practice,301,Sorting index for consistent ordering,,1285,                ),"[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 1267]"
‚ö†Ô∏è SAST Risk (Low): Potentially large DataFrame concatenation,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 6902, 3746, 1588, 6060, 19778, 1673, 36686, 341]",0.5,1342,sast_risk,304,Potentially large DataFrame concatenation,Low,1301,"                    P_all.append(pd.DataFrame(P.cpu().numpy(), index=index))","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 350, 62, 439, 13, 33295, 7, 30094, 13, 6601, 19778, 7, 47, 13, 36166, 22446, 77, 32152, 22784, 6376, 28, 9630, 4008]"
‚úÖ Best Practice: Sorting index for consistent ordering,"[26486, 227, 6705, 19939, 25, 311, 24707, 6376, 329, 6414, 16216]",0.5,1342,best_practice,311,Sorting index for consistent ordering,,1342,,[]
‚ö†Ô∏è SAST Risk (Low): Potentially large DataFrame concatenation,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 6902, 3746, 1588, 6060, 19778, 1673, 36686, 341]",0.5,1358,sast_risk,314,Potentially large DataFrame concatenation,Low,1342,            if return_pred:,"[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 611, 1441, 62, 28764, 25]"
‚úÖ Best Practice: Sorting index for consistent ordering,"[26486, 227, 6705, 19939, 25, 311, 24707, 6376, 329, 6414, 16216]",0.5,1368,best_practice,321,Sorting index for consistent ordering,,1358,        metrics = {,"[220, 220, 220, 220, 220, 220, 220, 20731, 796, 1391]"
‚úÖ Best Practice: Use of logging for tracking the flow and state of the application,"[26486, 227, 6705, 19939, 25, 5765, 286, 18931, 329, 9646, 262, 5202, 290, 1181, 286, 262, 3586]",0.5,1411,best_practice,308,Use of logging for tracking the flow and state of the application,,1368,"            X = np.c_[pred.cpu().numpy(), label.cpu().numpy(), all_preds.cpu().numpy()]","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 1395, 796, 45941, 13, 66, 62, 58, 28764, 13, 36166, 22446, 77, 32152, 22784, 6167, 13, 36166, 22446, 77, 32152, 22784, 477, 62, 28764, 82, 13, 36166, 22446, 77, 32152, 3419, 60]"
‚úÖ Best Practice: Use of logging for tracking the flow and state of the application,"[26486, 227, 6705, 19939, 25, 5765, 286, 18931, 329, 9646, 262, 5202, 290, 1181, 286, 262, 3586]",0.5,1411,best_practice,313,Use of logging for tracking the flow and state of the application,,1411,,[]
‚úÖ Best Practice: Use of logging for tracking the flow and state of the application,"[26486, 227, 6705, 19939, 25, 5765, 286, 18931, 329, 9646, 262, 5202, 290, 1181, 286, 262, 3586]",0.5,1433,best_practice,315,Use of logging for tracking the flow and state of the application,,1411,                preds.append(pred),"[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 2747, 82, 13, 33295, 7, 28764, 8]"
‚úÖ Best Practice: Use of logging for tracking the flow and state of the application,"[26486, 227, 6705, 19939, 25, 5765, 286, 18931, 329, 9646, 262, 5202, 290, 1181, 286, 262, 3586]",0.5,1479,best_practice,318,Use of logging for tracking the flow and state of the application,,1433,"                    probs.append(pd.DataFrame(prob.cpu().numpy(), index=index, columns=columns))","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 386, 1443, 13, 33295, 7, 30094, 13, 6601, 19778, 7, 1676, 65, 13, 36166, 22446, 77, 32152, 22784, 6376, 28, 9630, 11, 15180, 28, 28665, 82, 4008]"
‚úÖ Best Practice: Use of logging for tracking the flow and state of the application,"[26486, 227, 6705, 19939, 25, 5765, 286, 18931, 329, 9646, 262, 5202, 290, 1181, 286, 262, 3586]",0.5,1499,best_practice,324,Use of logging for tracking the flow and state of the application,,1479,"            ""IC"": metrics.IC.mean(),","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 366, 2149, 1298, 20731, 13, 2149, 13, 32604, 22784]"
‚úÖ Best Practice: Use of logging for tracking the flow and state of the application,"[26486, 227, 6705, 19939, 25, 5765, 286, 18931, 329, 9646, 262, 5202, 290, 1181, 286, 262, 3586]",0.5,1524,best_practice,328,Use of logging for tracking the flow and state of the application,,1499,        if self._writer is not None and epoch >= 0 and not is_pretrain:,"[220, 220, 220, 220, 220, 220, 220, 611, 2116, 13557, 16002, 318, 407, 6045, 290, 36835, 18189, 657, 290, 407, 318, 62, 5310, 3201, 25]"
‚úÖ Best Practice: Use of logging for tracking the flow and state of the application,"[26486, 227, 6705, 19939, 25, 5765, 286, 18931, 329, 9646, 262, 5202, 290, 1181, 286, 262, 3586]",0.5,1536,best_practice,332,Use of logging for tracking the flow and state of the application,,1524,        if return_pred:,"[220, 220, 220, 220, 220, 220, 220, 611, 1441, 62, 28764, 25]"
‚ö†Ô∏è SAST Risk (Low): Potential file path manipulation vulnerability,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 32480, 2393, 3108, 17512, 15131]",1.0,1574,sast_risk,343,Potential file path manipulation vulnerability,Low,1536,                    probs.index = data_set.restore_index(probs.index),"[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 386, 1443, 13, 9630, 796, 1366, 62, 2617, 13, 2118, 382, 62, 9630, 7, 1676, 1443, 13, 9630, 8]"
‚úÖ Best Practice: Use of logging for tracking the flow and state of the application,"[26486, 227, 6705, 19939, 25, 5765, 286, 18931, 329, 9646, 262, 5202, 290, 1181, 286, 262, 3586]",0.5,1599,best_practice,349,Use of logging for tracking the flow and state of the application,,1574,                if self.use_daily_transport:,"[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 611, 2116, 13, 1904, 62, 29468, 62, 7645, 634, 25]"
‚úÖ Best Practice: Use of logging for tracking the flow and state of the application,"[26486, 227, 6705, 19939, 25, 5765, 286, 18931, 329, 9646, 262, 5202, 290, 1181, 286, 262, 3586]",0.5,1639,best_practice,352,Use of logging for tracking the flow and state of the application,,1599,                    P_all.index = data_set.restore_index(P_all.index),"[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 350, 62, 439, 13, 9630, 796, 1366, 62, 2617, 13, 2118, 382, 62, 9630, 7, 47, 62, 439, 13, 9630, 8]"
‚ö†Ô∏è SAST Risk (Low): Using mutable default arguments like dict() can lead to unexpected behavior.,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 8554, 4517, 540, 4277, 7159, 588, 8633, 3419, 460, 1085, 284, 10059, 4069, 13]",1.0,1672,sast_risk,348,Using mutable default arguments like dict() can lead to unexpected behavior.,Low,1639,"                P_all = pd.concat(P_all, axis=0)","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 350, 62, 439, 796, 279, 67, 13, 1102, 9246, 7, 47, 62, 439, 11, 16488, 28, 15, 8]"
üß† ML Signal: Use of Adam optimizer indicates a common pattern in training ML models.,"[8582, 100, 254, 10373, 26484, 25, 5765, 286, 7244, 6436, 7509, 9217, 257, 2219, 3912, 287, 3047, 10373, 4981, 13]",1.0,1672,ml_signal,357,Use of Adam optimizer indicates a common pattern in training ML models.,,1672,,[]
üß† ML Signal: Re-initializing optimizer for different training phases.,"[8582, 100, 254, 10373, 26484, 25, 797, 12, 36733, 2890, 6436, 7509, 329, 1180, 3047, 21164, 13]",1.0,1700,ml_signal,363,Re-initializing optimizer for different training phases.,,1672,"            ""model"": copy.deepcopy(self.model.state_dict()),","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 366, 19849, 1298, 4866, 13, 22089, 30073, 7, 944, 13, 19849, 13, 5219, 62, 11600, 3419, 828]"
‚ö†Ô∏è SAST Risk (Low): Potential path traversal if logdir is not properly sanitized.,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 32480, 3108, 33038, 282, 611, 2604, 15908, 318, 407, 6105, 5336, 36951, 13]",1.0,1700,sast_risk,376,Potential path traversal if logdir is not properly sanitized.,Low,1700,,[]
‚ö†Ô∏è SAST Risk (Low): Potential path traversal if logdir is not properly sanitized.,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 32480, 3108, 33038, 282, 611, 2604, 15908, 318, 407, 6105, 5336, 36951, 13]",1.0,1731,sast_risk,380,Potential path traversal if logdir is not properly sanitized.,Low,1700,                train_set.clear_memory()  # NOTE: clear the shared memory,"[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 4512, 62, 2617, 13, 20063, 62, 31673, 3419, 220, 1303, 24550, 25, 1598, 262, 4888, 4088]"
‚ö†Ô∏è SAST Risk (Low): Potential path traversal if logdir is not properly sanitized.,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 32480, 3108, 33038, 282, 611, 2604, 15908, 318, 407, 6105, 5336, 36951, 13]",1.0,1761,sast_risk,382,Potential path traversal if logdir is not properly sanitized.,Low,1731,"                evals_result[""train""].append(train_metrics)","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 819, 874, 62, 20274, 14692, 27432, 1, 4083, 33295, 7, 27432, 62, 4164, 10466, 8]"
‚ö†Ô∏è SAST Risk (Low): Potential path traversal if logdir is not properly sanitized.,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 32480, 3108, 33038, 282, 611, 2604, 15908, 318, 407, 6105, 5336, 36951, 13]",1.0,1761,sast_risk,384,Potential path traversal if logdir is not properly sanitized.,Low,1761,,[]
‚ö†Ô∏è SAST Risk (Low): Potential path traversal if logdir is not properly sanitized.,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 32480, 3108, 33038, 282, 611, 2604, 15908, 318, 407, 6105, 5336, 36951, 13]",1.0,1787,sast_risk,386,Potential path traversal if logdir is not properly sanitized.,Low,1761,"            evals_result[""valid""].append(valid_metrics)","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 819, 874, 62, 20274, 14692, 12102, 1, 4083, 33295, 7, 12102, 62, 4164, 10466, 8]"
‚ö†Ô∏è SAST Risk (Low): Potential path traversal if logdir is not properly sanitized.,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 32480, 3108, 33038, 282, 611, 2604, 15908, 318, 407, 6105, 5336, 36951, 13]",1.0,1787,sast_risk,388,Potential path traversal if logdir is not properly sanitized.,Low,1787,,[]
‚ö†Ô∏è SAST Risk (Low): Potential path traversal if logdir is not properly sanitized.,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 32480, 3108, 33038, 282, 611, 2604, 15908, 318, 407, 6105, 5336, 36951, 13]",1.0,1787,sast_risk,388,Potential path traversal if logdir is not properly sanitized.,Low,1787,,[]
‚ö†Ô∏è SAST Risk (Low): Potential path traversal if logdir is not properly sanitized.,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 32480, 3108, 33038, 282, 611, 2604, 15908, 318, 407, 6105, 5336, 36951, 13]",1.0,1787,sast_risk,388,Potential path traversal if logdir is not properly sanitized.,Low,1787,,[]
‚ö†Ô∏è SAST Risk (Low): Potential path traversal if logdir is not properly sanitized.,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 32480, 3108, 33038, 282, 611, 2604, 15908, 318, 407, 6105, 5336, 36951, 13]",1.0,1787,sast_risk,388,Potential path traversal if logdir is not properly sanitized.,Low,1787,,[]
‚ö†Ô∏è SAST Risk (Low): Potential path traversal if logdir is not properly sanitized.,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 32480, 3108, 33038, 282, 611, 2604, 15908, 318, 407, 6105, 5336, 36951, 13]",1.0,1787,sast_risk,388,Potential path traversal if logdir is not properly sanitized.,Low,1787,,[]
‚ö†Ô∏è SAST Risk (Low): Potential path traversal if logdir is not properly sanitized.,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 32480, 3108, 33038, 282, 611, 2604, 15908, 318, 407, 6105, 5336, 36951, 13]",1.0,1823,sast_risk,410,Potential path traversal if logdir is not properly sanitized.,Low,1787,"        self.logger.info(""best score: %.6lf @ %d"" % (best_score, best_epoch))","[220, 220, 220, 220, 220, 220, 220, 2116, 13, 6404, 1362, 13, 10951, 7203, 13466, 4776, 25, 4064, 13, 21, 1652, 2488, 4064, 67, 1, 4064, 357, 13466, 62, 26675, 11, 1266, 62, 538, 5374, 4008]"
‚ö†Ô∏è SAST Risk (Low): Potential path traversal if logdir is not properly sanitized.,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 32480, 3108, 33038, 282, 611, 2604, 15908, 318, 407, 6105, 5336, 36951, 13]",1.0,1835,sast_risk,421,Potential path traversal if logdir is not properly sanitized.,Low,1823,        self.fitted = True,"[220, 220, 220, 220, 220, 220, 220, 2116, 13, 38631, 796, 6407]"
"‚úÖ Best Practice: Method signature includes default parameter values, improving usability.","[26486, 227, 6705, 19939, 25, 11789, 9877, 3407, 4277, 11507, 3815, 11, 10068, 42863, 13]",1.0,1859,best_practice,412,"Method signature includes default parameter values, improving usability.",,1835,"        self.tra.load_state_dict(best_params[""tra""])","[220, 220, 220, 220, 220, 220, 220, 2116, 13, 9535, 13, 2220, 62, 5219, 62, 11600, 7, 13466, 62, 37266, 14692, 9535, 8973, 8]"
‚úÖ Best Practice: Using assert to enforce type checking for the dataset parameter.,"[26486, 227, 6705, 19939, 25, 8554, 6818, 284, 4605, 2099, 10627, 329, 262, 27039, 11507, 13]",1.0,1870,best_practice,414,Using assert to enforce type checking for the dataset parameter.,,1859,        return best_score,"[220, 220, 220, 220, 220, 220, 220, 1441, 1266, 62, 26675]"
"‚ö†Ô∏è SAST Risk (Low): Potential for assert statement to be disabled in optimized mode, leading to type issues.","[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 32480, 329, 6818, 2643, 284, 307, 10058, 287, 23392, 4235, 11, 3756, 284, 2099, 2428, 13]",0.5,1888,sast_risk,416,"Potential for assert statement to be disabled in optimized mode, leading to type issues.",Low,1870,"    def fit(self, dataset, evals_result=dict()):","[220, 220, 220, 825, 4197, 7, 944, 11, 27039, 11, 819, 874, 62, 20274, 28, 11600, 3419, 2599]"
"‚ö†Ô∏è SAST Risk (Medium): Raises a ValueError if the model is not fitted, which could be a denial of service vector if not handled properly by the caller.","[158, 248, 254, 37929, 311, 11262, 19602, 357, 31205, 2599, 7567, 2696, 257, 11052, 12331, 611, 262, 2746, 318, 407, 18235, 11, 543, 714, 307, 257, 14425, 286, 2139, 15879, 611, 407, 12118, 6105, 416, 262, 24955, 13]",0.5,1938,sast_risk,417,"Raises a ValueError if the model is not fitted, which could be a denial of service vector if not handled properly by the caller.",Medium,1888,"        assert isinstance(dataset, MTSDatasetH), ""TRAModel only supports `qlib.contrib.data.dataset.MTSDatasetH`""","[220, 220, 220, 220, 220, 220, 220, 6818, 318, 39098, 7, 19608, 292, 316, 11, 337, 4694, 27354, 292, 316, 39, 828, 366, 5446, 2390, 375, 417, 691, 6971, 4600, 80, 8019, 13, 3642, 822, 13, 7890, 13, 19608, 292, 316, 13, 44, 4694, 27354, 292, 316, 39, 63, 1]"
‚úÖ Best Practice: Preparing the dataset for the specified segment.,"[26486, 227, 6705, 19939, 25, 19141, 1723, 262, 27039, 329, 262, 7368, 10618, 13]",0.5,1938,best_practice,420,Preparing the dataset for the specified segment.,,1938,,[]
"üß† ML Signal: Calls a method to test the model, indicating a pattern of model evaluation.","[8582, 100, 254, 10373, 26484, 25, 27592, 257, 2446, 284, 1332, 262, 2746, 11, 12739, 257, 3912, 286, 2746, 12660, 13]",0.5,1950,ml_signal,421,"Calls a method to test the model, indicating a pattern of model evaluation.",,1938,        self.fitted = True,"[220, 220, 220, 220, 220, 220, 220, 2116, 13, 38631, 796, 6407]"
"üß† ML Signal: Logging metrics, which is useful for monitoring model performance.","[8582, 100, 254, 10373, 26484, 25, 5972, 2667, 20731, 11, 543, 318, 4465, 329, 9904, 2746, 2854, 13]",0.5,1962,ml_signal,421,"Logging metrics, which is useful for monitoring model performance.",,1950,        self.fitted = True,"[220, 220, 220, 220, 220, 220, 220, 2116, 13, 38631, 796, 6407]"
"üß† ML Signal: Returns predictions, a common pattern in ML model interfaces.","[8582, 100, 254, 10373, 26484, 25, 16409, 16277, 11, 257, 2219, 3912, 287, 10373, 2746, 20314, 13]",1.0,1974,ml_signal,421,"Returns predictions, a common pattern in ML model interfaces.",,1962,        self.fitted = True,"[220, 220, 220, 220, 220, 220, 220, 2116, 13, 38631, 796, 6407]"
‚úÖ Best Practice: Class docstring provides a clear description of the class and its parameters,"[26486, 227, 6705, 19939, 25, 5016, 2205, 8841, 3769, 257, 1598, 6764, 286, 262, 1398, 290, 663, 10007]",1.0,1974,best_practice,420,Class docstring provides a clear description of the class and its parameters,,1974,,[]
‚úÖ Best Practice: Consider validating input parameters for expected types and ranges,"[26486, 227, 6705, 19939, 25, 12642, 4938, 803, 5128, 10007, 329, 2938, 3858, 290, 16069]",0.5,1974,best_practice,447,Consider validating input parameters for expected types and ranges,,1974,,[]
üß† ML Signal: Dynamic RNN architecture selection based on parameter,"[8582, 100, 254, 10373, 26484, 25, 26977, 371, 6144, 10959, 6356, 1912, 319, 11507]",0.5,1987,ml_signal,451,Dynamic RNN architecture selection based on parameter,,1974,        if self.logdir:,"[220, 220, 220, 220, 220, 220, 220, 611, 2116, 13, 6404, 15908, 25]"
‚ö†Ô∏è SAST Risk (Low): getattr can lead to security risks if rnn_arch is not validated,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 651, 35226, 460, 1085, 284, 2324, 7476, 611, 374, 20471, 62, 998, 318, 407, 31031]",0.5,2000,sast_risk,451,getattr can lead to security risks if rnn_arch is not validated,Low,1987,        if self.logdir:,"[220, 220, 220, 220, 220, 220, 220, 611, 2116, 13, 6404, 15908, 25]"
"üß† ML Signal: Checks if input projection is used, indicating a flexible model architecture","[8582, 100, 254, 10373, 26484, 25, 47719, 611, 5128, 20128, 318, 973, 11, 12739, 257, 12846, 2746, 10959]",1.0,2039,ml_signal,465,"Checks if input projection is used, indicating a flexible model architecture",,2000,"                train_probs.to_pickle(self.logdir + ""/train_prob.pkl"")","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 4512, 62, 1676, 1443, 13, 1462, 62, 27729, 293, 7, 944, 13, 6404, 15908, 1343, 12813, 27432, 62, 1676, 65, 13, 79, 41582, 4943]"
üß† ML Signal: Use of RNN indicates sequence processing,"[8582, 100, 254, 10373, 26484, 25, 5765, 286, 371, 6144, 9217, 8379, 7587]",1.0,2039,ml_signal,468,Use of RNN indicates sequence processing,,2039,,[]
üß† ML Signal: Conditional logic based on RNN architecture type,"[8582, 100, 254, 10373, 26484, 25, 9724, 1859, 9156, 1912, 319, 371, 6144, 10959, 2099]",1.0,2076,ml_signal,470,Conditional logic based on RNN architecture type,,2039,"                train_P.to_pickle(self.logdir + ""/train_P.pkl"")","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 4512, 62, 47, 13, 1462, 62, 27729, 293, 7, 944, 13, 6404, 15908, 1343, 12813, 27432, 62, 47, 13, 79, 41582, 4943]"
‚úÖ Best Practice: Using mean to aggregate outputs for consistent output size,"[26486, 227, 6705, 19939, 25, 8554, 1612, 284, 19406, 23862, 329, 6414, 5072, 2546]",0.5,2076,best_practice,473,Using mean to aggregate outputs for consistent output size,,2076,,[]
üß† ML Signal: Use of attention mechanism for sequence weighting,"[8582, 100, 254, 10373, 26484, 25, 5765, 286, 3241, 9030, 329, 8379, 3463, 278]",1.0,2095,ml_signal,475,Use of attention mechanism for sequence weighting,,2076,"                ""config"": {","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 366, 11250, 1298, 1391]"
üß† ML Signal: Transformation and non-linearity applied to RNN output,"[8582, 100, 254, 10373, 26484, 25, 49127, 290, 1729, 12, 29127, 414, 5625, 284, 371, 6144, 5072]",0.5,2125,ml_signal,477,Transformation and non-linearity applied to RNN output,,2095,"                    ""tra_config"": self.tra_config,","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 366, 9535, 62, 11250, 1298, 2116, 13, 9535, 62, 11250, 11]"
üß† ML Signal: Softmax used for attention score calculation,"[8582, 100, 254, 10373, 26484, 25, 8297, 9806, 973, 329, 3241, 4776, 17952]",1.0,2151,ml_signal,479,Softmax used for attention score calculation,,2125,"                    ""lr"": self.lr,","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 366, 14050, 1298, 2116, 13, 14050, 11]"
üß† ML Signal: Weighted sum for attention output,"[8582, 100, 254, 10373, 26484, 25, 14331, 276, 2160, 329, 3241, 5072]",1.0,2181,ml_signal,481,Weighted sum for attention output,,2151,"                    ""early_stop"": self.early_stop,","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 366, 11458, 62, 11338, 1298, 2116, 13, 11458, 62, 11338, 11]"
‚úÖ Best Practice: Concatenating outputs for enriched feature representation,"[26486, 227, 6705, 19939, 25, 1482, 9246, 268, 803, 23862, 329, 35601, 3895, 10552]",0.5,2209,best_practice,483,Concatenating outputs for enriched feature representation,,2181,"                    ""lamb"": self.lamb,","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 366, 2543, 65, 1298, 2116, 13, 2543, 65, 11]"
‚úÖ Best Practice: Inheriting from nn.Module is standard for PyTorch models and layers.,"[26486, 227, 6705, 19939, 25, 47025, 1780, 422, 299, 77, 13, 26796, 318, 3210, 329, 9485, 15884, 354, 4981, 290, 11685, 13]",0.5,2239,best_practice,477,Inheriting from nn.Module is standard for PyTorch models and layers.,,2209,"                    ""tra_config"": self.tra_config,","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 366, 9535, 62, 11250, 1298, 2116, 13, 9535, 62, 11250, 11]"
‚úÖ Best Practice: Use of super() to initialize the parent class,"[26486, 227, 6705, 19939, 25, 5765, 286, 2208, 3419, 284, 41216, 262, 2560, 1398]",0.5,2265,best_practice,479,Use of super() to initialize the parent class,,2239,"                    ""lr"": self.lr,","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 366, 14050, 1298, 2116, 13, 14050, 11]"
"üß† ML Signal: Use of dropout, common in neural network models to prevent overfitting","[8582, 100, 254, 10373, 26484, 25, 5765, 286, 4268, 448, 11, 2219, 287, 17019, 3127, 4981, 284, 2948, 625, 32232]",1.0,2295,ml_signal,481,"Use of dropout, common in neural network models to prevent overfitting",,2265,"                    ""early_stop"": self.early_stop,","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 366, 11458, 62, 11338, 1298, 2116, 13, 11458, 62, 11338, 11]"
"üß† ML Signal: Initialization of positional encoding matrix, common in transformer models","[8582, 100, 254, 10373, 26484, 25, 20768, 1634, 286, 45203, 21004, 17593, 11, 2219, 287, 47385, 4981]",1.0,2323,ml_signal,483,"Initialization of positional encoding matrix, common in transformer models",,2295,"                    ""lamb"": self.lamb,","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 366, 2543, 65, 1298, 2116, 13, 2543, 65, 11]"
üß† ML Signal: Use of torch.arange to create a sequence of positions,"[8582, 100, 254, 10373, 26484, 25, 5765, 286, 28034, 13, 283, 858, 284, 2251, 257, 8379, 286, 6116]",1.0,2349,ml_signal,485,Use of torch.arange to create a sequence of positions,,2323,"                    ""alpha"": self.alpha,","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 366, 26591, 1298, 2116, 13, 26591, 11]"
"üß† ML Signal: Calculation of div_term for scaling positions, specific to transformer models","[8582, 100, 254, 10373, 26484, 25, 2199, 14902, 286, 2659, 62, 4354, 329, 20796, 6116, 11, 2176, 284, 47385, 4981]",1.0,2377,ml_signal,487,"Calculation of div_term for scaling positions, specific to transformer models",,2349,"                    ""logdir"": self.logdir,","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 366, 6404, 15908, 1298, 2116, 13, 6404, 15908, 11]"
üß† ML Signal: Use of sine and cosine functions for positional encoding,"[8582, 100, 254, 10373, 26484, 25, 5765, 286, 264, 500, 290, 8615, 500, 5499, 329, 45203, 21004]",1.0,2407,ml_signal,489,Use of sine and cosine functions for positional encoding,,2377,"                    ""init_state"": self.init_state,","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 366, 15003, 62, 5219, 1298, 2116, 13, 15003, 62, 5219, 11]"
üß† ML Signal: Reshaping positional encoding for model input,"[8582, 100, 254, 10373, 26484, 25, 1874, 71, 9269, 45203, 21004, 329, 2746, 5128]",0.5,2423,ml_signal,492,Reshaping positional encoding for model input,,2407,"                },","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 8964]"
‚úÖ Best Practice: Use of register_buffer to store tensors not considered model parameters,"[26486, 227, 6705, 19939, 25, 5765, 286, 7881, 62, 22252, 284, 3650, 11192, 669, 407, 3177, 2746, 10007]",1.0,2439,best_practice,492,Use of register_buffer to store tensors not considered model parameters,,2423,"                },","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 8964]"
"üß† ML Signal: Use of positional encoding in a forward pass, common in transformer models","[8582, 100, 254, 10373, 26484, 25, 5765, 286, 45203, 21004, 287, 257, 2651, 1208, 11, 2219, 287, 47385, 4981]",0.5,2469,ml_signal,489,"Use of positional encoding in a forward pass, common in transformer models",,2439,"                    ""init_state"": self.init_state,","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 366, 15003, 62, 5219, 1298, 2116, 13, 15003, 62, 5219, 11]"
üß† ML Signal: Use of dropout for regularization in neural networks,"[8582, 100, 254, 10373, 26484, 25, 5765, 286, 4268, 448, 329, 3218, 1634, 287, 17019, 7686]",1.0,2505,ml_signal,491,Use of dropout for regularization in neural networks,,2469,"                    ""use_daily_transport"": self.use_daily_transport,","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 366, 1904, 62, 29468, 62, 7645, 634, 1298, 2116, 13, 1904, 62, 29468, 62, 7645, 634, 11]"
"üß† ML Signal: Definition of a Transformer model class, useful for identifying model architecture patterns","[8582, 100, 254, 10373, 26484, 25, 30396, 286, 257, 3602, 16354, 2746, 1398, 11, 4465, 329, 13720, 2746, 10959, 7572]",0.5,2541,ml_signal,491,"Definition of a Transformer model class, useful for identifying model architecture patterns",,2505,"                    ""use_daily_transport"": self.use_daily_transport,","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 366, 1904, 62, 29468, 62, 7645, 634, 1298, 2116, 13, 1904, 62, 29468, 62, 7645, 634, 11]"
‚úÖ Best Practice: Call to super() ensures proper initialization of the base class,"[26486, 227, 6705, 19939, 25, 4889, 284, 2208, 3419, 19047, 1774, 37588, 286, 262, 2779, 1398]",1.0,2541,best_practice,509,Call to super() ensures proper initialization of the base class,,2541,,[]
üß† ML Signal: Storing model hyperparameters as instance variables,"[8582, 100, 254, 10373, 26484, 25, 520, 3255, 2746, 8718, 17143, 7307, 355, 4554, 9633]",1.0,2541,ml_signal,511,Storing model hyperparameters as instance variables,,2541,,[]
üß† ML Signal: Storing model hyperparameters as instance variables,"[8582, 100, 254, 10373, 26484, 25, 520, 3255, 2746, 8718, 17143, 7307, 355, 4554, 9633]",1.0,2549,ml_signal,513,Storing model hyperparameters as instance variables,,2541,class RNN(nn.Module):,"[4871, 371, 6144, 7, 20471, 13, 26796, 2599]"
üß† ML Signal: Storing model hyperparameters as instance variables,"[8582, 100, 254, 10373, 26484, 25, 520, 3255, 2746, 8718, 17143, 7307, 355, 4554, 9633]",1.0,2549,ml_signal,515,Storing model hyperparameters as instance variables,,2549,,[]
üß† ML Signal: Storing model hyperparameters as instance variables,"[8582, 100, 254, 10373, 26484, 25, 520, 3255, 2746, 8718, 17143, 7307, 355, 4554, 9633]",1.0,2555,ml_signal,516,Storing model hyperparameters as instance variables,,2549,    Args:,"[220, 220, 220, 943, 14542, 25]"
‚úÖ Best Practice: Using nn.Linear for input projection,"[26486, 227, 6705, 19939, 25, 8554, 299, 77, 13, 14993, 451, 329, 5128, 20128]",0.5,2573,best_practice,519,Using nn.Linear for input projection,,2555,        num_layers (int): number of hidden layers,"[220, 220, 220, 220, 220, 220, 220, 997, 62, 75, 6962, 357, 600, 2599, 1271, 286, 7104, 11685]"
‚úÖ Best Practice: Using a separate class for positional encoding,"[26486, 227, 6705, 19939, 25, 8554, 257, 4553, 1398, 329, 45203, 21004]",0.5,2592,best_practice,521,Using a separate class for positional encoding,,2573,        use_attn (bool): whether use attention layer.,"[220, 220, 220, 220, 220, 220, 220, 779, 62, 1078, 77, 357, 30388, 2599, 1771, 779, 3241, 7679, 13]"
‚úÖ Best Practice: Using nn.TransformerEncoderLayer for modularity,"[26486, 227, 6705, 19939, 25, 8554, 299, 77, 13, 8291, 16354, 27195, 12342, 49925, 329, 26507, 414]",0.5,2607,best_practice,523,Using nn.TransformerEncoderLayer for modularity,,2592,        dropout (float): dropout rate,"[220, 220, 220, 220, 220, 220, 220, 4268, 448, 357, 22468, 2599, 4268, 448, 2494]"
‚úÖ Best Practice: Using nn.TransformerEncoder for building the encoder,"[26486, 227, 6705, 19939, 25, 8554, 299, 77, 13, 8291, 16354, 27195, 12342, 329, 2615, 262, 2207, 12342]",1.0,2616,best_practice,527,Using nn.TransformerEncoder for building the encoder,,2607,"        self,","[220, 220, 220, 220, 220, 220, 220, 2116, 11]"
üß† ML Signal: Storing model hyperparameters as instance variables,"[8582, 100, 254, 10373, 26484, 25, 520, 3255, 2746, 8718, 17143, 7307, 355, 4554, 9633]",1.0,2629,ml_signal,528,Storing model hyperparameters as instance variables,,2616,"        input_size=16,","[220, 220, 220, 220, 220, 220, 220, 5128, 62, 7857, 28, 1433, 11]"
"üß† ML Signal: Use of permute suggests handling of multi-dimensional data, common in ML models","[8582, 100, 254, 10373, 26484, 25, 5765, 286, 9943, 1133, 5644, 9041, 286, 5021, 12, 19577, 1366, 11, 2219, 287, 10373, 4981]",0.5,2662,ml_signal,522,"Use of permute suggests handling of multi-dimensional data, common in ML models",,2629,            we use concat attention as https://github.com/fulifeng/Adv-ALSTM/,"[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 356, 779, 1673, 265, 3241, 355, 3740, 1378, 12567, 13, 785, 14, 913, 361, 1516, 14, 22856, 12, 1847, 2257, 44, 14]"
"üß† ML Signal: Applying positional encoding, a common pattern in transformer models","[8582, 100, 254, 10373, 26484, 25, 2034, 3157, 45203, 21004, 11, 257, 2219, 3912, 287, 47385, 4981]",1.0,2666,ml_signal,524,"Applying positional encoding, a common pattern in transformer models",,2662,"    """"""","[220, 220, 220, 37227]"
"üß† ML Signal: Use of input projection, indicating transformation of input features","[8582, 100, 254, 10373, 26484, 25, 5765, 286, 5128, 20128, 11, 12739, 13389, 286, 5128, 3033]",0.5,2674,ml_signal,526,"Use of input projection, indicating transformation of input features",,2666,    def __init__(,"[220, 220, 220, 825, 11593, 15003, 834, 7]"
"üß† ML Signal: Use of encoder, typical in sequence-to-sequence models","[8582, 100, 254, 10373, 26484, 25, 5765, 286, 2207, 12342, 11, 7226, 287, 8379, 12, 1462, 12, 43167, 4981]",0.5,2687,ml_signal,528,"Use of encoder, typical in sequence-to-sequence models",,2674,"        input_size=16,","[220, 220, 220, 220, 220, 220, 220, 5128, 62, 7857, 28, 1433, 11]"
"‚úÖ Best Practice: Returning the last element of the output, common in sequence processing","[26486, 227, 6705, 19939, 25, 42882, 262, 938, 5002, 286, 262, 5072, 11, 2219, 287, 8379, 7587]",0.5,2700,best_practice,528,"Returning the last element of the output, common in sequence processing",,2687,"        input_size=16,","[220, 220, 220, 220, 220, 220, 220, 5128, 62, 7857, 28, 1433, 11]"
‚úÖ Best Practice: Importing necessary modules at the beginning of the file,"[26486, 227, 6705, 19939, 25, 17267, 278, 3306, 13103, 379, 262, 3726, 286, 262, 2393]",1.0,2709,best_practice,527,Importing necessary modules at the beginning of the file,,2700,"        self,","[220, 220, 220, 220, 220, 220, 220, 2116, 11]"
‚úÖ Best Practice: Using type hints for constructor arguments,"[26486, 227, 6705, 19939, 25, 8554, 2099, 20269, 329, 23772, 7159]",0.5,2725,best_practice,539,Using type hints for constructor arguments,,2709,        self.hidden_size = hidden_size,"[220, 220, 220, 220, 220, 220, 220, 2116, 13, 30342, 62, 7857, 796, 7104, 62, 7857]"
‚úÖ Best Practice: Calling the superclass constructor,"[26486, 227, 6705, 19939, 25, 32677, 262, 2208, 4871, 23772]",0.5,2757,best_practice,546,Calling the superclass constructor,,2725,"            self.input_proj = nn.Linear(input_size, hidden_size)","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 2116, 13, 15414, 62, 1676, 73, 796, 299, 77, 13, 14993, 451, 7, 15414, 62, 7857, 11, 7104, 62, 7857, 8]"
üß† ML Signal: Storing model parameters as instance variables,"[8582, 100, 254, 10373, 26484, 25, 520, 3255, 2746, 10007, 355, 4554, 9633]",0.5,2776,ml_signal,548,Storing model parameters as instance variables,,2757,            self.input_proj = None,"[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 2116, 13, 15414, 62, 1676, 73, 796, 6045]"
üß† ML Signal: Defining a linear layer for the router,"[8582, 100, 254, 10373, 26484, 25, 2896, 3191, 257, 14174, 7679, 329, 262, 20264]",0.5,2793,ml_signal,555,Defining a linear layer for the router,,2776,"            dropout=dropout,","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 4268, 448, 28, 14781, 448, 11]"
üß† ML Signal: Defining a linear layer for the output,"[8582, 100, 254, 10373, 26484, 25, 2896, 3191, 257, 14174, 7679, 329, 262, 5072]",0.5,2793,ml_signal,557,Defining a linear layer for the output,,2793,,[]
üß† ML Signal: Using ReLU activation function,"[8582, 100, 254, 10373, 26484, 25, 8554, 797, 41596, 14916, 2163]",1.0,2822,ml_signal,559,Using ReLU activation function,,2793,"            self.W = nn.Linear(hidden_size, hidden_size)","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 2116, 13, 54, 796, 299, 77, 13, 14993, 451, 7, 30342, 62, 7857, 11, 7104, 62, 7857, 8]"
üß† ML Signal: Using Gumbel Softmax for sampling,"[8582, 100, 254, 10373, 26484, 25, 8554, 402, 2178, 417, 8297, 9806, 329, 19232]",1.0,2840,ml_signal,566,Using Gumbel Softmax for sampling,,2822,        if self.input_proj is not None:,"[220, 220, 220, 220, 220, 220, 220, 611, 2116, 13, 15414, 62, 1676, 73, 318, 407, 6045, 25]"
‚ö†Ô∏è SAST Risk (Low): Use of assert for input validation can be disabled in optimized mode,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 5765, 286, 6818, 329, 5128, 21201, 460, 307, 10058, 287, 23392, 4235]",1.0,2865,sast_risk,551,Use of assert for input validation can be disabled in optimized mode,Low,2840,"            input_size=min(input_size, hidden_size),","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 5128, 62, 7857, 28, 1084, 7, 15414, 62, 7857, 11, 7104, 62, 7857, 828]"
üß† ML Signal: Use of nn.Linear indicates a neural network model component,"[8582, 100, 254, 10373, 26484, 25, 5765, 286, 299, 77, 13, 14993, 451, 9217, 257, 17019, 3127, 2746, 7515]",1.0,2865,ml_signal,557,Use of nn.Linear indicates a neural network model component,,2865,,[]
üß† ML Signal: Dynamic selection of RNN architecture based on input,"[8582, 100, 254, 10373, 26484, 25, 26977, 6356, 286, 371, 6144, 10959, 1912, 319, 5128]",1.0,2894,ml_signal,559,Dynamic selection of RNN architecture based on input,,2865,"            self.W = nn.Linear(hidden_size, hidden_size)","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 2116, 13, 54, 796, 299, 77, 13, 14993, 451, 7, 30342, 62, 7857, 11, 7104, 62, 7857, 8]"
üß† ML Signal: Conditional architecture design based on input parameters,"[8582, 100, 254, 10373, 26484, 25, 9724, 1859, 10959, 1486, 1912, 319, 5128, 10007]",1.0,2917,ml_signal,569,Conditional architecture design based on input parameters,,2894,"        rnn_out, last_out = self.rnn(x)","[220, 220, 220, 220, 220, 220, 220, 374, 20471, 62, 448, 11, 938, 62, 448, 796, 2116, 13, 81, 20471, 7, 87, 8]"
"üß† ML Signal: Method to reset parameters, indicating model reinitialization","[8582, 100, 254, 10373, 26484, 25, 11789, 284, 13259, 10007, 11, 12739, 2746, 6865, 6847, 1634]",0.5,2937,ml_signal,570,"Method to reset parameters, indicating model reinitialization",,2917,"        if self.rnn_arch == ""LSTM"":","[220, 220, 220, 220, 220, 220, 220, 611, 2116, 13, 81, 20471, 62, 998, 6624, 366, 43, 2257, 44, 1298]"
"üß† ML Signal: Iterating over model components, common in neural network structures","[8582, 100, 254, 10373, 26484, 25, 40806, 803, 625, 2746, 6805, 11, 2219, 287, 17019, 3127, 8573]",0.5,2958,ml_signal,572,"Iterating over model components, common in neural network structures",,2937,        last_out = last_out.mean(dim=0),"[220, 220, 220, 220, 220, 220, 220, 938, 62, 448, 796, 938, 62, 448, 13, 32604, 7, 27740, 28, 15, 8]"
"üß† ML Signal: Recursive parameter reset, typical in hierarchical model structures","[8582, 100, 254, 10373, 26484, 25, 3311, 30753, 11507, 13259, 11, 7226, 287, 38958, 2746, 8573]",0.5,2973,ml_signal,574,"Recursive parameter reset, typical in hierarchical model structures",,2958,        if self.use_attn:,"[220, 220, 220, 220, 220, 220, 220, 611, 2116, 13, 1904, 62, 1078, 77, 25]"
‚ö†Ô∏è SAST Risk (Low): Use of gumbel_softmax with hard=True can lead to non-differentiable operations,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 5765, 286, 308, 2178, 417, 62, 4215, 9806, 351, 1327, 28, 17821, 460, 1085, 284, 1729, 12, 39799, 3379, 4560]",0.5,2993,sast_risk,586,Use of gumbel_softmax with hard=True can lead to non-differentiable operations,Low,2973,"        super(PositionalEncoding, self).__init__()","[220, 220, 220, 220, 220, 220, 220, 2208, 7, 21604, 1859, 27195, 7656, 11, 2116, 737, 834, 15003, 834, 3419]"
‚ö†Ô∏è SAST Risk (Low): Potential numerical instability in softmax with small tau values,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 32480, 29052, 24842, 287, 2705, 9806, 351, 1402, 256, 559, 3815]",0.5,2993,sast_risk,588,Potential numerical instability in softmax with small tau values,Low,2993,,[]
üß† ML Signal: Function evaluates prediction accuracy using statistical metrics,"[8582, 100, 254, 10373, 26484, 25, 15553, 47850, 17724, 9922, 1262, 13905, 20731]",1.0,3015,ml_signal,589,Function evaluates prediction accuracy using statistical metrics,,2993,"        pe = torch.zeros(max_len, d_model)","[220, 220, 220, 220, 220, 220, 220, 613, 796, 28034, 13, 9107, 418, 7, 9806, 62, 11925, 11, 288, 62, 19849, 8]"
üß† ML Signal: Ranking predictions is a common preprocessing step in ML,"[8582, 100, 254, 10373, 26484, 25, 45407, 16277, 318, 257, 2219, 662, 36948, 2239, 287, 10373]",0.5,3061,ml_signal,591,Ranking predictions is a common preprocessing step in ML,,3015,"        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))","[220, 220, 220, 220, 220, 220, 220, 2659, 62, 4354, 796, 28034, 13, 11201, 7, 13165, 354, 13, 283, 858, 7, 15, 11, 288, 62, 19849, 11, 362, 737, 22468, 3419, 1635, 13841, 11018, 13, 6404, 7, 49388, 13, 15, 8, 1220, 288, 62, 19849, 4008]"
‚ö†Ô∏è SAST Risk (Low): Assumes 'pred' has 'score' and 'label' attributes,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 2195, 8139, 705, 28764, 6, 468, 705, 26675, 6, 290, 705, 18242, 6, 12608]",0.5,3086,sast_risk,593,Assumes 'pred' has 'score' and 'label' attributes,Low,3061,"        pe[:, 1::2] = torch.cos(position * div_term)","[220, 220, 220, 220, 220, 220, 220, 613, 58, 45299, 352, 3712, 17, 60, 796, 28034, 13, 6966, 7, 9150, 1635, 2659, 62, 4354, 8]"
‚ö†Ô∏è SAST Risk (Low): Assumes 'pred' has 'score' and 'label' attributes,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 2195, 8139, 705, 28764, 6, 468, 705, 26675, 6, 290, 705, 18242, 6, 12608]",0.5,3103,sast_risk,595,Assumes 'pred' has 'score' and 'label' attributes,Low,3086,"        self.register_buffer(""pe"", pe)","[220, 220, 220, 220, 220, 220, 220, 2116, 13, 30238, 62, 22252, 7203, 431, 1600, 613, 8]"
üß† ML Signal: Calculating difference between predicted and actual values,"[8582, 100, 254, 10373, 26484, 25, 27131, 803, 3580, 1022, 11001, 290, 4036, 3815]",1.0,3113,ml_signal,597,Calculating difference between predicted and actual values,,3103,"    def forward(self, x):","[220, 220, 220, 825, 2651, 7, 944, 11, 2124, 2599]"
üß† ML Signal: Mean Squared Error is a common metric for regression tasks,"[8582, 100, 254, 10373, 26484, 25, 22728, 5056, 1144, 13047, 318, 257, 2219, 18663, 329, 20683, 8861]",0.5,3128,ml_signal,599,Mean Squared Error is a common metric for regression tasks,,3113,        return self.dropout(x),"[220, 220, 220, 220, 220, 220, 220, 1441, 2116, 13, 14781, 448, 7, 87, 8]"
üß† ML Signal: Mean Absolute Error is a common metric for regression tasks,"[8582, 100, 254, 10373, 26484, 25, 22728, 36532, 13047, 318, 257, 2219, 18663, 329, 20683, 8861]",0.5,3128,ml_signal,601,Mean Absolute Error is a common metric for regression tasks,,3128,,[]
üß† ML Signal: Spearman correlation is used to measure rank correlation,"[8582, 100, 254, 10373, 26484, 25, 27836, 805, 16096, 318, 973, 284, 3953, 4279, 16096]",1.0,3135,ml_signal,603,Spearman correlation is used to measure rank correlation,,3128,"    """"""Transformer Model","[220, 220, 220, 37227, 8291, 16354, 9104]"
‚úÖ Best Practice: Returning a dictionary for structured results,"[26486, 227, 6705, 19939, 25, 42882, 257, 22155, 329, 20793, 2482]",0.5,3141,best_practice,605,Returning a dictionary for structured results,,3135,    Args:,"[220, 220, 220, 943, 14542, 25]"
"üß† ML Signal: Function to handle infinite values in tensors, useful for preprocessing in ML models","[8582, 100, 254, 10373, 26484, 25, 15553, 284, 5412, 15541, 3815, 287, 11192, 669, 11, 4465, 329, 662, 36948, 287, 10373, 4981]",1.0,3165,ml_signal,598,"Function to handle infinite values in tensors, useful for preprocessing in ML models",,3141,"        x = x + self.pe[: x.size(0), :]","[220, 220, 220, 220, 220, 220, 220, 2124, 796, 2124, 1343, 2116, 13, 431, 58, 25, 2124, 13, 7857, 7, 15, 828, 1058, 60]"
"üß† ML Signal: Identifying infinite values in a tensor, common in data preprocessing","[8582, 100, 254, 10373, 26484, 25, 11440, 4035, 15541, 3815, 287, 257, 11192, 273, 11, 2219, 287, 1366, 662, 36948]",1.0,3165,ml_signal,601,"Identifying infinite values in a tensor, common in data preprocessing",,3165,,[]
"üß† ML Signal: Finding indices of infinite values, useful for data cleaning","[8582, 100, 254, 10373, 26484, 25, 27063, 36525, 286, 15541, 3815, 11, 4465, 329, 1366, 12724]",1.0,3172,ml_signal,603,"Finding indices of infinite values, useful for data cleaning",,3165,"    """"""Transformer Model","[220, 220, 220, 37227, 8291, 16354, 9104]"
"‚úÖ Best Practice: Check for 2D tensor indices, ensures correct indexing","[26486, 227, 6705, 19939, 25, 6822, 329, 362, 35, 11192, 273, 36525, 11, 19047, 3376, 6376, 278]",0.5,3187,best_practice,607,"Check for 2D tensor indices, ensures correct indexing",,3172,        hidden_size (int): hidden size,"[220, 220, 220, 220, 220, 220, 220, 7104, 62, 7857, 357, 600, 2599, 7104, 2546]"
"‚úÖ Best Practice: Check for 1D tensor indices, ensures correct indexing","[26486, 227, 6705, 19939, 25, 6822, 329, 352, 35, 11192, 273, 36525, 11, 19047, 3376, 6376, 278]",0.5,3202,best_practice,610,"Check for 1D tensor indices, ensures correct indexing",,3187,        dropout (float): dropout rate,"[220, 220, 220, 220, 220, 220, 220, 4268, 448, 357, 22468, 2599, 4268, 448, 2494]"
"üß† ML Signal: Replacing inf with max value, a common strategy in data normalization","[8582, 100, 254, 10373, 26484, 25, 18407, 4092, 1167, 351, 3509, 1988, 11, 257, 2219, 4811, 287, 1366, 3487, 1634]",0.5,3210,ml_signal,613,"Replacing inf with max value, a common strategy in data normalization",,3202,    def __init__(,"[220, 220, 220, 825, 11593, 15003, 834, 7]"
‚úÖ Best Practice: Consider adding type hints for function parameters and return type for better readability and maintainability,"[26486, 227, 6705, 19939, 25, 12642, 4375, 2099, 20269, 329, 2163, 10007, 290, 1441, 2099, 329, 1365, 1100, 1799, 290, 5529, 1799]",0.5,3223,best_practice,615,Consider adding type hints for function parameters and return type for better readability and maintainability,,3210,"        input_size=16,","[220, 220, 220, 220, 220, 220, 220, 5128, 62, 7857, 28, 1433, 11]"
"‚ö†Ô∏è SAST Risk (Low): Using torch.no_grad() suppresses gradient computation, ensure this is intended","[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 8554, 28034, 13, 3919, 62, 9744, 3419, 802, 16746, 31312, 29964, 11, 4155, 428, 318, 5292]",0.5,3237,sast_risk,617,"Using torch.no_grad() suppresses gradient computation, ensure this is intended",Low,3223,"        num_layers=2,","[220, 220, 220, 220, 220, 220, 220, 997, 62, 75, 6962, 28, 17, 11]"
üß† ML Signal: Use of torch.exp suggests this function is part of a machine learning model,"[8582, 100, 254, 10373, 26484, 25, 5765, 286, 28034, 13, 11201, 5644, 428, 2163, 318, 636, 286, 257, 4572, 4673, 2746]",0.5,3251,ml_signal,619,Use of torch.exp suggests this function is part of a machine learning model,,3237,"        dropout=0.0,","[220, 220, 220, 220, 220, 220, 220, 4268, 448, 28, 15, 13, 15, 11]"
‚úÖ Best Practice: Ensure shoot_infs is defined elsewhere in the codebase,"[26486, 227, 6705, 19939, 25, 48987, 2686, 62, 259, 9501, 318, 5447, 8057, 287, 262, 2438, 8692]",0.5,3255,best_practice,621,Ensure shoot_infs is defined elsewhere in the codebase,,3251,    ):,"[220, 220, 220, 15179]"
üß† ML Signal: Iterative normalization pattern is common in ML algorithms,"[8582, 100, 254, 10373, 26484, 25, 40806, 876, 3487, 1634, 3912, 318, 2219, 287, 10373, 16113]",1.0,3271,ml_signal,624,Iterative normalization pattern is common in ML algorithms,,3255,        self.input_size = input_size,"[220, 220, 220, 220, 220, 220, 220, 2116, 13, 15414, 62, 7857, 796, 5128, 62, 7857]"
"üß† ML Signal: Function for calculating loss, common in training ML models","[8582, 100, 254, 10373, 26484, 25, 15553, 329, 26019, 2994, 11, 2219, 287, 3047, 10373, 4981]",1.0,3271,ml_signal,623,"Function for calculating loss, common in training ML models",,3271,,[]
"‚ö†Ô∏è SAST Risk (Low): Assumes 'label' is a tensor, potential for runtime errors if not","[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 2195, 8139, 705, 18242, 6, 318, 257, 11192, 273, 11, 2785, 329, 19124, 8563, 611, 407]",1.0,3287,sast_risk,625,"Assumes 'label' is a tensor, potential for runtime errors if not",Low,3271,        self.hidden_size = hidden_size,"[220, 220, 220, 220, 220, 220, 220, 2116, 13, 30342, 62, 7857, 796, 7104, 62, 7857]"
"üß† ML Signal: Handling different tensor shapes, common in ML preprocessing","[8582, 100, 254, 10373, 26484, 25, 49500, 1180, 11192, 273, 15268, 11, 2219, 287, 10373, 662, 36948]",1.0,3303,ml_signal,627,"Handling different tensor shapes, common in ML preprocessing",,3287,        self.num_heads = num_heads,"[220, 220, 220, 220, 220, 220, 220, 2116, 13, 22510, 62, 16600, 796, 997, 62, 16600]"
"‚ö†Ô∏è SAST Risk (Low): Assumes 'pred' and 'label' are compatible tensors, potential for runtime errors if not","[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 2195, 8139, 705, 28764, 6, 290, 705, 18242, 6, 389, 11670, 11192, 669, 11, 2785, 329, 19124, 8563, 611, 407]",1.0,3303,sast_risk,630,"Assumes 'pred' and 'label' are compatible tensors, potential for runtime errors if not",Low,3303,,[]
"üß† ML Signal: Function for min-max normalization, common in data preprocessing for ML models","[8582, 100, 254, 10373, 26484, 25, 15553, 329, 949, 12, 9806, 3487, 1634, 11, 2219, 287, 1366, 662, 36948, 329, 10373, 4981]",0.5,3303,ml_signal,628,"Function for min-max normalization, common in data preprocessing for ML models",,3303,,[]
"üß† ML Signal: Use of tensor operations, indicating potential use in ML frameworks like PyTorch","[8582, 100, 254, 10373, 26484, 25, 5765, 286, 11192, 273, 4560, 11, 12739, 2785, 779, 287, 10373, 29251, 588, 9485, 15884, 354]",0.5,3303,ml_signal,630,"Use of tensor operations, indicating potential use in ML frameworks like PyTorch",,3303,,[]
"üß† ML Signal: Use of tensor operations, indicating potential use in ML frameworks like PyTorch","[8582, 100, 254, 10373, 26484, 25, 5765, 286, 11192, 273, 4560, 11, 12739, 2785, 779, 287, 10373, 29251, 588, 9485, 15884, 354]",0.5,3321,ml_signal,632,"Use of tensor operations, indicating potential use in ML frameworks like PyTorch",,3303,        layer = nn.TransformerEncoderLayer(,"[220, 220, 220, 220, 220, 220, 220, 7679, 796, 299, 77, 13, 8291, 16354, 27195, 12342, 49925, 7]"
"üß† ML Signal: Handling edge cases where min equals max, common in data normalization","[8582, 100, 254, 10373, 26484, 25, 49500, 5743, 2663, 810, 949, 21767, 3509, 11, 2219, 287, 1366, 3487, 1634]",0.5,3329,ml_signal,634,"Handling edge cases where min equals max, common in data normalization",,3321,        ),"[220, 220, 220, 220, 220, 220, 220, 1267]"
‚ö†Ô∏è SAST Risk (Low): Potential division by zero if EPS is not defined or too small,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 32480, 7297, 416, 6632, 611, 47013, 318, 407, 5447, 393, 1165, 1402]",1.0,3329,sast_risk,636,Potential division by zero if EPS is not defined or too small,Low,3329,,[]
"üß† ML Signal: Handling edge cases where min equals max, common in data normalization","[8582, 100, 254, 10373, 26484, 25, 49500, 5743, 2663, 810, 949, 21767, 3509, 11, 2219, 287, 1366, 3487, 1634]",0.5,3329,ml_signal,636,"Handling edge cases where min equals max, common in data normalization",,3329,,[]
‚úÖ Best Practice: Clear and concise return statement,"[26486, 227, 6705, 19939, 25, 11459, 290, 35327, 1441, 2643]",0.5,3329,best_practice,636,Clear and concise return statement,,3329,,[]
‚úÖ Best Practice: Use of assert statements to validate input shapes and values,"[26486, 227, 6705, 19939, 25, 5765, 286, 6818, 6299, 284, 26571, 5128, 15268, 290, 3815]",0.5,3336,best_practice,649,Use of assert statements to validate input shapes and values,,3329,class TRA(nn.Module):,"[4871, 29125, 7, 20471, 13, 26796, 2599]"
‚úÖ Best Practice: Use of assert statements to validate input shapes and values,"[26486, 227, 6705, 19939, 25, 5765, 286, 6818, 6299, 284, 26571, 5128, 15268, 290, 3815]",0.5,3336,best_practice,651,Use of assert statements to validate input shapes and values,,3336,,[]
‚úÖ Best Practice: Use of assert statements to validate input shapes and values,"[26486, 227, 6705, 19939, 25, 5765, 286, 6818, 6299, 284, 26571, 5128, 15268, 290, 3815]",0.5,3353,best_practice,653,Use of assert statements to validate input shapes and values,,3336,    then routes the input sample to a specific predictor for training & inference.,"[220, 220, 220, 788, 11926, 262, 5128, 6291, 284, 257, 2176, 41568, 329, 3047, 1222, 32278, 13]"
üß† ML Signal: Use of torch.zeros_like to initialize tensors,"[8582, 100, 254, 10373, 26484, 25, 5765, 286, 28034, 13, 9107, 418, 62, 2339, 284, 41216, 11192, 669]",0.5,3359,ml_signal,655,Use of torch.zeros_like to initialize tensors,,3353,    Args:,"[220, 220, 220, 943, 14542, 25]"
üß† ML Signal: Use of boolean masking with torch tensors,"[8582, 100, 254, 10373, 26484, 25, 5765, 286, 25131, 9335, 278, 351, 28034, 11192, 669]",0.5,3384,ml_signal,657,Use of boolean masking with torch tensors,,3359,"        num_states (int): number of latent states (i.e., trading patterns)","[220, 220, 220, 220, 220, 220, 220, 997, 62, 27219, 357, 600, 2599, 1271, 286, 41270, 2585, 357, 72, 13, 68, 1539, 7313, 7572, 8]"
üß† ML Signal: Element-wise operations on masked tensors,"[8582, 100, 254, 10373, 26484, 25, 11703, 12, 3083, 4560, 319, 29229, 11192, 669]",0.5,3402,ml_signal,659,Element-wise operations on masked tensors,,3384,        hidden_size (int): hidden size of the router,"[220, 220, 220, 220, 220, 220, 220, 7104, 62, 7857, 357, 600, 2599, 7104, 2546, 286, 262, 20264]"
üß† ML Signal: Use of custom normalization function,"[8582, 100, 254, 10373, 26484, 25, 5765, 286, 2183, 3487, 1634, 2163]",0.5,3419,ml_signal,661,Use of custom normalization function,,3402,        src_info (str): information for the router,"[220, 220, 220, 220, 220, 220, 220, 12351, 62, 10951, 357, 2536, 2599, 1321, 329, 262, 20264]"
üß† ML Signal: Combination of current and historical loss with a parameter,"[8582, 100, 254, 10373, 26484, 25, 14336, 1883, 286, 1459, 290, 6754, 2994, 351, 257, 11507]",0.5,3423,ml_signal,662,Combination of current and historical loss with a parameter,,3419,"    """"""","[220, 220, 220, 37227]"
üß† ML Signal: Re-normalization of combined loss,"[8582, 100, 254, 10373, 26484, 25, 797, 12, 11265, 1634, 286, 5929, 2994]",1.0,3431,ml_signal,664,Re-normalization of combined loss,,3423,    def __init__(,"[220, 220, 220, 825, 11593, 15003, 834, 7]"
üß† ML Signal: Use of sinkhorn function for transport plan,"[8582, 100, 254, 10373, 26484, 25, 5765, 286, 14595, 25311, 2163, 329, 4839, 1410]",0.5,3444,ml_signal,667,Use of sinkhorn function for transport plan,,3431,"        num_states=1,","[220, 220, 220, 220, 220, 220, 220, 997, 62, 27219, 28, 16, 11]"
‚úÖ Best Practice: Deleting unused variables to free memory,"[26486, 227, 6705, 19939, 25, 42226, 889, 21958, 9633, 284, 1479, 4088]",0.5,3457,best_practice,668,Deleting unused variables to free memory,,3444,"        hidden_size=8,","[220, 220, 220, 220, 220, 220, 220, 7104, 62, 7857, 28, 23, 11]"
‚úÖ Best Practice: Clear conditional logic for different transport methods,"[26486, 227, 6705, 19939, 25, 11459, 26340, 9156, 329, 1180, 4839, 5050]",1.0,3471,best_practice,671,Clear conditional logic for different transport methods,,3457,"        dropout=0.0,","[220, 220, 220, 220, 220, 220, 220, 4268, 448, 28, 15, 13, 15, 11]"
üß† ML Signal: Use of weighted sum based on choice tensor,"[8582, 100, 254, 10373, 26484, 25, 5765, 286, 26356, 2160, 1912, 319, 3572, 11192, 273]",0.5,3487,ml_signal,673,Use of weighted sum based on choice tensor,,3471,"        src_info=""LR_TPE"",","[220, 220, 220, 220, 220, 220, 220, 12351, 62, 10951, 2625, 35972, 62, 7250, 36, 1600]"
üß† ML Signal: Use of argmax for selecting predictions,"[8582, 100, 254, 10373, 26484, 25, 5765, 286, 1822, 9806, 329, 17246, 16277]",0.5,3503,ml_signal,673,Use of argmax for selecting predictions,,3487,"        src_info=""LR_TPE"",","[220, 220, 220, 220, 220, 220, 220, 12351, 62, 10951, 2625, 35972, 62, 7250, 36, 1600]"
üß† ML Signal: Use of weighted sum based on transport plan,"[8582, 100, 254, 10373, 26484, 25, 5765, 286, 26356, 2160, 1912, 319, 4839, 1410]",0.5,3519,ml_signal,686,Use of weighted sum based on transport plan,,3503,        if self.num_states > 1:,"[220, 220, 220, 220, 220, 220, 220, 611, 2116, 13, 22510, 62, 27219, 1875, 352, 25]"
‚úÖ Best Practice: Clear conditional logic for different transport methods,"[26486, 227, 6705, 19939, 25, 11459, 26340, 9156, 329, 1180, 4839, 5050]",1.0,3535,best_practice,686,Clear conditional logic for different transport methods,,3519,        if self.num_states > 1:,"[220, 220, 220, 220, 220, 220, 220, 611, 2116, 13, 22510, 62, 27219, 1875, 352, 25]"
üß† ML Signal: Use of custom loss function,"[8582, 100, 254, 10373, 26484, 25, 5765, 286, 2183, 2994, 2163]",0.5,3551,ml_signal,686,Use of custom loss function,,3535,        if self.num_states > 1:,"[220, 220, 220, 220, 220, 220, 220, 611, 2116, 13, 22510, 62, 27219, 1875, 352, 25]"
üß† ML Signal: Calculation of mean loss using transport plan,"[8582, 100, 254, 10373, 26484, 25, 2199, 14902, 286, 1612, 2994, 1262, 4839, 1410]",0.5,3572,ml_signal,687,Calculation of mean loss using transport plan,,3551,"            if ""TPE"" in src_info:","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 611, 366, 7250, 36, 1, 287, 12351, 62, 10951, 25]"
üß† ML Signal: Returning multiple outputs from a function,"[8582, 100, 254, 10373, 26484, 25, 42882, 3294, 23862, 422, 257, 2163]",0.5,3599,ml_signal,689,Returning multiple outputs from a function,,3572,"                    input_size=num_states,","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 5128, 62, 7857, 28, 22510, 62, 27219, 11]"
‚ö†Ô∏è SAST Risk (Low): Lack of input validation for tensor dimensions and types,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 38289, 286, 5128, 21201, 329, 11192, 273, 15225, 290, 3858]",1.0,3615,sast_risk,686,Lack of input validation for tensor dimensions and types,Low,3599,        if self.num_states > 1:,"[220, 220, 220, 220, 220, 220, 220, 611, 2116, 13, 22510, 62, 27219, 1875, 352, 25]"
‚ö†Ô∏è SAST Risk (Low): Hardcoded method names could lead to errors if not handled properly,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 6912, 40976, 2446, 3891, 714, 1085, 284, 8563, 611, 407, 12118, 6105]",0.5,3642,sast_risk,689,Hardcoded method names could lead to errors if not handled properly,Low,3615,"                    input_size=num_states,","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 5128, 62, 7857, 28, 22510, 62, 27219, 11]"
‚ö†Ô∏è SAST Risk (Low): Potential issue if loss_fn is not defined or behaves unexpectedly,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 32480, 2071, 611, 2994, 62, 22184, 318, 407, 5447, 393, 39341, 25884]",1.0,3655,sast_risk,696,Potential issue if loss_fn is not defined or behaves unexpectedly,Low,3642,            else:,"[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 2073, 25]"
‚ö†Ô∏è SAST Risk (Low): Assumes all_loss is non-empty and contains valid tensors,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 2195, 8139, 477, 62, 22462, 318, 1729, 12, 28920, 290, 4909, 4938, 11192, 669]",0.5,3666,sast_risk,699,Assumes all_loss is non-empty and contains valid tensors,Low,3655,    def reset_parameters(self):,"[220, 220, 220, 825, 13259, 62, 17143, 7307, 7, 944, 2599]"
‚úÖ Best Practice: Detach tensors to avoid unnecessary gradient tracking,"[26486, 227, 6705, 19939, 25, 4614, 620, 11192, 669, 284, 3368, 13114, 31312, 9646]",0.5,3684,best_practice,701,Detach tensors to avoid unnecessary gradient tracking,,3666,            child.reset_parameters(),"[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 1200, 13, 42503, 62, 17143, 7307, 3419]"
‚úÖ Best Practice: Use of alpha for weighted combination is a common pattern,"[26486, 227, 6705, 19939, 25, 5765, 286, 17130, 329, 26356, 6087, 318, 257, 2219, 3912]",0.5,3698,best_practice,703,Use of alpha for weighted combination is a common pattern,,3684,"    def forward(self, hidden, hist_loss):","[220, 220, 220, 825, 2651, 7, 944, 11, 7104, 11, 1554, 62, 22462, 2599]"
‚ö†Ô∏è SAST Risk (Low): Assumes sinkhorn function is defined and behaves as expected,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 2195, 8139, 14595, 25311, 2163, 318, 5447, 290, 39341, 355, 2938]",0.5,3725,sast_risk,706,Assumes sinkhorn function is defined and behaves as expected,Low,3698,        if self.num_states == 1:  # no need for router when having only one prediction,"[220, 220, 220, 220, 220, 220, 220, 611, 2116, 13, 22510, 62, 27219, 6624, 352, 25, 220, 1303, 645, 761, 329, 20264, 618, 1719, 691, 530, 17724]"
üß† ML Signal: Use of matrix multiplication for prediction adjustment,"[8582, 100, 254, 10373, 26484, 25, 5765, 286, 17593, 48473, 329, 17724, 15068]",0.5,3734,ml_signal,716,Use of matrix multiplication for prediction adjustment,,3725,        else:,"[220, 220, 220, 220, 220, 220, 220, 2073, 25]"
üß† ML Signal: Use of argmax for selecting predictions,"[8582, 100, 254, 10373, 26484, 25, 5765, 286, 1822, 9806, 329, 17246, 16277]",0.5,3749,ml_signal,719,Use of argmax for selecting predictions,,3734,        out = self.fc(out),"[220, 220, 220, 220, 220, 220, 220, 503, 796, 2116, 13, 16072, 7, 448, 8]"
üß† ML Signal: Use of matrix multiplication for prediction adjustment,"[8582, 100, 254, 10373, 26484, 25, 5765, 286, 17593, 48473, 329, 17724, 15068]",0.5,3774,ml_signal,722,Use of matrix multiplication for prediction adjustment,,3749,"        prob = torch.softmax(out / self.tau, dim=-1)","[220, 220, 220, 220, 220, 220, 220, 1861, 796, 28034, 13, 4215, 9806, 7, 448, 1220, 2116, 13, 83, 559, 11, 5391, 10779, 16, 8]"
‚ö†Ô∏è SAST Risk (Low): Assumes pred is non-empty and contains valid tensors,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 2195, 8139, 2747, 318, 1729, 12, 28920, 290, 4909, 4938, 11192, 669]",0.5,3774,sast_risk,725,Assumes pred is non-empty and contains valid tensors,Low,3774,,[]
‚ö†Ô∏è SAST Risk (Low): Potential issue if loss_fn is not defined or behaves unexpectedly,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 32480, 2071, 611, 2994, 62, 22184, 318, 407, 5447, 393, 39341, 25884]",1.0,3794,sast_risk,728,Potential issue if loss_fn is not defined or behaves unexpectedly,Low,3774,    pred = pred.rank(pct=True)  # transform into percentiles,"[220, 220, 220, 2747, 796, 2747, 13, 43027, 7, 79, 310, 28, 17821, 8, 220, 1303, 6121, 656, 1411, 2915]"
‚ö†Ô∏è SAST Risk (Low): Assumes P and all_loss are compatible for multiplication,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 2195, 8139, 350, 290, 477, 62, 22462, 389, 11670, 329, 48473]",0.5,3802,sast_risk,731,Assumes P and all_loss are compatible for multiplication,Low,3794,    diff = score - label,"[220, 220, 220, 814, 796, 4776, 532, 6167]"
‚úÖ Best Practice: Initialize lists to collect issues for better error handling and reporting,"[26486, 227, 6705, 19939, 25, 20768, 1096, 8341, 284, 2824, 2428, 329, 1365, 4049, 9041, 290, 6447]",0.5,3802,best_practice,725,Initialize lists to collect issues for better error handling and reporting,,3802,,[]
üß† ML Signal: Use of metadata in state_dict indicates handling of model versioning or additional info,"[8582, 100, 254, 10373, 26484, 25, 5765, 286, 20150, 287, 1181, 62, 11600, 9217, 9041, 286, 2746, 2196, 278, 393, 3224, 7508]",0.5,3810,ml_signal,729,Use of metadata in state_dict indicates handling of model versioning or additional info,,3802,    score = pred.score,"[220, 220, 220, 4776, 796, 2747, 13, 26675]"
üß† ML Signal: Copying state_dict suggests intention to modify without affecting the original,"[8582, 100, 254, 10373, 26484, 25, 6955, 1112, 1181, 62, 11600, 5644, 6778, 284, 13096, 1231, 13891, 262, 2656]",0.5,3818,ml_signal,731,Copying state_dict suggests intention to modify without affecting the original,,3810,    diff = score - label,"[220, 220, 220, 814, 796, 4776, 532, 6167]"
üß† ML Signal: Preserving metadata in state_dict indicates importance of additional model information,"[8582, 100, 254, 10373, 26484, 25, 1763, 14344, 20150, 287, 1181, 62, 11600, 9217, 6817, 286, 3224, 2746, 1321]",0.5,3836,ml_signal,734,Preserving metadata in state_dict indicates importance of additional model information,,3818,"    IC = score.corr(label, method=""spearman"")","[220, 220, 220, 12460, 796, 4776, 13, 10215, 81, 7, 18242, 11, 2446, 2625, 4125, 283, 805, 4943]"
‚ö†Ô∏è SAST Risk (Low): Potential use of undefined variable 'metadata' if not defined elsewhere,"[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 32480, 779, 286, 28721, 7885, 705, 38993, 6, 611, 407, 5447, 8057]",0.5,3850,sast_risk,733,Potential use of undefined variable 'metadata' if not defined elsewhere,Low,3836,    MAE = (diff.abs()).mean(),"[220, 220, 220, 8779, 36, 796, 357, 26069, 13, 8937, 3419, 737, 32604, 3419]"
üß† ML Signal: Recursive function pattern for loading model components,"[8582, 100, 254, 10373, 26484, 25, 3311, 30753, 2163, 3912, 329, 11046, 2746, 6805]",0.5,3868,ml_signal,734,Recursive function pattern for loading model components,,3850,"    IC = score.corr(label, method=""spearman"")","[220, 220, 220, 12460, 796, 4776, 13, 10215, 81, 7, 18242, 11, 2446, 2625, 4125, 283, 805, 4943]"
üß† ML Signal: Recursive call to handle nested modules,"[8582, 100, 254, 10373, 26484, 25, 3311, 30753, 869, 284, 5412, 28376, 13103]",0.5,3891,ml_signal,741,Recursive call to handle nested modules,,3868,"    ind_inf = torch.nonzero(mask_inf, as_tuple=False)","[220, 220, 220, 773, 62, 10745, 796, 28034, 13, 13159, 22570, 7, 27932, 62, 10745, 11, 355, 62, 83, 29291, 28, 25101, 8]"
üß† ML Signal: Function call to load model state,"[8582, 100, 254, 10373, 26484, 25, 15553, 869, 284, 3440, 2746, 1181]",0.5,3905,ml_signal,743,Function call to load model state,,3891,        for ind in ind_inf:,"[220, 220, 220, 220, 220, 220, 220, 329, 773, 287, 773, 62, 10745, 25]"
"‚ö†Ô∏è SAST Risk (Low): Overwriting the 'load' function with None, which can lead to errors if 'load' is called again","[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 3827, 16502, 262, 705, 2220, 6, 2163, 351, 6045, 11, 543, 460, 1085, 284, 8563, 611, 705, 2220, 6, 318, 1444, 757]",1.0,3936,sast_risk,745,"Overwriting the 'load' function with None, which can lead to errors if 'load' is called again",Low,3905,"                inp_tensor[ind[0], ind[1]] = 0","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 287, 79, 62, 83, 22854, 58, 521, 58, 15, 4357, 773, 58, 16, 11907, 796, 657]"
‚úÖ Best Practice: Returning a dictionary for structured error reporting,"[26486, 227, 6705, 19939, 25, 42882, 257, 22155, 329, 20793, 4049, 6447]",0.5,3963,best_practice,747,Returning a dictionary for structured error reporting,,3936,                inp_tensor[ind[0]] = 0,"[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 287, 79, 62, 83, 22854, 58, 521, 58, 15, 11907, 796, 657]"
"‚ö†Ô∏è SAST Risk (Low): No import statements for pd, plt, io, np; potential NameError if not imported","[158, 248, 254, 37929, 311, 11262, 19602, 357, 20535, 2599, 1400, 1330, 6299, 329, 279, 67, 11, 458, 83, 11, 33245, 11, 45941, 26, 2785, 6530, 12331, 611, 407, 17392]",0.5,3977,sast_risk,743,"No import statements for pd, plt, io, np; potential NameError if not imported",Low,3963,        for ind in ind_inf:,"[220, 220, 220, 220, 220, 220, 220, 329, 773, 287, 773, 62, 10745, 25]"
‚úÖ Best Practice: Use isinstance to check if P is a DataFrame,"[26486, 227, 6705, 19939, 25, 5765, 318, 39098, 284, 2198, 611, 350, 318, 257, 6060, 19778]",0.5,4008,best_practice,745,Use isinstance to check if P is a DataFrame,,3977,"                inp_tensor[ind[0], ind[1]] = 0","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 287, 79, 62, 83, 22854, 58, 521, 58, 15, 4357, 773, 58, 16, 11907, 796, 657]"
‚úÖ Best Practice: Use of subplots for multiple plots in a single figure,"[26486, 227, 6705, 19939, 25, 5765, 286, 850, 489, 1747, 329, 3294, 21528, 287, 257, 2060, 3785]",0.5,4035,best_practice,747,Use of subplots for multiple plots in a single figure,,4008,                inp_tensor[ind[0]] = 0,"[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 287, 79, 62, 83, 22854, 58, 521, 58, 15, 11907, 796, 657]"
"üß† ML Signal: Plotting area chart, common in data visualization tasks","[8582, 100, 254, 10373, 26484, 25, 28114, 889, 1989, 8262, 11, 2219, 287, 1366, 32704, 8861]",0.5,4049,ml_signal,749,"Plotting area chart, common in data visualization tasks",,4035,        for ind in ind_inf:,"[220, 220, 220, 220, 220, 220, 220, 329, 773, 287, 773, 62, 10745, 25]"
üß† ML Signal: Using idxmax and value_counts for data analysis,"[8582, 100, 254, 10373, 26484, 25, 8554, 4686, 87, 9806, 290, 1988, 62, 9127, 82, 329, 1366, 3781]",0.5,4080,ml_signal,751,Using idxmax and value_counts for data analysis,,4049,"                inp_tensor[ind[0], ind[1]] = m","[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 287, 79, 62, 83, 22854, 58, 521, 58, 15, 4357, 773, 58, 16, 11907, 796, 285]"
‚úÖ Best Practice: Use of tight_layout to prevent overlap of subplots,"[26486, 227, 6705, 19939, 25, 5765, 286, 5381, 62, 39786, 284, 2948, 21721, 286, 850, 489, 1747]",0.5,4107,best_practice,753,Use of tight_layout to prevent overlap of subplots,,4080,                inp_tensor[ind[0]] = m,"[220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 287, 79, 62, 83, 22854, 58, 521, 58, 15, 11907, 796, 285]"
‚úÖ Best Practice: Use of BytesIO for in-memory byte buffer,"[26486, 227, 6705, 19939, 25, 5765, 286, 2750, 4879, 9399, 329, 287, 12, 31673, 18022, 11876]",0.5,4116,best_practice,754,Use of BytesIO for in-memory byte buffer,,4107,    return inp_tensor,"[220, 220, 220, 1441, 287, 79, 62, 83, 22854]"
‚úÖ Best Practice: Save figure to buffer in PNG format,"[26486, 227, 6705, 19939, 25, 12793, 3785, 284, 11876, 287, 36182, 5794]",0.5,4125,best_practice,754,Save figure to buffer in PNG format,,4116,    return inp_tensor,"[220, 220, 220, 1441, 287, 79, 62, 83, 22854]"
‚úÖ Best Practice: Read image from buffer,"[26486, 227, 6705, 19939, 25, 4149, 2939, 422, 11876]",0.5,4134,best_practice,754,Read image from buffer,,4125,    return inp_tensor,"[220, 220, 220, 1441, 287, 79, 62, 83, 22854]"
‚úÖ Best Practice: Close the plot to free up resources,"[26486, 227, 6705, 19939, 25, 13872, 262, 7110, 284, 1479, 510, 4133]",0.5,4143,best_practice,754,Close the plot to free up resources,,4134,    return inp_tensor,"[220, 220, 220, 1441, 287, 79, 62, 83, 22854]"
"üß† ML Signal: Conversion of image data to uint8 format, common in image processing","[8582, 100, 254, 10373, 26484, 25, 44101, 286, 2939, 1366, 284, 20398, 23, 5794, 11, 2219, 287, 2939, 7587]",0.5,4152,ml_signal,754,"Conversion of image data to uint8 format, common in image processing",,4143,    return inp_tensor,"[220, 220, 220, 1441, 287, 79, 62, 83, 22854]"
