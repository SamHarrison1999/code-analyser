[
  {
    "line": 6,
    "text": "from __future__ import print_function",
    "annotation": "\u2705 Best Practice: Use of relative imports for better modularity and maintainability",
    "confidence": 1.0,
    "tokens": [
      6738,
      11593,
      37443,
      834,
      1330,
      3601,
      62,
      8818
    ],
    "start_token": 0,
    "end_token": 8,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      3585,
      17944,
      329,
      1365,
      26507,
      414,
      290,
      5529,
      1799
    ],
    "label": "best_practice",
    "reason": "Use of relative imports for better modularity and maintainability"
  },
  {
    "line": 8,
    "text": "import numpy as np",
    "annotation": "\u2705 Best Practice: Use of relative imports for better modularity and maintainability",
    "confidence": 1.0,
    "tokens": [
      11748,
      299,
      32152,
      355,
      45941
    ],
    "start_token": 8,
    "end_token": 13,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      3585,
      17944,
      329,
      1365,
      26507,
      414,
      290,
      5529,
      1799
    ],
    "label": "best_practice",
    "reason": "Use of relative imports for better modularity and maintainability"
  },
  {
    "line": 15,
    "text": "import torch.optim as optim",
    "annotation": "\u2705 Best Practice: Use of relative imports for better modularity and maintainability",
    "confidence": 1.0,
    "tokens": [
      11748,
      28034,
      13,
      40085,
      355,
      6436
    ],
    "start_token": 13,
    "end_token": 19,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      3585,
      17944,
      329,
      1365,
      26507,
      414,
      290,
      5529,
      1799
    ],
    "label": "best_practice",
    "reason": "Use of relative imports for better modularity and maintainability"
  },
  {
    "line": 17,
    "text": "from torch.utils.data import Sampler",
    "annotation": "\u2705 Best Practice: Use of relative imports for better modularity and maintainability",
    "confidence": 1.0,
    "tokens": [
      6738,
      28034,
      13,
      26791,
      13,
      7890,
      1330,
      3409,
      20053
    ],
    "start_token": 19,
    "end_token": 28,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      3585,
      17944,
      329,
      1365,
      26507,
      414,
      290,
      5529,
      1799
    ],
    "label": "best_practice",
    "reason": "Use of relative imports for better modularity and maintainability"
  },
  {
    "line": 19,
    "text": "from .pytorch_utils import count_parameters",
    "annotation": "\u2705 Best Practice: Use of relative imports for better modularity and maintainability",
    "confidence": 1.0,
    "tokens": [
      6738,
      764,
      9078,
      13165,
      354,
      62,
      26791,
      1330,
      954,
      62,
      17143,
      7307
    ],
    "start_token": 28,
    "end_token": 40,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      3585,
      17944,
      329,
      1365,
      26507,
      414,
      290,
      5529,
      1799
    ],
    "label": "best_practice",
    "reason": "Use of relative imports for better modularity and maintainability"
  },
  {
    "line": 21,
    "text": "from ...data.dataset.handler import DataHandlerLP",
    "annotation": "\u2705 Best Practice: Use of relative imports for better modularity and maintainability",
    "confidence": 1.0,
    "tokens": [
      6738,
      2644,
      7890,
      13,
      19608,
      292,
      316,
      13,
      30281,
      1330,
      6060,
      25060,
      19930
    ],
    "start_token": 40,
    "end_token": 53,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      3585,
      17944,
      329,
      1365,
      26507,
      414,
      290,
      5529,
      1799
    ],
    "label": "best_practice",
    "reason": "Use of relative imports for better modularity and maintainability"
  },
  {
    "line": 24,
    "text": "",
    "annotation": "\u2705 Best Practice: Use of relative imports for better modularity and maintainability",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 53,
    "end_token": 53,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      3585,
      17944,
      329,
      1365,
      26507,
      414,
      290,
      5529,
      1799
    ],
    "label": "best_practice",
    "reason": "Use of relative imports for better modularity and maintainability"
  },
  {
    "line": 18,
    "text": "",
    "annotation": "\u2705 Best Practice: Inheriting from a base class (Sampler) promotes code reuse and consistency.",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 53,
    "end_token": 53,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      47025,
      1780,
      422,
      257,
      2779,
      1398,
      357,
      16305,
      20053,
      8,
      21068,
      2438,
      32349,
      290,
      15794,
      13
    ],
    "label": "best_practice",
    "reason": "Inheriting from a base class (Sampler) promotes code reuse and consistency."
  },
  {
    "line": 20,
    "text": "from ...model.base import Model",
    "annotation": "\ud83e\udde0 ML Signal: Initialization of class with data source, common pattern in data processing classes",
    "confidence": 1.0,
    "tokens": [
      6738,
      2644,
      19849,
      13,
      8692,
      1330,
      9104
    ],
    "start_token": 53,
    "end_token": 60,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      20768,
      1634,
      286,
      1398,
      351,
      1366,
      2723,
      11,
      2219,
      3912,
      287,
      1366,
      7587,
      6097
    ],
    "label": "ml_signal",
    "reason": "Initialization of class with data source, common pattern in data processing classes"
  },
  {
    "line": 21,
    "text": "from ...data.dataset.handler import DataHandlerLP",
    "annotation": "\u2705 Best Practice: Use of pandas for data manipulation, a standard library for such tasks",
    "confidence": 0.5,
    "tokens": [
      6738,
      2644,
      7890,
      13,
      19608,
      292,
      316,
      13,
      30281,
      1330,
      6060,
      25060,
      19930
    ],
    "start_token": 60,
    "end_token": 73,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      19798,
      292,
      329,
      1366,
      17512,
      11,
      257,
      3210,
      5888,
      329,
      884,
      8861
    ],
    "label": "best_practice",
    "reason": "Use of pandas for data manipulation, a standard library for such tasks"
  },
  {
    "line": 26,
    "text": "class DailyBatchSampler(Sampler):",
    "annotation": "\u2705 Best Practice: Use of numpy for efficient numerical operations",
    "confidence": 0.5,
    "tokens": [
      4871,
      6714,
      33,
      963,
      16305,
      20053,
      7,
      16305,
      20053,
      2599
    ],
    "start_token": 73,
    "end_token": 83,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      299,
      32152,
      329,
      6942,
      29052,
      4560
    ],
    "label": "best_practice",
    "reason": "Use of numpy for efficient numerical operations"
  },
  {
    "line": 28,
    "text": "        self.data_source = data_source",
    "annotation": "\u2705 Best Practice: Explicitly setting the first element of an array, improving code clarity",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      7890,
      62,
      10459,
      796,
      1366,
      62,
      10459
    ],
    "start_token": 83,
    "end_token": 99,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      11884,
      306,
      4634,
      262,
      717,
      5002,
      286,
      281,
      7177,
      11,
      10068,
      2438,
      16287
    ],
    "label": "best_practice",
    "reason": "Explicitly setting the first element of an array, improving code clarity"
  },
  {
    "line": 27,
    "text": "    def __init__(self, data_source):",
    "annotation": "\ud83e\udde0 ML Signal: Use of zip to iterate over two lists in parallel",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      825,
      11593,
      15003,
      834,
      7,
      944,
      11,
      1366,
      62,
      10459,
      2599
    ],
    "start_token": 99,
    "end_token": 113,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      19974,
      284,
      11629,
      378,
      625,
      734,
      8341,
      287,
      10730
    ],
    "label": "ml_signal",
    "reason": "Use of zip to iterate over two lists in parallel"
  },
  {
    "line": 29,
    "text": "        # calculate number of samples in each batch",
    "annotation": "\ud83e\udde0 ML Signal: Use of np.arange to generate a range of numbers",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1303,
      15284,
      1271,
      286,
      8405,
      287,
      1123,
      15458
    ],
    "start_token": 113,
    "end_token": 128,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      45941,
      13,
      283,
      858,
      284,
      7716,
      257,
      2837,
      286,
      3146
    ],
    "label": "ml_signal",
    "reason": "Use of np.arange to generate a range of numbers"
  },
  {
    "line": 29,
    "text": "        # calculate number of samples in each batch",
    "annotation": "\ud83e\udde0 ML Signal: Method overriding to customize behavior of built-in functions",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1303,
      15284,
      1271,
      286,
      8405,
      287,
      1123,
      15458
    ],
    "start_token": 128,
    "end_token": 143,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      11789,
      44987,
      284,
      24184,
      4069,
      286,
      3170,
      12,
      259,
      5499
    ],
    "label": "ml_signal",
    "reason": "Method overriding to customize behavior of built-in functions"
  },
  {
    "line": 31,
    "text": "            pd.Series(index=self.data_source.get_index()).groupby(\"datetime\", group_keys=False).size().values",
    "annotation": "\u2705 Best Practice: Using len() for objects that support it",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      279,
      67,
      13,
      27996,
      7,
      9630,
      28,
      944,
      13,
      7890,
      62,
      10459,
      13,
      1136,
      62,
      9630,
      3419,
      737,
      8094,
      1525,
      7203,
      19608,
      8079,
      1600,
      1448,
      62,
      13083,
      28,
      25101,
      737,
      7857,
      22446,
      27160
    ],
    "start_token": 143,
    "end_token": 187,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      8554,
      18896,
      3419,
      329,
      5563,
      326,
      1104,
      340
    ],
    "label": "best_practice",
    "reason": "Using len() for objects that support it"
  },
  {
    "line": 31,
    "text": "            pd.Series(index=self.data_source.get_index()).groupby(\"datetime\", group_keys=False).size().values",
    "annotation": "\u2705 Best Practice: Class docstring provides a clear description of the class and its parameters",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      279,
      67,
      13,
      27996,
      7,
      9630,
      28,
      944,
      13,
      7890,
      62,
      10459,
      13,
      1136,
      62,
      9630,
      3419,
      737,
      8094,
      1525,
      7203,
      19608,
      8079,
      1600,
      1448,
      62,
      13083,
      28,
      25101,
      737,
      7857,
      22446,
      27160
    ],
    "start_token": 187,
    "end_token": 231,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5016,
      2205,
      8841,
      3769,
      257,
      1598,
      6764,
      286,
      262,
      1398,
      290,
      663,
      10007
    ],
    "label": "best_practice",
    "reason": "Class docstring provides a clear description of the class and its parameters"
  },
  {
    "line": 65,
    "text": "        num_layers=2,",
    "annotation": "\u2705 Best Practice: Use of a logger for information and debugging purposes",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      997,
      62,
      75,
      6962,
      28,
      17,
      11
    ],
    "start_token": 231,
    "end_token": 245,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      257,
      49706,
      329,
      1321,
      290,
      28769,
      4959
    ],
    "label": "best_practice",
    "reason": "Use of a logger for information and debugging purposes"
  },
  {
    "line": 68,
    "text": "        lr=0.001,",
    "annotation": "\ud83e\udde0 ML Signal: Initialization of model hyperparameters",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      300,
      81,
      28,
      15,
      13,
      8298,
      11
    ],
    "start_token": 245,
    "end_token": 259,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      20768,
      1634,
      286,
      2746,
      8718,
      17143,
      7307
    ],
    "label": "ml_signal",
    "reason": "Initialization of model hyperparameters"
  },
  {
    "line": 77,
    "text": "        seed=None,",
    "annotation": "\ud83e\udde0 ML Signal: Use of optimizer choice in model training",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      9403,
      28,
      14202,
      11
    ],
    "start_token": 259,
    "end_token": 270,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      6436,
      7509,
      3572,
      287,
      2746,
      3047
    ],
    "label": "ml_signal",
    "reason": "Use of optimizer choice in model training"
  },
  {
    "line": 82,
    "text": "        self.logger.info(\"GATs pytorch version...\")",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential GPU index out of range if GPU is not available",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      6404,
      1362,
      13,
      10951,
      7203,
      38,
      1404,
      82,
      12972,
      13165,
      354,
      2196,
      9313,
      8
    ],
    "start_token": 270,
    "end_token": 293,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      11362,
      6376,
      503,
      286,
      2837,
      611,
      11362,
      318,
      407,
      1695
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential GPU index out of range if GPU is not available"
  },
  {
    "line": 119,
    "text": "                hidden_size,",
    "annotation": "\ud83e\udde0 ML Signal: Setting random seed for reproducibility",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      7104,
      62,
      7857,
      11
    ],
    "start_token": 293,
    "end_token": 312,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      25700,
      4738,
      9403,
      329,
      8186,
      66,
      2247
    ],
    "label": "ml_signal",
    "reason": "Setting random seed for reproducibility"
  },
  {
    "line": 126,
    "text": "                optimizer.lower(),",
    "annotation": "\ud83e\udde0 ML Signal: Initialization of a GAT model",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      6436,
      7509,
      13,
      21037,
      22784
    ],
    "start_token": 312,
    "end_token": 332,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      20768,
      1634,
      286,
      257,
      402,
      1404,
      2746
    ],
    "label": "ml_signal",
    "reason": "Initialization of a GAT model"
  },
  {
    "line": 133,
    "text": "            )",
    "annotation": "\ud83e\udde0 ML Signal: Logging model size for resource management",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1267
    ],
    "start_token": 332,
    "end_token": 344,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5972,
      2667,
      2746,
      2546,
      329,
      8271,
      4542
    ],
    "label": "ml_signal",
    "reason": "Logging model size for resource management"
  },
  {
    "line": 135,
    "text": "",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Use of hardcoded strings for optimizer names",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 344,
    "end_token": 344,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      5765,
      286,
      1327,
      40976,
      13042,
      329,
      6436,
      7509,
      3891
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Use of hardcoded strings for optimizer names"
  },
  {
    "line": 141,
    "text": "            d_feat=self.d_feat,",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Use of NotImplementedError for unsupported optimizers",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      288,
      62,
      27594,
      28,
      944,
      13,
      67,
      62,
      27594,
      11
    ],
    "start_token": 344,
    "end_token": 365,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      5765,
      286,
      1892,
      3546,
      1154,
      12061,
      12331,
      329,
      24222,
      6436,
      11341
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Use of NotImplementedError for unsupported optimizers"
  },
  {
    "line": 144,
    "text": "            dropout=self.dropout,",
    "annotation": "\ud83e\udde0 ML Signal: Moving model to the specified device (CPU/GPU)",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      4268,
      448,
      28,
      944,
      13,
      14781,
      448,
      11
    ],
    "start_token": 365,
    "end_token": 384,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      26768,
      2746,
      284,
      262,
      7368,
      3335,
      357,
      36037,
      14,
      33346,
      8
    ],
    "label": "ml_signal",
    "reason": "Moving model to the specified device (CPU/GPU)"
  },
  {
    "line": 137,
    "text": "            np.random.seed(self.seed)",
    "annotation": "\ud83e\udde0 ML Signal: Checks if the computation is set to run on a GPU",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      45941,
      13,
      25120,
      13,
      28826,
      7,
      944,
      13,
      28826,
      8
    ],
    "start_token": 384,
    "end_token": 405,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      47719,
      611,
      262,
      29964,
      318,
      900,
      284,
      1057,
      319,
      257,
      11362
    ],
    "label": "ml_signal",
    "reason": "Checks if the computation is set to run on a GPU"
  },
  {
    "line": 139,
    "text": "",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Assumes 'self.device' is a valid torch.device object",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 405,
    "end_token": 405,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      2195,
      8139,
      705,
      944,
      13,
      25202,
      6,
      318,
      257,
      4938,
      28034,
      13,
      25202,
      2134
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Assumes 'self.device' is a valid torch.device object"
  },
  {
    "line": 139,
    "text": "",
    "annotation": "\u2705 Best Practice: Consider adding type hints for function parameters and return type",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 405,
    "end_token": 405,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      12642,
      4375,
      2099,
      20269,
      329,
      2163,
      10007,
      290,
      1441,
      2099
    ],
    "label": "best_practice",
    "reason": "Consider adding type hints for function parameters and return type"
  },
  {
    "line": 141,
    "text": "            d_feat=self.d_feat,",
    "annotation": "\ud83e\udde0 ML Signal: Use of mean squared error (MSE) loss function, common in regression tasks",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      288,
      62,
      27594,
      28,
      944,
      13,
      67,
      62,
      27594,
      11
    ],
    "start_token": 405,
    "end_token": 426,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      1612,
      44345,
      4049,
      357,
      44,
      5188,
      8,
      2994,
      2163,
      11,
      2219,
      287,
      20683,
      8861
    ],
    "label": "ml_signal",
    "reason": "Use of mean squared error (MSE) loss function, common in regression tasks"
  },
  {
    "line": 143,
    "text": "            num_layers=self.num_layers,",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Ensure 'torch' is imported and 'pred' and 'label' are tensors to avoid runtime errors",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      997,
      62,
      75,
      6962,
      28,
      944,
      13,
      22510,
      62,
      75,
      6962,
      11
    ],
    "start_token": 426,
    "end_token": 449,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      48987,
      705,
      13165,
      354,
      6,
      318,
      17392,
      290,
      705,
      28764,
      6,
      290,
      705,
      18242,
      6,
      389,
      11192,
      669,
      284,
      3368,
      19124,
      8563
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Ensure 'torch' is imported and 'pred' and 'label' are tensors to avoid runtime errors"
  },
  {
    "line": 142,
    "text": "            hidden_size=self.hidden_size,",
    "annotation": "\ud83e\udde0 ML Signal: Custom loss function implementation",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      7104,
      62,
      7857,
      28,
      944,
      13,
      30342,
      62,
      7857,
      11
    ],
    "start_token": 449,
    "end_token": 470,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      8562,
      2994,
      2163,
      7822
    ],
    "label": "ml_signal",
    "reason": "Custom loss function implementation"
  },
  {
    "line": 144,
    "text": "            dropout=self.dropout,",
    "annotation": "\ud83e\udde0 ML Signal: Handling missing values in labels",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      4268,
      448,
      28,
      944,
      13,
      14781,
      448,
      11
    ],
    "start_token": 470,
    "end_token": 489,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      49500,
      4814,
      3815,
      287,
      14722
    ],
    "label": "ml_signal",
    "reason": "Handling missing values in labels"
  },
  {
    "line": 146,
    "text": "        )",
    "annotation": "\ud83e\udde0 ML Signal: Conditional logic based on loss type",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1267
    ],
    "start_token": 489,
    "end_token": 497,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      9724,
      1859,
      9156,
      1912,
      319,
      2994,
      2099
    ],
    "label": "ml_signal",
    "reason": "Conditional logic based on loss type"
  },
  {
    "line": 148,
    "text": "        self.logger.info(\"model size: {:.4f} MB\".format(count_parameters(self.GAT_model)))",
    "annotation": "\ud83e\udde0 ML Signal: Use of mean squared error for loss calculation",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      6404,
      1362,
      13,
      10951,
      7203,
      19849,
      2546,
      25,
      46110,
      13,
      19,
      69,
      92,
      10771,
      1911,
      18982,
      7,
      9127,
      62,
      17143,
      7307,
      7,
      944,
      13,
      38,
      1404,
      62,
      19849,
      22305
    ],
    "start_token": 497,
    "end_token": 535,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      1612,
      44345,
      4049,
      329,
      2994,
      17952
    ],
    "label": "ml_signal",
    "reason": "Use of mean squared error for loss calculation"
  },
  {
    "line": 150,
    "text": "        if optimizer.lower() == \"adam\":",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential for unhandled loss types leading to exceptions",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      611,
      6436,
      7509,
      13,
      21037,
      3419,
      6624,
      366,
      324,
      321,
      1298
    ],
    "start_token": 535,
    "end_token": 553,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      329,
      555,
      38788,
      2994,
      3858,
      3756,
      284,
      13269
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential for unhandled loss types leading to exceptions"
  },
  {
    "line": 147,
    "text": "        self.logger.info(\"model:\\n{:}\".format(self.GAT_model))",
    "annotation": "\u2705 Best Practice: Consider adding type hints for function parameters and return type for better readability and maintainability.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      6404,
      1362,
      13,
      10951,
      7203,
      19849,
      7479,
      77,
      90,
      25,
      92,
      1911,
      18982,
      7,
      944,
      13,
      38,
      1404,
      62,
      19849,
      4008
    ],
    "start_token": 553,
    "end_token": 583,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      12642,
      4375,
      2099,
      20269,
      329,
      2163,
      10007,
      290,
      1441,
      2099,
      329,
      1365,
      1100,
      1799,
      290,
      5529,
      1799,
      13
    ],
    "label": "best_practice",
    "reason": "Consider adding type hints for function parameters and return type for better readability and maintainability."
  },
  {
    "line": 149,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Use of torch.isfinite to create a mask for valid (finite) values in the label tensor.",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 583,
    "end_token": 583,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      28034,
      13,
      4468,
      9504,
      284,
      2251,
      257,
      9335,
      329,
      4938,
      357,
      69,
      9504,
      8,
      3815,
      287,
      262,
      6167,
      11192,
      273,
      13
    ],
    "label": "ml_signal",
    "reason": "Use of torch.isfinite to create a mask for valid (finite) values in the label tensor."
  },
  {
    "line": 151,
    "text": "            self.train_optimizer = optim.Adam(self.GAT_model.parameters(), lr=self.lr)",
    "annotation": "\ud83e\udde0 ML Signal: Conditional logic to handle different metric types, indicating a pattern of metric evaluation.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      27432,
      62,
      40085,
      7509,
      796,
      6436,
      13,
      23159,
      7,
      944,
      13,
      38,
      1404,
      62,
      19849,
      13,
      17143,
      7307,
      22784,
      300,
      81,
      28,
      944,
      13,
      14050,
      8
    ],
    "start_token": 583,
    "end_token": 622,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      9724,
      1859,
      9156,
      284,
      5412,
      1180,
      18663,
      3858,
      11,
      12739,
      257,
      3912,
      286,
      18663,
      12660,
      13
    ],
    "label": "ml_signal",
    "reason": "Conditional logic to handle different metric types, indicating a pattern of metric evaluation."
  },
  {
    "line": 153,
    "text": "            self.train_optimizer = optim.SGD(self.GAT_model.parameters(), lr=self.lr)",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential risk if loss_fn is not properly handling masked tensors.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      27432,
      62,
      40085,
      7509,
      796,
      6436,
      13,
      38475,
      35,
      7,
      944,
      13,
      38,
      1404,
      62,
      19849,
      13,
      17143,
      7307,
      22784,
      300,
      81,
      28,
      944,
      13,
      14050,
      8
    ],
    "start_token": 622,
    "end_token": 662,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      2526,
      611,
      2994,
      62,
      22184,
      318,
      407,
      6105,
      9041,
      29229,
      11192,
      669,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential risk if loss_fn is not properly handling masked tensors."
  },
  {
    "line": 155,
    "text": "            raise NotImplementedError(\"optimizer {} is not supported!\".format(optimizer))",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Use of string interpolation with user-controlled input in exception message.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      5298,
      1892,
      3546,
      1154,
      12061,
      12331,
      7203,
      40085,
      7509,
      23884,
      318,
      407,
      4855,
      48220,
      18982,
      7,
      40085,
      7509,
      4008
    ],
    "start_token": 662,
    "end_token": 692,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      5765,
      286,
      4731,
      39555,
      341,
      351,
      2836,
      12,
      14401,
      5128,
      287,
      6631,
      3275,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Use of string interpolation with user-controlled input in exception message."
  },
  {
    "line": 153,
    "text": "            self.train_optimizer = optim.SGD(self.GAT_model.parameters(), lr=self.lr)",
    "annotation": "\ud83e\udde0 ML Signal: Use of DataFrame groupby operation, common in data processing tasks",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      27432,
      62,
      40085,
      7509,
      796,
      6436,
      13,
      38475,
      35,
      7,
      944,
      13,
      38,
      1404,
      62,
      19849,
      13,
      17143,
      7307,
      22784,
      300,
      81,
      28,
      944,
      13,
      14050,
      8
    ],
    "start_token": 692,
    "end_token": 732,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      6060,
      19778,
      1448,
      1525,
      4905,
      11,
      2219,
      287,
      1366,
      7587,
      8861
    ],
    "label": "ml_signal",
    "reason": "Use of DataFrame groupby operation, common in data processing tasks"
  },
  {
    "line": 155,
    "text": "            raise NotImplementedError(\"optimizer {} is not supported!\".format(optimizer))",
    "annotation": "\ud83e\udde0 ML Signal: Use of numpy operations for array manipulation",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      5298,
      1892,
      3546,
      1154,
      12061,
      12331,
      7203,
      40085,
      7509,
      23884,
      318,
      407,
      4855,
      48220,
      18982,
      7,
      40085,
      7509,
      4008
    ],
    "start_token": 732,
    "end_token": 762,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      299,
      32152,
      4560,
      329,
      7177,
      17512
    ],
    "label": "ml_signal",
    "reason": "Use of numpy operations for array manipulation"
  },
  {
    "line": 158,
    "text": "        self.GAT_model.to(self.device)",
    "annotation": "\u2705 Best Practice: Conditional logic to handle optional shuffling",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      38,
      1404,
      62,
      19849,
      13,
      1462,
      7,
      944,
      13,
      25202,
      8
    ],
    "start_token": 762,
    "end_token": 782,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      9724,
      1859,
      9156,
      284,
      5412,
      11902,
      32299,
      1359
    ],
    "label": "best_practice",
    "reason": "Conditional logic to handle optional shuffling"
  },
  {
    "line": 160,
    "text": "    @property",
    "annotation": "\ud83e\udde0 ML Signal: Use of shuffling, indicating potential data randomization",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      2488,
      26745
    ],
    "start_token": 782,
    "end_token": 787,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      32299,
      1359,
      11,
      12739,
      2785,
      1366,
      4738,
      1634
    ],
    "label": "ml_signal",
    "reason": "Use of shuffling, indicating potential data randomization"
  },
  {
    "line": 162,
    "text": "        return self.device != torch.device(\"cpu\")",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Use of np.random.shuffle, which may affect reproducibility if not controlled",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1441,
      2116,
      13,
      25202,
      14512,
      28034,
      13,
      25202,
      7203,
      36166,
      4943
    ],
    "start_token": 787,
    "end_token": 805,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      5765,
      286,
      45941,
      13,
      25120,
      13,
      1477,
      18137,
      11,
      543,
      743,
      2689,
      8186,
      66,
      2247,
      611,
      407,
      6856
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Use of np.random.shuffle, which may affect reproducibility if not controlled"
  },
  {
    "line": 163,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Iterating over data_loader indicates a training loop pattern",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 805,
    "end_token": 805,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      40806,
      803,
      625,
      1366,
      62,
      29356,
      9217,
      257,
      3047,
      9052,
      3912
    ],
    "label": "ml_signal",
    "reason": "Iterating over data_loader indicates a training loop pattern"
  },
  {
    "line": 165,
    "text": "        loss = (pred - label) ** 2",
    "annotation": "\u2705 Best Practice: Squeeze is used to remove dimensions of size 1, ensuring data consistency",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2994,
      796,
      357,
      28764,
      532,
      6167,
      8,
      12429,
      362
    ],
    "start_token": 805,
    "end_token": 821,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5056,
      1453,
      2736,
      318,
      973,
      284,
      4781,
      15225,
      286,
      2546,
      352,
      11,
      13359,
      1366,
      15794
    ],
    "label": "best_practice",
    "reason": "Squeeze is used to remove dimensions of size 1, ensuring data consistency"
  },
  {
    "line": 167,
    "text": "",
    "annotation": "\u2705 Best Practice: Explicitly selecting features and labels improves code readability",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 821,
    "end_token": 821,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      11884,
      306,
      17246,
      3033,
      290,
      14722,
      19575,
      2438,
      1100,
      1799
    ],
    "label": "best_practice",
    "reason": "Explicitly selecting features and labels improves code readability"
  },
  {
    "line": 170,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Model prediction step in a training loop",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 821,
    "end_token": 821,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      9104,
      17724,
      2239,
      287,
      257,
      3047,
      9052
    ],
    "label": "ml_signal",
    "reason": "Model prediction step in a training loop"
  },
  {
    "line": 172,
    "text": "            return self.mse(pred[mask], label[mask])",
    "annotation": "\ud83e\udde0 ML Signal: Loss calculation is a key step in training",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1441,
      2116,
      13,
      76,
      325,
      7,
      28764,
      58,
      27932,
      4357,
      6167,
      58,
      27932,
      12962
    ],
    "start_token": 821,
    "end_token": 846,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      22014,
      17952,
      318,
      257,
      1994,
      2239,
      287,
      3047
    ],
    "label": "ml_signal",
    "reason": "Loss calculation is a key step in training"
  },
  {
    "line": 174,
    "text": "        raise ValueError(\"unknown loss `%s`\" % self.loss)",
    "annotation": "\ud83e\udde0 ML Signal: Optimizer zero_grad is a common pattern in training loops",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      5298,
      11052,
      12331,
      7203,
      34680,
      2994,
      4600,
      4,
      82,
      63,
      1,
      4064,
      2116,
      13,
      22462,
      8
    ],
    "start_token": 846,
    "end_token": 869,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      30011,
      7509,
      6632,
      62,
      9744,
      318,
      257,
      2219,
      3912,
      287,
      3047,
      23607
    ],
    "label": "ml_signal",
    "reason": "Optimizer zero_grad is a common pattern in training loops"
  },
  {
    "line": 176,
    "text": "    def metric_fn(self, pred, label):",
    "annotation": "\ud83e\udde0 ML Signal: Backward pass for gradient calculation",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      825,
      18663,
      62,
      22184,
      7,
      944,
      11,
      2747,
      11,
      6167,
      2599
    ],
    "start_token": 869,
    "end_token": 883,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5157,
      904,
      1208,
      329,
      31312,
      17952
    ],
    "label": "ml_signal",
    "reason": "Backward pass for gradient calculation"
  },
  {
    "line": 178,
    "text": "",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Clipping gradients to prevent exploding gradients, ensure it's set appropriately",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 883,
    "end_token": 883,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      1012,
      4501,
      3915,
      2334,
      284,
      2948,
      30990,
      3915,
      2334,
      11,
      4155,
      340,
      338,
      900,
      20431
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Clipping gradients to prevent exploding gradients, ensure it's set appropriately"
  },
  {
    "line": 180,
    "text": "            return -self.loss_fn(pred[mask], label[mask])",
    "annotation": "\ud83e\udde0 ML Signal: Optimizer step is a key part of the training loop",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1441,
      532,
      944,
      13,
      22462,
      62,
      22184,
      7,
      28764,
      58,
      27932,
      4357,
      6167,
      58,
      27932,
      12962
    ],
    "start_token": 883,
    "end_token": 910,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      30011,
      7509,
      2239,
      318,
      257,
      1994,
      636,
      286,
      262,
      3047,
      9052
    ],
    "label": "ml_signal",
    "reason": "Optimizer step is a key part of the training loop"
  },
  {
    "line": 174,
    "text": "        raise ValueError(\"unknown loss `%s`\" % self.loss)",
    "annotation": "\u2705 Best Practice: Set the model to evaluation mode to disable dropout and batch normalization layers.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      5298,
      11052,
      12331,
      7203,
      34680,
      2994,
      4600,
      4,
      82,
      63,
      1,
      4064,
      2116,
      13,
      22462,
      8
    ],
    "start_token": 910,
    "end_token": 933,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5345,
      262,
      2746,
      284,
      12660,
      4235,
      284,
      15560,
      4268,
      448,
      290,
      15458,
      3487,
      1634,
      11685,
      13
    ],
    "label": "best_practice",
    "reason": "Set the model to evaluation mode to disable dropout and batch normalization layers."
  },
  {
    "line": 179,
    "text": "        if self.metric in (\"\", \"loss\"):",
    "annotation": "\u2705 Best Practice: Squeeze the data to remove any singleton dimensions.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      611,
      2116,
      13,
      4164,
      1173,
      287,
      5855,
      1600,
      366,
      22462,
      1,
      2599
    ],
    "start_token": 933,
    "end_token": 952,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5056,
      1453,
      2736,
      262,
      1366,
      284,
      4781,
      597,
      2060,
      1122,
      15225,
      13
    ],
    "label": "best_practice",
    "reason": "Squeeze the data to remove any singleton dimensions."
  },
  {
    "line": 181,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Extracting features and labels from data is a common pattern in ML model evaluation.",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 952,
    "end_token": 952,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      29677,
      278,
      3033,
      290,
      14722,
      422,
      1366,
      318,
      257,
      2219,
      3912,
      287,
      10373,
      2746,
      12660,
      13
    ],
    "label": "ml_signal",
    "reason": "Extracting features and labels from data is a common pattern in ML model evaluation."
  },
  {
    "line": 184,
    "text": "    def get_daily_inter(self, df, shuffle=False):",
    "annotation": "\ud83e\udde0 ML Signal: Model prediction step, typical in ML workflows.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      825,
      651,
      62,
      29468,
      62,
      3849,
      7,
      944,
      11,
      47764,
      11,
      36273,
      28,
      25101,
      2599
    ],
    "start_token": 952,
    "end_token": 970,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      9104,
      17724,
      2239,
      11,
      7226,
      287,
      10373,
      670,
      44041,
      13
    ],
    "label": "ml_signal",
    "reason": "Model prediction step, typical in ML workflows."
  },
  {
    "line": 186,
    "text": "        daily_count = df.groupby(level=0, group_keys=False).size().values",
    "annotation": "\ud83e\udde0 ML Signal: Calculating loss, a key step in model evaluation.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      4445,
      62,
      9127,
      796,
      47764,
      13,
      8094,
      1525,
      7,
      5715,
      28,
      15,
      11,
      1448,
      62,
      13083,
      28,
      25101,
      737,
      7857,
      22446,
      27160
    ],
    "start_token": 970,
    "end_token": 999,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      27131,
      803,
      2994,
      11,
      257,
      1994,
      2239,
      287,
      2746,
      12660,
      13
    ],
    "label": "ml_signal",
    "reason": "Calculating loss, a key step in model evaluation."
  },
  {
    "line": 187,
    "text": "        daily_index = np.roll(np.cumsum(daily_count), 1)",
    "annotation": "\ud83e\udde0 ML Signal: Collecting loss values for later aggregation.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      4445,
      62,
      9630,
      796,
      45941,
      13,
      2487,
      7,
      37659,
      13,
      66,
      5700,
      388,
      7,
      29468,
      62,
      9127,
      828,
      352,
      8
    ],
    "start_token": 999,
    "end_token": 1026,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      9745,
      278,
      2994,
      3815,
      329,
      1568,
      46500,
      13
    ],
    "label": "ml_signal",
    "reason": "Collecting loss values for later aggregation."
  },
  {
    "line": 187,
    "text": "        daily_index = np.roll(np.cumsum(daily_count), 1)",
    "annotation": "\ud83e\udde0 ML Signal: Calculating a metric score, common in model evaluation.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      4445,
      62,
      9630,
      796,
      45941,
      13,
      2487,
      7,
      37659,
      13,
      66,
      5700,
      388,
      7,
      29468,
      62,
      9127,
      828,
      352,
      8
    ],
    "start_token": 1026,
    "end_token": 1053,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      27131,
      803,
      257,
      18663,
      4776,
      11,
      2219,
      287,
      2746,
      12660,
      13
    ],
    "label": "ml_signal",
    "reason": "Calculating a metric score, common in model evaluation."
  },
  {
    "line": 193,
    "text": "            daily_index, daily_count = zip(*daily_shuffle)",
    "annotation": "\ud83e\udde0 ML Signal: Collecting metric scores for later aggregation.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      4445,
      62,
      9630,
      11,
      4445,
      62,
      9127,
      796,
      19974,
      46491,
      29468,
      62,
      1477,
      18137,
      8
    ],
    "start_token": 1053,
    "end_token": 1079,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      9745,
      278,
      18663,
      8198,
      329,
      1568,
      46500,
      13
    ],
    "label": "ml_signal",
    "reason": "Collecting metric scores for later aggregation."
  },
  {
    "line": 194,
    "text": "        return daily_index, daily_count",
    "annotation": "\ud83e\udde0 ML Signal: Returning mean loss and score, typical in model evaluation.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1441,
      4445,
      62,
      9630,
      11,
      4445,
      62,
      9127
    ],
    "start_token": 1079,
    "end_token": 1094,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      42882,
      1612,
      2994,
      290,
      4776,
      11,
      7226,
      287,
      2746,
      12660,
      13
    ],
    "label": "ml_signal",
    "reason": "Returning mean loss and score, typical in model evaluation."
  },
  {
    "line": 193,
    "text": "            daily_index, daily_count = zip(*daily_shuffle)",
    "annotation": "\u2705 Best Practice: Use of descriptive variable names improves code readability.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      4445,
      62,
      9630,
      11,
      4445,
      62,
      9127,
      796,
      19974,
      46491,
      29468,
      62,
      1477,
      18137,
      8
    ],
    "start_token": 1094,
    "end_token": 1120,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      35644,
      7885,
      3891,
      19575,
      2438,
      1100,
      1799,
      13
    ],
    "label": "best_practice",
    "reason": "Use of descriptive variable names improves code readability."
  },
  {
    "line": 198,
    "text": "",
    "annotation": "\u2705 Best Practice: Configuring data with fillna_type ensures data consistency.",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 1120,
    "end_token": 1120,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      17056,
      870,
      1366,
      351,
      6070,
      2616,
      62,
      4906,
      19047,
      1366,
      15794,
      13
    ],
    "label": "best_practice",
    "reason": "Configuring data with fillna_type ensures data consistency."
  },
  {
    "line": 201,
    "text": "            feature = data[:, :, 0:-1].to(self.device)",
    "annotation": "\u2705 Best Practice: Use of custom sampler for data loading.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      3895,
      796,
      1366,
      58,
      45299,
      1058,
      11,
      657,
      21912,
      16,
      4083,
      1462,
      7,
      944,
      13,
      25202,
      8
    ],
    "start_token": 1120,
    "end_token": 1148,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      2183,
      6072,
      20053,
      329,
      1366,
      11046,
      13
    ],
    "label": "best_practice",
    "reason": "Use of custom sampler for data loading."
  },
  {
    "line": 204,
    "text": "            pred = self.GAT_model(feature.float())",
    "annotation": "\u2705 Best Practice: Use of DataLoader for efficient data handling.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2747,
      796,
      2116,
      13,
      38,
      1404,
      62,
      19849,
      7,
      30053,
      13,
      22468,
      28955
    ],
    "start_token": 1148,
    "end_token": 1172,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      6060,
      17401,
      329,
      6942,
      1366,
      9041,
      13
    ],
    "label": "best_practice",
    "reason": "Use of DataLoader for efficient data handling."
  },
  {
    "line": 207,
    "text": "            self.train_optimizer.zero_grad()",
    "annotation": "\u2705 Best Practice: Ensures save_path is valid or creates a new one.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      27432,
      62,
      40085,
      7509,
      13,
      22570,
      62,
      9744,
      3419
    ],
    "start_token": 1172,
    "end_token": 1194,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      48221,
      942,
      3613,
      62,
      6978,
      318,
      4938,
      393,
      8075,
      257,
      649,
      530,
      13
    ],
    "label": "best_practice",
    "reason": "Ensures save_path is valid or creates a new one."
  },
  {
    "line": 213,
    "text": "        self.GAT_model.eval()",
    "annotation": "\ud83e\udde0 ML Signal: Tracking evaluation results for training and validation.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      38,
      1404,
      62,
      19849,
      13,
      18206,
      3419
    ],
    "start_token": 1194,
    "end_token": 1210,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      37169,
      12660,
      2482,
      329,
      3047,
      290,
      21201,
      13
    ],
    "label": "ml_signal",
    "reason": "Tracking evaluation results for training and validation."
  },
  {
    "line": 217,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Conditional model initialization based on base_model type.",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 1210,
    "end_token": 1210,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      9724,
      1859,
      2746,
      37588,
      1912,
      319,
      2779,
      62,
      19849,
      2099,
      13
    ],
    "label": "ml_signal",
    "reason": "Conditional model initialization based on base_model type."
  },
  {
    "line": 225,
    "text": "            loss = self.loss_fn(pred, label)",
    "annotation": "\u26a0\ufe0f SAST Risk (Medium): Loading model state from a file can be risky if the file is untrusted.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2994,
      796,
      2116,
      13,
      22462,
      62,
      22184,
      7,
      28764,
      11,
      6167,
      8
    ],
    "start_token": 1210,
    "end_token": 1233,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      31205,
      2599,
      12320,
      2746,
      1181,
      422,
      257,
      2393,
      460,
      307,
      17564,
      611,
      262,
      2393,
      318,
      1418,
      81,
      8459,
      13
    ],
    "label": "sast_risk",
    "severity": "Medium",
    "reason": "Loading model state from a file can be risky if the file is untrusted."
  },
  {
    "line": 228,
    "text": "            score = self.metric_fn(pred, label)",
    "annotation": "\u2705 Best Practice: Use of dictionary comprehension for filtering state_dict.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      4776,
      796,
      2116,
      13,
      4164,
      1173,
      62,
      22184,
      7,
      28764,
      11,
      6167,
      8
    ],
    "start_token": 1233,
    "end_token": 1257,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      22155,
      35915,
      329,
      25431,
      1181,
      62,
      11600,
      13
    ],
    "label": "best_practice",
    "reason": "Use of dictionary comprehension for filtering state_dict."
  },
  {
    "line": 240,
    "text": "        dl_valid = dataset.prepare(\"valid\", col_set=[\"feature\", \"label\"], data_key=DataHandlerLP.DK_L)",
    "annotation": "\ud83e\udde0 ML Signal: Iterative training process over epochs.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      288,
      75,
      62,
      12102,
      796,
      27039,
      13,
      46012,
      533,
      7203,
      12102,
      1600,
      951,
      62,
      2617,
      28,
      14692,
      30053,
      1600,
      366,
      18242,
      33116,
      1366,
      62,
      2539,
      28,
      6601,
      25060,
      19930,
      13,
      48510,
      62,
      43,
      8
    ],
    "start_token": 1257,
    "end_token": 1298,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      40806,
      876,
      3047,
      1429,
      625,
      36835,
      82,
      13
    ],
    "label": "ml_signal",
    "reason": "Iterative training process over epochs."
  },
  {
    "line": 252,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Use of deepcopy to save the best model parameters.",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 1298,
    "end_token": 1298,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      2769,
      30073,
      284,
      3613,
      262,
      1266,
      2746,
      10007,
      13
    ],
    "label": "ml_signal",
    "reason": "Use of deepcopy to save the best model parameters."
  },
  {
    "line": 261,
    "text": "",
    "annotation": "\u26a0\ufe0f SAST Risk (Medium): Saving model state to a file can be risky if the file path is untrusted.",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 1298,
    "end_token": 1298,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      31205,
      2599,
      34689,
      2746,
      1181,
      284,
      257,
      2393,
      460,
      307,
      17564,
      611,
      262,
      2393,
      3108,
      318,
      1418,
      81,
      8459,
      13
    ],
    "label": "sast_risk",
    "severity": "Medium",
    "reason": "Saving model state to a file can be risky if the file path is untrusted."
  },
  {
    "line": 264,
    "text": "            pretrained_model = LSTMModel(d_feat=self.d_feat, hidden_size=self.hidden_size, num_layers=self.num_layers)",
    "annotation": "\u2705 Best Practice: Clearing GPU cache to free up memory.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2181,
      13363,
      62,
      19849,
      796,
      406,
      2257,
      44,
      17633,
      7,
      67,
      62,
      27594,
      28,
      944,
      13,
      67,
      62,
      27594,
      11,
      7104,
      62,
      7857,
      28,
      944,
      13,
      30342,
      62,
      7857,
      11,
      997,
      62,
      75,
      6962,
      28,
      944,
      13,
      22510,
      62,
      75,
      6962,
      8
    ],
    "start_token": 1298,
    "end_token": 1351,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      3779,
      1723,
      11362,
      12940,
      284,
      1479,
      510,
      4088,
      13
    ],
    "label": "best_practice",
    "reason": "Clearing GPU cache to free up memory."
  },
  {
    "line": 254,
    "text": "",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): No check for dataset validity or type, which could lead to runtime errors.",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 1351,
    "end_token": 1351,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      1400,
      2198,
      329,
      27039,
      19648,
      393,
      2099,
      11,
      543,
      714,
      1085,
      284,
      19124,
      8563,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "No check for dataset validity or type, which could lead to runtime errors."
  },
  {
    "line": 257,
    "text": "        best_score = -np.inf",
    "annotation": "\ud83e\udde0 ML Signal: Usage of dataset preparation with specific column sets and data keys.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1266,
      62,
      26675,
      796,
      532,
      37659,
      13,
      10745
    ],
    "start_token": 1351,
    "end_token": 1366,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      29566,
      286,
      27039,
      11824,
      351,
      2176,
      5721,
      5621,
      290,
      1366,
      8251,
      13
    ],
    "label": "ml_signal",
    "reason": "Usage of dataset preparation with specific column sets and data keys."
  },
  {
    "line": 259,
    "text": "        evals_result[\"train\"] = []",
    "annotation": "\ud83e\udde0 ML Signal: Configuration of data handling with specific fillna strategy.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      819,
      874,
      62,
      20274,
      14692,
      27432,
      8973,
      796,
      17635
    ],
    "start_token": 1366,
    "end_token": 1382,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      28373,
      286,
      1366,
      9041,
      351,
      2176,
      6070,
      2616,
      4811,
      13
    ],
    "label": "ml_signal",
    "reason": "Configuration of data handling with specific fillna strategy."
  },
  {
    "line": 261,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Usage of a custom sampler for data loading.",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 1382,
    "end_token": 1382,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      29566,
      286,
      257,
      2183,
      6072,
      20053,
      329,
      1366,
      11046,
      13
    ],
    "label": "ml_signal",
    "reason": "Usage of a custom sampler for data loading."
  },
  {
    "line": 263,
    "text": "        if self.base_model == \"LSTM\":",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential for resource exhaustion if n_jobs is set too high.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      611,
      2116,
      13,
      8692,
      62,
      19849,
      6624,
      366,
      43,
      2257,
      44,
      1298
    ],
    "start_token": 1382,
    "end_token": 1401,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      329,
      8271,
      32493,
      611,
      299,
      62,
      43863,
      318,
      900,
      1165,
      1029,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential for resource exhaustion if n_jobs is set too high."
  },
  {
    "line": 265,
    "text": "        elif self.base_model == \"GRU\":",
    "annotation": "\ud83e\udde0 ML Signal: Model evaluation mode set before prediction.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1288,
      361,
      2116,
      13,
      8692,
      62,
      19849,
      6624,
      366,
      10761,
      52,
      1298
    ],
    "start_token": 1401,
    "end_token": 1420,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      9104,
      12660,
      4235,
      900,
      878,
      17724,
      13
    ],
    "label": "ml_signal",
    "reason": "Model evaluation mode set before prediction."
  },
  {
    "line": 269,
    "text": "",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Assumes data shape without validation, which could lead to errors.",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 1420,
    "end_token": 1420,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      2195,
      8139,
      1366,
      5485,
      1231,
      21201,
      11,
      543,
      714,
      1085,
      284,
      8563,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Assumes data shape without validation, which could lead to errors."
  },
  {
    "line": 271,
    "text": "            self.logger.info(\"Loading pretrained model...\")",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Assumes specific data structure for feature extraction.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      6404,
      1362,
      13,
      10951,
      7203,
      19031,
      2181,
      13363,
      2746,
      9313,
      8
    ],
    "start_token": 1420,
    "end_token": 1444,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      2195,
      8139,
      2176,
      1366,
      4645,
      329,
      3895,
      22236,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Assumes specific data structure for feature extraction."
  },
  {
    "line": 273,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Use of model prediction with no_grad for inference.",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 1444,
    "end_token": 1444,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      2746,
      17724,
      351,
      645,
      62,
      9744,
      329,
      32278,
      13
    ],
    "label": "ml_signal",
    "reason": "Use of model prediction with no_grad for inference."
  },
  {
    "line": 280,
    "text": "        self.logger.info(\"Loading pretrained model Done...\")",
    "annotation": "\u2705 Best Practice: Using pd.Series for structured output with index.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      6404,
      1362,
      13,
      10951,
      7203,
      19031,
      2181,
      13363,
      2746,
      24429,
      9313,
      8
    ],
    "start_token": 1444,
    "end_token": 1465,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      8554,
      279,
      67,
      13,
      27996,
      329,
      20793,
      5072,
      351,
      6376,
      13
    ],
    "label": "best_practice",
    "reason": "Using pd.Series for structured output with index."
  },
  {
    "line": 269,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Custom neural network model class definition",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 1465,
    "end_token": 1465,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      8562,
      17019,
      3127,
      2746,
      1398,
      6770
    ],
    "label": "ml_signal",
    "reason": "Custom neural network model class definition"
  },
  {
    "line": 272,
    "text": "            pretrained_model.load_state_dict(torch.load(self.model_path, map_location=self.device))",
    "annotation": "\ud83e\udde0 ML Signal: Conditional logic to select model architecture",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2181,
      13363,
      62,
      19849,
      13,
      2220,
      62,
      5219,
      62,
      11600,
      7,
      13165,
      354,
      13,
      2220,
      7,
      944,
      13,
      19849,
      62,
      6978,
      11,
      3975,
      62,
      24886,
      28,
      944,
      13,
      25202,
      4008
    ],
    "start_token": 1465,
    "end_token": 1506,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      9724,
      1859,
      9156,
      284,
      2922,
      2746,
      10959
    ],
    "label": "ml_signal",
    "reason": "Conditional logic to select model architecture"
  },
  {
    "line": 273,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Use of GRU for sequence modeling",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 1506,
    "end_token": 1506,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      10863,
      52,
      329,
      8379,
      21128
    ],
    "label": "ml_signal",
    "reason": "Use of GRU for sequence modeling"
  },
  {
    "line": 281,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Conditional logic to select model architecture",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 1506,
    "end_token": 1506,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      9724,
      1859,
      9156,
      284,
      2922,
      2746,
      10959
    ],
    "label": "ml_signal",
    "reason": "Conditional logic to select model architecture"
  },
  {
    "line": 281,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Use of LSTM for sequence modeling",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 1506,
    "end_token": 1506,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      406,
      2257,
      44,
      329,
      8379,
      21128
    ],
    "label": "ml_signal",
    "reason": "Use of LSTM for sequence modeling"
  },
  {
    "line": 293,
    "text": "            self.logger.info(\"train %.6f, valid %.6f\" % (train_score, val_score))",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential for unhandled exception if base_model is invalid",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      6404,
      1362,
      13,
      10951,
      7203,
      27432,
      4064,
      13,
      21,
      69,
      11,
      4938,
      4064,
      13,
      21,
      69,
      1,
      4064,
      357,
      27432,
      62,
      26675,
      11,
      1188,
      62,
      26675,
      4008
    ],
    "start_token": 1506,
    "end_token": 1546,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      329,
      555,
      38788,
      6631,
      611,
      2779,
      62,
      19849,
      318,
      12515
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential for unhandled exception if base_model is invalid"
  },
  {
    "line": 297,
    "text": "            if val_score > best_score:",
    "annotation": "\ud83e\udde0 ML Signal: Use of linear transformation layer",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      611,
      1188,
      62,
      26675,
      1875,
      1266,
      62,
      26675,
      25
    ],
    "start_token": 1546,
    "end_token": 1566,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      14174,
      13389,
      7679
    ],
    "label": "ml_signal",
    "reason": "Use of linear transformation layer"
  },
  {
    "line": 299,
    "text": "                stop_steps = 0",
    "annotation": "\ud83e\udde0 ML Signal: Use of learnable parameter for attention mechanism",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2245,
      62,
      20214,
      796,
      657
    ],
    "start_token": 1566,
    "end_token": 1586,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      2193,
      540,
      11507,
      329,
      3241,
      9030
    ],
    "label": "ml_signal",
    "reason": "Use of learnable parameter for attention mechanism"
  },
  {
    "line": 302,
    "text": "            else:",
    "annotation": "\ud83e\udde0 ML Signal: Use of fully connected layers for output transformation",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2073,
      25
    ],
    "start_token": 1586,
    "end_token": 1599,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      3938,
      5884,
      11685,
      329,
      5072,
      13389
    ],
    "label": "ml_signal",
    "reason": "Use of fully connected layers for output transformation"
  },
  {
    "line": 305,
    "text": "                    self.logger.info(\"early stop\")",
    "annotation": "\ud83e\udde0 ML Signal: Use of activation function for non-linearity",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      6404,
      1362,
      13,
      10951,
      7203,
      11458,
      2245,
      4943
    ],
    "start_token": 1599,
    "end_token": 1628,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      14916,
      2163,
      329,
      1729,
      12,
      29127,
      414
    ],
    "label": "ml_signal",
    "reason": "Use of activation function for non-linearity"
  },
  {
    "line": 307,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Use of softmax for probability distribution",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 1628,
    "end_token": 1628,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      2705,
      9806,
      329,
      12867,
      6082
    ],
    "label": "ml_signal",
    "reason": "Use of softmax for probability distribution"
  },
  {
    "line": 300,
    "text": "                best_epoch = step",
    "annotation": "\ud83e\udde0 ML Signal: Use of transformation function on input data",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1266,
      62,
      538,
      5374,
      796,
      2239
    ],
    "start_token": 1628,
    "end_token": 1649,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      13389,
      2163,
      319,
      5128,
      1366
    ],
    "label": "ml_signal",
    "reason": "Use of transformation function on input data"
  },
  {
    "line": 302,
    "text": "            else:",
    "annotation": "\ud83e\udde0 ML Signal: Use of transformation function on input data",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2073,
      25
    ],
    "start_token": 1649,
    "end_token": 1662,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      13389,
      2163,
      319,
      5128,
      1366
    ],
    "label": "ml_signal",
    "reason": "Use of transformation function on input data"
  },
  {
    "line": 304,
    "text": "                if stop_steps >= self.early_stop:",
    "annotation": "\ud83e\udde0 ML Signal: Use of tensor shape to determine sample number",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      611,
      2245,
      62,
      20214,
      18189,
      2116,
      13,
      11458,
      62,
      11338,
      25
    ],
    "start_token": 1662,
    "end_token": 1688,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      11192,
      273,
      5485,
      284,
      5004,
      6291,
      1271
    ],
    "label": "ml_signal",
    "reason": "Use of tensor shape to determine sample number"
  },
  {
    "line": 306,
    "text": "                    break",
    "annotation": "\ud83e\udde0 ML Signal: Use of tensor shape to determine dimensionality",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2270
    ],
    "start_token": 1688,
    "end_token": 1708,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      11192,
      273,
      5485,
      284,
      5004,
      15793,
      1483
    ],
    "label": "ml_signal",
    "reason": "Use of tensor shape to determine dimensionality"
  },
  {
    "line": 308,
    "text": "        self.logger.info(\"best score: %.6lf @ %d\" % (best_score, best_epoch))",
    "annotation": "\ud83e\udde0 ML Signal: Expanding tensor for attention mechanism",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      6404,
      1362,
      13,
      10951,
      7203,
      13466,
      4776,
      25,
      4064,
      13,
      21,
      1652,
      2488,
      4064,
      67,
      1,
      4064,
      357,
      13466,
      62,
      26675,
      11,
      1266,
      62,
      538,
      5374,
      4008
    ],
    "start_token": 1708,
    "end_token": 1744,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5518,
      27225,
      11192,
      273,
      329,
      3241,
      9030
    ],
    "label": "ml_signal",
    "reason": "Expanding tensor for attention mechanism"
  },
  {
    "line": 310,
    "text": "        torch.save(best_param, save_path)",
    "annotation": "\ud83e\udde0 ML Signal: Transposing tensor for attention mechanism",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      28034,
      13,
      21928,
      7,
      13466,
      62,
      17143,
      11,
      3613,
      62,
      6978,
      8
    ],
    "start_token": 1744,
    "end_token": 1763,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      3602,
      32927,
      11192,
      273,
      329,
      3241,
      9030
    ],
    "label": "ml_signal",
    "reason": "Transposing tensor for attention mechanism"
  },
  {
    "line": 312,
    "text": "        if self.use_gpu:",
    "annotation": "\ud83e\udde0 ML Signal: Concatenating tensors for attention input",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      611,
      2116,
      13,
      1904,
      62,
      46999,
      25
    ],
    "start_token": 1763,
    "end_token": 1777,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      1482,
      9246,
      268,
      803,
      11192,
      669,
      329,
      3241,
      5128
    ],
    "label": "ml_signal",
    "reason": "Concatenating tensors for attention input"
  },
  {
    "line": 314,
    "text": "",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential misuse of transpose if self.a is not a 2D tensor",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 1777,
    "end_token": 1777,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      29169,
      286,
      1007,
      3455,
      611,
      2116,
      13,
      64,
      318,
      407,
      257,
      362,
      35,
      11192,
      273
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential misuse of transpose if self.a is not a 2D tensor"
  },
  {
    "line": 316,
    "text": "        if not self.fitted:",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential misuse of matrix multiplication if dimensions do not align",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      611,
      407,
      2116,
      13,
      38631,
      25
    ],
    "start_token": 1777,
    "end_token": 1790,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      29169,
      286,
      17593,
      48473,
      611,
      15225,
      466,
      407,
      10548
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential misuse of matrix multiplication if dimensions do not align"
  },
  {
    "line": 318,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Use of activation function in attention mechanism",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 1790,
    "end_token": 1790,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      14916,
      2163,
      287,
      3241,
      9030
    ],
    "label": "ml_signal",
    "reason": "Use of activation function in attention mechanism"
  },
  {
    "line": 319,
    "text": "        dl_test = dataset.prepare(\"test\", col_set=[\"feature\", \"label\"], data_key=DataHandlerLP.DK_I)",
    "annotation": "\ud83e\udde0 ML Signal: Use of softmax for attention weights",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      288,
      75,
      62,
      9288,
      796,
      27039,
      13,
      46012,
      533,
      7203,
      9288,
      1600,
      951,
      62,
      2617,
      28,
      14692,
      30053,
      1600,
      366,
      18242,
      33116,
      1366,
      62,
      2539,
      28,
      6601,
      25060,
      19930,
      13,
      48510,
      62,
      40,
      8
    ],
    "start_token": 1790,
    "end_token": 1831,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      2705,
      9806,
      329,
      3241,
      19590
    ],
    "label": "ml_signal",
    "reason": "Use of softmax for attention weights"
  },
  {
    "line": 319,
    "text": "        dl_test = dataset.prepare(\"test\", col_set=[\"feature\", \"label\"], data_key=DataHandlerLP.DK_I)",
    "annotation": "\u2705 Best Practice: Explicit return of computed attention weights",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      288,
      75,
      62,
      9288,
      796,
      27039,
      13,
      46012,
      533,
      7203,
      9288,
      1600,
      951,
      62,
      2617,
      28,
      14692,
      30053,
      1600,
      366,
      18242,
      33116,
      1366,
      62,
      2539,
      28,
      6601,
      25060,
      19930,
      13,
      48510,
      62,
      40,
      8
    ],
    "start_token": 1831,
    "end_token": 1872,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      11884,
      1441,
      286,
      29231,
      3241,
      19590
    ],
    "label": "best_practice",
    "reason": "Explicit return of computed attention weights"
  },
  {
    "line": 315,
    "text": "    def predict(self, dataset):",
    "annotation": "\ud83e\udde0 ML Signal: Use of attention mechanism in neural network",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      825,
      4331,
      7,
      944,
      11,
      27039,
      2599
    ],
    "start_token": 1872,
    "end_token": 1882,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      3241,
      9030,
      287,
      17019,
      3127
    ],
    "label": "ml_signal",
    "reason": "Use of attention mechanism in neural network"
  },
  {
    "line": 317,
    "text": "            raise ValueError(\"model is not fitted yet!\")",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential for incorrect matrix multiplication dimensions",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      5298,
      11052,
      12331,
      7203,
      19849,
      318,
      407,
      18235,
      1865,
      2474,
      8
    ],
    "start_token": 1882,
    "end_token": 1904,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      329,
      11491,
      17593,
      48473,
      15225
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential for incorrect matrix multiplication dimensions"
  },
  {
    "line": 319,
    "text": "        dl_test = dataset.prepare(\"test\", col_set=[\"feature\", \"label\"], data_key=DataHandlerLP.DK_I)",
    "annotation": "\ud83e\udde0 ML Signal: Use of fully connected layer in neural network",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      288,
      75,
      62,
      9288,
      796,
      27039,
      13,
      46012,
      533,
      7203,
      9288,
      1600,
      951,
      62,
      2617,
      28,
      14692,
      30053,
      1600,
      366,
      18242,
      33116,
      1366,
      62,
      2539,
      28,
      6601,
      25060,
      19930,
      13,
      48510,
      62,
      40,
      8
    ],
    "start_token": 1904,
    "end_token": 1945,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      3938,
      5884,
      7679,
      287,
      17019,
      3127
    ],
    "label": "ml_signal",
    "reason": "Use of fully connected layer in neural network"
  },
  {
    "line": 319,
    "text": "        dl_test = dataset.prepare(\"test\", col_set=[\"feature\", \"label\"], data_key=DataHandlerLP.DK_I)",
    "annotation": "\ud83e\udde0 ML Signal: Use of activation function in neural network",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      288,
      75,
      62,
      9288,
      796,
      27039,
      13,
      46012,
      533,
      7203,
      9288,
      1600,
      951,
      62,
      2617,
      28,
      14692,
      30053,
      1600,
      366,
      18242,
      33116,
      1366,
      62,
      2539,
      28,
      6601,
      25060,
      19930,
      13,
      48510,
      62,
      40,
      8
    ],
    "start_token": 1945,
    "end_token": 1986,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      14916,
      2163,
      287,
      17019,
      3127
    ],
    "label": "ml_signal",
    "reason": "Use of activation function in neural network"
  },
  {
    "line": 319,
    "text": "        dl_test = dataset.prepare(\"test\", col_set=[\"feature\", \"label\"], data_key=DataHandlerLP.DK_I)",
    "annotation": "\ud83e\udde0 ML Signal: Use of output layer in neural network",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      288,
      75,
      62,
      9288,
      796,
      27039,
      13,
      46012,
      533,
      7203,
      9288,
      1600,
      951,
      62,
      2617,
      28,
      14692,
      30053,
      1600,
      366,
      18242,
      33116,
      1366,
      62,
      2539,
      28,
      6601,
      25060,
      19930,
      13,
      48510,
      62,
      40,
      8
    ],
    "start_token": 1986,
    "end_token": 2027,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      5072,
      7679,
      287,
      17019,
      3127
    ],
    "label": "ml_signal",
    "reason": "Use of output layer in neural network"
  }
]