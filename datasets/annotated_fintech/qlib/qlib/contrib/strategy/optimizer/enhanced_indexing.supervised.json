[
  {
    "line": 4,
    "text": "import numpy as np",
    "annotation": "\u2705 Best Practice: Import only necessary components from a module to improve readability and maintainability",
    "confidence": 0.5,
    "tokens": [
      11748,
      299,
      32152,
      355,
      45941
    ],
    "start_token": 0,
    "end_token": 5,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      17267,
      691,
      3306,
      6805,
      422,
      257,
      8265,
      284,
      2987,
      1100,
      1799,
      290,
      5529,
      1799
    ],
    "label": "best_practice",
    "reason": "Import only necessary components from a module to improve readability and maintainability"
  },
  {
    "line": 6,
    "text": "",
    "annotation": "\u2705 Best Practice: Group related imports together for better organization",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 5,
    "end_token": 5,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      4912,
      3519,
      17944,
      1978,
      329,
      1365,
      4009
    ],
    "label": "best_practice",
    "reason": "Group related imports together for better organization"
  },
  {
    "line": 8,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Logging initialization indicates tracking and monitoring of optimizer behavior",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 5,
    "end_token": 5,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5972,
      2667,
      37588,
      9217,
      9646,
      290,
      9904,
      286,
      6436,
      7509,
      4069
    ],
    "label": "ml_signal",
    "reason": "Logging initialization indicates tracking and monitoring of optimizer behavior"
  },
  {
    "line": 34,
    "text": "        v = d @ F: factor deviation",
    "annotation": "\ud83e\udde0 ML Signal: The class docstring provides a detailed description of the optimization problem, which can be used to train models on financial optimization tasks.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      410,
      796,
      288,
      2488,
      376,
      25,
      5766,
      28833
    ],
    "start_token": 5,
    "end_token": 20,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      383,
      1398,
      2205,
      8841,
      3769,
      257,
      6496,
      6764,
      286,
      262,
      23989,
      1917,
      11,
      543,
      460,
      307,
      973,
      284,
      4512,
      4981,
      319,
      3176,
      23989,
      8861,
      13
    ],
    "label": "ml_signal",
    "reason": "The class docstring provides a detailed description of the optimization problem, which can be used to train models on financial optimization tasks."
  },
  {
    "line": 34,
    "text": "        v = d @ F: factor deviation",
    "annotation": "\u2705 Best Practice: The use of a detailed docstring improves code readability and maintainability by clearly explaining the purpose and constraints of the optimizer.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      410,
      796,
      288,
      2488,
      376,
      25,
      5766,
      28833
    ],
    "start_token": 20,
    "end_token": 35,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      383,
      779,
      286,
      257,
      6496,
      2205,
      8841,
      19575,
      2438,
      1100,
      1799,
      290,
      5529,
      1799,
      416,
      4084,
      11170,
      262,
      4007,
      290,
      17778,
      286,
      262,
      6436,
      7509,
      13
    ],
    "label": "best_practice",
    "reason": "The use of a detailed docstring improves code readability and maintainability by clearly explaining the purpose and constraints of the optimizer."
  },
  {
    "line": 54,
    "text": "        epsilon: float = 5e-5,",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Use of assert for input validation can be bypassed if Python is run with optimizations",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      304,
      862,
      33576,
      25,
      12178,
      796,
      642,
      68,
      12,
      20,
      11
    ],
    "start_token": 35,
    "end_token": 53,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      5765,
      286,
      6818,
      329,
      5128,
      21201,
      460,
      307,
      17286,
      276,
      611,
      11361,
      318,
      1057,
      351,
      41446
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Use of assert for input validation can be bypassed if Python is run with optimizations"
  },
  {
    "line": 56,
    "text": "    ):",
    "annotation": "\ud83e\udde0 ML Signal: Tracking initialization of risk aversion parameter",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      15179
    ],
    "start_token": 53,
    "end_token": 57,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      37169,
      37588,
      286,
      2526,
      41608,
      11507
    ],
    "label": "ml_signal",
    "reason": "Tracking initialization of risk aversion parameter"
  },
  {
    "line": 58,
    "text": "        Args:",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Use of assert for input validation can be bypassed if Python is run with optimizations",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      943,
      14542,
      25
    ],
    "start_token": 57,
    "end_token": 67,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      5765,
      286,
      6818,
      329,
      5128,
      21201,
      460,
      307,
      17286,
      276,
      611,
      11361,
      318,
      1057,
      351,
      41446
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Use of assert for input validation can be bypassed if Python is run with optimizations"
  },
  {
    "line": 60,
    "text": "            delta (float): total turnover limit",
    "annotation": "\ud83e\udde0 ML Signal: Tracking initialization of turnover limit",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      25979,
      357,
      22468,
      2599,
      2472,
      25079,
      4179
    ],
    "start_token": 67,
    "end_token": 85,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      37169,
      37588,
      286,
      25079,
      4179
    ],
    "label": "ml_signal",
    "reason": "Tracking initialization of turnover limit"
  },
  {
    "line": 62,
    "text": "            f_dev (list): factor deviation limit",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Use of assert for input validation can be bypassed if Python is run with optimizations",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      277,
      62,
      7959,
      357,
      4868,
      2599,
      5766,
      28833,
      4179
    ],
    "start_token": 85,
    "end_token": 105,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      5765,
      286,
      6818,
      329,
      5128,
      21201,
      460,
      307,
      17286,
      276,
      611,
      11361,
      318,
      1057,
      351,
      41446
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Use of assert for input validation can be bypassed if Python is run with optimizations"
  },
  {
    "line": 64,
    "text": "            epsilon (float): minimum weight",
    "annotation": "\ud83e\udde0 ML Signal: Tracking initialization of benchmark deviation limit",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      304,
      862,
      33576,
      357,
      22468,
      2599,
      5288,
      3463
    ],
    "start_token": 105,
    "end_token": 124,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      37169,
      37588,
      286,
      18335,
      28833,
      4179
    ],
    "label": "ml_signal",
    "reason": "Tracking initialization of benchmark deviation limit"
  },
  {
    "line": 66,
    "text": "        \"\"\"",
    "annotation": "\u2705 Best Practice: Check type before performing operations to avoid runtime errors",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      37227
    ],
    "start_token": 124,
    "end_token": 132,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      6822,
      2099,
      878,
      9489,
      4560,
      284,
      3368,
      19124,
      8563
    ],
    "label": "best_practice",
    "reason": "Check type before performing operations to avoid runtime errors"
  },
  {
    "line": 68,
    "text": "        assert lamb >= 0, \"risk aversion parameter `lamb` should be positive\"",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Use of assert for input validation can be bypassed if Python is run with optimizations",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      6818,
      19343,
      18189,
      657,
      11,
      366,
      19121,
      41608,
      11507,
      4600,
      2543,
      65,
      63,
      815,
      307,
      3967,
      1
    ],
    "start_token": 132,
    "end_token": 156,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      5765,
      286,
      6818,
      329,
      5128,
      21201,
      460,
      307,
      17286,
      276,
      611,
      11361,
      318,
      1057,
      351,
      41446
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Use of assert for input validation can be bypassed if Python is run with optimizations"
  },
  {
    "line": 69,
    "text": "        self.lamb = lamb",
    "annotation": "\u2705 Best Practice: Convert list to numpy array for efficient numerical operations",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      2543,
      65,
      796,
      19343
    ],
    "start_token": 156,
    "end_token": 169,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      38240,
      1351,
      284,
      299,
      32152,
      7177,
      329,
      6942,
      29052,
      4560
    ],
    "label": "best_practice",
    "reason": "Convert list to numpy array for efficient numerical operations"
  },
  {
    "line": 69,
    "text": "        self.lamb = lamb",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Use of assert for input validation can be bypassed if Python is run with optimizations",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      2543,
      65,
      796,
      19343
    ],
    "start_token": 169,
    "end_token": 182,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      5765,
      286,
      6818,
      329,
      5128,
      21201,
      460,
      307,
      17286,
      276,
      611,
      11361,
      318,
      1057,
      351,
      41446
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Use of assert for input validation can be bypassed if Python is run with optimizations"
  },
  {
    "line": 75,
    "text": "        self.b_dev = b_dev",
    "annotation": "\ud83e\udde0 ML Signal: Tracking initialization of factor deviation limit",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      65,
      62,
      7959,
      796,
      275,
      62,
      7959
    ],
    "start_token": 182,
    "end_token": 198,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      37169,
      37588,
      286,
      5766,
      28833,
      4179
    ],
    "label": "ml_signal",
    "reason": "Tracking initialization of factor deviation limit"
  },
  {
    "line": 77,
    "text": "        if isinstance(f_dev, float):",
    "annotation": "\ud83e\udde0 ML Signal: Tracking initialization of scale return flag",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      611,
      318,
      39098,
      7,
      69,
      62,
      7959,
      11,
      12178,
      2599
    ],
    "start_token": 198,
    "end_token": 215,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      37169,
      37588,
      286,
      5046,
      1441,
      6056
    ],
    "label": "ml_signal",
    "reason": "Tracking initialization of scale return flag"
  },
  {
    "line": 80,
    "text": "            f_dev = np.array(f_dev)",
    "annotation": "\ud83e\udde0 ML Signal: Tracking initialization of minimum weight",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      277,
      62,
      7959,
      796,
      45941,
      13,
      18747,
      7,
      69,
      62,
      7959,
      8
    ],
    "start_token": 215,
    "end_token": 238,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      37169,
      37588,
      286,
      5288,
      3463
    ],
    "label": "ml_signal",
    "reason": "Tracking initialization of minimum weight"
  },
  {
    "line": 80,
    "text": "            f_dev = np.array(f_dev)",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Mutable default argument for solver_kwargs can lead to unexpected behavior",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      277,
      62,
      7959,
      796,
      45941,
      13,
      18747,
      7,
      69,
      62,
      7959,
      8
    ],
    "start_token": 238,
    "end_token": 261,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      13859,
      540,
      4277,
      4578,
      329,
      1540,
      332,
      62,
      46265,
      22046,
      460,
      1085,
      284,
      10059,
      4069
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Mutable default argument for solver_kwargs can lead to unexpected behavior"
  },
  {
    "line": 93,
    "text": "        var_u: np.ndarray,",
    "annotation": "\ud83e\udde0 ML Signal: Scaling of input data is a common preprocessing step in ML models.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1401,
      62,
      84,
      25,
      45941,
      13,
      358,
      18747,
      11
    ],
    "start_token": 261,
    "end_token": 277,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      1446,
      4272,
      286,
      5128,
      1366,
      318,
      257,
      2219,
      662,
      36948,
      2239,
      287,
      10373,
      4981,
      13
    ],
    "label": "ml_signal",
    "reason": "Scaling of input data is a common preprocessing step in ML models."
  },
  {
    "line": 97,
    "text": "        mfs: Optional[np.ndarray] = None,",
    "annotation": "\u2705 Best Practice: Use of cvxpy for defining optimization variables.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      285,
      9501,
      25,
      32233,
      58,
      37659,
      13,
      358,
      18747,
      60,
      796,
      6045,
      11
    ],
    "start_token": 277,
    "end_token": 297,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      269,
      85,
      87,
      9078,
      329,
      16215,
      23989,
      9633,
      13
    ],
    "label": "best_practice",
    "reason": "Use of cvxpy for defining optimization variables."
  },
  {
    "line": 99,
    "text": "        \"\"\"",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Direct assignment to w.value without checking constraints.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      37227
    ],
    "start_token": 297,
    "end_token": 305,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      4128,
      16237,
      284,
      266,
      13,
      8367,
      1231,
      10627,
      17778,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Direct assignment to w.value without checking constraints."
  },
  {
    "line": 104,
    "text": "            var_u (np.ndarray): residual variance",
    "annotation": "\u2705 Best Practice: Use of cvxpy for quadratic form calculation.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1401,
      62,
      84,
      357,
      37659,
      13,
      358,
      18747,
      2599,
      29598,
      24198
    ],
    "start_token": 305,
    "end_token": 327,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      269,
      85,
      87,
      9078,
      329,
      15094,
      81,
      1512,
      1296,
      17952,
      13
    ],
    "label": "best_practice",
    "reason": "Use of cvxpy for quadratic form calculation."
  },
  {
    "line": 106,
    "text": "            wb (np.ndarray): benchmark weights",
    "annotation": "\u2705 Best Practice: Use of cvxpy for defining optimization objective.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      266,
      65,
      357,
      37659,
      13,
      358,
      18747,
      2599,
      18335,
      19590
    ],
    "start_token": 327,
    "end_token": 348,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      269,
      85,
      87,
      9078,
      329,
      16215,
      23989,
      9432,
      13
    ],
    "label": "best_practice",
    "reason": "Use of cvxpy for defining optimization objective."
  },
  {
    "line": 119,
    "text": "        w = cp.Variable(len(r), nonneg=True)",
    "annotation": "\u2705 Best Practice: Use of cvxpy for defining constraints.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      266,
      796,
      31396,
      13,
      43015,
      7,
      11925,
      7,
      81,
      828,
      1729,
      12480,
      28,
      17821,
      8
    ],
    "start_token": 348,
    "end_token": 370,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      269,
      85,
      87,
      9078,
      329,
      16215,
      17778,
      13
    ],
    "label": "best_practice",
    "reason": "Use of cvxpy for defining constraints."
  },
  {
    "line": 129,
    "text": "        obj = cp.Maximize(ret - self.lamb * risk)",
    "annotation": "\u2705 Best Practice: Use of cvxpy for solving optimization problems.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      26181,
      796,
      31396,
      13,
      11518,
      48439,
      7,
      1186,
      532,
      2116,
      13,
      2543,
      65,
      1635,
      2526,
      8
    ],
    "start_token": 370,
    "end_token": 393,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      269,
      85,
      87,
      9078,
      329,
      18120,
      23989,
      2761,
      13
    ],
    "label": "best_practice",
    "reason": "Use of cvxpy for solving optimization problems."
  },
  {
    "line": 135,
    "text": "        # bench bounds",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Logging of exception messages can expose sensitive information.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1303,
      7624,
      22303
    ],
    "start_token": 393,
    "end_token": 403,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      5972,
      2667,
      286,
      6631,
      6218,
      460,
      15651,
      8564,
      1321,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Logging of exception messages can expose sensitive information."
  },
  {
    "line": 140,
    "text": "        # force holding",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Direct assignment to w.value without checking constraints.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1303,
      2700,
      4769
    ],
    "start_token": 403,
    "end_token": 413,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      4128,
      16237,
      284,
      266,
      13,
      8367,
      1231,
      10627,
      17778,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Direct assignment to w.value without checking constraints."
  },
  {
    "line": 147,
    "text": "        if mfs is not None:",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Logging of exception messages can expose sensitive information.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      611,
      285,
      9501,
      318,
      407,
      6045,
      25
    ],
    "start_token": 413,
    "end_token": 427,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      5972,
      2667,
      286,
      6631,
      6218,
      460,
      15651,
      8564,
      1321,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Logging of exception messages can expose sensitive information."
  },
  {
    "line": 147,
    "text": "        if mfs is not None:",
    "annotation": "\u2705 Best Practice: Setting small weights to zero for numerical stability.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      611,
      285,
      9501,
      318,
      407,
      6045,
      25
    ],
    "start_token": 427,
    "end_token": 441,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      25700,
      1402,
      19590,
      284,
      6632,
      329,
      29052,
      10159,
      13
    ],
    "label": "best_practice",
    "reason": "Setting small weights to zero for numerical stability."
  }
]