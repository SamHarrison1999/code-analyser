[
  {
    "line": 9,
    "text": "",
    "annotation": "\u2705 Best Practice: Grouping imports by standard, third-party, and local can improve readability.",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 0,
    "end_token": 0,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      4912,
      278,
      17944,
      416,
      3210,
      11,
      2368,
      12,
      10608,
      11,
      290,
      1957,
      460,
      2987,
      1100,
      1799,
      13
    ],
    "label": "best_practice",
    "reason": "Grouping imports by standard, third-party, and local can improve readability."
  },
  {
    "line": 16,
    "text": "    - any data is missing",
    "annotation": "\u2705 Best Practice: Class docstring provides a clear description of the class functionality and checks performed.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      532,
      597,
      1366,
      318,
      4814
    ],
    "start_token": 0,
    "end_token": 8,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5016,
      2205,
      8841,
      3769,
      257,
      1598,
      6764,
      286,
      262,
      1398,
      11244,
      290,
      8794,
      6157,
      13
    ],
    "label": "best_practice",
    "reason": "Class docstring provides a clear description of the class functionality and checks performed."
  },
  {
    "line": 25,
    "text": "        freq=\"day\",",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Using assert for argument validation can be bypassed if Python is run with optimizations.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2030,
      80,
      2625,
      820,
      1600
    ],
    "start_token": 8,
    "end_token": 20,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      8554,
      6818,
      329,
      4578,
      21201,
      460,
      307,
      17286,
      276,
      611,
      11361,
      318,
      1057,
      351,
      41446,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Using assert for argument validation can be bypassed if Python is run with optimizations."
  },
  {
    "line": 27,
    "text": "        large_step_threshold_volume=3,",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Using assert for argument validation can be bypassed if Python is run with optimizations.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1588,
      62,
      9662,
      62,
      400,
      10126,
      62,
      29048,
      28,
      18,
      11
    ],
    "start_token": 20,
    "end_token": 38,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      8554,
      6818,
      329,
      4578,
      21201,
      460,
      307,
      17286,
      276,
      611,
      11361,
      318,
      1057,
      351,
      41446,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Using assert for argument validation can be bypassed if Python is run with optimizations."
  },
  {
    "line": 36,
    "text": "        self.large_step_threshold_price = large_step_threshold_price",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Using assert for directory validation can be bypassed if Python is run with optimizations.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      11664,
      62,
      9662,
      62,
      400,
      10126,
      62,
      20888,
      796,
      1588,
      62,
      9662,
      62,
      400,
      10126,
      62,
      20888
    ],
    "start_token": 38,
    "end_token": 64,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      8554,
      6818,
      329,
      8619,
      21201,
      460,
      307,
      17286,
      276,
      611,
      11361,
      318,
      1057,
      351,
      41446,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Using assert for directory validation can be bypassed if Python is run with optimizations."
  },
  {
    "line": 38,
    "text": "        self.missing_data_num = missing_data_num",
    "annotation": "\u2705 Best Practice: List comprehension for filtering files is efficient and concise.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      45688,
      62,
      7890,
      62,
      22510,
      796,
      4814,
      62,
      7890,
      62,
      22510
    ],
    "start_token": 64,
    "end_token": 84,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      7343,
      35915,
      329,
      25431,
      3696,
      318,
      6942,
      290,
      35327,
      13
    ],
    "label": "best_practice",
    "reason": "List comprehension for filtering files is efficient and concise."
  },
  {
    "line": 40,
    "text": "        if csv_path:",
    "annotation": "\ud83e\udde0 ML Signal: Usage of tqdm for progress indication can be a signal of handling large datasets.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      611,
      269,
      21370,
      62,
      6978,
      25
    ],
    "start_token": 84,
    "end_token": 97,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      29566,
      286,
      256,
      80,
      36020,
      329,
      4371,
      12955,
      460,
      307,
      257,
      6737,
      286,
      9041,
      1588,
      40522,
      13
    ],
    "label": "ml_signal",
    "reason": "Usage of tqdm for progress indication can be a signal of handling large datasets."
  },
  {
    "line": 42,
    "text": "            files = [f for f in os.listdir(csv_path) if f.endswith(\".csv\")]",
    "annotation": "\ud83e\udde0 ML Signal: Reading CSV files into DataFrames is a common pattern in data processing tasks.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      3696,
      796,
      685,
      69,
      329,
      277,
      287,
      28686,
      13,
      4868,
      15908,
      7,
      40664,
      62,
      6978,
      8,
      611,
      277,
      13,
      437,
      2032,
      342,
      7,
      1911,
      40664,
      4943,
      60
    ],
    "start_token": 97,
    "end_token": 135,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      11725,
      44189,
      3696,
      656,
      6060,
      35439,
      318,
      257,
      2219,
      3912,
      287,
      1366,
      7587,
      8861,
      13
    ],
    "label": "ml_signal",
    "reason": "Reading CSV files into DataFrames is a common pattern in data processing tasks."
  },
  {
    "line": 46,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Initialization of qlib indicates usage of a specific data handling library.",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 135,
    "end_token": 135,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      20768,
      1634,
      286,
      10662,
      8019,
      9217,
      8748,
      286,
      257,
      2176,
      1366,
      9041,
      5888,
      13
    ],
    "label": "ml_signal",
    "reason": "Initialization of qlib indicates usage of a specific data handling library."
  },
  {
    "line": 48,
    "text": "            qlib.init(provider_uri=qlib_dir)",
    "annotation": "\ud83e\udde0 ML Signal: Custom method for loading data suggests specialized data processing.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      10662,
      8019,
      13,
      15003,
      7,
      15234,
      1304,
      62,
      9900,
      28,
      80,
      8019,
      62,
      15908,
      8
    ],
    "start_token": 135,
    "end_token": 161,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      8562,
      2446,
      329,
      11046,
      1366,
      5644,
      16976,
      1366,
      7587,
      13
    ],
    "label": "ml_signal",
    "reason": "Custom method for loading data suggests specialized data processing."
  },
  {
    "line": 44,
    "text": "                df = pd.read_csv(os.path.join(csv_path, filename))",
    "annotation": "\ud83e\udde0 ML Signal: Usage of a method to list instruments, indicating data retrieval pattern",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      47764,
      796,
      279,
      67,
      13,
      961,
      62,
      40664,
      7,
      418,
      13,
      6978,
      13,
      22179,
      7,
      40664,
      62,
      6978,
      11,
      29472,
      4008
    ],
    "start_token": 161,
    "end_token": 197,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      29566,
      286,
      257,
      2446,
      284,
      1351,
      12834,
      11,
      12739,
      1366,
      45069,
      3912
    ],
    "label": "ml_signal",
    "reason": "Usage of a method to list instruments, indicating data retrieval pattern"
  },
  {
    "line": 48,
    "text": "            qlib.init(provider_uri=qlib_dir)",
    "annotation": "\ud83e\udde0 ML Signal: Iterating over a list of instruments, common in financial data processing",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      10662,
      8019,
      13,
      15003,
      7,
      15234,
      1304,
      62,
      9900,
      28,
      80,
      8019,
      62,
      15908,
      8
    ],
    "start_token": 197,
    "end_token": 223,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      40806,
      803,
      625,
      257,
      1351,
      286,
      12834,
      11,
      2219,
      287,
      3176,
      1366,
      7587
    ],
    "label": "ml_signal",
    "reason": "Iterating over a list of instruments, common in financial data processing"
  },
  {
    "line": 48,
    "text": "            qlib.init(provider_uri=qlib_dir)",
    "annotation": "\u2705 Best Practice: Using rename with inplace=True for clarity and efficiency",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      10662,
      8019,
      13,
      15003,
      7,
      15234,
      1304,
      62,
      9900,
      28,
      80,
      8019,
      62,
      15908,
      8
    ],
    "start_token": 223,
    "end_token": 249,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      8554,
      36265,
      351,
      287,
      5372,
      28,
      17821,
      329,
      16287,
      290,
      9332
    ],
    "label": "best_practice",
    "reason": "Using rename with inplace=True for clarity and efficiency"
  },
  {
    "line": 62,
    "text": "                    \"$high\": \"high\",",
    "annotation": "\ud83e\udde0 ML Signal: Storing processed data in a dictionary, indicating data organization pattern",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      17971,
      8929,
      1298,
      366,
      8929,
      1600
    ],
    "start_token": 249,
    "end_token": 274,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      520,
      3255,
      13686,
      1366,
      287,
      257,
      22155,
      11,
      12739,
      1366,
      4009,
      3912
    ],
    "label": "ml_signal",
    "reason": "Storing processed data in a dictionary, indicating data organization pattern"
  },
  {
    "line": 63,
    "text": "                    \"$volume\": \"volume\",",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Printing data frames can expose sensitive data in logs",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      17971,
      29048,
      1298,
      366,
      29048,
      1600
    ],
    "start_token": 274,
    "end_token": 299,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      44118,
      1366,
      13431,
      460,
      15651,
      8564,
      1366,
      287,
      17259
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Printing data frames can expose sensitive data in logs"
  },
  {
    "line": 71,
    "text": "    def check_missing_data(self) -> Optional[pd.DataFrame]:",
    "annotation": "\ud83e\udde0 ML Signal: Iterating over a dictionary of DataFrames to check for missing data",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      825,
      2198,
      62,
      45688,
      62,
      7890,
      7,
      944,
      8,
      4613,
      32233,
      58,
      30094,
      13,
      6601,
      19778,
      5974
    ],
    "start_token": 299,
    "end_token": 319,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      40806,
      803,
      625,
      257,
      22155,
      286,
      6060,
      35439,
      284,
      2198,
      329,
      4814,
      1366
    ],
    "label": "ml_signal",
    "reason": "Iterating over a dictionary of DataFrames to check for missing data"
  },
  {
    "line": 73,
    "text": "        result_dict = {",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential performance issue with multiple calls to df.isnull().sum()",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1255,
      62,
      11600,
      796,
      1391
    ],
    "start_token": 319,
    "end_token": 331,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      2854,
      2071,
      351,
      3294,
      3848,
      284,
      47764,
      13,
      271,
      8423,
      22446,
      16345,
      3419
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential performance issue with multiple calls to df.isnull().sum()"
  },
  {
    "line": 77,
    "text": "            \"low\": [],",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Repeated computation of df.isnull().sum() for each column",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      366,
      9319,
      1298,
      685,
      4357
    ],
    "start_token": 331,
    "end_token": 347,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      30558,
      515,
      29964,
      286,
      47764,
      13,
      271,
      8423,
      22446,
      16345,
      3419,
      329,
      1123,
      5721
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Repeated computation of df.isnull().sum() for each column"
  },
  {
    "line": 82,
    "text": "            missing_data_columns = df.isnull().sum()[df.isnull().sum() > self.missing_data_num].index.tolist()",
    "annotation": "\u2705 Best Practice: Use set_index for better DataFrame organization",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      4814,
      62,
      7890,
      62,
      28665,
      82,
      796,
      47764,
      13,
      271,
      8423,
      22446,
      16345,
      3419,
      58,
      7568,
      13,
      271,
      8423,
      22446,
      16345,
      3419,
      1875,
      2116,
      13,
      45688,
      62,
      7890,
      62,
      22510,
      4083,
      9630,
      13,
      83,
      349,
      396,
      3419
    ],
    "start_token": 347,
    "end_token": 395,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      900,
      62,
      9630,
      329,
      1365,
      6060,
      19778,
      4009
    ],
    "label": "best_practice",
    "reason": "Use set_index for better DataFrame organization"
  },
  {
    "line": 88,
    "text": "                result_dict[\"close\"].append(df.isnull().sum()[\"close\"])",
    "annotation": "\u2705 Best Practice: Use logging for informational messages",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1255,
      62,
      11600,
      14692,
      19836,
      1,
      4083,
      33295,
      7,
      7568,
      13,
      271,
      8423,
      22446,
      16345,
      3419,
      14692,
      19836,
      8973,
      8
    ],
    "start_token": 395,
    "end_token": 430,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      18931,
      329,
      21524,
      6218
    ],
    "label": "best_practice",
    "reason": "Use logging for informational messages"
  },
  {
    "line": 98,
    "text": "    def check_large_step_changes(self) -> Optional[pd.DataFrame]:",
    "annotation": "\u2705 Best Practice: Using pct_change with fill_method=None to handle NaN values explicitly",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      825,
      2198,
      62,
      11664,
      62,
      9662,
      62,
      36653,
      7,
      944,
      8,
      4613,
      32233,
      58,
      30094,
      13,
      6601,
      19778,
      5974
    ],
    "start_token": 430,
    "end_token": 452,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      8554,
      279,
      310,
      62,
      3803,
      351,
      6070,
      62,
      24396,
      28,
      14202,
      284,
      5412,
      11013,
      45,
      3815,
      11777
    ],
    "label": "best_practice",
    "reason": "Using pct_change with fill_method=None to handle NaN values explicitly"
  },
  {
    "line": 100,
    "text": "        result_dict = {",
    "annotation": "\ud83e\udde0 ML Signal: Different thresholds for 'volume' and price columns indicate domain-specific logic",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1255,
      62,
      11600,
      796,
      1391
    ],
    "start_token": 452,
    "end_token": 464,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      20615,
      40885,
      329,
      705,
      29048,
      6,
      290,
      2756,
      15180,
      7603,
      7386,
      12,
      11423,
      9156
    ],
    "label": "ml_signal",
    "reason": "Different thresholds for 'volume' and price columns indicate domain-specific logic"
  },
  {
    "line": 103,
    "text": "            \"date\": [],",
    "annotation": "\ud83e\udde0 ML Signal: Identifying and storing large step changes can be used for anomaly detection",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      366,
      4475,
      1298,
      685,
      4357
    ],
    "start_token": 464,
    "end_token": 480,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      11440,
      4035,
      290,
      23069,
      1588,
      2239,
      2458,
      460,
      307,
      973,
      329,
      32172,
      13326
    ],
    "label": "ml_signal",
    "reason": "Identifying and storing large step changes can be used for anomaly detection"
  },
  {
    "line": 107,
    "text": "            affected_columns = []",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential IndexError if large_steps is empty",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      5676,
      62,
      28665,
      82,
      796,
      17635
    ],
    "start_token": 480,
    "end_token": 497,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      12901,
      12331,
      611,
      1588,
      62,
      20214,
      318,
      6565
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential IndexError if large_steps is empty"
  },
  {
    "line": 115,
    "text": "                        result_dict[\"col_name\"].append(col)",
    "annotation": "\u2705 Best Practice: Logging informative messages for better traceability",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1255,
      62,
      11600,
      14692,
      4033,
      62,
      3672,
      1,
      4083,
      33295,
      7,
      4033,
      8
    ],
    "start_token": 497,
    "end_token": 533,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5972,
      2667,
      30304,
      6218,
      329,
      1365,
      12854,
      1799
    ],
    "label": "best_practice",
    "reason": "Logging informative messages for better traceability"
  },
  {
    "line": 115,
    "text": "                        result_dict[\"col_name\"].append(col)",
    "annotation": "\u2705 Best Practice: Use of a list to define required columns improves maintainability and readability.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1255,
      62,
      11600,
      14692,
      4033,
      62,
      3672,
      1,
      4083,
      33295,
      7,
      4033,
      8
    ],
    "start_token": 533,
    "end_token": 569,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      257,
      1351,
      284,
      8160,
      2672,
      15180,
      19575,
      5529,
      1799,
      290,
      1100,
      1799,
      13
    ],
    "label": "best_practice",
    "reason": "Use of a list to define required columns improves maintainability and readability."
  },
  {
    "line": 121,
    "text": "        if not result_df.empty:",
    "annotation": "\ud83e\udde0 ML Signal: Iterating over a dictionary of DataFrames is a common pattern in data processing tasks.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      611,
      407,
      1255,
      62,
      7568,
      13,
      28920,
      25
    ],
    "start_token": 569,
    "end_token": 584,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      40806,
      803,
      625,
      257,
      22155,
      286,
      6060,
      35439,
      318,
      257,
      2219,
      3912,
      287,
      1366,
      7587,
      8861,
      13
    ],
    "label": "ml_signal",
    "reason": "Iterating over a dictionary of DataFrames is a common pattern in data processing tasks."
  },
  {
    "line": 123,
    "text": "        else:",
    "annotation": "\u2705 Best Practice: Use of all() for checking presence of required columns is efficient and readable.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2073,
      25
    ],
    "start_token": 584,
    "end_token": 593,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      477,
      3419,
      329,
      10627,
      4931,
      286,
      2672,
      15180,
      318,
      6942,
      290,
      31744,
      13
    ],
    "label": "best_practice",
    "reason": "Use of all() for checking presence of required columns is efficient and readable."
  },
  {
    "line": 125,
    "text": "            return None",
    "annotation": "\u2705 Best Practice: List comprehension for missing columns is concise and efficient.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1441,
      6045
    ],
    "start_token": 593,
    "end_token": 606,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      7343,
      35915,
      329,
      4814,
      15180,
      318,
      35327,
      290,
      6942,
      13
    ],
    "label": "best_practice",
    "reason": "List comprehension for missing columns is concise and efficient."
  },
  {
    "line": 129,
    "text": "        required_columns = [\"open\", \"high\", \"low\", \"close\", \"volume\"]",
    "annotation": "\u2705 Best Practice: Converting results to a DataFrame for structured output is a good practice.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2672,
      62,
      28665,
      82,
      796,
      14631,
      9654,
      1600,
      366,
      8929,
      1600,
      366,
      9319,
      1600,
      366,
      19836,
      1600,
      366,
      29048,
      8973
    ],
    "start_token": 606,
    "end_token": 633,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      35602,
      889,
      2482,
      284,
      257,
      6060,
      19778,
      329,
      20793,
      5072,
      318,
      257,
      922,
      3357,
      13
    ],
    "label": "best_practice",
    "reason": "Converting results to a DataFrame for structured output is a good practice."
  },
  {
    "line": 133,
    "text": "        }",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Logging sensitive information can lead to information leakage.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1782
    ],
    "start_token": 633,
    "end_token": 641,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      5972,
      2667,
      8564,
      1321,
      460,
      1085,
      284,
      1321,
      47988,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Logging sensitive information can lead to information leakage."
  },
  {
    "line": 138,
    "text": "                result_dict[\"missing_col\"] += missing_required_columns",
    "annotation": "\ud83e\udde0 ML Signal: Iterating over a dictionary of DataFrames",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1255,
      62,
      11600,
      14692,
      45688,
      62,
      4033,
      8973,
      15853,
      4814,
      62,
      35827,
      62,
      28665,
      82
    ],
    "start_token": 641,
    "end_token": 671,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      40806,
      803,
      625,
      257,
      22155,
      286,
      6060,
      35439
    ],
    "label": "ml_signal",
    "reason": "Iterating over a dictionary of DataFrames"
  },
  {
    "line": 140,
    "text": "        result_df = pd.DataFrame(result_dict).set_index(\"instruments\")",
    "annotation": "\ud83e\udde0 ML Signal: Checking for specific substrings in filenames",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1255,
      62,
      7568,
      796,
      279,
      67,
      13,
      6601,
      19778,
      7,
      20274,
      62,
      11600,
      737,
      2617,
      62,
      9630,
      7203,
      259,
      2536,
      2886,
      4943
    ],
    "start_token": 671,
    "end_token": 700,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      39432,
      329,
      2176,
      850,
      37336,
      287,
      1226,
      268,
      1047
    ],
    "label": "ml_signal",
    "reason": "Checking for specific substrings in filenames"
  },
  {
    "line": 143,
    "text": "        else:",
    "annotation": "\ud83e\udde0 ML Signal: Checking for the presence of a specific column",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2073,
      25
    ],
    "start_token": 700,
    "end_token": 709,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      39432,
      329,
      262,
      4931,
      286,
      257,
      2176,
      5721
    ],
    "label": "ml_signal",
    "reason": "Checking for the presence of a specific column"
  },
  {
    "line": 146,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Checking if all values in a column are null",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 709,
    "end_token": 709,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      39432,
      611,
      477,
      3815,
      287,
      257,
      5721,
      389,
      9242
    ],
    "label": "ml_signal",
    "reason": "Checking if all values in a column are null"
  },
  {
    "line": 155,
    "text": "            if \"000300\" in filename or \"000903\" in filename or \"000905\" in filename:",
    "annotation": "\ud83e\udde0 ML Signal: Creating a DataFrame from a dictionary",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      611,
      366,
      830,
      6200,
      1,
      287,
      29472,
      393,
      366,
      830,
      24,
      3070,
      1,
      287,
      29472,
      393,
      366,
      830,
      44928,
      1,
      287,
      29472,
      25
    ],
    "start_token": 709,
    "end_token": 743,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      30481,
      257,
      6060,
      19778,
      422,
      257,
      22155
    ],
    "label": "ml_signal",
    "reason": "Creating a DataFrame from a dictionary"
  },
  {
    "line": 160,
    "text": "            if df[\"factor\"].isnull().all():",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential information exposure through logging",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      611,
      47764,
      14692,
      31412,
      1,
      4083,
      271,
      8423,
      22446,
      439,
      33529
    ],
    "start_token": 743,
    "end_token": 765,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      1321,
      7111,
      832,
      18931
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential information exposure through logging"
  },
  {
    "line": 162,
    "text": "                    result_dict[\"missing_factor_data\"].append(True)",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Logical error, duplicate condition check for check_large_step_changes_result",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1255,
      62,
      11600,
      14692,
      45688,
      62,
      31412,
      62,
      7890,
      1,
      4083,
      33295,
      7,
      17821,
      8
    ],
    "start_token": 765,
    "end_token": 799,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      5972,
      605,
      4049,
      11,
      23418,
      4006,
      2198,
      329,
      2198,
      62,
      11664,
      62,
      9662,
      62,
      36653,
      62,
      20274
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Logical error, duplicate condition check for check_large_step_changes_result"
  },
  {
    "line": 171,
    "text": "        else:",
    "annotation": "\u2705 Best Practice: Use logging instead of print for better control over output",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2073,
      25
    ],
    "start_token": 799,
    "end_token": 808,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      18931,
      2427,
      286,
      3601,
      329,
      1365,
      1630,
      625,
      5072
    ],
    "label": "best_practice",
    "reason": "Use logging instead of print for better control over output"
  },
  {
    "line": 175,
    "text": "    def check_data(self):",
    "annotation": "\u2705 Best Practice: Use logging instead of print for better control over output",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      825,
      2198,
      62,
      7890,
      7,
      944,
      2599
    ],
    "start_token": 808,
    "end_token": 818,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      18931,
      2427,
      286,
      3601,
      329,
      1365,
      1630,
      625,
      5072
    ],
    "label": "best_practice",
    "reason": "Use logging instead of print for better control over output"
  },
  {
    "line": 179,
    "text": "        check_missing_factor_result = self.check_missing_factor()",
    "annotation": "\u2705 Best Practice: Use logging instead of print for better control over output",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2198,
      62,
      45688,
      62,
      31412,
      62,
      20274,
      796,
      2116,
      13,
      9122,
      62,
      45688,
      62,
      31412,
      3419
    ],
    "start_token": 818,
    "end_token": 841,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      18931,
      2427,
      286,
      3601,
      329,
      1365,
      1630,
      625,
      5072
    ],
    "label": "best_practice",
    "reason": "Use logging instead of print for better control over output"
  },
  {
    "line": 183,
    "text": "            or check_required_columns_result is not None",
    "annotation": "\u2705 Best Practice: Use logging instead of print for better control over output",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      393,
      2198,
      62,
      35827,
      62,
      28665,
      82,
      62,
      20274,
      318,
      407,
      6045
    ],
    "start_token": 841,
    "end_token": 864,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      18931,
      2427,
      286,
      3601,
      329,
      1365,
      1630,
      625,
      5072
    ],
    "label": "best_practice",
    "reason": "Use logging instead of print for better control over output"
  },
  {
    "line": 183,
    "text": "            or check_required_columns_result is not None",
    "annotation": "\ud83e\udde0 ML Signal: Entry point for command-line interface",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      393,
      2198,
      62,
      35827,
      62,
      28665,
      82,
      62,
      20274,
      318,
      407,
      6045
    ],
    "start_token": 864,
    "end_token": 887,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      21617,
      966,
      329,
      3141,
      12,
      1370,
      7071
    ],
    "label": "ml_signal",
    "reason": "Entry point for command-line interface"
  },
  {
    "line": 183,
    "text": "            or check_required_columns_result is not None",
    "annotation": "\ud83e\udde0 ML Signal: Usage of fire for command-line interface",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      393,
      2198,
      62,
      35827,
      62,
      28665,
      82,
      62,
      20274,
      318,
      407,
      6045
    ],
    "start_token": 887,
    "end_token": 910,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      29566,
      286,
      2046,
      329,
      3141,
      12,
      1370,
      7071
    ],
    "label": "ml_signal",
    "reason": "Usage of fire for command-line interface"
  }
]