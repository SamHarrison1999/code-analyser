[
  {
    "line": 15,
    "text": "",
    "annotation": "\u2705 Best Practice: Alias for better readability and to avoid namespace conflicts",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 0,
    "end_token": 0,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      978,
      4448,
      329,
      1365,
      1100,
      1799,
      290,
      284,
      3368,
      25745,
      12333
    ],
    "label": "best_practice",
    "reason": "Alias for better readability and to avoid namespace conflicts"
  },
  {
    "line": 27,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Class for managing hyperparameter optimization, useful for ML model training",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 0,
    "end_token": 0,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5016,
      329,
      11149,
      8718,
      17143,
      2357,
      23989,
      11,
      4465,
      329,
      10373,
      2746,
      3047
    ],
    "label": "ml_signal",
    "reason": "Class for managing hyperparameter optimization, useful for ML model training"
  },
  {
    "line": 28,
    "text": "import collections",
    "annotation": "\u2705 Best Practice: Docstring provides a clear description of the class and its attributes",
    "confidence": 0.5,
    "tokens": [
      11748,
      17268
    ],
    "start_token": 0,
    "end_token": 2,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      14432,
      8841,
      3769,
      257,
      1598,
      6764,
      286,
      262,
      1398,
      290,
      663,
      12608
    ],
    "label": "best_practice",
    "reason": "Docstring provides a clear description of the class and its attributes"
  },
  {
    "line": 36,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Storing hyperparameter ranges for model optimization",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 2,
    "end_token": 2,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      520,
      3255,
      8718,
      17143,
      2357,
      16069,
      329,
      2746,
      23989
    ],
    "label": "ml_signal",
    "reason": "Storing hyperparameter ranges for model optimization"
  },
  {
    "line": 39,
    "text": "    \"\"\"Manages hyperparameter optimisation using random search for a single GPU.",
    "annotation": "\ud83e\udde0 ML Signal: Using a DataFrame to store results, indicating data analysis",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      37227,
      5124,
      1095,
      8718,
      17143,
      2357,
      6436,
      5612,
      1262,
      4738,
      2989,
      329,
      257,
      2060,
      11362,
      13
    ],
    "start_token": 2,
    "end_token": 21,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      8554,
      257,
      6060,
      19778,
      284,
      3650,
      2482,
      11,
      12739,
      1366,
      3781
    ],
    "label": "ml_signal",
    "reason": "Using a DataFrame to store results, indicating data analysis"
  },
  {
    "line": 41,
    "text": "    Attributes:",
    "annotation": "\ud83e\udde0 ML Signal: Storing fixed parameters for model configuration",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      49213,
      25
    ],
    "start_token": 21,
    "end_token": 26,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      520,
      3255,
      5969,
      10007,
      329,
      2746,
      8398
    ],
    "label": "ml_signal",
    "reason": "Storing fixed parameters for model configuration"
  },
  {
    "line": 43,
    "text": "      results: Dataframe of validation results.",
    "annotation": "\ud83e\udde0 ML Signal: Using a DataFrame to store saved parameters, indicating data analysis",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      2482,
      25,
      6060,
      14535,
      286,
      21201,
      2482,
      13
    ],
    "start_token": 26,
    "end_token": 39,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      8554,
      257,
      6060,
      19778,
      284,
      3650,
      7448,
      10007,
      11,
      12739,
      1366,
      3781
    ],
    "label": "ml_signal",
    "reason": "Using a DataFrame to store saved parameters, indicating data analysis"
  },
  {
    "line": 45,
    "text": "      saved_params: Dataframe of parameters trained.",
    "annotation": "\ud83e\udde0 ML Signal: Initializing best score with infinity for optimization",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      7448,
      62,
      37266,
      25,
      6060,
      14535,
      286,
      10007,
      8776,
      13
    ],
    "start_token": 39,
    "end_token": 54,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      20768,
      2890,
      1266,
      4776,
      351,
      37174,
      329,
      23989
    ],
    "label": "ml_signal",
    "reason": "Initializing best score with infinity for optimization"
  },
  {
    "line": 47,
    "text": "      optimal_name: Key to best configuration.",
    "annotation": "\ud83e\udde0 ML Signal: Storing folder path for model artifacts",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      16586,
      62,
      3672,
      25,
      7383,
      284,
      1266,
      8398,
      13
    ],
    "start_token": 54,
    "end_token": 68,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      520,
      3255,
      9483,
      3108,
      329,
      2746,
      20316
    ],
    "label": "ml_signal",
    "reason": "Storing folder path for model artifacts"
  },
  {
    "line": 51,
    "text": "    def __init__(self, param_ranges, fixed_params, model_folder, override_w_fixed_params=True):",
    "annotation": "\u2705 Best Practice: Ensuring the folder exists before using it",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      825,
      11593,
      15003,
      834,
      7,
      944,
      11,
      5772,
      62,
      81,
      6231,
      11,
      5969,
      62,
      37266,
      11,
      2746,
      62,
      43551,
      11,
      20957,
      62,
      86,
      62,
      34021,
      62,
      37266,
      28,
      17821,
      2599
    ],
    "start_token": 68,
    "end_token": 101,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      48221,
      870,
      262,
      9483,
      7160,
      878,
      1262,
      340
    ],
    "label": "best_practice",
    "reason": "Ensuring the folder exists before using it"
  },
  {
    "line": 52,
    "text": "        \"\"\"Instantiates model.",
    "annotation": "\ud83e\udde0 ML Signal: Flag to determine if fixed parameters should be overridden",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      37227,
      6310,
      17096,
      689,
      2746,
      13
    ],
    "start_token": 101,
    "end_token": 114,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      19762,
      284,
      5004,
      611,
      5969,
      10007,
      815,
      307,
      23170,
      4651
    ],
    "label": "ml_signal",
    "reason": "Flag to determine if fixed parameters should be overridden"
  },
  {
    "line": 51,
    "text": "    def __init__(self, param_ranges, fixed_params, model_folder, override_w_fixed_params=True):",
    "annotation": "\u2705 Best Practice: Consider using logging instead of print for better control over output",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      825,
      11593,
      15003,
      834,
      7,
      944,
      11,
      5772,
      62,
      81,
      6231,
      11,
      5969,
      62,
      37266,
      11,
      2746,
      62,
      43551,
      11,
      20957,
      62,
      86,
      62,
      34021,
      62,
      37266,
      28,
      17821,
      2599
    ],
    "start_token": 114,
    "end_token": 147,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      12642,
      1262,
      18931,
      2427,
      286,
      3601,
      329,
      1365,
      1630,
      625,
      5072
    ],
    "label": "best_practice",
    "reason": "Consider using logging instead of print for better control over output"
  },
  {
    "line": 53,
    "text": "",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): os.path.join can be vulnerable to directory traversal if inputs are not validated",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 147,
    "end_token": 147,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      28686,
      13,
      6978,
      13,
      22179,
      460,
      307,
      8826,
      284,
      8619,
      33038,
      282,
      611,
      17311,
      389,
      407,
      31031
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "os.path.join can be vulnerable to directory traversal if inputs are not validated"
  },
  {
    "line": 55,
    "text": "          param_ranges: Discrete hyperparameter range for random search.",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): os.path.join can be vulnerable to directory traversal if inputs are not validated",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      5772,
      62,
      81,
      6231,
      25,
      8444,
      8374,
      8718,
      17143,
      2357,
      2837,
      329,
      4738,
      2989,
      13
    ],
    "start_token": 147,
    "end_token": 171,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      28686,
      13,
      6978,
      13,
      22179,
      460,
      307,
      8826,
      284,
      8619,
      33038,
      282,
      611,
      17311,
      389,
      407,
      31031
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "os.path.join can be vulnerable to directory traversal if inputs are not validated"
  },
  {
    "line": 57,
    "text": "          model_folder: Folder to store optimisation artifacts.",
    "annotation": "\ud83e\udde0 ML Signal: Checking for the existence of files before processing",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2746,
      62,
      43551,
      25,
      48107,
      284,
      3650,
      6436,
      5612,
      20316,
      13
    ],
    "start_token": 171,
    "end_token": 191,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      39432,
      329,
      262,
      6224,
      286,
      3696,
      878,
      7587
    ],
    "label": "ml_signal",
    "reason": "Checking for the existence of files before processing"
  },
  {
    "line": 59,
    "text": "            parameters with new supplied values.",
    "annotation": "\ud83e\udde0 ML Signal: Loading data from CSV files into DataFrames",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      10007,
      351,
      649,
      14275,
      3815,
      13
    ],
    "start_token": 191,
    "end_token": 208,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      12320,
      1366,
      422,
      44189,
      3696,
      656,
      6060,
      35439
    ],
    "label": "ml_signal",
    "reason": "Loading data from CSV files into DataFrames"
  },
  {
    "line": 61,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Loading data from CSV files into DataFrames",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 208,
    "end_token": 208,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      12320,
      1366,
      422,
      44189,
      3696,
      656,
      6060,
      35439
    ],
    "label": "ml_signal",
    "reason": "Loading data from CSV files into DataFrames"
  },
  {
    "line": 63,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Checking if DataFrame is empty",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 208,
    "end_token": 208,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      39432,
      611,
      6060,
      19778,
      318,
      6565
    ],
    "label": "ml_signal",
    "reason": "Checking if DataFrame is empty"
  },
  {
    "line": 65,
    "text": "        self.results = pd.DataFrame()",
    "annotation": "\ud83e\udde0 ML Signal: Applying a function to a DataFrame column",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      43420,
      796,
      279,
      67,
      13,
      6601,
      19778,
      3419
    ],
    "start_token": 208,
    "end_token": 225,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      2034,
      3157,
      257,
      2163,
      284,
      257,
      6060,
      19778,
      5721
    ],
    "label": "ml_signal",
    "reason": "Applying a function to a DataFrame column"
  },
  {
    "line": 67,
    "text": "        self.saved_params = pd.DataFrame()",
    "annotation": "\ud83e\udde0 ML Signal: Finding the minimum value in a DataFrame column",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      82,
      9586,
      62,
      37266,
      796,
      279,
      67,
      13,
      6601,
      19778,
      3419
    ],
    "start_token": 225,
    "end_token": 245,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      27063,
      262,
      5288,
      1988,
      287,
      257,
      6060,
      19778,
      5721
    ],
    "label": "ml_signal",
    "reason": "Finding the minimum value in a DataFrame column"
  },
  {
    "line": 69,
    "text": "        self.best_score = np.Inf",
    "annotation": "\ud83e\udde0 ML Signal: Boolean indexing in DataFrames",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      13466,
      62,
      26675,
      796,
      45941,
      13,
      18943
    ],
    "start_token": 245,
    "end_token": 261,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      41146,
      6376,
      278,
      287,
      6060,
      35439
    ],
    "label": "ml_signal",
    "reason": "Boolean indexing in DataFrames"
  },
  {
    "line": 71,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Accessing DataFrame index",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 261,
    "end_token": 261,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      8798,
      278,
      6060,
      19778,
      6376
    ],
    "label": "ml_signal",
    "reason": "Accessing DataFrame index"
  },
  {
    "line": 66,
    "text": "        self.fixed_params = fixed_params",
    "annotation": "\ud83e\udde0 ML Signal: Method for retrieving parameters by key, useful for model configuration",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      34021,
      62,
      37266,
      796,
      5969,
      62,
      37266
    ],
    "start_token": 261,
    "end_token": 277,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      11789,
      329,
      50122,
      10007,
      416,
      1994,
      11,
      4465,
      329,
      2746,
      8398
    ],
    "label": "ml_signal",
    "reason": "Method for retrieving parameters by key, useful for model configuration"
  },
  {
    "line": 68,
    "text": "",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential KeyError if 'name' is not in 'params'",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 277,
    "end_token": 277,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      7383,
      12331,
      611,
      705,
      3672,
      6,
      318,
      407,
      287,
      705,
      37266,
      6
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential KeyError if 'name' is not in 'params'"
  },
  {
    "line": 70,
    "text": "        self.optimal_name = \"\"",
    "annotation": "\ud83e\udde0 ML Signal: Conditional logic for overriding parameters, indicating dynamic configuration",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      8738,
      4402,
      62,
      3672,
      796,
      13538
    ],
    "start_token": 277,
    "end_token": 292,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      9724,
      1859,
      9156,
      329,
      44987,
      10007,
      11,
      12739,
      8925,
      8398
    ],
    "label": "ml_signal",
    "reason": "Conditional logic for overriding parameters, indicating dynamic configuration"
  },
  {
    "line": 72,
    "text": "        # Setup",
    "annotation": "\ud83e\udde0 ML Signal: Iterating over fixed parameters, indicating a pattern of parameter management",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1303,
      31122
    ],
    "start_token": 292,
    "end_token": 301,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      40806,
      803,
      625,
      5969,
      10007,
      11,
      12739,
      257,
      3912,
      286,
      11507,
      4542
    ],
    "label": "ml_signal",
    "reason": "Iterating over fixed parameters, indicating a pattern of parameter management"
  },
  {
    "line": 74,
    "text": "        self.hyperparam_folder = model_folder",
    "annotation": "\u2705 Best Practice: Explicitly setting dictionary values for clarity",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      49229,
      17143,
      62,
      43551,
      796,
      2746,
      62,
      43551
    ],
    "start_token": 301,
    "end_token": 318,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      11884,
      306,
      4634,
      22155,
      3815,
      329,
      16287
    ],
    "label": "best_practice",
    "reason": "Explicitly setting dictionary values for clarity"
  },
  {
    "line": 76,
    "text": "",
    "annotation": "\u2705 Best Practice: Returning a dictionary copy to prevent external modifications",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 318,
    "end_token": 318,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      42882,
      257,
      22155,
      4866,
      284,
      2948,
      7097,
      19008
    ],
    "label": "best_practice",
    "reason": "Returning a dictionary copy to prevent external modifications"
  },
  {
    "line": 72,
    "text": "        # Setup",
    "annotation": "\u2705 Best Practice: Method docstring provides a clear description of the method's purpose",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1303,
      31122
    ],
    "start_token": 318,
    "end_token": 327,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      11789,
      2205,
      8841,
      3769,
      257,
      1598,
      6764,
      286,
      262,
      2446,
      338,
      4007
    ],
    "label": "best_practice",
    "reason": "Method docstring provides a clear description of the method's purpose"
  },
  {
    "line": 75,
    "text": "        utils.create_folder_if_not_exist(self.hyperparam_folder)",
    "annotation": "\ud83e\udde0 ML Signal: Accessing a property that likely stores the name of the optimal model or configuration",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      3384,
      4487,
      13,
      17953,
      62,
      43551,
      62,
      361,
      62,
      1662,
      62,
      38476,
      7,
      944,
      13,
      49229,
      17143,
      62,
      43551,
      8
    ],
    "start_token": 327,
    "end_token": 354,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      8798,
      278,
      257,
      3119,
      326,
      1884,
      7000,
      262,
      1438,
      286,
      262,
      16586,
      2746,
      393,
      8398
    ],
    "label": "ml_signal",
    "reason": "Accessing a property that likely stores the name of the optimal model or configuration"
  },
  {
    "line": 77,
    "text": "        self._override_w_fixed_params = override_w_fixed_params",
    "annotation": "\ud83e\udde0 ML Signal: Method call to retrieve parameters based on a model or configuration name",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13557,
      2502,
      13154,
      62,
      86,
      62,
      34021,
      62,
      37266,
      796,
      20957,
      62,
      86,
      62,
      34021,
      62,
      37266
    ],
    "start_token": 354,
    "end_token": 379,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      11789,
      869,
      284,
      19818,
      10007,
      1912,
      319,
      257,
      2746,
      393,
      8398,
      1438
    ],
    "label": "ml_signal",
    "reason": "Method call to retrieve parameters based on a model or configuration name"
  },
  {
    "line": 76,
    "text": "",
    "annotation": "\u26a0\ufe0f SAST Risk (High): Use of shutil.rmtree can delete important files if hyperparam_folder is not validated",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 379,
    "end_token": 379,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      11922,
      2599,
      5765,
      286,
      4423,
      346,
      13,
      81,
      16762,
      631,
      460,
      12233,
      1593,
      3696,
      611,
      8718,
      17143,
      62,
      43551,
      318,
      407,
      31031
    ],
    "label": "sast_risk",
    "severity": "High",
    "reason": "Use of shutil.rmtree can delete important files if hyperparam_folder is not validated"
  },
  {
    "line": 77,
    "text": "        self._override_w_fixed_params = override_w_fixed_params",
    "annotation": "\u2705 Best Practice: Consider adding error handling for file operations",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13557,
      2502,
      13154,
      62,
      86,
      62,
      34021,
      62,
      37266,
      796,
      20957,
      62,
      86,
      62,
      34021,
      62,
      37266
    ],
    "start_token": 379,
    "end_token": 404,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      12642,
      4375,
      4049,
      9041,
      329,
      2393,
      4560
    ],
    "label": "best_practice",
    "reason": "Consider adding error handling for file operations"
  },
  {
    "line": 79,
    "text": "    def load_results(self):",
    "annotation": "\u2705 Best Practice: Ensure the directory is created after clearing",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      825,
      3440,
      62,
      43420,
      7,
      944,
      2599
    ],
    "start_token": 404,
    "end_token": 414,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      48987,
      262,
      8619,
      318,
      2727,
      706,
      17304
    ],
    "label": "best_practice",
    "reason": "Ensure the directory is created after clearing"
  },
  {
    "line": 81,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Resetting results to an empty DataFrame indicates a pattern of iterative experimentation",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 414,
    "end_token": 414,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      30027,
      889,
      2482,
      284,
      281,
      6565,
      6060,
      19778,
      9217,
      257,
      3912,
      286,
      11629,
      876,
      29315
    ],
    "label": "ml_signal",
    "reason": "Resetting results to an empty DataFrame indicates a pattern of iterative experimentation"
  },
  {
    "line": 83,
    "text": "          A boolean indicating if previous results can be loaded.",
    "annotation": "\ud83e\udde0 ML Signal: Resetting saved parameters to an empty DataFrame indicates a pattern of iterative experimentation",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      317,
      25131,
      12739,
      611,
      2180,
      2482,
      460,
      307,
      9639,
      13
    ],
    "start_token": 414,
    "end_token": 433,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      30027,
      889,
      7448,
      10007,
      284,
      281,
      6565,
      6060,
      19778,
      9217,
      257,
      3912,
      286,
      11629,
      876,
      29315
    ],
    "label": "ml_signal",
    "reason": "Resetting saved parameters to an empty DataFrame indicates a pattern of iterative experimentation"
  },
  {
    "line": 84,
    "text": "        \"\"\"",
    "annotation": "\ud83e\udde0 ML Signal: Use of parameter validation logic",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      37227
    ],
    "start_token": 433,
    "end_token": 441,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      11507,
      21201,
      9156
    ],
    "label": "ml_signal",
    "reason": "Use of parameter validation logic"
  },
  {
    "line": 86,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: List comprehension for filtering invalid fields",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 441,
    "end_token": 441,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      7343,
      35915,
      329,
      25431,
      12515,
      7032
    ],
    "label": "ml_signal",
    "reason": "List comprehension for filtering invalid fields"
  },
  {
    "line": 88,
    "text": "        params_file = os.path.join(self.hyperparam_folder, \"params.csv\")",
    "annotation": "\ud83e\udde0 ML Signal: List comprehension for filtering missing fields",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      42287,
      62,
      7753,
      796,
      28686,
      13,
      6978,
      13,
      22179,
      7,
      944,
      13,
      49229,
      17143,
      62,
      43551,
      11,
      366,
      37266,
      13,
      40664,
      4943
    ],
    "start_token": 441,
    "end_token": 470,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      7343,
      35915,
      329,
      25431,
      4814,
      7032
    ],
    "label": "ml_signal",
    "reason": "List comprehension for filtering missing fields"
  },
  {
    "line": 91,
    "text": "            self.results = pd.read_csv(results_file, index_col=0)",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential information disclosure in error message",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      43420,
      796,
      279,
      67,
      13,
      961,
      62,
      40664,
      7,
      43420,
      62,
      7753,
      11,
      6376,
      62,
      4033,
      28,
      15,
      8
    ],
    "start_token": 470,
    "end_token": 502,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      1321,
      13019,
      287,
      4049,
      3275
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential information disclosure in error message"
  },
  {
    "line": 94,
    "text": "            if not self.results.empty:",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential information disclosure in error message",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      611,
      407,
      2116,
      13,
      43420,
      13,
      28920,
      25
    ],
    "start_token": 502,
    "end_token": 521,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      1321,
      13019,
      287,
      4049,
      3275
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential information disclosure in error message"
  },
  {
    "line": 93,
    "text": "",
    "annotation": "\u2705 Best Practice: Ensure params is a dictionary before processing",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 521,
    "end_token": 521,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      48987,
      42287,
      318,
      257,
      22155,
      878,
      7587
    ],
    "label": "best_practice",
    "reason": "Ensure params is a dictionary before processing"
  },
  {
    "line": 95,
    "text": "                self.results.at[\"loss\"] = self.results.loc[\"loss\"].apply(float)",
    "annotation": "\u2705 Best Practice: Use list comprehension for concise and readable code",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      43420,
      13,
      265,
      14692,
      22462,
      8973,
      796,
      2116,
      13,
      43420,
      13,
      17946,
      14692,
      22462,
      1,
      4083,
      39014,
      7,
      22468,
      8
    ],
    "start_token": 521,
    "end_token": 558,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      1351,
      35915,
      329,
      35327,
      290,
      31744,
      2438
    ],
    "label": "best_practice",
    "reason": "Use list comprehension for concise and readable code"
  },
  {
    "line": 97,
    "text": "",
    "annotation": "\u2705 Best Practice: Sorting ensures consistent order for generating unique keys",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 558,
    "end_token": 558,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      311,
      24707,
      19047,
      6414,
      1502,
      329,
      15453,
      3748,
      8251
    ],
    "label": "best_practice",
    "reason": "Sorting ensures consistent order for generating unique keys"
  },
  {
    "line": 98,
    "text": "                is_optimal = self.results.loc[\"loss\"] == self.best_score",
    "annotation": "\ud83e\udde0 ML Signal: Pattern of generating unique keys from dictionary parameters",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      318,
      62,
      8738,
      4402,
      796,
      2116,
      13,
      43420,
      13,
      17946,
      14692,
      22462,
      8973,
      6624,
      2116,
      13,
      13466,
      62,
      26675
    ],
    "start_token": 558,
    "end_token": 592,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      23939,
      286,
      15453,
      3748,
      8251,
      422,
      22155,
      10007
    ],
    "label": "ml_signal",
    "reason": "Pattern of generating unique keys from dictionary parameters"
  },
  {
    "line": 104,
    "text": "",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Lack of type checking for self.results.index could lead to unexpected errors if it's not iterable.",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 592,
    "end_token": 592,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      38289,
      286,
      2099,
      10627,
      329,
      2116,
      13,
      43420,
      13,
      9630,
      714,
      1085,
      284,
      10059,
      8563,
      611,
      340,
      338,
      407,
      11629,
      540,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Lack of type checking for self.results.index could lead to unexpected errors if it's not iterable."
  },
  {
    "line": 107,
    "text": "        params = self.saved_params",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Lack of type checking for self.param_ranges could lead to unexpected errors if it's not a dictionary.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      42287,
      796,
      2116,
      13,
      82,
      9586,
      62,
      37266
    ],
    "start_token": 592,
    "end_token": 607,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      38289,
      286,
      2099,
      10627,
      329,
      2116,
      13,
      17143,
      62,
      81,
      6231,
      714,
      1085,
      284,
      10059,
      8563,
      611,
      340,
      338,
      407,
      257,
      22155,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Lack of type checking for self.param_ranges could lead to unexpected errors if it's not a dictionary."
  },
  {
    "line": 109,
    "text": "        selected_params = dict(params[name])",
    "annotation": "\u2705 Best Practice: Sorting keys ensures consistent order, which can prevent non-deterministic behavior.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      6163,
      62,
      37266,
      796,
      8633,
      7,
      37266,
      58,
      3672,
      12962
    ],
    "start_token": 607,
    "end_token": 624,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      311,
      24707,
      8251,
      19047,
      6414,
      1502,
      11,
      543,
      460,
      2948,
      1729,
      12,
      67,
      2357,
      49228,
      4069,
      13
    ],
    "label": "best_practice",
    "reason": "Sorting keys ensures consistent order, which can prevent non-deterministic behavior."
  },
  {
    "line": 110,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Random choice of hyperparameters indicates a search strategy for model optimization",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 624,
    "end_token": 624,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      14534,
      3572,
      286,
      8718,
      17143,
      7307,
      9217,
      257,
      2989,
      4811,
      329,
      2746,
      23989
    ],
    "label": "ml_signal",
    "reason": "Random choice of hyperparameters indicates a search strategy for model optimization"
  },
  {
    "line": 116,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Iterative approach to hyperparameter tuning",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 624,
    "end_token": 624,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      40806,
      876,
      3164,
      284,
      8718,
      17143,
      2357,
      24549
    ],
    "label": "ml_signal",
    "reason": "Iterative approach to hyperparameter tuning"
  },
  {
    "line": 118,
    "text": "        \"\"\"Returns the optimal hyperparameters thus far.\"\"\"",
    "annotation": "\ud83e\udde0 ML Signal: Naming convention for parameter sets could be used to track experiments",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      37227,
      35561,
      262,
      16586,
      8718,
      17143,
      7307,
      4145,
      1290,
      526,
      15931
    ],
    "start_token": 624,
    "end_token": 642,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      399,
      3723,
      9831,
      329,
      11507,
      5621,
      714,
      307,
      973,
      284,
      2610,
      10256
    ],
    "label": "ml_signal",
    "reason": "Naming convention for parameter sets could be used to track experiments"
  },
  {
    "line": 121,
    "text": "",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Raising a generic ValueError without specific context",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 642,
    "end_token": 642,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      7567,
      1710,
      257,
      14276,
      11052,
      12331,
      1231,
      2176,
      4732
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Raising a generic ValueError without specific context"
  },
  {
    "line": 130,
    "text": "",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Handling of NaN loss values by setting them to infinity",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 642,
    "end_token": 642,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      49500,
      286,
      11013,
      45,
      2994,
      3815,
      416,
      4634,
      606,
      284,
      37174
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Handling of NaN loss values by setting them to infinity"
  },
  {
    "line": 133,
    "text": "",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Directory creation without exception handling",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 642,
    "end_token": 642,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      27387,
      6282,
      1231,
      6631,
      9041
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Directory creation without exception handling"
  },
  {
    "line": 136,
    "text": "        missing_fields = [k for k in valid_fields if k not in params]",
    "annotation": "\ud83e\udde0 ML Signal: Usage of hyperparameters to generate a unique name",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      4814,
      62,
      25747,
      796,
      685,
      74,
      329,
      479,
      287,
      4938,
      62,
      25747,
      611,
      479,
      407,
      287,
      42287,
      60
    ],
    "start_token": 642,
    "end_token": 667,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      29566,
      286,
      8718,
      17143,
      7307,
      284,
      7716,
      257,
      3748,
      1438
    ],
    "label": "ml_signal",
    "reason": "Usage of hyperparameters to generate a unique name"
  },
  {
    "line": 138,
    "text": "        if invalid_fields:",
    "annotation": "\ud83e\udde0 ML Signal: Logic to determine if the current model is optimal",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      611,
      12515,
      62,
      25747,
      25
    ],
    "start_token": 667,
    "end_token": 679,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      30146,
      284,
      5004,
      611,
      262,
      1459,
      2746,
      318,
      16586
    ],
    "label": "ml_signal",
    "reason": "Logic to determine if the current model is optimal"
  },
  {
    "line": 142,
    "text": "",
    "annotation": "\u2705 Best Practice: Informative print statement for debugging",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 679,
    "end_token": 679,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      45255,
      876,
      3601,
      2643,
      329,
      28769
    ],
    "label": "best_practice",
    "reason": "Informative print statement for debugging"
  },
  {
    "line": 144,
    "text": "        \"\"\"Returns a unique key for the supplied set of params.\"\"\"",
    "annotation": "\u26a0\ufe0f SAST Risk (Medium): Potential risk if model.save() does not handle exceptions",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      37227,
      35561,
      257,
      3748,
      1994,
      329,
      262,
      14275,
      900,
      286,
      42287,
      526,
      15931
    ],
    "start_token": 679,
    "end_token": 699,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      31205,
      2599,
      32480,
      2526,
      611,
      2746,
      13,
      21928,
      3419,
      857,
      407,
      5412,
      13269
    ],
    "label": "sast_risk",
    "severity": "Medium",
    "reason": "Potential risk if model.save() does not handle exceptions"
  },
  {
    "line": 146,
    "text": "        self._check_params(params)",
    "annotation": "\ud83e\udde0 ML Signal: Updating the best score and optimal model name",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13557,
      9122,
      62,
      37266,
      7,
      37266,
      8
    ],
    "start_token": 699,
    "end_token": 714,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      3205,
      38734,
      262,
      1266,
      4776,
      290,
      16586,
      2746,
      1438
    ],
    "label": "ml_signal",
    "reason": "Updating the best score and optimal model name"
  },
  {
    "line": 149,
    "text": "        fields.sort()",
    "annotation": "\ud83e\udde0 ML Signal: Storing results and parameters for each model",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      7032,
      13,
      30619,
      3419
    ],
    "start_token": 714,
    "end_token": 725,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      520,
      3255,
      2482,
      290,
      10007,
      329,
      1123,
      2746
    ],
    "label": "ml_signal",
    "reason": "Storing results and parameters for each model"
  },
  {
    "line": 149,
    "text": "        fields.sort()",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): File operations without exception handling",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      7032,
      13,
      30619,
      3419
    ],
    "start_token": 725,
    "end_token": 736,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      9220,
      4560,
      1231,
      6631,
      9041
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "File operations without exception handling"
  },
  {
    "line": 149,
    "text": "        fields.sort()",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): File operations without exception handling",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      7032,
      13,
      30619,
      3419
    ],
    "start_token": 736,
    "end_token": 747,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      9220,
      4560,
      1231,
      6631,
      9041
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "File operations without exception handling"
  },
  {
    "line": 156,
    "text": "        Args:",
    "annotation": "\ud83e\udde0 ML Signal: Return value indicates if the current model is the best",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      943,
      14542,
      25
    ],
    "start_token": 747,
    "end_token": 757,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      8229,
      1988,
      9217,
      611,
      262,
      1459,
      2746,
      318,
      262,
      1266
    ],
    "label": "ml_signal",
    "reason": "Return value indicates if the current model is the best"
  },
  {
    "line": 178,
    "text": "",
    "annotation": "\u2705 Best Practice: Use of np.ceil for calculating max_workers ensures correct rounding up.",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 757,
    "end_token": 757,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      45941,
      13,
      344,
      346,
      329,
      26019,
      3509,
      62,
      22896,
      19047,
      3376,
      38185,
      510,
      13
    ],
    "label": "best_practice",
    "reason": "Use of np.ceil for calculating max_workers ensures correct rounding up."
  },
  {
    "line": 179,
    "text": "        for _ in range(self._max_tries):",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential for ValueError if worker_number is greater than max_workers.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      329,
      4808,
      287,
      2837,
      7,
      944,
      13557,
      9806,
      62,
      83,
      1678,
      2599
    ],
    "start_token": 757,
    "end_token": 776,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      329,
      11052,
      12331,
      611,
      8383,
      62,
      17618,
      318,
      3744,
      621,
      3509,
      62,
      22896,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential for ValueError if worker_number is greater than max_workers."
  },
  {
    "line": 183,
    "text": "            if name not in ranges_to_skip:",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential for ValueError if worker_number is greater than search_iterations.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      611,
      1438,
      407,
      287,
      16069,
      62,
      1462,
      62,
      48267,
      25
    ],
    "start_token": 776,
    "end_token": 797,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      329,
      11052,
      12331,
      611,
      8383,
      62,
      17618,
      318,
      3744,
      621,
      2989,
      62,
      2676,
      602,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential for ValueError if worker_number is greater than search_iterations."
  },
  {
    "line": 192,
    "text": "          parameters: Hyperparameters used in optimisation.",
    "annotation": "\ud83e\udde0 ML Signal: Logging worker creation can be useful for tracking and debugging.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      10007,
      25,
      15079,
      17143,
      7307,
      973,
      287,
      6436,
      5612,
      13
    ],
    "start_token": 797,
    "end_token": 816,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5972,
      2667,
      8383,
      6282,
      460,
      307,
      4465,
      329,
      9646,
      290,
      28769,
      13
    ],
    "label": "ml_signal",
    "reason": "Logging worker creation can be useful for tracking and debugging."
  },
  {
    "line": 194,
    "text": "          model: Model to serialised if required.",
    "annotation": "\u2705 Best Practice: Use of os.path.join for path construction improves cross-platform compatibility.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2746,
      25,
      9104,
      284,
      11389,
      1417,
      611,
      2672,
      13
    ],
    "start_token": 816,
    "end_token": 834,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      28686,
      13,
      6978,
      13,
      22179,
      329,
      3108,
      5103,
      19575,
      3272,
      12,
      24254,
      17764,
      13
    ],
    "label": "best_practice",
    "reason": "Use of os.path.join for path construction improves cross-platform compatibility."
  },
  {
    "line": 196,
    "text": "",
    "annotation": "\u2705 Best Practice: Use of super() to call parent class constructor is a good practice.",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 834,
    "end_token": 834,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      2208,
      3419,
      284,
      869,
      2560,
      1398,
      23772,
      318,
      257,
      922,
      3357,
      13
    ],
    "label": "best_practice",
    "reason": "Use of super() to call parent class constructor is a good practice."
  },
  {
    "line": 198,
    "text": "          Boolean flag indicating if the model is the best seen so far.",
    "annotation": "\u2705 Best Practice: Use of os.path.join for path construction improves cross-platform compatibility.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      41146,
      6056,
      12739,
      611,
      262,
      2746,
      318,
      262,
      1266,
      1775,
      523,
      1290,
      13
    ],
    "start_token": 834,
    "end_token": 856,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      28686,
      13,
      6978,
      13,
      22179,
      329,
      3108,
      5103,
      19575,
      3272,
      12,
      24254,
      17764,
      13
    ],
    "label": "best_practice",
    "reason": "Use of os.path.join for path construction improves cross-platform compatibility."
  },
  {
    "line": 200,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Option to clear serialized parameters indicates flexibility in hyperparameter management.",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 856,
    "end_token": 856,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      16018,
      284,
      1598,
      11389,
      1143,
      10007,
      9217,
      13688,
      287,
      8718,
      17143,
      2357,
      4542,
      13
    ],
    "label": "ml_signal",
    "reason": "Option to clear serialized parameters indicates flexibility in hyperparameter management."
  },
  {
    "line": 202,
    "text": "            loss = np.Inf",
    "annotation": "\ud83e\udde0 ML Signal: Logging regeneration of hyperparameter list can be useful for tracking and debugging.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2994,
      796,
      45941,
      13,
      18943
    ],
    "start_token": 856,
    "end_token": 872,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5972,
      2667,
      27597,
      286,
      8718,
      17143,
      2357,
      1351,
      460,
      307,
      4465,
      329,
      9646,
      290,
      28769,
      13
    ],
    "label": "ml_signal",
    "reason": "Logging regeneration of hyperparameter list can be useful for tracking and debugging."
  },
  {
    "line": 203,
    "text": "",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential risk if os.path.exists and shutil.rmtree are not atomic.",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 872,
    "end_token": 872,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      2526,
      611,
      28686,
      13,
      6978,
      13,
      1069,
      1023,
      290,
      4423,
      346,
      13,
      81,
      16762,
      631,
      389,
      407,
      17226,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential risk if os.path.exists and shutil.rmtree are not atomic."
  },
  {
    "line": 207,
    "text": "        name = self._get_name(parameters)",
    "annotation": "\u2705 Best Practice: Use of utility function to create folder if not exists improves code reuse and readability.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1438,
      796,
      2116,
      13557,
      1136,
      62,
      3672,
      7,
      17143,
      7307,
      8
    ],
    "start_token": 872,
    "end_token": 890,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      10361,
      2163,
      284,
      2251,
      9483,
      611,
      407,
      7160,
      19575,
      2438,
      32349,
      290,
      1100,
      1799,
      13
    ],
    "label": "best_practice",
    "reason": "Use of utility function to create folder if not exists improves code reuse and readability."
  },
  {
    "line": 209,
    "text": "        is_optimal = self.results.empty or loss < self.best_score",
    "annotation": "\u2705 Best Practice: Use of os.path.join for path construction improves cross-platform compatibility.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      318,
      62,
      8738,
      4402,
      796,
      2116,
      13,
      43420,
      13,
      28920,
      393,
      2994,
      1279,
      2116,
      13,
      13466,
      62,
      26675
    ],
    "start_token": 890,
    "end_token": 915,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      28686,
      13,
      6978,
      13,
      22179,
      329,
      3108,
      5103,
      19575,
      3272,
      12,
      24254,
      17764,
      13
    ],
    "label": "best_practice",
    "reason": "Use of os.path.join for path construction improves cross-platform compatibility."
  },
  {
    "line": 215,
    "text": "                print(\"Optimal model found, updating\")",
    "annotation": "\ud83e\udde0 ML Signal: Loading serialized hyperparameters indicates a pattern of data persistence and retrieval.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      3601,
      7203,
      27871,
      4402,
      2746,
      1043,
      11,
      19698,
      4943
    ],
    "start_token": 915,
    "end_token": 939,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      12320,
      11389,
      1143,
      8718,
      17143,
      7307,
      9217,
      257,
      3912,
      286,
      1366,
      30802,
      290,
      45069,
      13
    ],
    "label": "ml_signal",
    "reason": "Loading serialized hyperparameters indicates a pattern of data persistence and retrieval."
  },
  {
    "line": 216,
    "text": "                model.save(self.hyperparam_folder)",
    "annotation": "\ud83e\udde0 ML Signal: Worker-specific search queue suggests distributed processing pattern.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2746,
      13,
      21928,
      7,
      944,
      13,
      49229,
      17143,
      62,
      43551,
      8
    ],
    "start_token": 939,
    "end_token": 965,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      35412,
      12,
      11423,
      2989,
      16834,
      5644,
      9387,
      7587,
      3912,
      13
    ],
    "label": "ml_signal",
    "reason": "Worker-specific search queue suggests distributed processing pattern."
  },
  {
    "line": 205,
    "text": "            os.makedirs(self.hyperparam_folder)",
    "annotation": "\u2705 Best Practice: Method name should follow PEP 8 naming conventions, consider renaming to `is_optimisation_completed`.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      28686,
      13,
      76,
      4335,
      17062,
      7,
      944,
      13,
      49229,
      17143,
      62,
      43551,
      8
    ],
    "start_token": 965,
    "end_token": 989,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      11789,
      1438,
      815,
      1061,
      350,
      8905,
      807,
      19264,
      21396,
      11,
      2074,
      8851,
      3723,
      284,
      4600,
      271,
      62,
      40085,
      5612,
      62,
      785,
      16838,
      44646
    ],
    "label": "best_practice",
    "reason": "Method name should follow PEP 8 naming conventions, consider renaming to `is_optimisation_completed`."
  },
  {
    "line": 207,
    "text": "        name = self._get_name(parameters)",
    "annotation": "\u2705 Best Practice: Simplify return statement to `return not self.worker_search_queue`.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1438,
      796,
      2116,
      13557,
      1136,
      62,
      3672,
      7,
      17143,
      7307,
      8
    ],
    "start_token": 989,
    "end_token": 1007,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      45157,
      1958,
      1441,
      2643,
      284,
      4600,
      7783,
      407,
      2116,
      13,
      28816,
      62,
      12947,
      62,
      36560,
      44646
    ],
    "label": "best_practice",
    "reason": "Simplify return statement to `return not self.worker_search_queue`."
  },
  {
    "line": 209,
    "text": "        is_optimal = self.results.empty or loss < self.best_score",
    "annotation": "\ud83e\udde0 ML Signal: Usage of hyperparameters suggests this is part of a machine learning workflow",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      318,
      62,
      8738,
      4402,
      796,
      2116,
      13,
      43420,
      13,
      28920,
      393,
      2994,
      1279,
      2116,
      13,
      13466,
      62,
      26675
    ],
    "start_token": 1007,
    "end_token": 1032,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      29566,
      286,
      8718,
      17143,
      7307,
      5644,
      428,
      318,
      636,
      286,
      257,
      4572,
      4673,
      30798
    ],
    "label": "ml_signal",
    "reason": "Usage of hyperparameters suggests this is part of a machine learning workflow"
  },
  {
    "line": 211,
    "text": "        # save the first model",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential IndexError if worker_search_queue is empty",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1303,
      3613,
      262,
      717,
      2746
    ],
    "start_token": 1032,
    "end_token": 1044,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      12901,
      12331,
      611,
      8383,
      62,
      12947,
      62,
      36560,
      318,
      6565
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential IndexError if worker_search_queue is empty"
  },
  {
    "line": 213,
    "text": "            # Try saving first, before updating info",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential KeyError if param_name is not in global_hyperparam_df",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1303,
      9993,
      8914,
      717,
      11,
      878,
      19698,
      7508
    ],
    "start_token": 1044,
    "end_token": 1063,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      7383,
      12331,
      611,
      5772,
      62,
      3672,
      318,
      407,
      287,
      3298,
      62,
      49229,
      17143,
      62,
      7568
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential KeyError if param_name is not in global_hyperparam_df"
  },
  {
    "line": 215,
    "text": "                print(\"Optimal model found, updating\")",
    "annotation": "\u2705 Best Practice: Use logging instead of print for better control over output",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      3601,
      7203,
      27871,
      4402,
      2746,
      1043,
      11,
      19698,
      4943
    ],
    "start_token": 1063,
    "end_token": 1087,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      18931,
      2427,
      286,
      3601,
      329,
      1365,
      1630,
      625,
      5072
    ],
    "label": "best_practice",
    "reason": "Use logging instead of print for better control over output"
  },
  {
    "line": 220,
    "text": "        self.results[name] = pd.Series({\"loss\": loss, \"info\": info})",
    "annotation": "\u2705 Best Practice: Use f-strings for better readability and performance",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      43420,
      58,
      3672,
      60,
      796,
      279,
      67,
      13,
      27996,
      7,
      4895,
      22462,
      1298,
      2994,
      11,
      366,
      10951,
      1298,
      7508,
      30072
    ],
    "start_token": 1087,
    "end_token": 1116,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      277,
      12,
      37336,
      329,
      1365,
      1100,
      1799,
      290,
      2854
    ],
    "label": "best_practice",
    "reason": "Use f-strings for better readability and performance"
  },
  {
    "line": 226,
    "text": "        return is_optimal",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential use of unvalidated file path",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1441,
      318,
      62,
      8738,
      4402
    ],
    "start_token": 1116,
    "end_token": 1128,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      779,
      286,
      555,
      12102,
      515,
      2393,
      3108
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential use of unvalidated file path"
  },
  {
    "line": 228,
    "text": "",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential use of unvalidated file path",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 1128,
    "end_token": 1128,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      779,
      286,
      555,
      12102,
      515,
      2393,
      3108
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential use of unvalidated file path"
  },
  {
    "line": 232,
    "text": "    def __init__(",
    "annotation": "\ud83e\udde0 ML Signal: Regenerating data when file is not found",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      825,
      11593,
      15003,
      834,
      7
    ],
    "start_token": 1128,
    "end_token": 1136,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      40721,
      803,
      1366,
      618,
      2393,
      318,
      407,
      1043
    ],
    "label": "ml_signal",
    "reason": "Regenerating data when file is not found"
  },
  {
    "line": 236,
    "text": "        root_model_folder,",
    "annotation": "\ud83e\udde0 ML Signal: Usage of a method to generate hyperparameter combinations, indicating a machine learning workflow.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      6808,
      62,
      19849,
      62,
      43551,
      11
    ],
    "start_token": 1136,
    "end_token": 1149,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      29566,
      286,
      257,
      2446,
      284,
      7716,
      8718,
      17143,
      2357,
      17790,
      11,
      12739,
      257,
      4572,
      4673,
      30798,
      13
    ],
    "label": "ml_signal",
    "reason": "Usage of a method to generate hyperparameter combinations, indicating a machine learning workflow."
  },
  {
    "line": 237,
    "text": "        worker_number,",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Use of print statements for logging, which may not be suitable for production environments.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      8383,
      62,
      17618,
      11
    ],
    "start_token": 1149,
    "end_token": 1160,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      5765,
      286,
      3601,
      6299,
      329,
      18931,
      11,
      543,
      743,
      407,
      307,
      11080,
      329,
      3227,
      12493,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Use of print statements for logging, which may not be suitable for production environments."
  },
  {
    "line": 237,
    "text": "        worker_number,",
    "annotation": "\u2705 Best Practice: Consider using a logging framework instead of print for better control over logging levels and outputs.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      8383,
      62,
      17618,
      11
    ],
    "start_token": 1160,
    "end_token": 1171,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      12642,
      1262,
      257,
      18931,
      9355,
      2427,
      286,
      3601,
      329,
      1365,
      1630,
      625,
      18931,
      2974,
      290,
      23862,
      13
    ],
    "label": "best_practice",
    "reason": "Consider using a logging framework instead of print for better control over logging levels and outputs."
  },
  {
    "line": 245,
    "text": "        hyperparameter combinations and serialises them",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential risk of overwriting existing files without warning.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      8718,
      17143,
      2357,
      17790,
      290,
      11389,
      2696,
      606
    ],
    "start_token": 1171,
    "end_token": 1186,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      2526,
      286,
      6993,
      799,
      278,
      4683,
      3696,
      1231,
      6509,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential risk of overwriting existing files without warning."
  },
  {
    "line": 245,
    "text": "        hyperparameter combinations and serialises them",
    "annotation": "\ud83e\udde0 ML Signal: Returning a DataFrame of hyperparameter combinations, relevant for ML model training or tuning.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      8718,
      17143,
      2357,
      17790,
      290,
      11389,
      2696,
      606
    ],
    "start_token": 1186,
    "end_token": 1201,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      42882,
      257,
      6060,
      19778,
      286,
      8718,
      17143,
      2357,
      17790,
      11,
      5981,
      329,
      10373,
      2746,
      3047,
      393,
      24549,
      13
    ],
    "label": "ml_signal",
    "reason": "Returning a DataFrame of hyperparameter combinations, relevant for ML model training or tuning."
  },
  {
    "line": 249,
    "text": "        resulting in parameter overlaps.",
    "annotation": "\ud83e\udde0 ML Signal: Setting a random seed for reproducibility in experiments",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      7186,
      287,
      11507,
      12893,
      1686,
      13
    ],
    "start_token": 1201,
    "end_token": 1214,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      25700,
      257,
      4738,
      9403,
      329,
      8186,
      66,
      2247,
      287,
      10256
    ],
    "label": "ml_signal",
    "reason": "Setting a random seed for reproducibility in experiments"
  },
  {
    "line": 253,
    "text": "          fixed_params: Fixed model parameters per experiment.",
    "annotation": "\ud83e\udde0 ML Signal: Iterating over a fixed number of search iterations for hyperparameter tuning",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      5969,
      62,
      37266,
      25,
      10832,
      2746,
      10007,
      583,
      6306,
      13
    ],
    "start_token": 1214,
    "end_token": 1233,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      40806,
      803,
      625,
      257,
      5969,
      1271,
      286,
      2989,
      34820,
      329,
      8718,
      17143,
      2357,
      24549
    ],
    "label": "ml_signal",
    "reason": "Iterating over a fixed number of search iterations for hyperparameter tuning"
  },
  {
    "line": 255,
    "text": "          worker_number: Worker index defining which set of hyperparameters to",
    "annotation": "\ud83e\udde0 ML Signal: Using a method to get the next set of hyperparameters",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      8383,
      62,
      17618,
      25,
      35412,
      6376,
      16215,
      543,
      900,
      286,
      8718,
      17143,
      7307,
      284
    ],
    "start_token": 1233,
    "end_token": 1256,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      8554,
      257,
      2446,
      284,
      651,
      262,
      1306,
      900,
      286,
      8718,
      17143,
      7307
    ],
    "label": "ml_signal",
    "reason": "Using a method to get the next set of hyperparameters"
  },
  {
    "line": 257,
    "text": "          search_iterations: Maximum number of random search iterations.",
    "annotation": "\ud83e\udde0 ML Signal: Generating a unique name for each set of hyperparameters",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2989,
      62,
      2676,
      602,
      25,
      22246,
      1271,
      286,
      4738,
      2989,
      34820,
      13
    ],
    "start_token": 1256,
    "end_token": 1277,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      2980,
      803,
      257,
      3748,
      1438,
      329,
      1123,
      900,
      286,
      8718,
      17143,
      7307
    ],
    "label": "ml_signal",
    "reason": "Generating a unique name for each set of hyperparameters"
  },
  {
    "line": 261,
    "text": "        \"\"\"",
    "annotation": "\ud83e\udde0 ML Signal: Creating a DataFrame to store hyperparameter combinations",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      37227
    ],
    "start_token": 1277,
    "end_token": 1285,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      30481,
      257,
      6060,
      19778,
      284,
      3650,
      8718,
      17143,
      2357,
      17790
    ],
    "label": "ml_signal",
    "reason": "Creating a DataFrame to store hyperparameter combinations"
  },
  {
    "line": 261,
    "text": "        \"\"\"",
    "annotation": "\u2705 Best Practice: Call to superclass method ensures proper inheritance behavior",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      37227
    ],
    "start_token": 1285,
    "end_token": 1293,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      4889,
      284,
      2208,
      4871,
      2446,
      19047,
      1774,
      24155,
      4069
    ],
    "label": "best_practice",
    "reason": "Call to superclass method ensures proper inheritance behavior"
  },
  {
    "line": 263,
    "text": "        max_workers = int(np.ceil(search_iterations / num_iterations_per_worker))",
    "annotation": "\ud83e\udde0 ML Signal: Resets internal state, indicating a pattern of state management",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      3509,
      62,
      22896,
      796,
      493,
      7,
      37659,
      13,
      344,
      346,
      7,
      12947,
      62,
      2676,
      602,
      1220,
      997,
      62,
      2676,
      602,
      62,
      525,
      62,
      28816,
      4008
    ],
    "start_token": 1293,
    "end_token": 1325,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      1874,
      1039,
      5387,
      1181,
      11,
      12739,
      257,
      3912,
      286,
      1181,
      4542
    ],
    "label": "ml_signal",
    "reason": "Resets internal state, indicating a pattern of state management"
  },
  {
    "line": 268,
    "text": "                \"Worker number ({}) cannot be larger than the total number of workers!\".format(max_workers)",
    "annotation": "\u2705 Best Practice: Use of superclass method to ensure proper inheritance and method extension",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      366,
      12468,
      263,
      1271,
      37913,
      30072,
      2314,
      307,
      4025,
      621,
      262,
      2472,
      1271,
      286,
      3259,
      48220,
      18982,
      7,
      9806,
      62,
      22896,
      8
    ],
    "start_token": 1325,
    "end_token": 1362,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      2208,
      4871,
      2446,
      284,
      4155,
      1774,
      24155,
      290,
      2446,
      7552
    ],
    "label": "best_practice",
    "reason": "Use of superclass method to ensure proper inheritance and method extension"
  },
  {
    "line": 271,
    "text": "            raise ValueError(",
    "annotation": "\ud83e\udde0 ML Signal: Conditional logic based on the success of a method call",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      5298,
      11052,
      12331,
      7
    ],
    "start_token": 1362,
    "end_token": 1377,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      9724,
      1859,
      9156,
      1912,
      319,
      262,
      1943,
      286,
      257,
      2446,
      869
    ],
    "label": "ml_signal",
    "reason": "Conditional logic based on the success of a method call"
  },
  {
    "line": 273,
    "text": "                    worker_number, search_iterations",
    "annotation": "\ud83e\udde0 ML Signal: Return of a boolean value indicating success or failure",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      8383,
      62,
      17618,
      11,
      2989,
      62,
      2676,
      602
    ],
    "start_token": 1377,
    "end_token": 1404,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      8229,
      286,
      257,
      25131,
      1988,
      12739,
      1943,
      393,
      5287
    ],
    "label": "ml_signal",
    "reason": "Return of a boolean value indicating success or failure"
  },
  {
    "line": 277,
    "text": "        print(\"*** Creating hyperparameter manager for worker {} ***\".format(worker_number))",
    "annotation": "\ud83e\udde0 ML Signal: Use of a DataFrame to manage hyperparameter combinations",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      3601,
      7203,
      8162,
      30481,
      8718,
      17143,
      2357,
      4706,
      329,
      8383,
      23884,
      17202,
      1911,
      18982,
      7,
      28816,
      62,
      17618,
      4008
    ],
    "start_token": 1404,
    "end_token": 1430,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      257,
      6060,
      19778,
      284,
      6687,
      8718,
      17143,
      2357,
      17790
    ],
    "label": "ml_signal",
    "reason": "Use of a DataFrame to manage hyperparameter combinations"
  },
  {
    "line": 279,
    "text": "        hyperparam_folder = os.path.join(root_model_folder, str(worker_number))",
    "annotation": "\ud83e\udde0 ML Signal: Filtering DataFrame based on worker number",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      8718,
      17143,
      62,
      43551,
      796,
      28686,
      13,
      6978,
      13,
      22179,
      7,
      15763,
      62,
      19849,
      62,
      43551,
      11,
      965,
      7,
      28816,
      62,
      17618,
      4008
    ],
    "start_token": 1430,
    "end_token": 1460,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      7066,
      20212,
      6060,
      19778,
      1912,
      319,
      8383,
      1271
    ],
    "label": "ml_signal",
    "reason": "Filtering DataFrame based on worker number"
  },
  {
    "line": 281,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Identifying unprocessed hyperparameter combinations",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 1460,
    "end_token": 1460,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      11440,
      4035,
      555,
      14681,
      276,
      8718,
      17143,
      2357,
      17790
    ],
    "label": "ml_signal",
    "reason": "Identifying unprocessed hyperparameter combinations"
  },
  {
    "line": 282,
    "text": "        serialised_ranges_folder = os.path.join(root_model_folder, \"hyperparams\")",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential for large memory usage with Deque if left_overs is large",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      11389,
      1417,
      62,
      81,
      6231,
      62,
      43551,
      796,
      28686,
      13,
      6978,
      13,
      22179,
      7,
      15763,
      62,
      19849,
      62,
      43551,
      11,
      366,
      49229,
      37266,
      4943
    ],
    "start_token": 1460,
    "end_token": 1491,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      329,
      1588,
      4088,
      8748,
      351,
      1024,
      4188,
      611,
      1364,
      62,
      13801,
      318,
      1588
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential for large memory usage with Deque if left_overs is large"
  },
  {
    "line": 288,
    "text": "        utils.create_folder_if_not_exist(serialised_ranges_folder)",
    "annotation": "\u2705 Best Practice: Use of DataFrame.copy() to avoid modifying the original DataFrame",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      3384,
      4487,
      13,
      17953,
      62,
      43551,
      62,
      361,
      62,
      1662,
      62,
      38476,
      7,
      46911,
      1417,
      62,
      81,
      6231,
      62,
      43551,
      8
    ],
    "start_token": 1491,
    "end_token": 1519,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      6060,
      19778,
      13,
      30073,
      3419,
      284,
      3368,
      30620,
      262,
      2656,
      6060,
      19778
    ],
    "label": "best_practice",
    "reason": "Use of DataFrame.copy() to avoid modifying the original DataFrame"
  },
  {
    "line": 290,
    "text": "        self.serialised_ranges_path = os.path.join(serialised_ranges_folder, \"ranges_{}.csv\".format(search_iterations))",
    "annotation": "\ud83e\udde0 ML Signal: Use of total_search_iterations could indicate a pattern in distributed computing",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      46911,
      1417,
      62,
      81,
      6231,
      62,
      6978,
      796,
      28686,
      13,
      6978,
      13,
      22179,
      7,
      46911,
      1417,
      62,
      81,
      6231,
      62,
      43551,
      11,
      366,
      81,
      6231,
      23330,
      27422,
      40664,
      1911,
      18982,
      7,
      12947,
      62,
      2676,
      602,
      4008
    ],
    "start_token": 1519,
    "end_token": 1564,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      2472,
      62,
      12947,
      62,
      2676,
      602,
      714,
      7603,
      257,
      3912,
      287,
      9387,
      14492
    ],
    "label": "ml_signal",
    "reason": "Use of total_search_iterations could indicate a pattern in distributed computing"
  },
  {
    "line": 292,
    "text": "        self.worker_num = worker_number",
    "annotation": "\ud83e\udde0 ML Signal: Use of num_iterations_per_worker could indicate a pattern in workload distribution",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      28816,
      62,
      22510,
      796,
      8383,
      62,
      17618
    ],
    "start_token": 1564,
    "end_token": 1580,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      997,
      62,
      2676,
      602,
      62,
      525,
      62,
      28816,
      714,
      7603,
      257,
      3912,
      287,
      26211,
      6082
    ],
    "label": "ml_signal",
    "reason": "Use of num_iterations_per_worker could indicate a pattern in workload distribution"
  },
  {
    "line": 294,
    "text": "        self.num_iterations_per_worker = num_iterations_per_worker",
    "annotation": "\u2705 Best Practice: Use of np.ceil to ensure all iterations are covered by workers",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      22510,
      62,
      2676,
      602,
      62,
      525,
      62,
      28816,
      796,
      997,
      62,
      2676,
      602,
      62,
      525,
      62,
      28816
    ],
    "start_token": 1580,
    "end_token": 1606,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      45941,
      13,
      344,
      346,
      284,
      4155,
      477,
      34820,
      389,
      5017,
      416,
      3259
    ],
    "label": "best_practice",
    "reason": "Use of np.ceil to ensure all iterations are covered by workers"
  },
  {
    "line": 294,
    "text": "        self.num_iterations_per_worker = num_iterations_per_worker",
    "annotation": "\u2705 Best Practice: Use of np.concatenate and np.tile for efficient array creation",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      22510,
      62,
      2676,
      602,
      62,
      525,
      62,
      28816,
      796,
      997,
      62,
      2676,
      602,
      62,
      525,
      62,
      28816
    ],
    "start_token": 1606,
    "end_token": 1632,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      45941,
      13,
      1102,
      9246,
      268,
      378,
      290,
      45941,
      13,
      40927,
      329,
      6942,
      7177,
      6282
    ],
    "label": "best_practice",
    "reason": "Use of np.concatenate and np.tile for efficient array creation"
  },
  {
    "line": 294,
    "text": "        self.num_iterations_per_worker = num_iterations_per_worker",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential IndexError if len(output) > len(worker_idx)",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2116,
      13,
      22510,
      62,
      2676,
      602,
      62,
      525,
      62,
      28816,
      796,
      997,
      62,
      2676,
      602,
      62,
      525,
      62,
      28816
    ],
    "start_token": 1632,
    "end_token": 1658,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      12901,
      12331,
      611,
      18896,
      7,
      22915,
      8,
      1875,
      18896,
      7,
      28816,
      62,
      312,
      87,
      8
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential IndexError if len(output) > len(worker_idx)"
  }
]