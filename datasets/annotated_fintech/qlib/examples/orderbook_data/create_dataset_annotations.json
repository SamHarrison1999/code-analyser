[
  {
    "line": 25,
    "text": "from pandas import DataFrame",
    "annotation": "\u2705 Best Practice: Use of Path from pathlib for file path operations improves code portability and readability.",
    "confidence": 1.0,
    "tokens": [
      6738,
      19798,
      292,
      1330,
      6060,
      19778
    ],
    "start_token": 0,
    "end_token": 6,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      10644,
      422,
      3108,
      8019,
      329,
      2393,
      3108,
      4560,
      19575,
      2438,
      2493,
      1799,
      290,
      1100,
      1799,
      13
    ],
    "label": "best_practice",
    "reason": "Use of Path from pathlib for file path operations improves code portability and readability."
  },
  {
    "line": 27,
    "text": "from pymongo.mongo_client import MongoClient",
    "annotation": "\ud83e\udde0 ML Signal: Use of parallel processing with joblib, indicating performance optimization.",
    "confidence": 0.5,
    "tokens": [
      6738,
      279,
      4948,
      25162,
      13,
      76,
      25162,
      62,
      16366,
      1330,
      42591,
      11792
    ],
    "start_token": 6,
    "end_token": 18,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      10730,
      7587,
      351,
      1693,
      8019,
      11,
      12739,
      2854,
      23989,
      13
    ],
    "label": "ml_signal",
    "reason": "Use of parallel processing with joblib, indicating performance optimization."
  },
  {
    "line": 29,
    "text": "DIRNAME = Path(__file__).absolute().resolve().parent",
    "annotation": "\u2705 Best Practice: Use of Path for constructing file paths.",
    "confidence": 1.0,
    "tokens": [
      34720,
      20608,
      796,
      10644,
      7,
      834,
      7753,
      834,
      737,
      48546,
      22446,
      411,
      6442,
      22446,
      8000
    ],
    "start_token": 18,
    "end_token": 33,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      10644,
      329,
      30580,
      2393,
      13532,
      13
    ],
    "label": "best_practice",
    "reason": "Use of Path for constructing file paths."
  },
  {
    "line": 31,
    "text": "# CONFIG",
    "annotation": "\u2705 Best Practice: Use of Path for constructing file paths.",
    "confidence": 1.0,
    "tokens": [
      2,
      25626
    ],
    "start_token": 33,
    "end_token": 35,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      10644,
      329,
      30580,
      2393,
      13532,
      13
    ],
    "label": "best_practice",
    "reason": "Use of Path for constructing file paths."
  },
  {
    "line": 33,
    "text": "LOG_FILE_PATH = DIRNAME / \"log_file\"",
    "annotation": "\u2705 Best Practice: Use of Path for constructing file paths.",
    "confidence": 1.0,
    "tokens": [
      25294,
      62,
      25664,
      62,
      34219,
      796,
      360,
      4663,
      20608,
      1220,
      366,
      6404,
      62,
      7753,
      1
    ],
    "start_token": 35,
    "end_token": 50,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      10644,
      329,
      30580,
      2393,
      13532,
      13
    ],
    "label": "best_practice",
    "reason": "Use of Path for constructing file paths."
  },
  {
    "line": 35,
    "text": "DATABASE_PATH = DIRNAME / \"orig_data\"",
    "annotation": "\u2705 Best Practice: Use of Path for constructing file paths.",
    "confidence": 1.0,
    "tokens": [
      35,
      1404,
      6242,
      11159,
      62,
      34219,
      796,
      360,
      4663,
      20608,
      1220,
      366,
      11612,
      62,
      7890,
      1
    ],
    "start_token": 50,
    "end_token": 66,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      10644,
      329,
      30580,
      2393,
      13532,
      13
    ],
    "label": "best_practice",
    "reason": "Use of Path for constructing file paths."
  },
  {
    "line": 37,
    "text": "DATA_FINISH_INFO_PATH = DIRNAME / \"./data_finish_info\"",
    "annotation": "\u2705 Best Practice: Use of Path for constructing file paths.",
    "confidence": 1.0,
    "tokens": [
      26947,
      62,
      20032,
      18422,
      62,
      10778,
      62,
      34219,
      796,
      360,
      4663,
      20608,
      1220,
      366,
      19571,
      7890,
      62,
      15643,
      680,
      62,
      10951,
      1
    ],
    "start_token": 66,
    "end_token": 88,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      10644,
      329,
      30580,
      2393,
      13532,
      13
    ],
    "label": "best_practice",
    "reason": "Use of Path for constructing file paths."
  },
  {
    "line": 38,
    "text": "DOC_TYPE = [\"Tick\", \"Order\", \"OrderQueue\", \"Transaction\", \"Day\", \"Minute\"]",
    "annotation": "\ud83e\udde0 ML Signal: Use of a list to define document types, indicating structured data handling.",
    "confidence": 0.5,
    "tokens": [
      38715,
      62,
      25216,
      796,
      14631,
      51,
      624,
      1600,
      366,
      18743,
      1600,
      366,
      18743,
      34991,
      1600,
      366,
      48720,
      1600,
      366,
      12393,
      1600,
      366,
      9452,
      1133,
      8973
    ],
    "start_token": 88,
    "end_token": 113,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      257,
      1351,
      284,
      8160,
      3188,
      3858,
      11,
      12739,
      20793,
      1366,
      9041,
      13
    ],
    "label": "ml_signal",
    "reason": "Use of a list to define document types, indicating structured data handling."
  },
  {
    "line": 41,
    "text": "ARCTIC_SRV = \"127.0.0.1\"",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Large constant value for MAX_SIZE could lead to excessive memory usage.",
    "confidence": 0.5,
    "tokens": [
      1503,
      4177,
      2149,
      62,
      12562,
      53,
      796,
      366,
      16799,
      13,
      15,
      13,
      15,
      13,
      16,
      1
    ],
    "start_token": 113,
    "end_token": 129,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      13601,
      6937,
      1988,
      329,
      25882,
      62,
      33489,
      714,
      1085,
      284,
      13181,
      4088,
      8748,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Large constant value for MAX_SIZE could lead to excessive memory usage."
  },
  {
    "line": 43,
    "text": "",
    "annotation": "\u2705 Best Practice: Use of Path for constructing file paths.",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 129,
    "end_token": 129,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      10644,
      329,
      30580,
      2393,
      13532,
      13
    ],
    "label": "best_practice",
    "reason": "Use of Path for constructing file paths."
  },
  {
    "line": 45,
    "text": "    if str.lower(doc_type) == str.lower(\"Tick\"):",
    "annotation": "\u26a0\ufe0f SAST Risk (Medium): Hardcoded IP address for ARCTIC_SRV could lead to security vulnerabilities.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      611,
      965,
      13,
      21037,
      7,
      15390,
      62,
      4906,
      8,
      6624,
      965,
      13,
      21037,
      7203,
      51,
      624,
      1,
      2599
    ],
    "start_token": 129,
    "end_token": 150,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      31205,
      2599,
      6912,
      40976,
      6101,
      2209,
      329,
      5923,
      4177,
      2149,
      62,
      12562,
      53,
      714,
      1085,
      284,
      2324,
      23805,
      13
    ],
    "label": "sast_risk",
    "severity": "Medium",
    "reason": "Hardcoded IP address for ARCTIC_SRV could lead to security vulnerabilities."
  },
  {
    "line": 36,
    "text": "DATA_INFO_PATH = DIRNAME / \"data_info\"",
    "annotation": "\u2705 Best Practice: Use of str.lower() ensures case-insensitive comparison",
    "confidence": 1.0,
    "tokens": [
      26947,
      62,
      10778,
      62,
      34219,
      796,
      360,
      4663,
      20608,
      1220,
      366,
      7890,
      62,
      10951,
      1
    ],
    "start_token": 150,
    "end_token": 165,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      965,
      13,
      21037,
      3419,
      19047,
      1339,
      12,
      1040,
      18464,
      7208
    ],
    "label": "best_practice",
    "reason": "Use of str.lower() ensures case-insensitive comparison"
  },
  {
    "line": 38,
    "text": "DOC_TYPE = [\"Tick\", \"Order\", \"OrderQueue\", \"Transaction\", \"Day\", \"Minute\"]",
    "annotation": "\u2705 Best Practice: Use of str.lower() ensures case-insensitive comparison",
    "confidence": 1.0,
    "tokens": [
      38715,
      62,
      25216,
      796,
      14631,
      51,
      624,
      1600,
      366,
      18743,
      1600,
      366,
      18743,
      34991,
      1600,
      366,
      48720,
      1600,
      366,
      12393,
      1600,
      366,
      9452,
      1133,
      8973
    ],
    "start_token": 165,
    "end_token": 190,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      965,
      13,
      21037,
      3419,
      19047,
      1339,
      12,
      1040,
      18464,
      7208
    ],
    "label": "best_practice",
    "reason": "Use of str.lower() ensures case-insensitive comparison"
  },
  {
    "line": 42,
    "text": "",
    "annotation": "\u2705 Best Practice: Use of str.lower() ensures consistent output format",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 190,
    "end_token": 190,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      965,
      13,
      21037,
      3419,
      19047,
      6414,
      5072,
      5794
    ],
    "label": "best_practice",
    "reason": "Use of str.lower() ensures consistent output format"
  },
  {
    "line": 41,
    "text": "ARCTIC_SRV = \"127.0.0.1\"",
    "annotation": "\ud83e\udde0 ML Signal: Function checks stock codes based on exchange place",
    "confidence": 0.5,
    "tokens": [
      1503,
      4177,
      2149,
      62,
      12562,
      53,
      796,
      366,
      16799,
      13,
      15,
      13,
      15,
      13,
      16,
      1
    ],
    "start_token": 190,
    "end_token": 206,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      15553,
      8794,
      4283,
      12416,
      1912,
      319,
      5163,
      1295
    ],
    "label": "ml_signal",
    "reason": "Function checks stock codes based on exchange place"
  },
  {
    "line": 43,
    "text": "",
    "annotation": "\u2705 Best Practice: Use of clear conditional checks for readability",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 206,
    "end_token": 206,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      1598,
      26340,
      8794,
      329,
      1100,
      1799
    ],
    "label": "best_practice",
    "reason": "Use of clear conditional checks for readability"
  },
  {
    "line": 46,
    "text": "        return \"ticks\"",
    "annotation": "\u2705 Best Practice: Use of clear conditional checks for readability",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1441,
      366,
      83,
      3378,
      1
    ],
    "start_token": 206,
    "end_token": 218,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      1598,
      26340,
      8794,
      329,
      1100,
      1799
    ],
    "label": "best_practice",
    "reason": "Use of clear conditional checks for readability"
  },
  {
    "line": 47,
    "text": "    else:",
    "annotation": "\u2705 Best Practice: Consider importing necessary modules at the beginning of the file for better readability and maintainability.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      2073,
      25
    ],
    "start_token": 218,
    "end_token": 223,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      12642,
      33332,
      3306,
      13103,
      379,
      262,
      3726,
      286,
      262,
      2393,
      329,
      1365,
      1100,
      1799,
      290,
      5529,
      1799,
      13
    ],
    "label": "best_practice",
    "reason": "Consider importing necessary modules at the beginning of the file for better readability and maintainability."
  },
  {
    "line": 55,
    "text": "        return False",
    "annotation": "\u2705 Best Practice: Use descriptive variable names for better readability.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1441,
      10352
    ],
    "start_token": 223,
    "end_token": 232,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      35644,
      7885,
      3891,
      329,
      1365,
      1100,
      1799,
      13
    ],
    "label": "best_practice",
    "reason": "Use descriptive variable names for better readability."
  },
  {
    "line": 57,
    "text": "",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential logic flaw if exchange_place is not \"SH\" or \"SZ\".",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 232,
    "end_token": 232,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      9156,
      11804,
      611,
      5163,
      62,
      5372,
      318,
      407,
      366,
      9693,
      1,
      393,
      366,
      50,
      57,
      1911
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential logic flaw if exchange_place is not \"SH\" or \"SZ\"."
  },
  {
    "line": 60,
    "text": "    \"\"\"",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential logic flaw if exchange_place is not \"SH\" or \"SZ\".",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      37227
    ],
    "start_token": 232,
    "end_token": 236,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      9156,
      11804,
      611,
      5163,
      62,
      5372,
      318,
      407,
      366,
      9693,
      1,
      393,
      366,
      50,
      57,
      1911
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential logic flaw if exchange_place is not \"SH\" or \"SZ\"."
  },
  {
    "line": 63,
    "text": "    filepath: the path of csv",
    "annotation": "\ud83e\udde0 ML Signal: Reading CSV files is a common operation that can be used to identify data processing patterns.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      2393,
      6978,
      25,
      262,
      3108,
      286,
      269,
      21370
    ],
    "start_token": 236,
    "end_token": 247,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      11725,
      44189,
      3696,
      318,
      257,
      2219,
      4905,
      326,
      460,
      307,
      973,
      284,
      5911,
      1366,
      7587,
      7572,
      13
    ],
    "label": "ml_signal",
    "reason": "Reading CSV files is a common operation that can be used to identify data processing patterns."
  },
  {
    "line": 65,
    "text": "    \"\"\"",
    "annotation": "\u2705 Best Practice: Avoid redundant code by reusing the 'code' variable instead of reassigning it.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      37227
    ],
    "start_token": 247,
    "end_token": 251,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      24390,
      30806,
      2438,
      416,
      302,
      3500,
      262,
      705,
      8189,
      6,
      7885,
      2427,
      286,
      12719,
      38944,
      340,
      13
    ],
    "label": "best_practice",
    "reason": "Avoid redundant code by reusing the 'code' variable instead of reassigning it."
  },
  {
    "line": 64,
    "text": "    arc: arclink created by a process",
    "annotation": "\u2705 Best Practice: Use consistent string formatting for better readability and maintainability",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      10389,
      25,
      610,
      565,
      676,
      2727,
      416,
      257,
      1429
    ],
    "start_token": 251,
    "end_token": 263,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      6414,
      4731,
      33313,
      329,
      1365,
      1100,
      1799,
      290,
      5529,
      1799
    ],
    "label": "best_practice",
    "reason": "Use consistent string formatting for better readability and maintainability"
  },
  {
    "line": 73,
    "text": "    code = os.path.split(filepath)[-1].split(\".csv\")[0]",
    "annotation": "\ud83e\udde0 ML Signal: Usage of pandas DataFrame and list operations",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      2438,
      796,
      28686,
      13,
      6978,
      13,
      35312,
      7,
      7753,
      6978,
      38381,
      12,
      16,
      4083,
      35312,
      7,
      1911,
      40664,
      4943,
      58,
      15,
      60
    ],
    "start_token": 263,
    "end_token": 288,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      29566,
      286,
      19798,
      292,
      6060,
      19778,
      290,
      1351,
      4560
    ],
    "label": "ml_signal",
    "reason": "Usage of pandas DataFrame and list operations"
  },
  {
    "line": 78,
    "text": "        if hms[0] == \"1\":  # >=10,",
    "annotation": "\ud83e\udde0 ML Signal: Exception handling pattern",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      611,
      289,
      907,
      58,
      15,
      60,
      6624,
      366,
      16,
      1298,
      220,
      1303,
      18189,
      940,
      11
    ],
    "start_token": 288,
    "end_token": 310,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      35528,
      9041,
      3912
    ],
    "label": "ml_signal",
    "reason": "Exception handling pattern"
  },
  {
    "line": 83,
    "text": "            return (",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential information disclosure through error messages",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1441,
      357
    ],
    "start_token": 310,
    "end_token": 323,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      1321,
      13019,
      832,
      4049,
      6218
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential information disclosure through error messages"
  },
  {
    "line": 87,
    "text": "    ## Discard the entire row if wrong data timestamp encoutered.",
    "annotation": "\ud83e\udde0 ML Signal: Usage of pandas DatetimeIndex",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      22492,
      8444,
      446,
      262,
      2104,
      5752,
      611,
      2642,
      1366,
      41033,
      2207,
      448,
      1068,
      13
    ],
    "start_token": 323,
    "end_token": 340,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      29566,
      286,
      19798,
      292,
      16092,
      8079,
      15732
    ],
    "label": "ml_signal",
    "reason": "Usage of pandas DatetimeIndex"
  },
  {
    "line": 90,
    "text": "    for index, t in enumerate(timestamp):",
    "annotation": "\u2705 Best Practice: Dropping unused columns to optimize DataFrame size",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      329,
      6376,
      11,
      256,
      287,
      27056,
      378,
      7,
      16514,
      27823,
      2599
    ],
    "start_token": 340,
    "end_token": 354,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      21045,
      2105,
      21958,
      15180,
      284,
      27183,
      6060,
      19778,
      2546
    ],
    "label": "best_practice",
    "reason": "Dropping unused columns to optimize DataFrame size"
  },
  {
    "line": 96,
    "text": "    # to-do: writting to logs",
    "annotation": "\ud83e\udde0 ML Signal: Iterating over DataFrame rows",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      1303,
      284,
      12,
      4598,
      25,
      1319,
      2535,
      284,
      17259
    ],
    "start_token": 354,
    "end_token": 366,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      40806,
      803,
      625,
      6060,
      19778,
      15274
    ],
    "label": "ml_signal",
    "reason": "Iterating over DataFrame rows"
  },
  {
    "line": 102,
    "text": "    timestamp = list(zip(list(df[\"date\"]), list(df[\"time\"])))  ## The cleaned timestamp",
    "annotation": "\ud83e\udde0 ML Signal: Function call pattern",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      41033,
      796,
      1351,
      7,
      13344,
      7,
      4868,
      7,
      7568,
      14692,
      4475,
      8973,
      828,
      1351,
      7,
      7568,
      14692,
      2435,
      8973,
      22305,
      220,
      22492,
      383,
      20750,
      41033
    ],
    "start_token": 366,
    "end_token": 394,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      15553,
      869,
      3912
    ],
    "label": "ml_signal",
    "reason": "Function call pattern"
  },
  {
    "line": 107,
    "text": "    df = df.drop(columns=[\"date\", \"time\", \"name\", \"code\", \"wind_code\"])",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential information disclosure through print statements",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      47764,
      796,
      47764,
      13,
      14781,
      7,
      28665,
      82,
      28,
      14692,
      4475,
      1600,
      366,
      2435,
      1600,
      366,
      3672,
      1600,
      366,
      8189,
      1600,
      366,
      7972,
      62,
      8189,
      8973,
      8
    ],
    "start_token": 394,
    "end_token": 424,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      1321,
      13019,
      832,
      3601,
      6299
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential information disclosure through print statements"
  },
  {
    "line": 111,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Conditional logic for updating or writing data",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 424,
    "end_token": 424,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      9724,
      1859,
      9156,
      329,
      19698,
      393,
      3597,
      1366
    ],
    "label": "ml_signal",
    "reason": "Conditional logic for updating or writing data"
  },
  {
    "line": 114,
    "text": "        df[\"ab\"] = [",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential information disclosure through print statements",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      47764,
      14692,
      397,
      8973,
      796,
      685
    ],
    "start_token": 424,
    "end_token": 437,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      1321,
      13019,
      832,
      3601,
      6299
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential information disclosure through print statements"
  },
  {
    "line": 107,
    "text": "    df = df.drop(columns=[\"date\", \"time\", \"name\", \"code\", \"wind_code\"])",
    "annotation": "\u26a0\ufe0f SAST Risk (Medium): Missing import statements for 'os', 'traceback', and 'Arctic' can lead to runtime errors.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      47764,
      796,
      47764,
      13,
      14781,
      7,
      28665,
      82,
      28,
      14692,
      4475,
      1600,
      366,
      2435,
      1600,
      366,
      3672,
      1600,
      366,
      8189,
      1600,
      366,
      7972,
      62,
      8189,
      8973,
      8
    ],
    "start_token": 437,
    "end_token": 467,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      31205,
      2599,
      25639,
      1330,
      6299,
      329,
      705,
      418,
      3256,
      705,
      40546,
      1891,
      3256,
      290,
      705,
      3163,
      11048,
      6,
      460,
      1085,
      284,
      19124,
      8563,
      13
    ],
    "label": "sast_risk",
    "severity": "Medium",
    "reason": "Missing import statements for 'os', 'traceback', and 'Arctic' can lead to runtime errors."
  },
  {
    "line": 109,
    "text": "    df[\"date\"] = pd.to_datetime(pd_timestamp)",
    "annotation": "\ud83e\udde0 ML Signal: Using process ID (PID) to create unique log file names.",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      47764,
      14692,
      4475,
      8973,
      796,
      279,
      67,
      13,
      1462,
      62,
      19608,
      8079,
      7,
      30094,
      62,
      16514,
      27823,
      8
    ],
    "start_token": 467,
    "end_token": 488,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      8554,
      1429,
      4522,
      357,
      47,
      2389,
      8,
      284,
      2251,
      3748,
      2604,
      2393,
      3891,
      13
    ],
    "label": "ml_signal",
    "reason": "Using process ID (PID) to create unique log file names."
  },
  {
    "line": 111,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Extracting code from the file path, indicating file naming conventions.",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 488,
    "end_token": 488,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      29677,
      278,
      2438,
      422,
      262,
      2393,
      3108,
      11,
      12739,
      2393,
      19264,
      21396,
      13
    ],
    "label": "ml_signal",
    "reason": "Extracting code from the file path, indicating file naming conventions."
  },
  {
    "line": 113,
    "text": "        ## extract ab1~ab50",
    "annotation": "\u26a0\ufe0f SAST Risk (Medium): 'ARCTIC_SRV' is used without being defined or imported, leading to potential NameError.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      22492,
      7925,
      450,
      16,
      93,
      397,
      1120
    ],
    "start_token": 488,
    "end_token": 502,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      31205,
      2599,
      705,
      1503,
      4177,
      2149,
      62,
      12562,
      53,
      6,
      318,
      973,
      1231,
      852,
      5447,
      393,
      17392,
      11,
      3756,
      284,
      2785,
      6530,
      12331,
      13
    ],
    "label": "sast_risk",
    "severity": "Medium",
    "reason": "'ARCTIC_SRV' is used without being defined or imported, leading to potential NameError."
  },
  {
    "line": 116,
    "text": "            for timestamp, row in df.iterrows()",
    "annotation": "\u2705 Best Practice: Logging every 100th index for progress tracking.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      329,
      41033,
      11,
      5752,
      287,
      47764,
      13,
      2676,
      8516,
      3419
    ],
    "start_token": 502,
    "end_token": 523,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5972,
      2667,
      790,
      1802,
      400,
      6376,
      329,
      4371,
      9646,
      13
    ],
    "label": "best_practice",
    "reason": "Logging every 100th index for progress tracking."
  },
  {
    "line": 118,
    "text": "        df = df.drop(columns=[\"ab\" + str(i) for i in range(1, 51)])",
    "annotation": "\ud83e\udde0 ML Signal: Function call pattern with specific parameters.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      47764,
      796,
      47764,
      13,
      14781,
      7,
      28665,
      82,
      28,
      14692,
      397,
      1,
      1343,
      965,
      7,
      72,
      8,
      329,
      1312,
      287,
      2837,
      7,
      16,
      11,
      6885,
      8,
      12962
    ],
    "start_token": 523,
    "end_token": 557,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      15553,
      869,
      3912,
      351,
      2176,
      10007,
      13
    ],
    "label": "ml_signal",
    "reason": "Function call pattern with specific parameters."
  },
  {
    "line": 121,
    "text": "    # arc.initialize_library(type, lib_type=CHUNK_STORE)",
    "annotation": "\u2705 Best Practice: Checking for non-empty error list before proceeding.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      1303,
      10389,
      13,
      36733,
      1096,
      62,
      32016,
      7,
      4906,
      11,
      9195,
      62,
      4906,
      28,
      3398,
      4944,
      42,
      62,
      2257,
      6965,
      8
    ],
    "start_token": 557,
    "end_token": 581,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      39432,
      329,
      1729,
      12,
      28920,
      4049,
      1351,
      878,
      18788,
      13
    ],
    "label": "best_practice",
    "reason": "Checking for non-empty error list before proceeding."
  },
  {
    "line": 123,
    "text": "",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Using 'open' without 'with' statement can lead to file descriptor leaks.",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 581,
    "end_token": 581,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      8554,
      705,
      9654,
      6,
      1231,
      705,
      4480,
      6,
      2643,
      460,
      1085,
      284,
      2393,
      43087,
      17316,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Using 'open' without 'with' statement can lead to file descriptor leaks."
  },
  {
    "line": 124,
    "text": "    symbol = \"\".join([exchange_place, code])",
    "annotation": "\ud83e\udde0 ML Signal: Logging error details to a file.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      6194,
      796,
      366,
      1911,
      22179,
      26933,
      1069,
      3803,
      62,
      5372,
      11,
      2438,
      12962
    ],
    "start_token": 581,
    "end_token": 597,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5972,
      2667,
      4049,
      3307,
      284,
      257,
      2393,
      13
    ],
    "label": "ml_signal",
    "reason": "Logging error details to a file."
  },
  {
    "line": 129,
    "text": "        lib.update(symbol, df, chunk_size=\"D\")",
    "annotation": "\ud83e\udde0 ML Signal: Capturing and logging exceptions.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      9195,
      13,
      19119,
      7,
      1837,
      23650,
      11,
      47764,
      11,
      16058,
      62,
      7857,
      2625,
      35,
      4943
    ],
    "start_token": 597,
    "end_token": 619,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      6790,
      870,
      290,
      18931,
      13269,
      13
    ],
    "label": "ml_signal",
    "reason": "Capturing and logging exceptions."
  },
  {
    "line": 132,
    "text": "        lib.write(symbol, df, chunk_size=\"D\")",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Using 'open' without 'with' statement can lead to file descriptor leaks.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      9195,
      13,
      13564,
      7,
      1837,
      23650,
      11,
      47764,
      11,
      16058,
      62,
      7857,
      2625,
      35,
      4943
    ],
    "start_token": 619,
    "end_token": 641,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      8554,
      705,
      9654,
      6,
      1231,
      705,
      4480,
      6,
      2643,
      460,
      1085,
      284,
      2393,
      43087,
      17316,
      13
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Using 'open' without 'with' statement can lead to file descriptor leaks."
  },
  {
    "line": 134,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Logging failure details to a file.",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 641,
    "end_token": 641,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5972,
      2667,
      5287,
      3307,
      284,
      257,
      2393,
      13
    ],
    "label": "ml_signal",
    "reason": "Logging failure details to a file."
  },
  {
    "line": 138,
    "text": "    code = os.path.split(filepath)[-1].split(\".csv\")[0]",
    "annotation": "\ud83e\udde0 ML Signal: Resetting the Arctic connection, indicating resource management.",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      2438,
      796,
      28686,
      13,
      6978,
      13,
      35312,
      7,
      7753,
      6978,
      38381,
      12,
      16,
      4083,
      35312,
      7,
      1911,
      40664,
      4943,
      58,
      15,
      60
    ],
    "start_token": 641,
    "end_token": 666,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      30027,
      889,
      262,
      15723,
      4637,
      11,
      12739,
      8271,
      4542,
      13
    ],
    "label": "ml_signal",
    "reason": "Resetting the Arctic connection, indicating resource management."
  },
  {
    "line": 127,
    "text": "        if df.empty == True:",
    "annotation": "\u26a0\ufe0f SAST Risk (Medium): Missing import statement for 'os', 'time', 'traceback', 'Parallel', 'delayed', 'N_JOBS', 'DOC_TYPE', 'DATABASE_PATH', 'DATA_PATH', 'DATA_INFO_PATH', 'DATA_FINISH_INFO_PATH', 'LOG_FILE_PATH'",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      611,
      47764,
      13,
      28920,
      6624,
      6407,
      25
    ],
    "start_token": 666,
    "end_token": 680,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      31205,
      2599,
      25639,
      1330,
      2643,
      329,
      705,
      418,
      3256,
      705,
      2435,
      3256,
      705,
      40546,
      1891,
      3256,
      705,
      10044,
      29363,
      3256,
      705,
      12381,
      16548,
      3256,
      705,
      45,
      62,
      45006,
      4462,
      3256,
      705,
      38715,
      62,
      25216,
      3256,
      705,
      35,
      1404,
      6242,
      11159,
      62,
      34219,
      3256,
      705,
      26947,
      62,
      34219,
      3256,
      705,
      26947,
      62,
      10778,
      62,
      34219,
      3256,
      705,
      26947,
      62,
      20032,
      18422,
      62,
      10778,
      62,
      34219,
      3256,
      705,
      25294,
      62,
      25664,
      62,
      34219,
      6
    ],
    "label": "sast_risk",
    "severity": "Medium",
    "reason": "Missing import statement for 'os', 'time', 'traceback', 'Parallel', 'delayed', 'N_JOBS', 'DOC_TYPE', 'DATABASE_PATH', 'DATA_PATH', 'DATA_INFO_PATH', 'DATA_FINISH_INFO_PATH', 'LOG_FILE_PATH'"
  },
  {
    "line": 129,
    "text": "        lib.update(symbol, df, chunk_size=\"D\")",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Using os.getpid() can expose process IDs which might be sensitive in some contexts",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      9195,
      13,
      19119,
      7,
      1837,
      23650,
      11,
      47764,
      11,
      16058,
      62,
      7857,
      2625,
      35,
      4943
    ],
    "start_token": 680,
    "end_token": 702,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      8554,
      28686,
      13,
      1136,
      35317,
      3419,
      460,
      15651,
      1429,
      32373,
      543,
      1244,
      307,
      8564,
      287,
      617,
      26307
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Using os.getpid() can expose process IDs which might be sensitive in some contexts"
  },
  {
    "line": 131,
    "text": "        print(\"write {0}, date={1}\".format(symbol, date))",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential for incorrect behavior if DOC_TYPE is not defined or is mutable",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      3601,
      7203,
      13564,
      1391,
      15,
      5512,
      3128,
      34758,
      16,
      92,
      1911,
      18982,
      7,
      1837,
      23650,
      11,
      3128,
      4008
    ],
    "start_token": 702,
    "end_token": 727,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      329,
      11491,
      4069,
      611,
      37760,
      62,
      25216,
      318,
      407,
      5447,
      393,
      318,
      4517,
      540
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential for incorrect behavior if DOC_TYPE is not defined or is mutable"
  },
  {
    "line": 138,
    "text": "    code = os.path.split(filepath)[-1].split(\".csv\")[0]",
    "annotation": "\u26a0\ufe0f SAST Risk (High): Use of os.system() with unsanitized input can lead to command injection vulnerabilities",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      2438,
      796,
      28686,
      13,
      6978,
      13,
      35312,
      7,
      7753,
      6978,
      38381,
      12,
      16,
      4083,
      35312,
      7,
      1911,
      40664,
      4943,
      58,
      15,
      60
    ],
    "start_token": 727,
    "end_token": 752,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      11922,
      2599,
      5765,
      286,
      28686,
      13,
      10057,
      3419,
      351,
      5576,
      272,
      36951,
      5128,
      460,
      1085,
      284,
      3141,
      16954,
      23805
    ],
    "label": "sast_risk",
    "severity": "High",
    "reason": "Use of os.system() with unsanitized input can lead to command injection vulnerabilities"
  },
  {
    "line": 138,
    "text": "    code = os.path.split(filepath)[-1].split(\".csv\")[0]",
    "annotation": "\u26a0\ufe0f SAST Risk (High): Use of os.system() with unsanitized input can lead to command injection vulnerabilities",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      2438,
      796,
      28686,
      13,
      6978,
      13,
      35312,
      7,
      7753,
      6978,
      38381,
      12,
      16,
      4083,
      35312,
      7,
      1911,
      40664,
      4943,
      58,
      15,
      60
    ],
    "start_token": 752,
    "end_token": 777,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      11922,
      2599,
      5765,
      286,
      28686,
      13,
      10057,
      3419,
      351,
      5576,
      272,
      36951,
      5128,
      460,
      1085,
      284,
      3141,
      16954,
      23805
    ],
    "label": "sast_risk",
    "severity": "High",
    "reason": "Use of os.system() with unsanitized input can lead to command injection vulnerabilities"
  },
  {
    "line": 143,
    "text": "        error_index_list = add_one_stock_daily_data(filepath, type, exchange_place, arc, date)",
    "annotation": "\u26a0\ufe0f SAST Risk (High): Use of os.system() with unsanitized input can lead to command injection vulnerabilities",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      4049,
      62,
      9630,
      62,
      4868,
      796,
      751,
      62,
      505,
      62,
      13578,
      62,
      29468,
      62,
      7890,
      7,
      7753,
      6978,
      11,
      2099,
      11,
      5163,
      62,
      5372,
      11,
      10389,
      11,
      3128,
      8
    ],
    "start_token": 777,
    "end_token": 813,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      11922,
      2599,
      5765,
      286,
      28686,
      13,
      10057,
      3419,
      351,
      5576,
      272,
      36951,
      5128,
      460,
      1085,
      284,
      3141,
      16954,
      23805
    ],
    "label": "sast_risk",
    "severity": "High",
    "reason": "Use of os.system() with unsanitized input can lead to command injection vulnerabilities"
  },
  {
    "line": 147,
    "text": "            f.close()",
    "annotation": "\u26a0\ufe0f SAST Risk (High): Use of os.system() with unsanitized input can lead to command injection vulnerabilities",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      277,
      13,
      19836,
      3419
    ],
    "start_token": 813,
    "end_token": 828,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      11922,
      2599,
      5765,
      286,
      28686,
      13,
      10057,
      3419,
      351,
      5576,
      272,
      36951,
      5128,
      460,
      1085,
      284,
      3141,
      16954,
      23805
    ],
    "label": "sast_risk",
    "severity": "High",
    "reason": "Use of os.system() with unsanitized input can lead to command injection vulnerabilities"
  },
  {
    "line": 149,
    "text": "    except Exception as e:",
    "annotation": "\u26a0\ufe0f SAST Risk (High): Use of os.system() with unsanitized input can lead to command injection vulnerabilities",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      2845,
      35528,
      355,
      304,
      25
    ],
    "start_token": 828,
    "end_token": 836,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      11922,
      2599,
      5765,
      286,
      28686,
      13,
      10057,
      3419,
      351,
      5576,
      272,
      36951,
      5128,
      460,
      1085,
      284,
      3141,
      16954,
      23805
    ],
    "label": "sast_risk",
    "severity": "High",
    "reason": "Use of os.system() with unsanitized input can lead to command injection vulnerabilities"
  },
  {
    "line": 151,
    "text": "        print(\"error:\" + str(e))",
    "annotation": "\u26a0\ufe0f SAST Risk (High): Use of os.system() with unsanitized input can lead to command injection vulnerabilities",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      3601,
      7203,
      18224,
      11097,
      1343,
      965,
      7,
      68,
      4008
    ],
    "start_token": 836,
    "end_token": 852,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      11922,
      2599,
      5765,
      286,
      28686,
      13,
      10057,
      3419,
      351,
      5576,
      272,
      36951,
      5128,
      460,
      1085,
      284,
      3141,
      16954,
      23805
    ],
    "label": "sast_risk",
    "severity": "High",
    "reason": "Use of os.system() with unsanitized input can lead to command injection vulnerabilities"
  },
  {
    "line": 151,
    "text": "        print(\"error:\" + str(e))",
    "annotation": "\u26a0\ufe0f SAST Risk (High): Use of os.system() with unsanitized input can lead to command injection vulnerabilities",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      3601,
      7203,
      18224,
      11097,
      1343,
      965,
      7,
      68,
      4008
    ],
    "start_token": 852,
    "end_token": 868,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      11922,
      2599,
      5765,
      286,
      28686,
      13,
      10057,
      3419,
      351,
      5576,
      272,
      36951,
      5128,
      460,
      1085,
      284,
      3141,
      16954,
      23805
    ],
    "label": "sast_risk",
    "severity": "High",
    "reason": "Use of os.system() with unsanitized input can lead to command injection vulnerabilities"
  },
  {
    "line": 151,
    "text": "        print(\"error:\" + str(e))",
    "annotation": "\u26a0\ufe0f SAST Risk (High): Use of os.system() with unsanitized input can lead to command injection vulnerabilities",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      3601,
      7203,
      18224,
      11097,
      1343,
      965,
      7,
      68,
      4008
    ],
    "start_token": 868,
    "end_token": 884,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      11922,
      2599,
      5765,
      286,
      28686,
      13,
      10057,
      3419,
      351,
      5576,
      272,
      36951,
      5128,
      460,
      1085,
      284,
      3141,
      16954,
      23805
    ],
    "label": "sast_risk",
    "severity": "High",
    "reason": "Use of os.system() with unsanitized input can lead to command injection vulnerabilities"
  },
  {
    "line": 159,
    "text": "",
    "annotation": "\u26a0\ufe0f SAST Risk (High): Use of os.system() with unsanitized input can lead to command injection vulnerabilities",
    "confidence": 1.0,
    "tokens": [],
    "start_token": 884,
    "end_token": 884,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      11922,
      2599,
      5765,
      286,
      28686,
      13,
      10057,
      3419,
      351,
      5576,
      272,
      36951,
      5128,
      460,
      1085,
      284,
      3141,
      16954,
      23805
    ],
    "label": "sast_risk",
    "severity": "High",
    "reason": "Use of os.system() with unsanitized input can lead to command injection vulnerabilities"
  },
  {
    "line": 160,
    "text": "def add_data(tick_date, doc_type, stock_name_dict):",
    "annotation": "\u2705 Best Practice: Use of os.path.exists() to check file existence is a good practice",
    "confidence": 0.5,
    "tokens": [
      4299,
      751,
      62,
      7890,
      7,
      42298,
      62,
      4475,
      11,
      2205,
      62,
      4906,
      11,
      4283,
      62,
      3672,
      62,
      11600,
      2599
    ],
    "start_token": 884,
    "end_token": 903,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      28686,
      13,
      6978,
      13,
      1069,
      1023,
      3419,
      284,
      2198,
      2393,
      6224,
      318,
      257,
      922,
      3357
    ],
    "label": "best_practice",
    "reason": "Use of os.path.exists() to check file existence is a good practice"
  },
  {
    "line": 160,
    "text": "def add_data(tick_date, doc_type, stock_name_dict):",
    "annotation": "\u2705 Best Practice: Use of set operations to find common elements is efficient",
    "confidence": 0.5,
    "tokens": [
      4299,
      751,
      62,
      7890,
      7,
      42298,
      62,
      4475,
      11,
      2205,
      62,
      4906,
      11,
      4283,
      62,
      3672,
      62,
      11600,
      2599
    ],
    "start_token": 903,
    "end_token": 922,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      900,
      4560,
      284,
      1064,
      2219,
      4847,
      318,
      6942
    ],
    "label": "best_practice",
    "reason": "Use of set operations to find common elements is efficient"
  },
  {
    "line": 174,
    "text": "            f\"tar -xvzf {DATA_PATH}/{tick_date + '_{}.tar.gz'.format(doc_type)} -C {DATA_PATH}/ {tick_date + '_' + doc_type}/SZ\"",
    "annotation": "\u2705 Best Practice: Use of set operations to find common elements is efficient",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      277,
      1,
      18870,
      532,
      87,
      85,
      89,
      69,
      1391,
      26947,
      62,
      34219,
      92,
      14,
      90,
      42298,
      62,
      4475,
      1343,
      705,
      23330,
      27422,
      18870,
      13,
      34586,
      4458,
      18982,
      7,
      15390,
      62,
      4906,
      38165,
      532,
      34,
      1391,
      26947,
      62,
      34219,
      92,
      14,
      1391,
      42298,
      62,
      4475,
      1343,
      705,
      62,
      6,
      1343,
      2205,
      62,
      4906,
      92,
      14,
      50,
      57,
      1
    ],
    "start_token": 922,
    "end_token": 990,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      900,
      4560,
      284,
      1064,
      2219,
      4847,
      318,
      6942
    ],
    "label": "best_practice",
    "reason": "Use of set operations to find common elements is efficient"
  },
  {
    "line": 187,
    "text": "        is_files_exist = {\"sh\": os.path.exists(temp_data_path_sh), \"sz\": os.path.exists(temp_data_path_sz)}",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential file path traversal if DATA_INFO_PATH is not properly sanitized",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      318,
      62,
      16624,
      62,
      38476,
      796,
      19779,
      1477,
      1298,
      28686,
      13,
      6978,
      13,
      1069,
      1023,
      7,
      29510,
      62,
      7890,
      62,
      6978,
      62,
      1477,
      828,
      366,
      82,
      89,
      1298,
      28686,
      13,
      6978,
      13,
      1069,
      1023,
      7,
      29510,
      62,
      7890,
      62,
      6978,
      62,
      82,
      89,
      38165
    ],
    "start_token": 990,
    "end_token": 1041,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      2393,
      3108,
      33038,
      282,
      611,
      42865,
      62,
      10778,
      62,
      34219,
      318,
      407,
      6105,
      5336,
      36951
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential file path traversal if DATA_INFO_PATH is not properly sanitized"
  },
  {
    "line": 190,
    "text": "            (",
    "annotation": "\u2705 Best Practice: Use of Parallel processing to improve performance",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      357
    ],
    "start_token": 1041,
    "end_token": 1053,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      42945,
      7587,
      284,
      2987,
      2854
    ],
    "label": "best_practice",
    "reason": "Use of Parallel processing to improve performance"
  },
  {
    "line": 198,
    "text": "        sh_files = (",
    "annotation": "\u2705 Best Practice: Use of Parallel processing to improve performance",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      427,
      62,
      16624,
      796,
      357
    ],
    "start_token": 1053,
    "end_token": 1065,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      42945,
      7587,
      284,
      2987,
      2854
    ],
    "label": "best_practice",
    "reason": "Use of Parallel processing to improve performance"
  },
  {
    "line": 205,
    "text": "        )",
    "annotation": "\u26a0\ufe0f SAST Risk (High): Use of os.system() with unsanitized input can lead to command injection vulnerabilities",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1267
    ],
    "start_token": 1065,
    "end_token": 1073,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      11922,
      2599,
      5765,
      286,
      28686,
      13,
      10057,
      3419,
      351,
      5576,
      272,
      36951,
      5128,
      460,
      1085,
      284,
      3141,
      16954,
      23805
    ],
    "label": "sast_risk",
    "severity": "High",
    "reason": "Use of os.system() with unsanitized input can lead to command injection vulnerabilities"
  },
  {
    "line": 207,
    "text": "        print(\"sz_file_nums:{}, sh_file_nums:{}\".format(sz_file_nums, sh_file_nums))",
    "annotation": "\u26a0\ufe0f SAST Risk (High): Use of os.system() with unsanitized input can lead to command injection vulnerabilities",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      3601,
      7203,
      82,
      89,
      62,
      7753,
      62,
      77,
      5700,
      29164,
      5512,
      427,
      62,
      7753,
      62,
      77,
      5700,
      29164,
      92,
      1911,
      18982,
      7,
      82,
      89,
      62,
      7753,
      62,
      77,
      5700,
      11,
      427,
      62,
      7753,
      62,
      77,
      5700,
      4008
    ],
    "start_token": 1073,
    "end_token": 1117,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      11922,
      2599,
      5765,
      286,
      28686,
      13,
      10057,
      3419,
      351,
      5576,
      272,
      36951,
      5128,
      460,
      1085,
      284,
      3141,
      16954,
      23805
    ],
    "label": "sast_risk",
    "severity": "High",
    "reason": "Use of os.system() with unsanitized input can lead to command injection vulnerabilities"
  },
  {
    "line": 210,
    "text": "        f.write(\"sz:{}, sh:{}, date:{}:\".format(sz_file_nums, sh_file_nums, tick_date) + \"\\n\")",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential file path traversal if DATA_FINISH_INFO_PATH is not properly sanitized",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      277,
      13,
      13564,
      7203,
      82,
      89,
      29164,
      5512,
      427,
      29164,
      5512,
      3128,
      29164,
      38362,
      1911,
      18982,
      7,
      82,
      89,
      62,
      7753,
      62,
      77,
      5700,
      11,
      427,
      62,
      7753,
      62,
      77,
      5700,
      11,
      4378,
      62,
      4475,
      8,
      1343,
      37082,
      77,
      4943
    ],
    "start_token": 1117,
    "end_token": 1164,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      2393,
      3108,
      33038,
      282,
      611,
      42865,
      62,
      20032,
      18422,
      62,
      10778,
      62,
      34219,
      318,
      407,
      6105,
      5336,
      36951
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential file path traversal if DATA_FINISH_INFO_PATH is not properly sanitized"
  },
  {
    "line": 215,
    "text": "            Parallel(n_jobs=N_JOBS)(",
    "annotation": "\u2705 Best Practice: Use of traceback for detailed error information",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      42945,
      7,
      77,
      62,
      43863,
      28,
      45,
      62,
      45006,
      4462,
      5769
    ],
    "start_token": 1164,
    "end_token": 1186,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      12854,
      1891,
      329,
      6496,
      4049,
      1321
    ],
    "label": "best_practice",
    "reason": "Use of traceback for detailed error information"
  },
  {
    "line": 218,
    "text": "                )",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential file path traversal if LOG_FILE_PATH is not properly sanitized",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1267
    ],
    "start_token": 1186,
    "end_token": 1202,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      2393,
      3108,
      33038,
      282,
      611,
      41605,
      62,
      25664,
      62,
      34219,
      318,
      407,
      6105,
      5336,
      36951
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential file path traversal if LOG_FILE_PATH is not properly sanitized"
  },
  {
    "line": 202,
    "text": "            )",
    "annotation": "\ud83e\udde0 ML Signal: Use of MongoClient indicates interaction with a MongoDB database",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1267
    ],
    "start_token": 1202,
    "end_token": 1214,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      42591,
      11792,
      9217,
      10375,
      351,
      257,
      42591,
      11012,
      6831
    ],
    "label": "ml_signal",
    "reason": "Use of MongoClient indicates interaction with a MongoDB database"
  },
  {
    "line": 203,
    "text": "            if is_files_exist[\"sh\"]",
    "annotation": "\u26a0\ufe0f SAST Risk (High): Dropping a database can lead to data loss if not handled properly",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      611,
      318,
      62,
      16624,
      62,
      38476,
      14692,
      1477,
      8973
    ],
    "start_token": 1214,
    "end_token": 1234,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      11922,
      2599,
      21045,
      2105,
      257,
      6831,
      460,
      1085,
      284,
      1366,
      2994,
      611,
      407,
      12118,
      6105
    ],
    "label": "sast_risk",
    "severity": "High",
    "reason": "Dropping a database can lead to data loss if not handled properly"
  },
  {
    "line": 205,
    "text": "        )",
    "annotation": "\u26a0\ufe0f SAST Risk (High): Dropping a database is a destructive operation and should be used with caution",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1267
    ],
    "start_token": 1234,
    "end_token": 1242,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      11922,
      2599,
      21045,
      2105,
      257,
      6831,
      318,
      257,
      17656,
      4905,
      290,
      815,
      307,
      973,
      351,
      13041
    ],
    "label": "sast_risk",
    "severity": "High",
    "reason": "Dropping a database is a destructive operation and should be used with caution"
  },
  {
    "line": 205,
    "text": "        )",
    "annotation": "\ud83e\udde0 ML Signal: Use of Arctic library for data storage",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1267
    ],
    "start_token": 1242,
    "end_token": 1250,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      15723,
      5888,
      329,
      1366,
      6143
    ],
    "label": "ml_signal",
    "reason": "Use of Arctic library for data storage"
  },
  {
    "line": 207,
    "text": "        print(\"sz_file_nums:{}, sh_file_nums:{}\".format(sz_file_nums, sh_file_nums))",
    "annotation": "\ud83e\udde0 ML Signal: Iterating over document types to initialize libraries",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      3601,
      7203,
      82,
      89,
      62,
      7753,
      62,
      77,
      5700,
      29164,
      5512,
      427,
      62,
      7753,
      62,
      77,
      5700,
      29164,
      92,
      1911,
      18982,
      7,
      82,
      89,
      62,
      7753,
      62,
      77,
      5700,
      11,
      427,
      62,
      7753,
      62,
      77,
      5700,
      4008
    ],
    "start_token": 1250,
    "end_token": 1294,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      40806,
      803,
      625,
      3188,
      3858,
      284,
      41216,
      12782
    ],
    "label": "ml_signal",
    "reason": "Iterating over document types to initialize libraries"
  },
  {
    "line": 209,
    "text": "        f = (DATA_INFO_PATH / \"data_info_log_{}_{}\".format(doc_type, tick_date)).open(\"w+\")",
    "annotation": "\ud83e\udde0 ML Signal: Dynamic library name generation based on document type",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      277,
      796,
      357,
      26947,
      62,
      10778,
      62,
      34219,
      1220,
      366,
      7890,
      62,
      10951,
      62,
      6404,
      23330,
      92,
      23330,
      92,
      1911,
      18982,
      7,
      15390,
      62,
      4906,
      11,
      4378,
      62,
      4475,
      29720,
      9654,
      7203,
      86,
      10,
      4943
    ],
    "start_token": 1294,
    "end_token": 1336,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      26977,
      5888,
      1438,
      5270,
      1912,
      319,
      3188,
      2099
    ],
    "label": "ml_signal",
    "reason": "Dynamic library name generation based on document type"
  },
  {
    "line": 210,
    "text": "        f.write(\"sz:{}, sh:{}, date:{}:\".format(sz_file_nums, sh_file_nums, tick_date) + \"\\n\")",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): Potential risk if get_library_name or DOC_TYPE are user-controlled",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      277,
      13,
      13564,
      7203,
      82,
      89,
      29164,
      5512,
      427,
      29164,
      5512,
      3128,
      29164,
      38362,
      1911,
      18982,
      7,
      82,
      89,
      62,
      7753,
      62,
      77,
      5700,
      11,
      427,
      62,
      7753,
      62,
      77,
      5700,
      11,
      4378,
      62,
      4475,
      8,
      1343,
      37082,
      77,
      4943
    ],
    "start_token": 1336,
    "end_token": 1383,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      32480,
      2526,
      611,
      651,
      62,
      32016,
      62,
      3672,
      393,
      37760,
      62,
      25216,
      389,
      2836,
      12,
      14401
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "Potential risk if get_library_name or DOC_TYPE are user-controlled"
  },
  {
    "line": 209,
    "text": "        f = (DATA_INFO_PATH / \"data_info_log_{}_{}\".format(doc_type, tick_date)).open(\"w+\")",
    "annotation": "\ud83e\udde0 ML Signal: Use of Path object for file system operations",
    "confidence": 1.0,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      277,
      796,
      357,
      26947,
      62,
      10778,
      62,
      34219,
      1220,
      366,
      7890,
      62,
      10951,
      62,
      6404,
      23330,
      92,
      23330,
      92,
      1911,
      18982,
      7,
      15390,
      62,
      4906,
      11,
      4378,
      62,
      4475,
      29720,
      9654,
      7203,
      86,
      10,
      4943
    ],
    "start_token": 1383,
    "end_token": 1425,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      10644,
      2134,
      329,
      2393,
      1080,
      4560
    ],
    "label": "ml_signal",
    "reason": "Use of Path object for file system operations"
  },
  {
    "line": 211,
    "text": "        f.close()",
    "annotation": "\u26a0\ufe0f SAST Risk (Medium): Potentially dangerous operation, deletes entire directory tree",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      277,
      13,
      19836,
      3419
    ],
    "start_token": 1425,
    "end_token": 1436,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      31205,
      2599,
      6902,
      3746,
      4923,
      4905,
      11,
      28128,
      274,
      2104,
      8619,
      5509
    ],
    "label": "sast_risk",
    "severity": "Medium",
    "reason": "Potentially dangerous operation, deletes entire directory tree"
  },
  {
    "line": 214,
    "text": "            # write is not thread-safe, update may be thread-safe",
    "annotation": "\u2705 Best Practice: Use of mkdir with parents=True and exist_ok=True for safe directory creation",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1303,
      3551,
      318,
      407,
      4704,
      12,
      21230,
      11,
      4296,
      743,
      307,
      4704,
      12,
      21230
    ],
    "start_token": 1436,
    "end_token": 1461,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      33480,
      15908,
      351,
      3397,
      28,
      17821,
      290,
      2152,
      62,
      482,
      28,
      17821,
      329,
      3338,
      8619,
      6282
    ],
    "label": "best_practice",
    "reason": "Use of mkdir with parents=True and exist_ok=True for safe directory creation"
  },
  {
    "line": 214,
    "text": "            # write is not thread-safe, update may be thread-safe",
    "annotation": "\u2705 Best Practice: Use of list comprehension for filtering and transforming lists",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1303,
      3551,
      318,
      407,
      4704,
      12,
      21230,
      11,
      4296,
      743,
      307,
      4704,
      12,
      21230
    ],
    "start_token": 1461,
    "end_token": 1486,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      1351,
      35915,
      329,
      25431,
      290,
      25449,
      8341
    ],
    "label": "best_practice",
    "reason": "Use of list comprehension for filtering and transforming lists"
  },
  {
    "line": 217,
    "text": "                    os.path.join(temp_data_path_sh, name + \".csv\"), doc_type, \"SH\", index, tick_date",
    "annotation": "\ud83e\udde0 ML Signal: Usage of external library Arctic",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      28686,
      13,
      6978,
      13,
      22179,
      7,
      29510,
      62,
      7890,
      62,
      6978,
      62,
      1477,
      11,
      1438,
      1343,
      27071,
      40664,
      12340,
      2205,
      62,
      4906,
      11,
      366,
      9693,
      1600,
      6376,
      11,
      4378,
      62,
      4475
    ],
    "start_token": 1486,
    "end_token": 1536,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      29566,
      286,
      7097,
      5888,
      15723
    ],
    "label": "ml_signal",
    "reason": "Usage of external library Arctic"
  },
  {
    "line": 220,
    "text": "            )",
    "annotation": "\ud83e\udde0 ML Signal: Setting quotas for resources",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1267
    ],
    "start_token": 1536,
    "end_token": 1548,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      25700,
      38736,
      329,
      4133
    ],
    "label": "ml_signal",
    "reason": "Setting quotas for resources"
  },
  {
    "line": 222,
    "text": "            # write is not thread-safe, update may be thread-safe",
    "annotation": "\ud83e\udde0 ML Signal: Resetting state of an external resource",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      1303,
      3551,
      318,
      407,
      4704,
      12,
      21230,
      11,
      4296,
      743,
      307,
      4704,
      12,
      21230
    ],
    "start_token": 1548,
    "end_token": 1573,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      30027,
      889,
      1181,
      286,
      281,
      7097,
      8271
    ],
    "label": "ml_signal",
    "reason": "Resetting state of an external resource"
  },
  {
    "line": 225,
    "text": "                    os.path.join(temp_data_path_sz, name + \".csv\"), doc_type, \"SZ\", index, tick_date",
    "annotation": "\u2705 Best Practice: Use of set to remove duplicates",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      28686,
      13,
      6978,
      13,
      22179,
      7,
      29510,
      62,
      7890,
      62,
      6978,
      62,
      82,
      89,
      11,
      1438,
      1343,
      27071,
      40664,
      12340,
      2205,
      62,
      4906,
      11,
      366,
      50,
      57,
      1600,
      6376,
      11,
      4378,
      62,
      4475
    ],
    "start_token": 1573,
    "end_token": 1625,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      900,
      284,
      4781,
      14184,
      16856
    ],
    "label": "best_practice",
    "reason": "Use of set to remove duplicates"
  },
  {
    "line": 227,
    "text": "                for index, name in enumerate(list(sz_files))",
    "annotation": "\u2705 Best Practice: Converting integers to strings in a list",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      329,
      6376,
      11,
      1438,
      287,
      27056,
      378,
      7,
      4868,
      7,
      82,
      89,
      62,
      16624,
      4008
    ],
    "start_token": 1625,
    "end_token": 1655,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      35602,
      889,
      37014,
      284,
      13042,
      287,
      257,
      1351
    ],
    "label": "best_practice",
    "reason": "Converting integers to strings in a list"
  },
  {
    "line": 231,
    "text": "        os.system(f\"rm -rf {DATA_PATH}/{tick_date + '_' + doc_type}\")",
    "annotation": "\u26a0\ufe0f SAST Risk (Low): File not closed using a context manager",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      28686,
      13,
      10057,
      7,
      69,
      1,
      26224,
      532,
      41871,
      1391,
      26947,
      62,
      34219,
      92,
      14,
      90,
      42298,
      62,
      4475,
      1343,
      705,
      62,
      6,
      1343,
      2205,
      62,
      4906,
      92,
      4943
    ],
    "start_token": 1655,
    "end_token": 1691,
    "annotation_tokens": [
      158,
      248,
      254,
      37929,
      311,
      11262,
      19602,
      357,
      20535,
      2599,
      9220,
      407,
      4838,
      1262,
      257,
      4732,
      4706
    ],
    "label": "sast_risk",
    "severity": "Low",
    "reason": "File not closed using a context manager"
  },
  {
    "line": 232,
    "text": "        total_time = time.time() - begin_time",
    "annotation": "\u2705 Best Practice: Use of list comprehension for processing file lines",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      2472,
      62,
      2435,
      796,
      640,
      13,
      2435,
      3419,
      532,
      2221,
      62,
      2435
    ],
    "start_token": 1691,
    "end_token": 1710,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      1351,
      35915,
      329,
      7587,
      2393,
      3951
    ],
    "label": "best_practice",
    "reason": "Use of list comprehension for processing file lines"
  },
  {
    "line": 235,
    "text": "        f.close()",
    "annotation": "\u2705 Best Practice: Dictionary comprehension for better readability",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      277,
      13,
      19836,
      3419
    ],
    "start_token": 1710,
    "end_token": 1721,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      28261,
      35915,
      329,
      1365,
      1100,
      1799
    ],
    "label": "best_practice",
    "reason": "Dictionary comprehension for better readability"
  },
  {
    "line": 241,
    "text": "        f.write(\"fail:\" + str(tick_date) + \"\\n\" + str(e) + \"\\n\" + str(info) + \"\\n\")",
    "annotation": "\ud83e\udde0 ML Signal: Repeated initialization of Arctic object",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      277,
      13,
      13564,
      7203,
      32165,
      11097,
      1343,
      965,
      7,
      42298,
      62,
      4475,
      8,
      1343,
      37082,
      77,
      1,
      1343,
      965,
      7,
      68,
      8,
      1343,
      37082,
      77,
      1,
      1343,
      965,
      7,
      10951,
      8,
      1343,
      37082,
      77,
      4943
    ],
    "start_token": 1721,
    "end_token": 1763,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      30558,
      515,
      37588,
      286,
      15723,
      2134
    ],
    "label": "ml_signal",
    "reason": "Repeated initialization of Arctic object"
  },
  {
    "line": 243,
    "text": "",
    "annotation": "\ud83e\udde0 ML Signal: Checking for existing symbols in a library",
    "confidence": 0.5,
    "tokens": [],
    "start_token": 1763,
    "end_token": 1763,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      39432,
      329,
      4683,
      14354,
      287,
      257,
      5888
    ],
    "label": "ml_signal",
    "reason": "Checking for existing symbols in a library"
  },
  {
    "line": 250,
    "text": "        client.drop_database(\"arctic\")",
    "annotation": "\u2705 Best Practice: Use of pandas DataFrame for data handling",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      5456,
      13,
      14781,
      62,
      48806,
      7203,
      283,
      11048,
      4943
    ],
    "start_token": 1763,
    "end_token": 1779,
    "annotation_tokens": [
      26486,
      227,
      6705,
      19939,
      25,
      5765,
      286,
      19798,
      292,
      6060,
      19778,
      329,
      1366,
      9041
    ],
    "label": "best_practice",
    "reason": "Use of pandas DataFrame for data handling"
  },
  {
    "line": 250,
    "text": "        client.drop_database(\"arctic\")",
    "annotation": "\ud83e\udde0 ML Signal: Writing data to a library",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      5456,
      13,
      14781,
      62,
      48806,
      7203,
      283,
      11048,
      4943
    ],
    "start_token": 1779,
    "end_token": 1795,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      22183,
      1366,
      284,
      257,
      5888
    ],
    "label": "ml_signal",
    "reason": "Writing data to a library"
  },
  {
    "line": 250,
    "text": "        client.drop_database(\"arctic\")",
    "annotation": "\ud83e\udde0 ML Signal: Resetting state of an external resource",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      5456,
      13,
      14781,
      62,
      48806,
      7203,
      283,
      11048,
      4943
    ],
    "start_token": 1795,
    "end_token": 1811,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      30027,
      889,
      1181,
      286,
      281,
      7097,
      8271
    ],
    "label": "ml_signal",
    "reason": "Resetting state of an external resource"
  },
  {
    "line": 250,
    "text": "        client.drop_database(\"arctic\")",
    "annotation": "\ud83e\udde0 ML Signal: Use of parallel processing",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      5456,
      13,
      14781,
      62,
      48806,
      7203,
      283,
      11048,
      4943
    ],
    "start_token": 1811,
    "end_token": 1827,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      10730,
      7587
    ],
    "label": "ml_signal",
    "reason": "Use of parallel processing"
  },
  {
    "line": 250,
    "text": "        client.drop_database(\"arctic\")",
    "annotation": "\ud83e\udde0 ML Signal: Use of fire library for command-line interface",
    "confidence": 0.5,
    "tokens": [
      220,
      220,
      220,
      220,
      220,
      220,
      220,
      5456,
      13,
      14781,
      62,
      48806,
      7203,
      283,
      11048,
      4943
    ],
    "start_token": 1827,
    "end_token": 1843,
    "annotation_tokens": [
      8582,
      100,
      254,
      10373,
      26484,
      25,
      5765,
      286,
      2046,
      5888,
      329,
      3141,
      12,
      1370,
      7071
    ],
    "label": "ml_signal",
    "reason": "Use of fire library for command-line interface"
  }
]