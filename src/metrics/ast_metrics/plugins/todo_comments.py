# File: code_analyser/src/metrics/ast_metrics/plugins/todo_comments.py

import ast
import re
from .base import ASTMetricPlugin  # âœ… required import


# ðŸ§  ML Signal: TODO/FIXME comments are predictive of incomplete or transitional code states
# âš ï¸ SAST Risk: Leftover TODOs or FIXMEs can indicate unresolved logic, vulnerabilities, or known defects
# âœ… Best Practice: Include metadata and scoring to enable AI overlays and dashboard filtering
class TodoCommentPlugin(ASTMetricPlugin):
    """
    Counts the number of TODO or FIXME comments in the source code.

    Only lines that begin with '#' are considered, case-insensitively.
    """

    # âœ… Best Practice: Unique identifier for discovery and registration
    plugin_name = "todo_comments"

    # âœ… Best Practice: Tags useful for quality and tracking of unresolved code
    plugin_tags = ["comments", "incomplete", "quality", "reminder", "sast"]

    def name(self) -> str:
        return self.plugin_name

    def visit(self, tree: ast.AST, code: str) -> int:
        # âœ… Best Practice: Scan for comment lines with TODO/FIXME using regex
        return sum(
            1
            for line in code.splitlines()
            if line.strip().startswith("#")
            and re.search(r"\b(?:TODO|FIXME)\b", line, re.IGNORECASE)
        )

    def severity_level(self, tree: ast.AST, code: str) -> str:
        # âœ… Best Practice: High severity if many unresolved TODOs are found
        count = self.visit(tree, code)
        if count == 0:
            return "low"
        elif count <= 3:
            return "medium"
        else:
            return "high"

    def confidence_score(self, tree: ast.AST, code: str) -> float:
        # âœ… Best Practice: Simple linear scaling based on number of matches
        count = self.visit(tree, code)
        return min(1.0, 0.25 * count)  # Max confidence at 4+
